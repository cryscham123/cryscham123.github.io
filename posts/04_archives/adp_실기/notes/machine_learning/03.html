<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="ko" xml:lang="ko"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>분류 - 산탄데르 고객 만족 예측 – 김형훈의 학습 블로그</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../../site_libs/quarto-nav/headroom.min.js"></script>
<link href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/04.html" rel="next">
<link href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/02.html" rel="prev">
<link href="../../../../../favicon" rel="icon">
<script src="../../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "일치 없음",
    "search-matching-documents-text": "일치된 문서",
    "search-copy-link-title": "검색 링크 복사",
    "search-hide-matches-text": "추가 검색 결과 숨기기",
    "search-more-match-text": "추가 검색결과",
    "search-more-matches-text": "추가 검색결과",
    "search-clear-button-title": "제거",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "취소",
    "search-submit-button-title": "검색",
    "search-label": "검색"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-GRXCD70RKK"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
 
  gtag('consent', 'default', {
    'ad_storage': 'denied',
    'analytics_storage': 'denied'
  });
gtag('config', 'G-GRXCD70RKK', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdn.jsdelivr.net/npm/@mariusbongarts/previewbox/dist/link/index.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../../../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../../index.html">
    <span class="navbar-title">김형훈의 학습 블로그</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="탐색 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../index.html"> 
<span class="menu-text">PARA</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../all.html"> 
<span class="menu-text">전체 게시글</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="사이드바 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../../../posts/04_archives/tofel_준비/index.html">Archives</a></li><li class="breadcrumb-item"><a href="../../../../../posts/04_archives/adp_실기/index.html">ADP 실기 준비 - try 1</a></li><li class="breadcrumb-item"><a href="../../../../../posts/04_archives/adp_실기/notes/00.pdf">Notes</a></li><li class="breadcrumb-item"><a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/00.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/03.html">분류 - 산탄데르 고객 만족 예측</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="사이드바 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Inboxes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/00_inboxes/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">인간 관계론 - 데일 카네기</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/00_inboxes/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">다중 공산성</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Projects</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/01_projects/bs_3_2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">학부 3학년 2학기</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Cte</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/cte/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Before</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/cte/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">After</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">공급사슬관리</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/공급사슬관리/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/공급사슬관리/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SCM 의사결정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/공급사슬관리/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">수요 관리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/공급사슬관리/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">S&amp;OP: Sales and Operations Planning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/공급사슬관리/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TFC 게임 개요</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/공급사슬관리/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">재고 관리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/공급사슬관리/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">재고 관리 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/공급사슬관리/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">채찍 효과</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">기공수</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/기공수/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">무한 급수</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/기공수/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">테일러 급수</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">시뮬레이션</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/시뮬레이션/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">신재생에너지</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/신재생에너지/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">개인 발표 - 공짜 탄소배출권 발급 사건</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false">
 <span class="menu-text">품질경영</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/품질경영/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">품질관리의 기본개념</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/품질경영/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">품질변동과 공정능력</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/품질경영/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">관리도</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">프로세스경영</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/프로세스경영/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">프로세스 경영 개요</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/프로세스경영/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BPM 개요</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/프로세스경영/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">프로세스 경영 구축 방법론</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/프로세스경영/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BPM 표준</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/프로세스경영/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BPMN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/프로세스경영/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">프로세스 모델링 표준: WS-BPEL</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/bs_3_2/notes/프로세스경영/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DMN</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/01_projects/진로준비/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">진로 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false">
 <span class="menu-text">금융</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/진로준비/notes/금융/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">관심 분야 JD</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="false">
 <span class="menu-text">대학원</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-16" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/진로준비/notes/대학원/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">관심 분야 JD</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/진로준비/notes/대학원/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">연구실</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/진로준비/notes/대학원/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">대학원 준비</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/01_projects/진로준비/notes/대학원/03.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">자기소개서</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false">
 <span class="menu-text">Areas</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-17" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/02_areas/deep_learning/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-18" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-19" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/deep_learning/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">퍼셉트론</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/deep_learning/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">신경망</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/deep_learning/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">신경망 학습</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/deep_learning/notes/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">오차역전법</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/deep_learning/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">학습 관련 기술들</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/deep_learning/notes/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">합성곱 신경망</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/deep_learning/notes/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">자연어와 단어의 분산 표현</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/deep_learning/notes/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">word2vec</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/02_areas/42_seoul/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">42 Seoul</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-20" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-20" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-21" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-21" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-21" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/42_seoul/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ft_transcendence - github action</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/42_seoul/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">inception-of-things part 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/42_seoul/notes/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">cloud-1 개념 설명</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/42_seoul/notes/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">cloud-1 코드 설명</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/02_areas/kaggle/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Kaggle</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-22" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-22" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-23" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-23" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-23" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-24" role="navigation" aria-expanded="false">
 <span class="menu-text">Titanic</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-24" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-24" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/kaggle/notes/titanic/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">titanic</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/02_areas/machine_learning/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-25" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-25" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-26" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-26" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-26" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">data preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simple Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Polynorminal Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Tree Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">random forest</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">K Nearest Neighbors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machine</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Naive Bayes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Tree Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random Forest</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">k-means clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">hierarchical clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Apriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/17.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Eclat</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/machine_learning/notes/18.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Upper Confidence Bound</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/02_areas/ros/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ROS</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-27" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-27" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-28" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-28" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-28" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/02_areas/ros/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-29" role="navigation" aria-expanded="false">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-29" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-29" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/problem_solve/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Problem Solving</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/03_resources/blog/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blog</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-30" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-30" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-31" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-31" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-31" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/blog/notes/0.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PARA Blog 제작</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/blog/notes/1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Second Brain - 티아고 포르테</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/03_resources/hadoop/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hadoop</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-32" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-32" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-33" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-33" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-33" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/hadoop/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hadoop Ecosystem</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/03_resources/선형대수/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">선형대수</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-34" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-34" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-35" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-35" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-35" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">what is linear algebra</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2-기초(1)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2-기초(2)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3-몰라</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">벡터와 공간</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">선형결합과 생성</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">linear independence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Subspaces and the basis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">vector dot product, cross product</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">가감법으로 연립방정식을 풀기 위한 행렬</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Null space and Column space</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">linear transformations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">역함수와 역변환</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/선형대수/notes/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">전치행렬</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/03_resources/인생/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">인생</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-36" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-36" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-37" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-37" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-37" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/인생/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">나의 단점에 관한 고찰</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/03_resources/helm/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Helm</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-38" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-38" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-39" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-39" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-39" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/helm/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">개요</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/03_resources/terraform/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Terraform</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-40" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-40" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-41" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-41" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-41" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-42" role="navigation" aria-expanded="false">
 <span class="menu-text">Tfc</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-42" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-42" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/terraform/notes/tfc/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Terraform Cloud</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/03_resources/air_flow/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AirFlow</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-43" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-43" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-44" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-44" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-44" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/air_flow/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/air_flow/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding pipeline</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/03_resources/smart_contract/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Smart Contract</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-45" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-45" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-46" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-46" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-46" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-47" role="navigation" aria-expanded="false">
 <span class="menu-text">Block Chain Basic</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-47" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-47" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/smart_contract/notes/block_chain_basic/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">what is a blockchain?</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/03_resources/금융/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">금융</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-48" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-48" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-49" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-49" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-49" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/금융/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">돈의 심리학 - 모건 하우절</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/03_resources/quantum_programming/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantum Programming</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-50" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-50" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-51" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-51" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-51" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/quantum_programming/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantum Programming</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/03_resources/quantum_programming/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Qiskit</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-52" role="navigation" aria-expanded="true">
 <span class="menu-text">Archives</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-52" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-52" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/tofel_준비/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TOFEL 준비</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/04_archives/sqld/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SQLD 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-53" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-53" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-54" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-54" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-54" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/sqld/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">데이터 모델의 이해</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/sqld/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SQL 기본 및 활용</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/04_archives/adp_필기/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ADP 필기 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-55" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-55" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-56" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-56" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-56" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 - 데이터 이해</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 - 데이터의 가치와 미래</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 - 가치 창조를 위한 데이터 사이언스와 전략 인사이트</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 - 데이터 처리 프로세스</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 - 데이터 처리 기술</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 - 데이터 분석 기획의 이해</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 - 분석 마스터 플랜</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - 데이터 마트</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - 통계분석</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - 정형 데이터 마이닝</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - 비정형 데이터 마이닝</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5 - 시각화 인사이트 프로세스</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5 - 시각화 디자인</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">시험을 보고 왔습니다.</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_필기/notes/16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">안녕하세요. 데이터 분석 전문가(진)입니다.</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/04_archives/vault/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">vault</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-57" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-57" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-58" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-58" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-58" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/vault/notes/0_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/04_archives/opic/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OPIc 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-59" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-59" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-60" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-60" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-60" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/opic/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">오픽 구조 파악</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/opic/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">설문 script 정리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/opic/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tips</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/opic/notes/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">일정 정리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/opic/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">돌발 script 정리</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/04_archives/toeic/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Toeic 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-61" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-61" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-62" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-62" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-62" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/toeic/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Toeic 문법</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/04_archives/k8s/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">k8s</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-63" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-63" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-64" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-64" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-64" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/k8s/notes/0_core_concept.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">k8s cluster architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/k8s/notes/1_scheduler.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">manual scheduling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/k8s/notes/2_logging_monitoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">metrics server</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/k8s/notes/3_cluster_maintainance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">fail tolerance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/k8s/notes/4_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Authentication</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/k8s/notes/5_storage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Persistant volume</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/k8s/notes/6_network.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">core DNS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/k8s/notes/7_design_cluster.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">HA in master node</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/04_archives/bs_3_1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">학부 3학년 1학기</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-65" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-65" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-66" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-66" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-66" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3학년 1학기 후기</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-67" role="navigation" aria-expanded="false">
 <span class="menu-text">Computer</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-67" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-67" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/computer/01.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">컴퓨팅적 사고 1차 발표 구현 raw script</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/computer/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">컴퓨팅적사고 발표 ppt</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-68" role="navigation" aria-expanded="false">
 <span class="menu-text">Data Mining</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-68" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-68" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">데이터 전처리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분류</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">random forest</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support vector machine</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">association rule mining</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ensemble</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">XGBoost</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/11.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">데이터마이닝 1차 팀과제 script</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dataminig 1차 발표 ppt</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">classification with trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/data_mining/16.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">청소년기의 심리·정서적 요인을 통한 성인 진입기 진로 안정형·탐색형 성향 분류 예측</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-69" role="navigation" aria-expanded="false">
 <span class="menu-text">Dsa</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-69" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-69" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/dsa/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">시험 범위</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/dsa/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">시험 범위</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-70" role="navigation" aria-expanded="false">
 <span class="menu-text">OR</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-70" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-70" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simplex 표 계산</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear Programming Algorithm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simplex Method (part 5)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">쌍대이론과 민감도 분석 (part 6)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/06.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OR 과제 - 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/07.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OR 과제 - 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/08.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OR 과제 - 3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/09.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OR 과제 - 4</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">선형계획을 위한 다른 알고리즘들</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">수송문제와 할당 문제들</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/12.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OR 과제 - 6</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">시험 범위</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">수송문제와 할당 문제들</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/OR/16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">네트워크 최적화 모형</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-71" role="navigation" aria-expanded="false">
 <span class="menu-text">Others</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-71" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-71" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/others/1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">자기 소개서</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/others/2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">성적 장학금</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/others/3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">봉사</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-72" role="navigation" aria-expanded="false">
 <span class="menu-text">Product</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-72" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-72" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Matching Supply with Demand</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">조직을 프로세스 관점에서 바라보기</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">공급 프로세스의 이해: 프로세스 처리능력 평가</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">제품 설계 기법 및 기업 프로세스 유형</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">인건비 추정과 감축</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">배치 생산 및 경제적 주문량 모형</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">프로세스 성과에 미치는 변동성의 영향: 대기시간 문제</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">프로세스 성과에 미치는 변동성의 영향: 산술 손실</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">프로젝트 관리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">예측</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">총괄생산계획</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">기준생산계획 및 자재소요계획</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/product/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">일정 계획</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-73" role="navigation" aria-expanded="false">
 <span class="menu-text">Statistics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-73" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-73" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/statistics/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률과 통계 1 정리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/statistics/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">통계적 추정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/statistics/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">통계적 가설검정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/statistics/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ANOVA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/statistics/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regression Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/statistics/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analysis of categorical data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_3_1/notes/statistics/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률과 통계 R 실습 과제</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/04_archives/adp_실기/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ADP 실기 준비 - try 1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-74" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-74" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-75" role="navigation" aria-expanded="true">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-75" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-75" class="collapse list-unstyled sidebar-section depth3 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/00.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ADP 정리 노트</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">모델링, 평가 템플릿</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA 템플릿</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">전처리 템플릿</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">회귀분석 템플릿</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분산 분석 템플릿</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">비지도 학습 템플릿</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">시계열 분석</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">기타</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률과 통계</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">try 1 후기</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-76" role="navigation" aria-expanded="false">
 <span class="menu-text">Bayse</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-76" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-76" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">베이즈 정리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">비율 추정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">수량 추정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">공산과 가산</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">최솟값, 최댓값 그리고 혼합 분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">포아송 과정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">의사결정분석</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">검정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">비교</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분류</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">로지스틱 회귀</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">회귀</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/17.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">켤레사전분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/bayse/18.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">MCMC</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-77" role="navigation" aria-expanded="false">
 <span class="menu-text">Core</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-77" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-77" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/core/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/core/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">전처리</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-78" role="navigation" aria-expanded="false">
 <span class="menu-text">Etc</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-78" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-78" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/etc/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">다차원 척도법 (Multidimensional Scaling)</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-79" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-79" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-79" class="collapse list-unstyled sidebar-section depth4 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Titanic</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분류 - 결정 트리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분류 - 앙상블</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/03.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">분류 - 산탄데르 고객 만족 예측</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분류 - 신용 카드 사기 검출</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">회귀</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">차원 축소</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">텍스트 분석</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">텍스트 분석 - 20 뉴스그룹 분류</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">텍스트 분석 - 감성 분석</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-80" role="navigation" aria-expanded="false">
 <span class="menu-text">Nonparametric</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-80" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-80" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/Nonparametric/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">intro</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/Nonparametric/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">순열검정과 전통적인 비모수통계</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/Nonparametric/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">두 변수의 연관성과 독립성</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-81" role="navigation" aria-expanded="false">
 <span class="menu-text">Statistics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-81" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-81" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/statistics/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-82" role="navigation" aria-expanded="false">
 <span class="menu-text">Time Series</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-82" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-82" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/time_series/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/time_series/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">단순 미래 예측</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/time_series/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률보행</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/time_series/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">이동평균과정 모델링</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/time_series/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">자기귀모형</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/time_series/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">복잡한 시계열 모델</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/time_series/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">계절성 고려</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/adp_실기/notes/time_series/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">외생 변수 추가하기</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/04_archives/aws_saa/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AWS SAA 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-83" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-83" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-84" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-84" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-84" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/00_region.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">aws global infrastructure</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/01_IAM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Define IAM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/02_ec2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">what is EC2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/03_ebs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">what is ebs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/04_elb_asg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ELB</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Amazon RDS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/06_route53.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Route53</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/07_S3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AWS S3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/08_cloudfront.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CloudFront</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/09_aws_storage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AWS Snow Family</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/10_message_queue.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AWS SQS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/11_serverless.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AWS Lambda</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/12_database.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">database choice in aws</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/13_data_analytics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Performance Improvement</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/14_machine_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Amazon Rekognition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/15_monitoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Amazon CloudWatch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/16_IAM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AWS Organization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/17_AWS_secure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KMS(Key Management Service)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/18_VPC.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">VPC</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/aws_saa/notes/19_DR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Disaster Recovery(DR)</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/04_archives/bs_2_2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2학년 2학기 학부 정리</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-85" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-85" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-86" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-86" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-86" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-87" role="navigation" aria-expanded="false">
 <span class="menu-text">Bs Database</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-87" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-87" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_database/01-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">An Overview of Database</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_database/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Relational Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_database/04-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Database Normalization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_database/04-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SQL</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_database/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Modeling and the Entity-Relationship Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_database/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Database Design</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_database/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Database Administration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_database/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ASP.NET</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_database/work1.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">데이터베이스설계및활용 개인과제 #2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_database/work2.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4조 기말과제 제안서</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_database/work4.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">숭실대학교 학생식당 식자제 SCM 설계</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-88" role="navigation" aria-expanded="false">
 <span class="menu-text">Bs Human</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-88" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-88" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_human/0_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Human Factors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_human/1_reaserch_method.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Research Method in Human Factors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_human/2_human_information_processing_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Human Information Processing Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sensor System (Visual)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Auditory Haptic</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Signal Detection Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_human/6_attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Attention</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_human/7_display.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Display</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_human/8_control.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Control</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_human/인간공학-보고서-초안.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">맥도날드 키오스크 UI 개선 보고서</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-89" role="navigation" aria-expanded="false">
 <span class="menu-text">Bs Statistics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-89" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-89" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률과 통계의 정의</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률변수와 확률분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_statistics/3-확률변수의-기댓값.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률변수의 기댓값</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">이산형 확률분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">연속형 확률분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_statistics/6-정규분포.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">정규 분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">표본의 분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/bs_2_2/notes/bs_statistics/8-central-limit-theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">중심 극한 정리</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../posts/04_archives/toeic_speaking/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">토익 스피킹 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-90" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-90" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-91" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-91" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-91" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../posts/04_archives/toeic_speaking/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">토익 스피킹 후기</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of Contents</h2>
   
  <ul>
  <li><a href="#preprocessing" id="toc-preprocessing" class="nav-link active" data-scroll-target="#preprocessing">Preprocessing</a></li>
  <li><a href="#xgboost" id="toc-xgboost" class="nav-link" data-scroll-target="#xgboost">XGBoost</a>
  <ul class="collapse">
  <li><a href="#베이지안-최적화" id="toc-베이지안-최적화" class="nav-link" data-scroll-target="#베이지안-최적화">베이지안 최적화</a></li>
  <li><a href="#재-학습" id="toc-재-학습" class="nav-link" data-scroll-target="#재-학습">재 학습</a></li>
  <li><a href="#plot-importance" id="toc-plot-importance" class="nav-link" data-scroll-target="#plot-importance">plot importance</a></li>
  </ul></li>
  <li><a href="#lightgbm" id="toc-lightgbm" class="nav-link" data-scroll-target="#lightgbm">LightGBM</a>
  <ul class="collapse">
  <li><a href="#베이지안-최적화-1" id="toc-베이지안-최적화-1" class="nav-link" data-scroll-target="#베이지안-최적화-1">베이지안 최적화</a></li>
  <li><a href="#재학습" id="toc-재학습" class="nav-link" data-scroll-target="#재학습">재학습</a></li>
  </ul></li>
  <li><a href="#제출" id="toc-제출" class="nav-link" data-scroll-target="#제출">제출</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../../../posts/04_archives/tofel_준비/index.html">Archives</a></li><li class="breadcrumb-item"><a href="../../../../../posts/04_archives/adp_실기/index.html">ADP 실기 준비 - try 1</a></li><li class="breadcrumb-item"><a href="../../../../../posts/04_archives/adp_실기/notes/00.pdf">Notes</a></li><li class="breadcrumb-item"><a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/00.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/03.html">분류 - 산탄데르 고객 만족 예측</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">분류 - 산탄데르 고객 만족 예측</h1>
  <div class="quarto-categories">
    <div class="quarto-category">머신 러닝</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">공개</div>
    <div class="quarto-title-meta-contents">
      <p class="date">2025년 7월 27일</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p><img src="../../../../../img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="preprocessing">Preprocessing</h2>
<div id="7fedd07a" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'font.family'</span>] <span class="op">=</span> <span class="st">'Noto Sans KR'</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'_data/santander/train.csv'</span>, encoding<span class="op">=</span><span class="st">'latin-1'</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 76020 entries, 0 to 76019
Columns: 371 entries, ID to TARGET
dtypes: float64(111), int64(260)
memory usage: 215.2 MB</code></pre>
</div>
</div>
<div id="ce66c231" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df.describe()</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ID</th>
<th data-quarto-table-cell-role="th">var3</th>
<th data-quarto-table-cell-role="th">var15</th>
<th data-quarto-table-cell-role="th">imp_ent_var16_ult1</th>
<th data-quarto-table-cell-role="th">imp_op_var39_comer_ult1</th>
<th data-quarto-table-cell-role="th">imp_op_var39_comer_ult3</th>
<th data-quarto-table-cell-role="th">imp_op_var40_comer_ult1</th>
<th data-quarto-table-cell-role="th">imp_op_var40_comer_ult3</th>
<th data-quarto-table-cell-role="th">imp_op_var40_efect_ult1</th>
<th data-quarto-table-cell-role="th">imp_op_var40_efect_ult3</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">saldo_medio_var33_hace2</th>
<th data-quarto-table-cell-role="th">saldo_medio_var33_hace3</th>
<th data-quarto-table-cell-role="th">saldo_medio_var33_ult1</th>
<th data-quarto-table-cell-role="th">saldo_medio_var33_ult3</th>
<th data-quarto-table-cell-role="th">saldo_medio_var44_hace2</th>
<th data-quarto-table-cell-role="th">saldo_medio_var44_hace3</th>
<th data-quarto-table-cell-role="th">saldo_medio_var44_ult1</th>
<th data-quarto-table-cell-role="th">saldo_medio_var44_ult3</th>
<th data-quarto-table-cell-role="th">var38</th>
<th data-quarto-table-cell-role="th">TARGET</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>...</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>7.602000e+04</td>
<td>76020.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>75964.050723</td>
<td>-1523.199277</td>
<td>33.212865</td>
<td>86.208265</td>
<td>72.363067</td>
<td>119.529632</td>
<td>3.559130</td>
<td>6.472698</td>
<td>0.412946</td>
<td>0.567352</td>
<td>...</td>
<td>7.935824</td>
<td>1.365146</td>
<td>12.215580</td>
<td>8.784074</td>
<td>31.505324</td>
<td>1.858575</td>
<td>76.026165</td>
<td>56.614351</td>
<td>1.172358e+05</td>
<td>0.039569</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>43781.947379</td>
<td>39033.462364</td>
<td>12.956486</td>
<td>1614.757313</td>
<td>339.315831</td>
<td>546.266294</td>
<td>93.155749</td>
<td>153.737066</td>
<td>30.604864</td>
<td>36.513513</td>
<td>...</td>
<td>455.887218</td>
<td>113.959637</td>
<td>783.207399</td>
<td>538.439211</td>
<td>2013.125393</td>
<td>147.786584</td>
<td>4040.337842</td>
<td>2852.579397</td>
<td>1.826646e+05</td>
<td>0.194945</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>1.000000</td>
<td>-999999.000000</td>
<td>5.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>5.163750e+03</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>38104.750000</td>
<td>2.000000</td>
<td>23.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>6.787061e+04</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>76043.000000</td>
<td>2.000000</td>
<td>28.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.064092e+05</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>113748.750000</td>
<td>2.000000</td>
<td>40.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.187563e+05</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>151838.000000</td>
<td>238.000000</td>
<td>105.000000</td>
<td>210000.000000</td>
<td>12888.030000</td>
<td>21024.810000</td>
<td>8237.820000</td>
<td>11073.570000</td>
<td>6600.000000</td>
<td>6600.000000</td>
<td>...</td>
<td>50003.880000</td>
<td>20385.720000</td>
<td>138831.630000</td>
<td>91778.730000</td>
<td>438329.220000</td>
<td>24650.010000</td>
<td>681462.900000</td>
<td>397884.300000</td>
<td>2.203474e+07</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

<p>8 rows × 371 columns</p>
</div>
</div>
</div>
<div id="dd1f03da" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'var3'</span>].replace(<span class="op">-</span><span class="dv">999999</span>, <span class="dv">2</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>df.drop(<span class="st">'ID'</span>, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>X_features <span class="op">=</span> df.iloc[:, :<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> df.iloc[:, <span class="op">-</span><span class="dv">1</span>]</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="618c0e4e" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> pd.read_csv(<span class="st">'_data/santander/test.csv'</span>, encoding<span class="op">=</span><span class="st">'latin-1'</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'var3'</span>].replace(<span class="op">-</span><span class="dv">999999</span>, <span class="dv">2</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>test_df.drop(<span class="st">'ID'</span>, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="637bf5d6" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X_features, labels, test_size<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>train, test의 label의 비율이 동일한게 좋은걸까</li>
</ul>
</section>
<section id="xgboost" class="level2">
<h2 class="anchored" data-anchor-id="xgboost">XGBoost</h2>
<div id="6f409853" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>X_tr, X_val, y_tr, y_val <span class="op">=</span> train_test_split(X_train, y_train, test_size<span class="op">=</span><span class="fl">0.3</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1ba15f60" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>evals <span class="op">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>xgb_clf <span class="op">=</span> XGBClassifier(n_estimators<span class="op">=</span><span class="dv">400</span>, </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                    learning_rate<span class="op">=</span><span class="fl">0.05</span>, </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>                    early_stopping_rounds<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>                    eval_metric<span class="op">=</span>[<span class="st">'auc'</span>])</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>xgb_clf.fit(X_tr, y_tr, eval_set<span class="op">=</span>evals, verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>xgb_roc_score <span class="op">=</span> roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, <span class="dv">1</span>])</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>xgb_roc_score<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="베이지안-최적화" class="level3">
<h3 class="anchored" data-anchor-id="베이지안-최적화">베이지안 최적화</h3>
<div id="1b31b6f9" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective_func(search_space):</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    xgb_clf <span class="op">=</span> XGBClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>                            early_stopping_rounds<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>                            eval_metric<span class="op">=</span><span class="st">'auc'</span>,</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>                            max_depth<span class="op">=</span><span class="bu">int</span>(search_space[<span class="st">'max_depth'</span>]),</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>                            min_child_weight<span class="op">=</span><span class="bu">int</span>(search_space[<span class="st">'min_child_weight'</span>]),</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>                            colsample_bytree<span class="op">=</span>search_space[<span class="st">'colsample_bytree'</span>],</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>                            learning_rate<span class="op">=</span>search_space[<span class="st">'learning_rate'</span>])</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    roc_auc_list <span class="op">=</span> []</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tr_index, val_index <span class="kw">in</span> kf.split(X_train):</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        X_tr, y_tr <span class="op">=</span> X_train.iloc[tr_index], y_train.iloc[tr_index]</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        X_val, y_val <span class="op">=</span>  X_train.iloc[val_index], y_train.iloc[val_index]</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        xgb_clf.fit(X_tr, y_tr, eval_set<span class="op">=</span>[(X_tr, y_tr), (X_val, y_val)])</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, <span class="dv">1</span>])</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        roc_auc_list.append(score)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span> <span class="op">*</span> np.mean(roc_auc_list)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f38f3cc3" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hyperopt <span class="im">import</span> hp, fmin, tpe, Trials</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>xgb_search_space <span class="op">=</span> {</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">'max_depth'</span>: hp.quniform(<span class="st">'max_depth'</span>, <span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">1</span>),</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">'min_child_weight'</span>: hp.quniform(<span class="st">'min_child_weight'</span>, <span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">1</span>),</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">'colsample_bytree'</span>: hp.uniform(<span class="st">'colsample_bytree'</span>, <span class="fl">0.5</span>, <span class="fl">0.95</span>),</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">'learning_rate'</span>: hp.uniform(<span class="st">'learning_rate'</span>, <span class="fl">0.01</span>, <span class="fl">0.2</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>trials <span class="op">=</span> Trials()</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>best <span class="op">=</span> fmin(fn<span class="op">=</span>objective_func,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>            space<span class="op">=</span>xgb_search_space,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>            algo<span class="op">=</span>tpe.suggest,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>            max_evals<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>            trials<span class="op">=</span>trials)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="재-학습" class="level3">
<h3 class="anchored" data-anchor-id="재-학습">재 학습</h3>
<div id="dfcb6ac0" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>evals <span class="op">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>xgb_clf <span class="op">=</span> XGBClassifier(n_estimators<span class="op">=</span><span class="dv">500</span>, </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>                    learning_rate<span class="op">=</span><span class="bu">round</span>(best[<span class="st">'learning_rate'</span>], <span class="dv">5</span>),</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>                    max_depth<span class="op">=</span><span class="bu">int</span>(best[<span class="st">'max_depth'</span>]),</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>                    min_child_weight<span class="op">=</span><span class="bu">int</span>(best[<span class="st">'min_child_weight'</span>]),</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>                    colsample_bytree<span class="op">=</span><span class="bu">round</span>(best[<span class="st">'colsample_bytree'</span>], <span class="dv">5</span>),</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>                    early_stopping_rounds<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>                    eval_metric<span class="op">=</span>[<span class="st">'auc'</span>])</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>xgb_clf.fit(X_tr, y_tr, eval_set<span class="op">=</span>evals, verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>xgb_roc_score <span class="op">=</span> roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, <span class="dv">1</span>])</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>xgb_roc_score<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="plot-importance" class="level3">
<h3 class="anchored" data-anchor-id="plot-importance">plot importance</h3>
<div id="aaf3503d" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> plot_importance</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>plot_importance(xgb_clf, max_num_features<span class="op">=</span><span class="dv">20</span>, height<span class="op">=</span><span class="fl">0.4</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="lightgbm" class="level2">
<h2 class="anchored" data-anchor-id="lightgbm">LightGBM</h2>
<div id="f767eb16" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lightgbm <span class="im">import</span> LGBMClassifier</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>lgbm_clf <span class="op">=</span> LGBMClassifier(n_estimators<span class="op">=</span><span class="dv">500</span>, early_stopping_rounds<span class="op">=</span><span class="dv">100</span>, eval_metric<span class="op">=</span><span class="st">'auc'</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>eval_set <span class="op">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>lgbm_clf.fit(X_tr, y_tr, eval_set<span class="op">=</span>eval_set)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>lgbm_roc_score <span class="op">=</span> roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, <span class="dv">1</span>])</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>lgbm_roc_score<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100
[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Info] Number of positive: 1680, number of negative: 40891
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007185 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 13313
[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 246
[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039463 -&gt; initscore=-3.192116
[LightGBM] [Info] Start training from score -3.192116
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[38]    training's binary_logloss: 0.115227 valid_1's binary_logloss: 0.136678
[LightGBM] [Warning] Unknown parameter: eval_metric
0.835</code></pre>
</div>
</div>
<section id="베이지안-최적화-1" class="level3">
<h3 class="anchored" data-anchor-id="베이지안-최적화-1">베이지안 최적화</h3>
<div id="2b2c2571" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective_func(search_space):</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    lgbm_clf <span class="op">=</span> LGBMClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>                            early_stopping_rounds<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>                            eval_metric<span class="op">=</span><span class="st">'auc'</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>                            num_leaves<span class="op">=</span><span class="bu">int</span>(search_space[<span class="st">'num_leaves'</span>]),</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>                            max_depth<span class="op">=</span><span class="bu">int</span>(search_space[<span class="st">'max_depth'</span>]),</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>                            min_child_samples<span class="op">=</span><span class="bu">int</span>(search_space[<span class="st">'min_child_samples'</span>]),</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>                            subsample<span class="op">=</span>search_space[<span class="st">'subsample'</span>],</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>                            learning_rate<span class="op">=</span>search_space[<span class="st">'learning_rate'</span>])</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    roc_auc_list <span class="op">=</span> []</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tr_index, val_index <span class="kw">in</span> kf.split(X_train):</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        X_tr, y_tr <span class="op">=</span> X_train.iloc[tr_index], y_train.iloc[tr_index]</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        X_val, y_val <span class="op">=</span>  X_train.iloc[val_index], y_train.iloc[val_index]</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>        lgbm_clf.fit(X_tr, y_tr, eval_set<span class="op">=</span>[(X_tr, y_tr), (X_val, y_val)])</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, <span class="dv">1</span>])</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>        roc_auc_list.append(score)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span> <span class="op">*</span> np.mean(roc_auc_list)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="8063226d" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hyperopt <span class="im">import</span> hp, fmin, tpe, Trials</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>lgbm_search_space <span class="op">=</span> {</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">'num_leaves'</span>: hp.quniform(<span class="st">'num_leaves'</span>, <span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">1</span>),</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">'max_depth'</span>: hp.quniform(<span class="st">'max_depth'</span>, <span class="dv">100</span>, <span class="dv">160</span>, <span class="dv">1</span>),</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">'min_child_samples'</span>: hp.quniform(<span class="st">'min_child_samples'</span>, <span class="dv">60</span>, <span class="dv">100</span>, <span class="dv">1</span>),</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">'subsample'</span>: hp.uniform(<span class="st">'subsample'</span>, <span class="fl">0.7</span>, <span class="dv">1</span>),</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">'learning_rate'</span>: hp.uniform(<span class="st">'learning_rate'</span>, <span class="fl">0.01</span>, <span class="fl">0.2</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>trials <span class="op">=</span> Trials()</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>best <span class="op">=</span> fmin(fn<span class="op">=</span>objective_func,</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>            space<span class="op">=</span>lgbm_search_space,</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>            algo<span class="op">=</span>tpe.suggest,</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>            max_evals<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>            trials<span class="op">=</span>trials)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009724 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Total Bins 12869
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Start training from score -3.184987
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      Training until validation scores don't improve for 30 rounds
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      Did not meet early stopping. Best iteration is:
[71]    training's binary_logloss: 0.112255 valid_1's binary_logloss: 0.135706
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008359 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Total Bins 12947
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Start training from score -3.196685
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      Training until validation scores don't improve for 30 rounds
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      Did not meet early stopping. Best iteration is:
[76]    training's binary_logloss: 0.110659 valid_1's binary_logloss: 0.138201
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007536 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Total Bins 12908
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Start training from score -3.181760
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      Training until validation scores don't improve for 30 rounds
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      Early stopping, best iteration is:
[61]    training's binary_logloss: 0.115291 valid_1's binary_logloss: 0.135127
  0%|          | 0/50 [00:03&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:03&lt;?, ?trial/s, best loss=?]  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006936 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Total Bins 12812
  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Start training from score -3.184987
  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 Training until validation scores don't improve for 30 rounds
  2%|▏         | 1/50 [00:03&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 Early stopping, best iteration is:
[23]    training's binary_logloss: 0.116064 valid_1's binary_logloss: 0.136172
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008904 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Total Bins 12943
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Start training from score -3.196685
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 Training until validation scores don't improve for 30 rounds
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 Early stopping, best iteration is:
[16]    training's binary_logloss: 0.120339 valid_1's binary_logloss: 0.138716
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:04&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012688 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Total Bins 12908
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Start training from score -3.181760
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 Training until validation scores don't improve for 30 rounds
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 Early stopping, best iteration is:
[16]    training's binary_logloss: 0.122183 valid_1's binary_logloss: 0.135018
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:05&lt;02:51,  3.51s/trial, best loss: -0.8321249357878048]  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011380 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Total Bins 12804
  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Start training from score -3.184987
  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 Training until validation scores don't improve for 30 rounds
  4%|▍         | 2/50 [00:05&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 Early stopping, best iteration is:
[25]    training's binary_logloss: 0.116716 valid_1's binary_logloss: 0.136274
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008522 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Total Bins 12847
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Start training from score -3.196685
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 Training until validation scores don't improve for 30 rounds
  4%|▍         | 2/50 [00:06&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 Early stopping, best iteration is:
[25]    training's binary_logloss: 0.115805 valid_1's binary_logloss: 0.137993
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010308 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Total Bins 12817
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Start training from score -3.181760
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 Training until validation scores don't improve for 30 rounds
  4%|▍         | 2/50 [00:07&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 Early stopping, best iteration is:
[25]    training's binary_logloss: 0.116979 valid_1's binary_logloss: 0.135074
  4%|▍         | 2/50 [00:08&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:08&lt;02:07,  2.65s/trial, best loss: -0.8321249357878048]  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009715 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Total Bins 12944
  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Start training from score -3.184987
  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 Training until validation scores don't improve for 30 rounds
  6%|▌         | 3/50 [00:08&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 Early stopping, best iteration is:
[18]    training's binary_logloss: 0.11434  valid_1's binary_logloss: 0.136843
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007691 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Total Bins 12993
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Start training from score -3.196685
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 Training until validation scores don't improve for 30 rounds
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 Early stopping, best iteration is:
[18]    training's binary_logloss: 0.113403 valid_1's binary_logloss: 0.13851
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:09&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:10&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
  6%|▌         | 3/50 [00:10&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008144 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  6%|▌         | 3/50 [00:10&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Total Bins 12917
  6%|▌         | 3/50 [00:10&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
  6%|▌         | 3/50 [00:10&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:10&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:10&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
  6%|▌         | 3/50 [00:10&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Start training from score -3.181760
  6%|▌         | 3/50 [00:10&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 Training until validation scores don't improve for 30 rounds
  6%|▌         | 3/50 [00:10&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 Early stopping, best iteration is:
[13]    training's binary_logloss: 0.11959  valid_1's binary_logloss: 0.135042
  6%|▌         | 3/50 [00:10&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:10&lt;02:12,  2.83s/trial, best loss: -0.8321249357878048]  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007364 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Total Bins 12804
  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Start training from score -3.184987
  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 Training until validation scores don't improve for 30 rounds
  8%|▊         | 4/50 [00:10&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 Early stopping, best iteration is:
[50]    training's binary_logloss: 0.114951 valid_1's binary_logloss: 0.135266
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009043 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Total Bins 12838
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Start training from score -3.196685
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 Training until validation scores don't improve for 30 rounds
  8%|▊         | 4/50 [00:11&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 Early stopping, best iteration is:
[49]    training's binary_logloss: 0.114376 valid_1's binary_logloss: 0.138019
  8%|▊         | 4/50 [00:12&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:12&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:12&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:12&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:13&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
  8%|▊         | 4/50 [00:13&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006748 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  8%|▊         | 4/50 [00:13&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Total Bins 12817
  8%|▊         | 4/50 [00:13&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  8%|▊         | 4/50 [00:13&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:13&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:13&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
  8%|▊         | 4/50 [00:13&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Info] Start training from score -3.181760
  8%|▊         | 4/50 [00:13&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 Training until validation scores don't improve for 30 rounds
  8%|▊         | 4/50 [00:13&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 Early stopping, best iteration is:
[51]    training's binary_logloss: 0.114762 valid_1's binary_logloss: 0.135074
  8%|▊         | 4/50 [00:13&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:13&lt;01:53,  2.46s/trial, best loss: -0.8321249357878048] 10%|█         | 5/50 [00:13&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:13&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:13&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:13&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 10%|█         | 5/50 [00:13&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007293 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 10%|█         | 5/50 [00:13&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Total Bins 12812
 10%|█         | 5/50 [00:13&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
 10%|█         | 5/50 [00:13&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:13&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:13&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Start training from score -3.184987
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 Training until validation scores don't improve for 30 rounds
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 Early stopping, best iteration is:
[28]    training's binary_logloss: 0.11413  valid_1's binary_logloss: 0.13591
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008305 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Total Bins 12943
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Start training from score -3.196685
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 Training until validation scores don't improve for 30 rounds
 10%|█         | 5/50 [00:14&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 Early stopping, best iteration is:
[17]    training's binary_logloss: 0.120592 valid_1's binary_logloss: 0.138248
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009350 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Total Bins 12879
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Info] Start training from score -3.181760
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 Training until validation scores don't improve for 30 rounds
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 Early stopping, best iteration is:
[26]    training's binary_logloss: 0.116027 valid_1's binary_logloss: 0.134638
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:15&lt;02:02,  2.73s/trial, best loss: -0.8321345573094822] 12%|█▏        | 6/50 [00:15&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:15&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:15&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007637 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Total Bins 12900
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Start training from score -3.184987
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 Training until validation scores don't improve for 30 rounds
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 Early stopping, best iteration is:
[33]    training's binary_logloss: 0.113658 valid_1's binary_logloss: 0.13587
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010190 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Total Bins 12993
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Start training from score -3.196685
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 Training until validation scores don't improve for 30 rounds
 12%|█▏        | 6/50 [00:16&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 Early stopping, best iteration is:
[31]    training's binary_logloss: 0.113983 valid_1's binary_logloss: 0.138398
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009348 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Total Bins 12917
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Start training from score -3.181760
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 Training until validation scores don't improve for 30 rounds
 12%|█▏        | 6/50 [00:17&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 Early stopping, best iteration is:
[28]    training's binary_logloss: 0.116757 valid_1's binary_logloss: 0.135006
 12%|█▏        | 6/50 [00:18&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:18&lt;01:49,  2.49s/trial, best loss: -0.8321862965498973] 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014190 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Total Bins 12804
 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Start training from score -3.184987
 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 Training until validation scores don't improve for 30 rounds
 14%|█▍        | 7/50 [00:18&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 Did not meet early stopping. Best iteration is:
[95]    training's binary_logloss: 0.115034 valid_1's binary_logloss: 0.135206
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007240 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Total Bins 12847
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Start training from score -3.196685
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 Training until validation scores don't improve for 30 rounds
 14%|█▍        | 7/50 [00:19&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 Did not meet early stopping. Best iteration is:
[95]    training's binary_logloss: 0.114229 valid_1's binary_logloss: 0.137941
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008922 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Total Bins 12817
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Info] Start training from score -3.181760
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 Training until validation scores don't improve for 30 rounds
 14%|█▍        | 7/50 [00:20&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 Did not meet early stopping. Best iteration is:
[97]    training's binary_logloss: 0.11512  valid_1's binary_logloss: 0.134343
 14%|█▍        | 7/50 [00:21&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:21&lt;01:49,  2.55s/trial, best loss: -0.8321862965498973] 16%|█▌        | 8/50 [00:21&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:21&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:21&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:21&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 16%|█▌        | 8/50 [00:21&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009362 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 16%|█▌        | 8/50 [00:21&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Total Bins 12804
 16%|█▌        | 8/50 [00:21&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 16%|█▌        | 8/50 [00:21&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:21&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:21&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 16%|█▌        | 8/50 [00:21&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Start training from score -3.184987
 16%|█▌        | 8/50 [00:22&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 Training until validation scores don't improve for 30 rounds
 16%|█▌        | 8/50 [00:22&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 Did not meet early stopping. Best iteration is:
[80]    training's binary_logloss: 0.116244 valid_1's binary_logloss: 0.135104
 16%|█▌        | 8/50 [00:22&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019852 seconds.
You can set `force_col_wise=true` to remove the overhead.
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Total Bins 12838
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Start training from score -3.196685
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 Training until validation scores don't improve for 30 rounds
 16%|█▌        | 8/50 [00:23&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 Did not meet early stopping. Best iteration is:
[76]    training's binary_logloss: 0.116122 valid_1's binary_logloss: 0.137831
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008059 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Total Bins 12817
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Info] Start training from score -3.181760
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 Training until validation scores don't improve for 30 rounds
 16%|█▌        | 8/50 [00:24&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 Did not meet early stopping. Best iteration is:
[72]    training's binary_logloss: 0.11803  valid_1's binary_logloss: 0.134506
 16%|█▌        | 8/50 [00:25&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:25&lt;01:56,  2.77s/trial, best loss: -0.8334837969495431] 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007825 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Total Bins 12804
 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Start training from score -3.184987
 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 Training until validation scores don't improve for 30 rounds
 18%|█▊        | 9/50 [00:25&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 Early stopping, best iteration is:
[19]    training's binary_logloss: 0.119694 valid_1's binary_logloss: 0.135681
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007929 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Total Bins 12838
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Start training from score -3.196685
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 Training until validation scores don't improve for 30 rounds
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 Early stopping, best iteration is:
[16]    training's binary_logloss: 0.120319 valid_1's binary_logloss: 0.138538
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009337 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Total Bins 12817
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:26&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 18%|█▊        | 9/50 [00:27&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Info] Start training from score -3.181760
 18%|█▊        | 9/50 [00:27&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 Training until validation scores don't improve for 30 rounds
 18%|█▊        | 9/50 [00:27&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 Early stopping, best iteration is:
[17]    training's binary_logloss: 0.120802 valid_1's binary_logloss: 0.13482
 18%|█▊        | 9/50 [00:27&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:27&lt;02:07,  3.11s/trial, best loss: -0.8335214645673078] 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008130 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Total Bins 12804
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  Training until validation scores don't improve for 30 rounds
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  Early stopping, best iteration is:
[51]    training's binary_logloss: 0.119408 valid_1's binary_logloss: 0.134911
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:27&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009044 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Total Bins 12838
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  Training until validation scores don't improve for 30 rounds
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  Early stopping, best iteration is:
[49]    training's binary_logloss: 0.119133 valid_1's binary_logloss: 0.137546
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007803 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Total Bins 12817
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 20%|██        | 10/50 [00:28&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:29&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:29&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 20%|██        | 10/50 [00:29&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 20%|██        | 10/50 [00:29&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  Training until validation scores don't improve for 30 rounds
 20%|██        | 10/50 [00:29&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  Early stopping, best iteration is:
[47]    training's binary_logloss: 0.120688 valid_1's binary_logloss: 0.134302
 20%|██        | 10/50 [00:29&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:29&lt;01:47,  2.69s/trial, best loss: -0.8335214645673078] 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011880 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12804
 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 22%|██▏       | 11/50 [00:29&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.115117 valid_1's binary_logloss: 0.136209
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011556 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12838
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 22%|██▏       | 11/50 [00:30&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[27]    training's binary_logloss: 0.115512 valid_1's binary_logloss: 0.138156
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008892 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12817
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 22%|██▏       | 11/50 [00:31&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[25]    training's binary_logloss: 0.117743 valid_1's binary_logloss: 0.134897
 22%|██▏       | 11/50 [00:32&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:32&lt;01:39,  2.54s/trial, best loss: -0.8345904314135609] 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008049 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12804
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[25]    training's binary_logloss: 0.118268 valid_1's binary_logloss: 0.135684
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 24%|██▍       | 12/50 [00:32&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006989 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12847
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[22]    training's binary_logloss: 0.118735 valid_1's binary_logloss: 0.137976
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006796 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12817
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[24]    training's binary_logloss: 0.119628 valid_1's binary_logloss: 0.134916
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:33&lt;01:38,  2.59s/trial, best loss: -0.8345904314135609] 26%|██▌       | 13/50 [00:33&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010210 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12804
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[40]    training's binary_logloss: 0.114319 valid_1's binary_logloss: 0.135995
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:34&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007309 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12838
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[39]    training's binary_logloss: 0.113925 valid_1's binary_logloss: 0.137893
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009469 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12817
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 26%|██▌       | 13/50 [00:35&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[33]    training's binary_logloss: 0.117803 valid_1's binary_logloss: 0.135217
 26%|██▌       | 13/50 [00:36&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:36&lt;01:27,  2.36s/trial, best loss: -0.8345904314135609] 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007370 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12804
 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 28%|██▊       | 14/50 [00:36&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  Did not meet early stopping. Best iteration is:
[99]    training's binary_logloss: 0.117141 valid_1's binary_logloss: 0.135196
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013043 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12838
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 28%|██▊       | 14/50 [00:37&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  Did not meet early stopping. Best iteration is:
[97]    training's binary_logloss: 0.116927 valid_1's binary_logloss: 0.137695
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010449 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12817
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 28%|██▊       | 14/50 [00:38&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.117458 valid_1's binary_logloss: 0.134804
 28%|██▊       | 14/50 [00:39&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:39&lt;01:26,  2.40s/trial, best loss: -0.8345904314135609] 30%|███       | 15/50 [00:39&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:39&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:39&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:40&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 30%|███       | 15/50 [00:40&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009063 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 30%|███       | 15/50 [00:40&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12821
 30%|███       | 15/50 [00:40&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 30%|███       | 15/50 [00:40&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:40&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:40&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 30%|███       | 15/50 [00:40&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 30%|███       | 15/50 [00:40&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 30%|███       | 15/50 [00:40&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[28]    training's binary_logloss: 0.11267  valid_1's binary_logloss: 0.136106
 30%|███       | 15/50 [00:40&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:40&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009274 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12943
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[22]    training's binary_logloss: 0.115948 valid_1's binary_logloss: 0.13866
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:41&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011803 seconds.
You can set `force_col_wise=true` to remove the overhead.
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12908
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[23]    training's binary_logloss: 0.116131 valid_1's binary_logloss: 0.135187
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:42&lt;01:33,  2.67s/trial, best loss: -0.8345904314135609] 32%|███▏      | 16/50 [00:42&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:42&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:42&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:42&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 32%|███▏      | 16/50 [00:42&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008073 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 32%|███▏      | 16/50 [00:42&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12900
 32%|███▏      | 16/50 [00:42&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 32%|███▏      | 16/50 [00:42&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:42&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:42&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 32%|███▏      | 16/50 [00:43&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 32%|███▏      | 16/50 [00:43&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 32%|███▏      | 16/50 [00:43&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  Did not meet early stopping. Best iteration is:
[84]    training's binary_logloss: 0.11371  valid_1's binary_logloss: 0.135137
 32%|███▏      | 16/50 [00:43&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:43&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:43&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:43&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:43&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 32%|███▏      | 16/50 [00:43&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007565 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 32%|███▏      | 16/50 [00:43&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12993
 32%|███▏      | 16/50 [00:43&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 32%|███▏      | 16/50 [00:43&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[67]    training's binary_logloss: 0.116405 valid_1's binary_logloss: 0.138124
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008722 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12917
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 32%|███▏      | 16/50 [00:44&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:45&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:45&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 32%|███▏      | 16/50 [00:45&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 32%|███▏      | 16/50 [00:45&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 32%|███▏      | 16/50 [00:45&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  Did not meet early stopping. Best iteration is:
[84]    training's binary_logloss: 0.114059 valid_1's binary_logloss: 0.134317
 32%|███▏      | 16/50 [00:45&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:45&lt;01:33,  2.76s/trial, best loss: -0.8345904314135609] 34%|███▍      | 17/50 [00:45&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:45&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:45&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:45&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 34%|███▍      | 17/50 [00:45&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009001 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 34%|███▍      | 17/50 [00:45&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12804
 34%|███▍      | 17/50 [00:45&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 34%|███▍      | 17/50 [00:45&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:45&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:45&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[60]    training's binary_logloss: 0.116861 valid_1's binary_logloss: 0.134877
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008590 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12838
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 34%|███▍      | 17/50 [00:46&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[58]    training's binary_logloss: 0.11687  valid_1's binary_logloss: 0.13752
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006636 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Total Bins 12817
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  Training until validation scores don't improve for 30 rounds
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  Early stopping, best iteration is:
[67]    training's binary_logloss: 0.115782 valid_1's binary_logloss: 0.134209
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:47&lt;01:32,  2.82s/trial, best loss: -0.8345904314135609] 36%|███▌      | 18/50 [00:47&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007175 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12944
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[20]    training's binary_logloss: 0.117901 valid_1's binary_logloss: 0.135627
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008634 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12993
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 36%|███▌      | 18/50 [00:48&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[24]    training's binary_logloss: 0.114214 valid_1's binary_logloss: 0.138485
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008114 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12917
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[19]    training's binary_logloss: 0.118579 valid_1's binary_logloss: 0.135136
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:49&lt;01:25,  2.66s/trial, best loss: -0.8346199818249235] 38%|███▊      | 19/50 [00:49&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:49&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:49&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007573 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12869
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[64]    training's binary_logloss: 0.112009 valid_1's binary_logloss: 0.13523
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:50&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007871 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12947
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[61]    training's binary_logloss: 0.112082 valid_1's binary_logloss: 0.13837
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:51&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:52&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 38%|███▊      | 19/50 [00:52&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008356 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 38%|███▊      | 19/50 [00:52&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12908
 38%|███▊      | 19/50 [00:52&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200
 38%|███▊      | 19/50 [00:52&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:52&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:52&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 38%|███▊      | 19/50 [00:52&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 38%|███▊      | 19/50 [00:52&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 38%|███▊      | 19/50 [00:52&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[60]    training's binary_logloss: 0.113244 valid_1's binary_logloss: 0.134797
 38%|███▊      | 19/50 [00:52&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:52&lt;01:14,  2.42s/trial, best loss: -0.8346199818249235] 40%|████      | 20/50 [00:52&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:52&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:52&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:52&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 40%|████      | 20/50 [00:52&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007853 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12804
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.13445  valid_1's binary_logloss: 0.139692
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008540 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12838
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 40%|████      | 20/50 [00:53&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.133592 valid_1's binary_logloss: 0.142113
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010222 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12817
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 40%|████      | 20/50 [00:54&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.135205 valid_1's binary_logloss: 0.138742
 40%|████      | 20/50 [00:55&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:55&lt;01:17,  2.58s/trial, best loss: -0.8346199818249235] 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008607 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12804
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[52]    training's binary_logloss: 0.118045 valid_1's binary_logloss: 0.134995
 42%|████▏     | 21/50 [00:55&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009509 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12913
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[49]    training's binary_logloss: 0.118325 valid_1's binary_logloss: 0.137852
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:56&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:57&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 42%|████▏     | 21/50 [00:57&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 42%|████▏     | 21/50 [00:57&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12879
 42%|████▏     | 21/50 [00:57&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 42%|████▏     | 21/50 [00:57&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:57&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:57&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 42%|████▏     | 21/50 [00:57&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 42%|████▏     | 21/50 [00:57&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 42%|████▏     | 21/50 [00:57&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[54]    training's binary_logloss: 0.118203 valid_1's binary_logloss: 0.134179
 42%|████▏     | 21/50 [00:57&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:57&lt;01:13,  2.55s/trial, best loss: -0.8346199818249235] 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009051 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12804
 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 44%|████▍     | 22/50 [00:57&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[19]    training's binary_logloss: 0.118534 valid_1's binary_logloss: 0.136106
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007194 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12913
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[15]    training's binary_logloss: 0.120171 valid_1's binary_logloss: 0.137868
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007805 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12879
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 44%|████▍     | 22/50 [00:58&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[20]    training's binary_logloss: 0.118138 valid_1's binary_logloss: 0.13535
 44%|████▍     | 22/50 [00:59&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:59&lt;01:09,  2.47s/trial, best loss: -0.8346199818249235] 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008298 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12804
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.123442 valid_1's binary_logloss: 0.135652
 46%|████▌     | 23/50 [00:59&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007983 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12838
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.122527 valid_1's binary_logloss: 0.138185
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:00&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:01&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [01:01&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:01&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 46%|████▌     | 23/50 [01:01&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012976 seconds.
You can set `force_col_wise=true` to remove the overhead.
 46%|████▌     | 23/50 [01:01&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12817
 46%|████▌     | 23/50 [01:01&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 46%|████▌     | 23/50 [01:01&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:01&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [01:01&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 46%|████▌     | 23/50 [01:01&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 46%|████▌     | 23/50 [01:01&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 46%|████▌     | 23/50 [01:01&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.123812 valid_1's binary_logloss: 0.13482
 46%|████▌     | 23/50 [01:02&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:02&lt;01:00,  2.23s/trial, best loss: -0.8346199818249235] 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007683 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12804
 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 48%|████▊     | 24/50 [01:02&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[55]    training's binary_logloss: 0.118913 valid_1's binary_logloss: 0.134591
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007060 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12838
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 48%|████▊     | 24/50 [01:03&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[51]    training's binary_logloss: 0.119109 valid_1's binary_logloss: 0.137532
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007158 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Total Bins 12817
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  Training until validation scores don't improve for 30 rounds
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  Early stopping, best iteration is:
[53]    training's binary_logloss: 0.119682 valid_1's binary_logloss: 0.134044
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:04&lt;01:06,  2.56s/trial, best loss: -0.8346199818249235] 50%|█████     | 25/50 [01:04&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:04&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:04&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006965 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12804
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[41]    training's binary_logloss: 0.116789 valid_1's binary_logloss: 0.135098
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009464 seconds.
You can set `force_col_wise=true` to remove the overhead.
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12838
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 50%|█████     | 25/50 [01:05&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[39]    training's binary_logloss: 0.116539 valid_1's binary_logloss: 0.138054
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006983 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12817
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[39]    training's binary_logloss: 0.117685 valid_1's binary_logloss: 0.134656
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:06&lt;01:01,  2.47s/trial, best loss: -0.8353293081416346] 52%|█████▏    | 26/50 [01:06&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008118 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12804
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.131216 valid_1's binary_logloss: 0.139484
 52%|█████▏    | 26/50 [01:07&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017901 seconds.
You can set `force_col_wise=true` to remove the overhead.
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12903
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 52%|█████▏    | 26/50 [01:08&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.130191 valid_1's binary_logloss: 0.141574
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007720 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12879
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 52%|█████▏    | 26/50 [01:09&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.131799 valid_1's binary_logloss: 0.138351
 52%|█████▏    | 26/50 [01:10&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:10&lt;00:57,  2.38s/trial, best loss: -0.8353293081416346] 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007748 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12804
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[60]    training's binary_logloss: 0.119196 valid_1's binary_logloss: 0.134697
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:10&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007410 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12838
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[60]    training's binary_logloss: 0.118245 valid_1's binary_logloss: 0.137653
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008656 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12817
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 54%|█████▍    | 27/50 [01:11&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[58]    training's binary_logloss: 0.11982  valid_1's binary_logloss: 0.134115
 54%|█████▍    | 27/50 [01:12&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:12&lt;01:00,  2.64s/trial, best loss: -0.8353293081416346] 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008201 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12804
 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 56%|█████▌    | 28/50 [01:12&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[55]    training's binary_logloss: 0.118255 valid_1's binary_logloss: 0.13523
 56%|█████▌    | 28/50 [01:13&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:13&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:13&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:13&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:13&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 56%|█████▌    | 28/50 [01:13&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008806 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 56%|█████▌    | 28/50 [01:13&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12838
 56%|█████▌    | 28/50 [01:13&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 56%|█████▌    | 28/50 [01:13&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:13&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:13&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 56%|█████▌    | 28/50 [01:14&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 56%|█████▌    | 28/50 [01:14&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 56%|█████▌    | 28/50 [01:14&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[58]    training's binary_logloss: 0.116637 valid_1's binary_logloss: 0.137971
 56%|█████▌    | 28/50 [01:14&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:14&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011744 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12817
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[57]    training's binary_logloss: 0.118083 valid_1's binary_logloss: 0.134172
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:15&lt;00:55,  2.51s/trial, best loss: -0.8353293081416346] 58%|█████▊    | 29/50 [01:15&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009021 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12804
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[69]    training's binary_logloss: 0.118755 valid_1's binary_logloss: 0.134976
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:16&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:17&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 58%|█████▊    | 29/50 [01:17&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013066 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 58%|█████▊    | 29/50 [01:17&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12913
 58%|█████▊    | 29/50 [01:17&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 58%|█████▊    | 29/50 [01:17&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:17&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:17&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 58%|█████▊    | 29/50 [01:17&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 58%|█████▊    | 29/50 [01:17&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 58%|█████▊    | 29/50 [01:17&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[66]    training's binary_logloss: 0.118516 valid_1's binary_logloss: 0.13759
 58%|█████▊    | 29/50 [01:17&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:17&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011270 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12879
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[69]    training's binary_logloss: 0.119213 valid_1's binary_logloss: 0.134123
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:18&lt;00:58,  2.81s/trial, best loss: -0.8353293081416346] 60%|██████    | 30/50 [01:18&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007448 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12804
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.124451 valid_1's binary_logloss: 0.135306
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:19&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008631 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12943
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.123486 valid_1's binary_logloss: 0.137957
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007884 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12879
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:20&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 60%|██████    | 30/50 [01:21&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 60%|██████    | 30/50 [01:21&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 60%|██████    | 30/50 [01:21&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.124936 valid_1's binary_logloss: 0.13456
 60%|██████    | 30/50 [01:21&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:21&lt;00:57,  2.88s/trial, best loss: -0.8353293081416346] 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013677 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12896
 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 62%|██████▏   | 31/50 [01:21&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.123182 valid_1's binary_logloss: 0.13554
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010535 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12947
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 62%|██████▏   | 31/50 [01:22&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.12218  valid_1's binary_logloss: 0.138117
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007774 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12908
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 62%|██████▏   | 31/50 [01:23&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.123535 valid_1's binary_logloss: 0.134833
 62%|██████▏   | 31/50 [01:24&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:24&lt;00:53,  2.80s/trial, best loss: -0.8353293081416346] 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016300 seconds.
You can set `force_col_wise=true` to remove the overhead.
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12804
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[30]    training's binary_logloss: 0.119038 valid_1's binary_logloss: 0.134688
 64%|██████▍   | 32/50 [01:24&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008723 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12943
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[30]    training's binary_logloss: 0.118066 valid_1's binary_logloss: 0.137695
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012208 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12879
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:25&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 64%|██████▍   | 32/50 [01:26&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 64%|██████▍   | 32/50 [01:26&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 64%|██████▍   | 32/50 [01:26&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.120385 valid_1's binary_logloss: 0.134541
 64%|██████▍   | 32/50 [01:26&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:26&lt;00:49,  2.77s/trial, best loss: -0.8353293081416346] 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007626 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12804
 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 66%|██████▌   | 33/50 [01:26&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[42]    training's binary_logloss: 0.113008 valid_1's binary_logloss: 0.135691
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012098 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12903
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[31]    training's binary_logloss: 0.117041 valid_1's binary_logloss: 0.138101
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:27&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009215 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12879
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[42]    training's binary_logloss: 0.113562 valid_1's binary_logloss: 0.134568
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:28&lt;00:43,  2.56s/trial, best loss: -0.8353293081416346] 68%|██████▊   | 34/50 [01:28&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:28&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:28&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008779 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12804
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.121864 valid_1's binary_logloss: 0.135488
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007069 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12903
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 68%|██████▊   | 34/50 [01:29&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.120934 valid_1's binary_logloss: 0.138049
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012046 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12879
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 68%|██████▊   | 34/50 [01:30&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.122219 valid_1's binary_logloss: 0.134581
 68%|██████▊   | 34/50 [01:31&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:31&lt;00:40,  2.53s/trial, best loss: -0.8353293081416346] 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007576 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12812
 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 70%|███████   | 35/50 [01:31&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.129099 valid_1's binary_logloss: 0.137718
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007789 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12943
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 70%|███████   | 35/50 [01:32&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.128316 valid_1's binary_logloss: 0.140125
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010383 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12879
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 70%|███████   | 35/50 [01:33&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.129766 valid_1's binary_logloss: 0.136703
 70%|███████   | 35/50 [01:34&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:34&lt;00:38,  2.60s/trial, best loss: -0.8353293081416346] 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009033 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12804
 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 72%|███████▏  | 36/50 [01:34&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.120857 valid_1's binary_logloss: 0.135392
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007741 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12903
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[31]    training's binary_logloss: 0.118985 valid_1's binary_logloss: 0.137371
 72%|███████▏  | 36/50 [01:35&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010013 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12817
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  Early stopping, best iteration is:
[30]    training's binary_logloss: 0.120758 valid_1's binary_logloss: 0.134185
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:36&lt;00:37,  2.71s/trial, best loss: -0.8353293081416346] 74%|███████▍  | 37/50 [01:36&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:36&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:36&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:36&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 74%|███████▍  | 37/50 [01:36&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008582 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 74%|███████▍  | 37/50 [01:36&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12804
 74%|███████▍  | 37/50 [01:36&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 74%|███████▍  | 37/50 [01:36&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:37&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:37&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 74%|███████▍  | 37/50 [01:37&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 74%|███████▍  | 37/50 [01:37&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 74%|███████▍  | 37/50 [01:37&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.122004 valid_1's binary_logloss: 0.134892
 74%|███████▍  | 37/50 [01:37&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:37&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:37&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:37&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:37&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 74%|███████▍  | 37/50 [01:37&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007974 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12838
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.120947 valid_1's binary_logloss: 0.137433
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008872 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Total Bins 12817
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  Training until validation scores don't improve for 30 rounds
 74%|███████▍  | 37/50 [01:38&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.122411 valid_1's binary_logloss: 0.134261
 74%|███████▍  | 37/50 [01:39&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:39&lt;00:33,  2.54s/trial, best loss: -0.8353293081416346] 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014886 seconds.
You can set `force_col_wise=true` to remove the overhead.
 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Total Bins 12804
 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Start training from score -3.184987
 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 Training until validation scores don't improve for 30 rounds
 76%|███████▌  | 38/50 [01:39&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 Early stopping, best iteration is:
[15]    training's binary_logloss: 0.120015 valid_1's binary_logloss: 0.136651
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012741 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Total Bins 12838
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Start training from score -3.196685
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 Training until validation scores don't improve for 30 rounds
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 Early stopping, best iteration is:
[15]    training's binary_logloss: 0.118939 valid_1's binary_logloss: 0.138894
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 76%|███████▌  | 38/50 [01:40&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010061 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 76%|███████▌  | 38/50 [01:41&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Total Bins 12817
 76%|███████▌  | 38/50 [01:41&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 76%|███████▌  | 38/50 [01:41&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:41&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:41&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 76%|███████▌  | 38/50 [01:41&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Start training from score -3.181760
 76%|███████▌  | 38/50 [01:41&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 Training until validation scores don't improve for 30 rounds
 76%|███████▌  | 38/50 [01:41&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 Early stopping, best iteration is:
[12]    training's binary_logloss: 0.122953 valid_1's binary_logloss: 0.134958
 76%|███████▌  | 38/50 [01:41&lt;00:31,  2.62s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:41&lt;00:31,  2.62s/trial, best loss: -0.835331797276512] 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008189 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Total Bins 12804
 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Start training from score -3.184987
 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 Training until validation scores don't improve for 30 rounds
 78%|███████▊  | 39/50 [01:41&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 Did not meet early stopping. Best iteration is:
[88]    training's binary_logloss: 0.117929 valid_1's binary_logloss: 0.135205
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008863 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Total Bins 12838
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Start training from score -3.196685
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 Training until validation scores don't improve for 30 rounds
 78%|███████▊  | 39/50 [01:42&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 Did not meet early stopping. Best iteration is:
[81]    training's binary_logloss: 0.11844  valid_1's binary_logloss: 0.137484
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009540 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Total Bins 12817
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Start training from score -3.181760
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 Training until validation scores don't improve for 30 rounds
 78%|███████▊  | 39/50 [01:43&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 Did not meet early stopping. Best iteration is:
[85]    training's binary_logloss: 0.118939 valid_1's binary_logloss: 0.134806
 78%|███████▊  | 39/50 [01:44&lt;00:26,  2.39s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:44&lt;00:26,  2.39s/trial, best loss: -0.835331797276512] 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007878 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Total Bins 12804
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Start training from score -3.184987
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 Training until validation scores don't improve for 30 rounds
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 Early stopping, best iteration is:
[50]    training's binary_logloss: 0.119598 valid_1's binary_logloss: 0.134559
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:44&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013151 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Total Bins 12838
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Start training from score -3.196685
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 Training until validation scores don't improve for 30 rounds
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 Early stopping, best iteration is:
[51]    training's binary_logloss: 0.118541 valid_1's binary_logloss: 0.137523
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:45&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:46&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 80%|████████  | 40/50 [01:46&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011190 seconds.
You can set `force_col_wise=true` to remove the overhead.
 80%|████████  | 40/50 [01:46&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Total Bins 12817
 80%|████████  | 40/50 [01:46&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 80%|████████  | 40/50 [01:46&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:46&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:46&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 80%|████████  | 40/50 [01:46&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Info] Start training from score -3.181760
 80%|████████  | 40/50 [01:46&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 Training until validation scores don't improve for 30 rounds
 80%|████████  | 40/50 [01:46&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 Early stopping, best iteration is:
[48]    training's binary_logloss: 0.120332 valid_1's binary_logloss: 0.134165
 80%|████████  | 40/50 [01:46&lt;00:25,  2.54s/trial, best loss: -0.835331797276512]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:46&lt;00:25,  2.54s/trial, best loss: -0.835331797276512] 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006984 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12804
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[33]    training's binary_logloss: 0.119524 valid_1's binary_logloss: 0.135441
 82%|████████▏ | 41/50 [01:47&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008826 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12838
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[28]    training's binary_logloss: 0.120257 valid_1's binary_logloss: 0.137469
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007049 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12817
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 82%|████████▏ | 41/50 [01:48&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.121158 valid_1's binary_logloss: 0.134384
 82%|████████▏ | 41/50 [01:49&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:49&lt;00:24,  2.72s/trial, best loss: -0.8357102168343064] 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008870 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12804
 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 84%|████████▍ | 42/50 [01:49&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[30]    training's binary_logloss: 0.117395 valid_1's binary_logloss: 0.136137
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012995 seconds.
You can set `force_col_wise=true` to remove the overhead.
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12838
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[33]    training's binary_logloss: 0.115053 valid_1's binary_logloss: 0.138202
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:50&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008256 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12817
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[40]    training's binary_logloss: 0.112815 valid_1's binary_logloss: 0.134646
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:51&lt;00:19,  2.47s/trial, best loss: -0.8357102168343064] 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006767 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12804
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[43]    training's binary_logloss: 0.116209 valid_1's binary_logloss: 0.135515
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007724 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12838
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 86%|████████▌ | 43/50 [01:52&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[41]    training's binary_logloss: 0.116373 valid_1's binary_logloss: 0.13768
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015228 seconds.
You can set `force_col_wise=true` to remove the overhead.
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12817
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 86%|████████▌ | 43/50 [01:53&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[38]    training's binary_logloss: 0.118563 valid_1's binary_logloss: 0.13498
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.49s/trial, best loss: -0.8357102168343064] 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008542 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12804
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[25]    training's binary_logloss: 0.120117 valid_1's binary_logloss: 0.134789
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008040 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12838
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[25]    training's binary_logloss: 0.119394 valid_1's binary_logloss: 0.137658
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009460 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12817
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 88%|████████▊ | 44/50 [01:55&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[37]    training's binary_logloss: 0.114421 valid_1's binary_logloss: 0.134479
 88%|████████▊ | 44/50 [01:56&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:56&lt;00:14,  2.47s/trial, best loss: -0.8357102168343064] 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010005 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12804
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.115234 valid_1's binary_logloss: 0.135872
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008841 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12838
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[27]    training's binary_logloss: 0.115194 valid_1's binary_logloss: 0.138408
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010236 seconds.
You can set `force_col_wise=true` to remove the overhead.
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12817
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:57&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 90%|█████████ | 45/50 [01:58&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 90%|█████████ | 45/50 [01:58&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 90%|█████████ | 45/50 [01:58&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[26]    training's binary_logloss: 0.116992 valid_1's binary_logloss: 0.135531
 90%|█████████ | 45/50 [01:58&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:58&lt;00:11,  2.31s/trial, best loss: -0.8357102168343064] 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007834 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12804
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[20]    training's binary_logloss: 0.115923 valid_1's binary_logloss: 0.13639
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009212 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12838
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[17]    training's binary_logloss: 0.117019 valid_1's binary_logloss: 0.138229
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [01:59&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:00&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 92%|█████████▏| 46/50 [02:00&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010055 seconds.
You can set `force_col_wise=true` to remove the overhead.
 92%|█████████▏| 46/50 [02:00&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12817
 92%|█████████▏| 46/50 [02:00&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 92%|█████████▏| 46/50 [02:00&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:00&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [02:00&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 92%|█████████▏| 46/50 [02:00&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 92%|█████████▏| 46/50 [02:00&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 92%|█████████▏| 46/50 [02:00&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[18]    training's binary_logloss: 0.117591 valid_1's binary_logloss: 0.135204
 92%|█████████▏| 46/50 [02:00&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:00&lt;00:09,  2.32s/trial, best loss: -0.8357102168343064] 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009290 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12804
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[27]    training's binary_logloss: 0.117985 valid_1's binary_logloss: 0.135367
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010413 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12838
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[25]    training's binary_logloss: 0.117671 valid_1's binary_logloss: 0.137665
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008027 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12817
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[23]    training's binary_logloss: 0.120142 valid_1's binary_logloss: 0.135155
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:02&lt;00:06,  2.22s/trial, best loss: -0.8357102168343064] 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014548 seconds.
You can set `force_col_wise=true` to remove the overhead.
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12804
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  Early stopping, best iteration is:
[69]    training's binary_logloss: 0.117534 valid_1's binary_logloss: 0.134864
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007901 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12838
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  Did not meet early stopping. Best iteration is:
[82]    training's binary_logloss: 0.114016 valid_1's binary_logloss: 0.137702
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:04&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012228 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12817
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  Did not meet early stopping. Best iteration is:
[75]    training's binary_logloss: 0.116413 valid_1's binary_logloss: 0.134882
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:05&lt;00:04,  2.25s/trial, best loss: -0.8357102168343064] 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1611, number of negative: 38933
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013063 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12804
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -&gt; initscore=-3.184987
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.184987
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  Did not meet early stopping. Best iteration is:
[99]    training's binary_logloss: 0.115727 valid_1's binary_logloss: 0.135247
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1593, number of negative: 38951
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008711 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12847
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -&gt; initscore=-3.196685
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.196685
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.11494  valid_1's binary_logloss: 0.137861
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:07&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of positive: 1616, number of negative: 38928
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007797 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Total Bins 12817
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -&gt; initscore=-3.181760
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Info] Start training from score -3.181760
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  Training until validation scores don't improve for 30 rounds
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  Did not meet early stopping. Best iteration is:
[99]    training's binary_logloss: 0.116161 valid_1's binary_logloss: 0.134483
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:08&lt;00:02,  2.49s/trial, best loss: -0.8357102168343064]100%|██████████| 50/50 [02:08&lt;00:00,  2.67s/trial, best loss: -0.8357102168343064]100%|██████████| 50/50 [02:08&lt;00:00,  2.58s/trial, best loss: -0.8357102168343064]
{'learning_rate': 0.07078424888661622, 'max_depth': 143.0, 'min_child_samples': 93.0, 'num_leaves': 33.0, 'subsample': 0.9935662058378432}</code></pre>
</div>
</div>
</section>
<section id="재학습" class="level3">
<h3 class="anchored" data-anchor-id="재학습">재학습</h3>
<div id="8f3a2e85" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>lgbm_clf <span class="op">=</span> LGBMClassifier(n_estimators<span class="op">=</span><span class="dv">500</span>, </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>                          num_leaves<span class="op">=</span><span class="bu">int</span>(best[<span class="st">'num_leaves'</span>]),</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>                          max_depth<span class="op">=</span><span class="bu">int</span>(best[<span class="st">'max_depth'</span>]),</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>                          min_child_samples<span class="op">=</span><span class="bu">int</span>(best[<span class="st">'min_child_samples'</span>]),</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>                          subsample<span class="op">=</span><span class="bu">round</span>(best[<span class="st">'subsample'</span>], <span class="dv">5</span>),</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>                          learning_rate<span class="op">=</span><span class="bu">round</span>(best[<span class="st">'learning_rate'</span>], <span class="dv">5</span>),</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>                          early_stopping_rounds<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>                          eval_metric<span class="op">=</span><span class="st">'auc'</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>eval_set <span class="op">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>lgbm_clf.fit(X_tr, y_tr, eval_set<span class="op">=</span>eval_set)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>lgbm_roc_score <span class="op">=</span> roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, <span class="dv">1</span>])</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>lgbm_roc_score<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100
[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Info] Number of positive: 1680, number of negative: 40891
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010648 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 12882
[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 192
[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039463 -&gt; initscore=-3.192116
[LightGBM] [Info] Start training from score -3.192116
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[43]    training's binary_logloss: 0.120912 valid_1's binary_logloss: 0.136896
[LightGBM] [Warning] Unknown parameter: eval_metric
0.835</code></pre>
</div>
</div>
</section>
</section>
<section id="제출" class="level2">
<h2 class="anchored" data-anchor-id="제출">제출</h2>
<div id="07194e50" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> lgbm_clf.predict(test_df)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>submit <span class="op">=</span> pd.read_csv(<span class="st">'_data/santander/sample_submission.csv'</span>, encoding<span class="op">=</span><span class="st">'latin-1'</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>submit[<span class="st">'TARGET'</span>] <span class="op">=</span> target</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>submit.to_csv(<span class="st">'_data/santander/submission.csv'</span>, encoding<span class="op">=</span><span class="st">'latin-1'</span>, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Warning] Unknown parameter: eval_metric</code></pre>
</div>
</div>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "복사완료!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "복사완료!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/cryscham123\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="cryscham123/cryscham123.github.io" data-repo-id="R_kgDONGE9Rw" data-category="Announcements" data-category-id="DIC_kwDONGE9R84CjtIQ" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" data-loading="lazy" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="light">
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/02.html" class="pagination-link" aria-label="분류 - 앙상블">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">분류 - 앙상블</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../../../posts/04_archives/adp_실기/notes/machine_learning/04.html" class="pagination-link" aria-label="분류 - 신용 카드 사기 검출">
        <span class="nav-page-text">분류 - 신용 카드 사기 검출</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2024 김형훈</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




<script src="../../../../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>