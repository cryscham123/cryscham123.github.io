---
title: "analysis"
date: 2025-05-22
categories: ["data mining"]
---

![](/img/human-thumb.jpg){.post-thumbnail}

## 데이터 load

```{r}
library(tidyverse)
library(survey)
library(semPlot)
library(caret)
library(randomForest)
library(pROC)
library(dplyr)
library(stringr)
library(kableExtra)

set.seed(1234)

X_train <- read.csv("_data/train_data.csv")
X_test <- read.csv("_data/test_data.csv")
y_train <- factor(X_train$y)
y_test <- factor(X_test$y)
weights_train <- X_train$weights
weights_test <- X_test$weights
X_train <- X_train %>% select(-y, -weights)
X_test <- X_test %>% select(-y, -weights)
```

## 무작위 분류기 (Random Classifier)


```{r}
# 훈련 데이터에서 클래스 비율 계산
class_proportions <- table(y_train) / length(y_train)

# 테스트 데이터에 대한 무작위 예측 생성
# 클래스 비율에 맞게 무작위로 샘플링
random_predictions <- sample(levels(y_test), 
                            size = length(y_test), 
                            replace = TRUE, 
                            prob = class_proportions)
random_predictions <- factor(random_predictions, levels = levels(y_test))

# 가중 혼동 행렬 계산
weighted_confusion_matrix_random <- matrix(0,
                                          nrow = length(levels(y_test)),
                                          ncol = length(levels(y_test)),
                                          dimnames = list(Actual = levels(y_test), Predicted = levels(y_test)))

for (i in 1:length(y_test)) {
  actual_cat <- as.character(y_test[i])
  predicted_cat <- as.character(random_predictions[i])
  weight <- weights_test[i]
  if (actual_cat %in% levels(y_test) && predicted_cat %in% levels(y_test)) {
    weighted_confusion_matrix_random[actual_cat, predicted_cat] <- weighted_confusion_matrix_random[actual_cat, predicted_cat] + weight
  }
}

cat("\n=== 무작위 분류기 가중 혼동 행렬 ===\n")
print(round(weighted_confusion_matrix_random, 2))

# 무작위 분류기 가중 성능 지표 계산
total_weighted_sum_random <- sum(weighted_confusion_matrix_random)
weighted_accuracy_random <- sum(diag(weighted_confusion_matrix_random)) / total_weighted_sum_random
cat("\n=== 무작위 분류기 가중 성능 지표 ===\n")
cat("가중 정확도:", round(weighted_accuracy_random, 4), "\n")

# 각 범주별 가중 정밀도, 재현율, F1-score 계산
weighted_precision_random <- numeric(length(levels(y_test)))
weighted_recall_random <- numeric(length(levels(y_test)))
weighted_f1_score_random <- numeric(length(levels(y_test)))
names(weighted_precision_random) <- names(weighted_recall_random) <- names(weighted_f1_score_random) <- levels(y_test)

for (cat in levels(y_test)) {
  TP <- weighted_confusion_matrix_random[cat, cat]
  FP <- sum(weighted_confusion_matrix_random[, cat]) - TP
  FN <- sum(weighted_confusion_matrix_random[cat, ]) - TP

  weighted_precision_random[cat] <- ifelse((TP + FP) == 0, 0, TP / (TP + FP))
  weighted_recall_random[cat] <- ifelse((TP + FN) == 0, 0, TP / (TP + FN))
  weighted_f1_score_random[cat] <- ifelse((weighted_precision_random[cat] + weighted_recall_random[cat]) == 0, 0,
                                        2 * (weighted_precision_random[cat] * weighted_recall_random[cat]) / (weighted_precision_random[cat] + weighted_recall_random[cat]))
}

cat("\n무작위 분류기 범주별 가중 정밀도:\n")
print(round(weighted_precision_random, 4))

cat("\n무작위 분류기 범주별 가중 재현율:\n")
print(round(weighted_recall_random, 4))

cat("\n무작위 분류기 범주별 가중 F1-score:\n")
print(round(weighted_f1_score_random, 4))
```


## Random Forest 모델 학습 및 평가

```{r}
rf_model <- randomForest(
  x = X_train,
  y = y_train,
  weights = weights_train,
  ntree = 500,
  mtry = floor(sqrt(ncol(X_train))),
  importance = TRUE,
  sampsize = table(y_train),
  replace = TRUE
)
varImpPlot(rf_model)
y_pred <- predict(rf_model, X_test)
actual_classes <- y_test
predicted_classes <- y_pred
test_weights <- weights_test
outcome_levels <- levels(actual_classes)
weighted_confusion_matrix <- matrix(0,
                                   nrow = length(outcome_levels),
                                   ncol = length(outcome_levels),
                                   dimnames = list(Actual = outcome_levels, Predicted = outcome_levels))
for (i in 1:length(actual_classes)) {
  actual_cat <- as.character(actual_classes[i])
  predicted_cat <- as.character(predicted_classes[i])
  weight <- test_weights[i]
  weighted_confusion_matrix[actual_cat, predicted_cat] <- weighted_confusion_matrix[actual_cat, predicted_cat] + weight
}
print(round(weighted_confusion_matrix, 2))
total_weighted_sum <- sum(weighted_confusion_matrix)
weighted_accuracy <- sum(diag(weighted_confusion_matrix)) / total_weighted_sum
cat("\n=== 가중 성능 지표 ===\n")
cat("가중 정확도:", round(weighted_accuracy, 4), "\n")
weighted_precision <- numeric(length(outcome_levels))
weighted_recall <- numeric(length(outcome_levels))
weighted_f1_score <- numeric(length(outcome_levels))
names(weighted_precision) <- names(weighted_recall) <- names(weighted_f1_score) <- outcome_levels

for (cat in outcome_levels) {
  TP <- weighted_confusion_matrix[cat, cat]
  FP <- sum(weighted_confusion_matrix[, cat]) - TP # 해당 열의 합 - TP
  FN <- sum(weighted_confusion_matrix[cat, ]) - TP # 해당 행의 합 - TP
  weighted_precision[cat] <- ifelse((TP + FP) == 0, 0, TP / (TP + FP))
  weighted_recall[cat] <- ifelse((TP + FN) == 0, 0, TP / (TP + FN))
  weighted_f1_score[cat] <- ifelse((weighted_precision[cat] + weighted_recall[cat]) == 0, 0,
                                    2 * (weighted_precision[cat] * weighted_recall[cat]) / (weighted_precision[cat] + weighted_recall[cat]))
}
cat("\n범주별 가중 정밀도:\n")
print(round(weighted_precision, 4))
cat("\n범주별 가중 재현율:\n")
print(round(weighted_recall, 4))
cat("\n범주별 가중 F1-score:\n")
print(round(weighted_f1_score, 4))
y_pred_prob <- predict(rf_model, X_test, type = "prob")
cat("\n비가중 ROC 곡선 (참고용):\n")
plot_roc <- function() {
  num_classes <- length(levels(y_test))
  if (num_classes <= 4 && num_classes > 0) { # 범주가 1개 이하이면 플롯 불가능
    par(mfrow = c(2, ceiling(num_classes/2)))
  } else if (num_classes > 4) {
    par(mfrow = c(2, 2)) # 범주가 많으면 일부만 표시하거나 레이아웃 조정 필요
    warning("범주가 4개 이상입니다. 일부 ROC 곡선만 표시될 수 있습니다. 레이아웃을 조정하거나 플롯 코드 를 수정하세요.")
  } else {
    cat("ROC 곡선을 그릴 범주가 부족합니다.\n")
    return(numeric(0)) # 빈 numeric 반환
  }
  auc_values <- numeric(num_classes)
  names(auc_values) <- levels(y_test)
  for (i in 1:num_classes) {
    class_label <- levels(y_test)[i]
    if(class_label %in% unique(y_test) && class_label %in% colnames(y_pred_prob)) {
      roc_obj <- roc(response = ifelse(y_test == class_label, 1, 0), predictor = y_pred_prob[, class_label])
      auc_values[i] <- auc(roc_obj)
      plot(roc_obj, main = paste("ROC for", class_label, "(Unweighted)"), col = "blue", lwd = 2)
      abline(a = 0, b = 1, lty = 2, col = "gray")
      text(0.5, 0.3, paste("AUC =", round(auc_values[i], 3)), col = "red")
      } else {
        cat("클래스", class_label, "에 대한 ROC 곡선을 그릴 수 없습니다 (데이터 부족).\n")
        auc_values[i] <- NA # AUC 값에 NA 할당
        plot.new() # 빈 플롯 생성
        text(0.5, 0.5, paste("No ROC for", class_label))
      }
  }
  par(mfrow = c(1, 1))
  return(auc_values)
}
auc_values_unweighted <- plot_roc()
cat("\n각 클래스별 비가중 AUC:\n")
print(data.frame(Class = levels(y_test), AUC_Unweighted = auc_values_unweighted))
```

## 모델 튜닝

```{r}
ctrl <- trainControl(
  method = "cv",
  number = 5,
  savePredictions = "final",
  classProbs = TRUE,
  summaryFunction = multiClassSummary
)
param_grid <- expand.grid(
  mtry = floor(sqrt(ncol(X_train)))
)
if (ncol(X_train) == 1) {
  param_grid <- expand.grid(mtry = 1)
}
rf_tuned <- train(
  x = X_train,
  y = y_train,
  method = "rf",
  metric = "Accuracy",
  weights = weights_train,
  trControl = ctrl,
  tuneGrid = param_grid,
  importance = TRUE,
  ntree = 500
)
print(rf_tuned)
y_pred_tuned <- predict(rf_tuned, X_test)
actual_classes_tuned <- y_test
predicted_classes_tuned <- y_pred_tuned
test_weights_tuned <- weights_test
weighted_confusion_matrix_tuned <- matrix(0,
                                         nrow = length(levels(actual_classes_tuned)),
                                         ncol = length(levels(actual_classes_tuned)),
                                         dimnames = list(Actual = levels(actual_classes_tuned), Predicted = levels(actual_classes_tuned)))

for (i in 1:length(actual_classes_tuned)) {
  actual_cat <- as.character(actual_classes_tuned[i])
  predicted_cat <- as.character(predicted_classes_tuned[i])
  weight <- test_weights_tuned[i]
   if (actual_cat %in% levels(actual_classes_tuned) && predicted_cat %in% levels(actual_classes_tuned)) {
      weighted_confusion_matrix_tuned[actual_cat, predicted_cat] <- weighted_confusion_matrix_tuned[actual_cat, predicted_cat] + weight
  } else {
      warning(paste("튜닝 모델: 유효하지 않은 범주 발견: 실제 =", actual_cat, ", 예측 =", predicted_cat, "인 개체 (인덱스:", i, ")"))
  }
}
cat("\n=== 튜닝된 모델 가중 혼동 행렬 ===\n")
print(round(weighted_confusion_matrix_tuned, 2)) # 보기 좋게 반올림하여 출력
total_weighted_sum_tuned <- sum(weighted_confusion_matrix_tuned)
weighted_accuracy_tuned <- sum(diag(weighted_confusion_matrix_tuned)) / total_weighted_sum_tuned
cat("\n=== 튜닝된 모델 가중 성능 지표 ===\n")
cat("가중 정확도:", round(weighted_accuracy_tuned, 4), "\n")
weighted_precision_tuned <- numeric(length(levels(actual_classes_tuned)))
weighted_recall_tuned <- numeric(length(levels(actual_classes_tuned)))
weighted_f1_score_tuned <- numeric(length(levels(actual_classes_tuned)))
names(weighted_precision_tuned) <- names(weighted_recall_tuned) <- names(weighted_f1_score_tuned) <- levels(actual_classes_tuned)
for (cat in levels(actual_classes_tuned)) {
  TP <- weighted_confusion_matrix_tuned[cat, cat]
  FP <- sum(weighted_confusion_matrix_tuned[, cat]) - TP
  FN <- sum(weighted_confusion_matrix_tuned[cat, ]) - TP

  weighted_precision_tuned[cat] <- ifelse((TP + FP) == 0, 0, TP / (TP + FP))
  weighted_recall_tuned[cat] <- ifelse((TP + FN) == 0, 0, TP / (TP + FN))
  weighted_f1_score_tuned[cat] <- ifelse((weighted_precision_tuned[cat] + weighted_recall_tuned[cat]) == 0, 0,
                                    2 * (weighted_precision_tuned[cat] * weighted_recall_tuned[cat]) / (weighted_precision_tuned[cat] + weighted_recall_tuned[cat]))
}

cat("\n튜닝된 모델 범주별 가중 정밀도:\n")
print(round(weighted_precision_tuned, 4))

cat("\n튜닝된 모델 범주별 가중 재현율:\n")
print(round(weighted_recall_tuned, 4))

cat("\n튜닝된 모델 범주별 가중 F1-score:\n")
print(round(weighted_f1_score_tuned, 4))

importance_obj_tuned <- varImp(rf_tuned)

if("importance" %in% names(importance_obj_tuned)) {
  imp_df_tuned <- importance_obj_tuned$importance
} else {
  imp_df_tuned <- importance_obj_tuned
}

var_names_tuned <- rownames(imp_df_tuned)
if("Overall" %in% colnames(imp_df_tuned)) {
  var_importance_tuned <- imp_df_tuned$Overall
} else {
  var_importance_tuned <- imp_df_tuned[,1]
}

importance_df_tuned <- data.frame(
  Variable = var_names_tuned,
  Importance = var_importance_tuned
)
importance_df_tuned <- importance_df_tuned[order(importance_df_tuned$Importance, decreasing = TRUE),]

# 상위 10개 변수 출력 (튜닝된 모델)
top_vars_tuned <- head(importance_df_tuned$Variable, 10)
cat("\n튜닝된 모델에서 가장 중요한 변수 상위 10개:\n")
print(top_vars_tuned)
```

## XGBoost 모델


```{r}
# XGBoost 모델 학습 및 평가
library(xgboost)

# 데이터 변환 (XGBoost는 DMatrix 형식을 사용)
# 먼저 factor를 수치형으로 변환
y_train_numeric <- as.integer(y_train) - 1  # 0부터 시작하는 인덱스로 변환
y_test_numeric <- as.integer(y_test) - 1

# XGBoost DMatrix 생성
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = y_train_numeric, weight = weights_train)
dtest <- xgb.DMatrix(data = as.matrix(X_test), label = y_test_numeric, weight = weights_test)

# 모델 파라미터 설정
xgb_params <- list(
  objective = "multi:softprob",
  eval_metric = "mlogloss",
  num_class = length(levels(y_train)),
  eta = 0.3,               # 학습률
  max_depth = 6,           # 트리 최대 깊이
  min_child_weight = 1,    # 최소 자식 노드 가중치 합
  subsample = 0.8,         # 샘플링 비율
  colsample_bytree = 0.8   # 특성 샘플링 비율
)

# XGBoost 모델 학습
cat("\nXGBoost 모델 학습 중...\n")
xgb_model <- xgb.train(
  params = xgb_params,
  data = dtrain,
  nrounds = 100,           # 부스팅 반복 횟수
  verbose = 0
)
cat("XGBoost 모델 학습 완료.\n")

# 변수 중요도 확인
xgb_importance <- xgb.importance(model = xgb_model)
if (nrow(xgb_importance) > 0) {
  cat("\nXGBoost 변수 중요도 상위 10개:\n")
  print(head(xgb_importance, 10))
  xgb.plot.importance(xgb_importance, top_n = 10)
} else {
  cat("\nXGBoost 변수 중요도를 계산할 수 없습니다.\n")
}

# XGBoost 모델로 테스트 세트 예측
cat("\nXGBoost 모델로 테스트 세트 예측 중...\n")
xgb_pred_probs <- predict(xgb_model, dtest)
# 예측 확률을 행렬로 변환 (각 클래스별 확률값)
xgb_pred_probs_matrix <- matrix(xgb_pred_probs, nrow = length(y_test), byrow = TRUE)
# 가장 높은 확률을 가진 클래스를 예측값으로 선택
y_pred_xgb_idx <- apply(xgb_pred_probs_matrix, 1, which.max) - 1  # 0-based 인덱스
# 다시 factor로 변환
y_pred_xgb <- factor(levels(y_test)[y_pred_xgb_idx + 1], levels = levels(y_test))
cat("예측 완료.\n")

# 가중 혼동 행렬 계산
weighted_confusion_matrix_xgb <- matrix(0,
                                       nrow = length(levels(y_test)),
                                       ncol = length(levels(y_test)),
                                       dimnames = list(Actual = levels(y_test), Predicted = levels(y_test)))

for (i in 1:length(y_test)) {
  actual_cat <- as.character(y_test[i])
  predicted_cat <- as.character(y_pred_xgb[i])
  weight <- weights_test[i]
  if (actual_cat %in% levels(y_test) && predicted_cat %in% levels(y_test)) {
    weighted_confusion_matrix_xgb[actual_cat, predicted_cat] <- weighted_confusion_matrix_xgb[actual_cat, predicted_cat] + weight
  }
}

cat("\n=== XGBoost 모델 가중 혼동 행렬 ===\n")
print(round(weighted_confusion_matrix_xgb, 2))

# XGBoost 모델 가중 성능 지표 계산
total_weighted_sum_xgb <- sum(weighted_confusion_matrix_xgb)
weighted_accuracy_xgb <- sum(diag(weighted_confusion_matrix_xgb)) / total_weighted_sum_xgb
cat("\n=== XGBoost 모델 가중 성능 지표 ===\n")
cat("가중 정확도:", round(weighted_accuracy_xgb, 4), "\n")

# 각 범주별 가중 정밀도, 재현율, F1-score 계산
weighted_precision_xgb <- numeric(length(levels(y_test)))
weighted_recall_xgb <- numeric(length(levels(y_test)))
weighted_f1_score_xgb <- numeric(length(levels(y_test)))
names(weighted_precision_xgb) <- names(weighted_recall_xgb) <- names(weighted_f1_score_xgb) <- levels(y_test)

for (cat in levels(y_test)) {
  TP <- weighted_confusion_matrix_xgb[cat, cat]
  FP <- sum(weighted_confusion_matrix_xgb[, cat]) - TP
  FN <- sum(weighted_confusion_matrix_xgb[cat, ]) - TP

  weighted_precision_xgb[cat] <- ifelse((TP + FP) == 0, 0, TP / (TP + FP))
  weighted_recall_xgb[cat] <- ifelse((TP + FN) == 0, 0, TP / (TP + FN))
  weighted_f1_score_xgb[cat] <- ifelse((weighted_precision_xgb[cat] + weighted_recall_xgb[cat]) == 0, 0,
                                     2 * (weighted_precision_xgb[cat] * weighted_recall_xgb[cat]) / (weighted_precision_xgb[cat] + weighted_recall_xgb[cat]))
}

cat("\nXGBoost 모델 범주별 가중 정밀도:\n")
print(round(weighted_precision_xgb, 4))

cat("\nXGBoost 모델 범주별 가중 재현율:\n")
print(round(weighted_recall_xgb, 4))

cat("\nXGBoost 모델 범주별 가중 F1-score:\n")
print(round(weighted_f1_score_xgb, 4))
```

## 로지스틱 회귀 모델

```{r}
# 다항 로지스틱 회귀 모델 학습 및 평가
library(nnet)

# 다항 로지스틱 회귀 모델 학습 (가중치 적용)
cat("\n다항 로지스틱 회귀 모델 학습 중...\n")
# X_train에 열 이름이 없으면 추가
if(is.null(colnames(X_train))) {
  colnames(X_train) <- paste0("V", 1:ncol(X_train))
}

# 학습 데이터를 데이터프레임으로 변환
train_df <- as.data.frame(X_train)
train_df$y <- y_train

# 다항 로지스틱 회귀 모델 학습
logistic_model <- multinom(
  y ~ .,
  data = train_df,
  weights = weights_train,
  trace = FALSE
)
cat("다항 로지스틱 회귀 모델 학습 완료.\n")

# 모델 요약
print(summary(logistic_model))

# 테스트 세트 예측
cat("\n다항 로지스틱 회귀 모델로 테스트 세트 예측 중...\n")
# X_test에 열 이름이 없으면 추가
if(is.null(colnames(X_test))) {
  colnames(X_test) <- paste0("V", 1:ncol(X_test))
}
y_pred_logistic <- predict(logistic_model, newdata = as.data.frame(X_test))
cat("예측 완료.\n")

# 가중 혼동 행렬 계산
weighted_confusion_matrix_logistic <- matrix(0,
                                           nrow = length(levels(y_test)),
                                           ncol = length(levels(y_test)),
                                           dimnames = list(Actual = levels(y_test), Predicted = levels(y_test)))

for (i in 1:length(y_test)) {
  actual_cat <- as.character(y_test[i])
  predicted_cat <- as.character(y_pred_logistic[i])
  weight <- weights_test[i]
  if (actual_cat %in% levels(y_test) && predicted_cat %in% levels(y_test)) {
    weighted_confusion_matrix_logistic[actual_cat, predicted_cat] <- weighted_confusion_matrix_logistic[actual_cat, predicted_cat] + weight
  }
}

cat("\n=== 다항 로지스틱 회귀 모델 가중 혼동 행렬 ===\n")
print(round(weighted_confusion_matrix_logistic, 2))

# 다항 로지스틱 회귀 모델 가중 성능 지표 계산
total_weighted_sum_logistic <- sum(weighted_confusion_matrix_logistic)
weighted_accuracy_logistic <- sum(diag(weighted_confusion_matrix_logistic)) / total_weighted_sum_logistic
cat("\n=== 다항 로지스틱 회귀 모델 가중 성능 지표 ===\n")
cat("가중 정확도:", round(weighted_accuracy_logistic, 4), "\n")

# 각 범주별 가중 정밀도, 재현율, F1-score 계산
weighted_precision_logistic <- numeric(length(levels(y_test)))
weighted_recall_logistic <- numeric(length(levels(y_test)))
weighted_f1_score_logistic <- numeric(length(levels(y_test)))
names(weighted_precision_logistic) <- names(weighted_recall_logistic) <- names(weighted_f1_score_logistic) <- levels(y_test)

for (cat in levels(y_test)) {
  TP <- weighted_confusion_matrix_logistic[cat, cat]
  FP <- sum(weighted_confusion_matrix_logistic[, cat]) - TP
  FN <- sum(weighted_confusion_matrix_logistic[cat, ]) - TP

  weighted_precision_logistic[cat] <- ifelse((TP + FP) == 0, 0, TP / (TP + FP))
  weighted_recall_logistic[cat] <- ifelse((TP + FN) == 0, 0, TP / (TP + FN))
  weighted_f1_score_logistic[cat] <- ifelse((weighted_precision_logistic[cat] + weighted_recall_logistic[cat]) == 0, 0,
                                          2 * (weighted_precision_logistic[cat] * weighted_recall_logistic[cat]) / (weighted_precision_logistic[cat] + weighted_recall_logistic[cat]))
}

cat("\n다항 로지스틱 회귀 모델 범주별 가중 정밀도:\n")
print(round(weighted_precision_logistic, 4))

cat("\n다항 로지스틱 회귀 모델 범주별 가중 재현율:\n")
print(round(weighted_recall_logistic, 4))

cat("\n다항 로지스틱 회귀 모델 범주별 가중 F1-score:\n")
print(round(weighted_f1_score_logistic, 4))
```

## 최종 모델 성능 비교

```{r}
# 모든 모델의 가중 정확도 비교
final_metrics <- data.frame(
  Metric = c("가중 정확도"),
  RandomForest = c(round(weighted_accuracy_tuned * 100, 2)),
  # C50_Tree = c(round(weighted_accuracy_c50 * 100, 2)),
  XGBoost = c(round(weighted_accuracy_xgb * 100, 2)),
  # SVM = c(round(weighted_accuracy_svm * 100, 2)),
  # KNN = c(round(weighted_accuracy_knn * 100, 2)),
  LogisticRegression = c(round(weighted_accuracy_logistic * 100, 2))
)

# 결과 출력
cat("\n=== 최종 모델 가중 정확도 비교 ===\n")
print(kable(final_metrics, caption = "원본 모델 vs 튜닝 모델 가중 정확도 비교"))

# 클래스별 가중 성능 지표 (튜닝된 모델 결과 사용 권장)
cat("\n=== 튜닝된 모델 범주별 가중 성능 지표 ===\n")
class_weighted_metrics_tuned <- data.frame(
  Class = levels(y_test), # y_test 또는 actual_classes_tuned 사용 가능
  Weighted_Precision = round(weighted_precision_tuned, 4),
  Weighted_Recall = round(weighted_recall_tuned, 4),
  Weighted_F1 = round(weighted_f1_score_tuned, 4)
)
print(kable(class_weighted_metrics_tuned, caption = "튜닝된 모델 클래스별 가중 성능 지표"))


# 최종 변수 중요도 요약 (튜닝된 모델 결과 사용)
cat("\n=== 튜닝된 모델 변수 중요도 ===\n")
print(kable(head(importance_df_tuned, 10), caption = "튜닝된 모델 상위 10개 중요 변수 (가중치 고려 학습 결과)"))
```
