---
title: "XGBoost"
date: 2025-06-14
categories: ["data mining", "학부 정리"]
---

![](/img/stat-thumb.jpg){.post-thumbnail}

- 결측치 자체 처리

## 회귀

- similarity score: $\frac{(sum of residuals)^2}{number of residuals + λ}$
- λ를 높이면 잔차의 수에 따른 민감도를 완화할 수 있다. overfitting 방지
- gain: $Left_{similarity} + Right_{similarity} - Parent_{similarity}$
- gain값이 높은 속성을 선택
- gain 값이 특정 γ보다 낮으면 가지치기
- leaf value: $\frac{sum of residuals}{number of residuals + λ}$
- 예측값 갱신: $기존 값 + learning rate(eta) * leaf value$로 예측

## 분류

- similarity score: $\frac{(sum of residuals)^2}{∑_{i=1}^{n}(previous probability_i * (1 - previous probability_i)) + λ}$
- leaf value: $\frac{sum of residuals}{∑_{i=1}^{n}(previous probability_i * (1 - previous probability_i)) + λ}$
- 예측값 갱신: log(odds) = $log \frac{p}{1 - p} + learning rate * leaf value$
    - new probability = $\frac{e^{log(odds)}}{1 + e^{log(odds)}}$
- 잔차는 점점 0에 수렴하고, probability는 실제 값(1, 0)에 수렴한다.
- min_child_weight: leaf node의 최소 가중치 합($∑_{i=1}^{n} (previous probability * (1 - previous probility$)이 이 값보다 작으면 분할하지 않음
