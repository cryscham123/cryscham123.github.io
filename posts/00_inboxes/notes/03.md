---
title: "다중 공산성"
date: 2025-08-04
categories: ["대학원"]
---

![](/img/stat-thumb.jpg){.post-thumbnail}

- [해당 논문 참고](https://dspace.mit.edu/bitstream/handle/1721.1/48530/multicollinearit00farr.pdf)

## 다중 공산성

- 독립 변수 집합 X 가 본래는 서로 독립적(직교적)이어야 한다는 가정에서 벗어난 정도.

## 문제

- 회귀계수 `추정치의 분산이 커지고`, 결과적으로 `추정이 매우 불안정`해짐.
- 특정 독립변수가 설명하는 `효과`를 다른 변수와 `구분하기 어려워짐`.
- 예측력이나 설명력이 높게 나올 수 있지만, `모형의 구조적 해석은 신뢰할 수 어려움`.
- 물론 이런 문제들은 `중요한 변수`에 영향을 줄 때 생김.


## 해결 방법

### 잘못된 예시

1. 그냥 둔다
1. 직교화
    - PCA(주성분 분석)나 요인분석 등을 사용하여 독립변수들을 직교화
    - 요인이 해석 불가능한 경우가 아니면 좋지 않음
1. 규칙 기반 접근: 상관계수가 0.8이 넘는걸 제거하거나, 종속변수의 상관계수보다 높은 변수 제거
    - 직관에만 의존하고, 잘못된 결론을 낳을 수 있음

### 좋은 예시

다중 공산성의 문제를 세부적으로 진단하고 각각에 대해 해결 방법을 다음과 같이 제시한다.

1. 전 변수 집합 대상:
    - 독립변수의 전체 차원이 부족한 경우
    - 표본을 더 모으거나 새로운 변수를 도입
1. 개별 변수의 계수 추정이 불안정한 경우(표본 오차가 큰 경우)
    - 특정 변수가 다른 변수들의 선형 결합으로 표현될 수 있는 경우
    - VIF가 10을 넘을 경우
    - 덜 중요하다면 제거
    - 중요하다면 변수에 대한 독립적 정보 보강(세분화, ...)
1. 두 변수의 상관계수가 높은 경우
    - 둘의 관계를 설명하는 제 3의 변수 도입(요인 분석 등)
    - 둘 중 하나를 제거
