[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "Inboxes\n\n\n\n\n\n\n분류되지 않은 노트 (2)\n    \n\n\n\nTitle\nDate\nCategories\n\n\n\n\n나의 단점에 관한 고찰\n2025-03-06\n인생\n\n\n인간 관계론 - 데일 카네기\n2025-02-02\n독서, 인간 관계\n\n\n\n\n    \n\n\n\n\n\n\n\n\nProjects\n\n\n\n\n\n현재 진행중인 프로젝트\n\n\n\n\n    \n    \n    \n        \n            \n                \n                    학부 3학년 1학기\n                    on-going\n                \n                \n                    Started: 2024-12-21\n                    \n                    Calculating...\n                \n                \n                    산업공학 학부\n                \n                3학년 1학기 학부 할 일 총 정리\n            \n        \n        \n\n\n\n\n\n\n\n\nAreas\n\n\n\n\n\n관리 / 책임 영역\n\n\n\n\n    \n    \n        \n            42 Seoul\n        \n        \n        \n            선형대수\n        \n        \n        \n            Machine Learning\n        \n        \n\n\n\n\n\n\n\n\nResources\n\n\n\n\n\n진행 전인 프로젝트\n\n\n\n\n    \n    \n    \n        \n            \n                \n                    TOFEL 준비\n                    before-start\n                \n                \n                    Started: None\n                    \n                    Calculating...\n                \n                \n                    English\n                \n                준비해 봅시다\n            \n        \n        \n\n\n\n관심 분야\n\n\n\n\n    \n    \n        \n            Blog\n        \n        \n        \n            Terraform\n        \n        \n        \n            Problem Solving\n        \n        \n        \n            Smart Contract\n        \n        \n        \n            금융\n        \n        \n        \n            Quantum Programming\n        \n        \n\n\n\n\n\n\n\n\nArchives\n\n\n\n\n\n완료된 프로젝트\n\n\n\n\n    \n    \n    \n        \n            \n                \n                    ADP 실기 준비\n                    failed\n                \n                \n                    Started: 2024-12-21\n                    \n                    Calculating...\n                \n                \n                    자격증 데이터 분석 python\n                \n                ADP 실기를 준비해 봅시다.\n            \n        \n        \n        \n            \n                \n                    AWS SAA 준비\n                    completed\n                \n                \n                    Started: 2024-04-15\n                    \n                    Calculating...\n                \n                \n                    자격증 cloud\n                \n                AWS SAA를 준비해 봅시다.\n            \n        \n        \n        \n            \n                \n                    2학년 2학기 학부 정리\n                    completed\n                \n                \n                    Started: 2024-09-02\n                    \n                    Calculating...\n                \n                \n                    산업공학 학부\n                \n                2학년 2학기 학부 개념 정리\n            \n        \n        \n        \n            \n                \n                    ADP 필기 준비\n                    completed\n                \n                \n                    Started: 2025-02-02\n                    \n                    Calculating...\n                \n                \n                    자격증 데이터 분석\n                \n                과연 2번째 도전은 성공할 것인가\n            \n        \n        \n\n\n\n보관중인 자료\n\n\n\n\n    \n    \n        \n            vault\n        \n        \n        \n            k8s"
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/scholarships/1.html",
    "href": "posts/01_projects/bs_3_1/notes/scholarships/1.html",
    "title": "자기 소개서",
    "section": "",
    "text": "자기소개 및 가치관 (500자 이내)\n\n저는 데이터 분석과 IT 인프라 설계 분야에 깊은 관심을 가지고 있는 산업공학과 학생입니다. 산업공학을 전공하며 시스템 최적화와 데이터 기반 의사결정에 대한 이론을 배우며 데이터 분석 및 IT 인프라 설계 분야에 관심을 가지게 되었고, 이를 실무에 적용할 수 있는 지식을 학습하고자 42서울 교육기관에서 2년 동안 IT 관련 학습을 진행했습니다. 또한 이 기간 동안 AWS와 ADsP(Advanced Data Analytics Semi-Professional) 자격증을 취득하며 클라우드 컴퓨팅과 데이터 분석에 대한 기초 역량을 쌓았습니다.\n저는 효율적이고 신뢰할 수 있는 시스템을 구축하는 것을 가장 중요한 가치로 삼고 있습니다. 이러한 시스템은 데이터 손실과 보안 위협을 방지할 뿐만 아니라, 장기적인 성장의 토대가 되기 때문입니다. 현재는 데이터와 블록체인 기술을 활용하여 복잡한 문제를 단순화하고, 효율적인 해결책을 찾는 데 큰 관심을 가지고 있습니다. 앞으로도 지속적인 학습과 경험을 통해 해당 분야에서 전문성을 키워가고자 합니다.\n\n졸업 후 IT 및 블록체인 분야에 관련해서 이루고자 하는 꿈과 선정 사유 (500자 이내)\n\n저는 데이터 분석, IT 인프라, 블록체인 기술을 융합하여 현실의 복잡한 문제들을 해결하고 혁신적인 가치를 창출하는 데 기여하고 싶습니다. 전공 수업과 프로젝트를 통해 데이터가 지닌 잠재력을 배워가면서, 동시에 데이터의 신뢰성과 보안이라는 중요한 과제에 대해서도 깊이 고민하게 되었습니다. 특히 42서울에서의 학습 경험을 통해, 안전하고 효율적인 데이터 활용을 위해서는 IT 인프라와 블록체인 기술의 역할이 매우 중요하다는 것을 깨달았습니다. 이러한 경험들을 바탕으로 IT 인프라와 블록체인 기술에 더욱 관심을 가지게 되었고, 관련 기술 서적과 온라인 자료를 통해 꾸준히 학습하며 이해의 폭을 넓혀가고 있습니다. 앞으로도 끊임없이 배우고 성장하여 데이터의 가치를 안전하게 실현할 수 있는 시스템을 만드는 데 기여하고 싶습니다.\n\n목표 달성을 위한 그간의 성과 및 계획 (500자 이내)\n\n저의 주요 성과로는 42서울에서의 프로젝트 경험과 AWS, ADsP 자격증 취득을 들 수 있습니다. 42서울에서 진행한 Solidity 기반 이더리움 스마트 컨트랙트 설계 및 배포 프로젝트를 통해 블록체인의 핵심 원리와 실제 활용 방안을 학습했습니다. 또한 Vagrant, Kubernetes(K8s), ArgoCD, GitLab helm 배포 프로젝트를 수행하며 온프레미스 환경에서의 인프라 설계와 개발 환경 관리 역량을 키웠고, 이를 통해 클라우드와 온프레미스 환경의 IT 인프라 운영에 대한 실질적인 이해도를 높일 수 있었습니다. 향후 계획으로는 학부 과정에 충실히 임하면서 데이터사이언스 대학원 진학을 위한 준비를 체계적으로 진행하고자 합니다. 대학원에서는 빅데이터 처리, 머신러닝, 딥러닝 등 데이터 분석의 핵심 기술을 심도 있게 학습하고자 합니다. 이와 병행하여 온라인 강좌 수강과 실전 프로젝트 수행을 통해 IT 인프라 및 블록체인 분야의 역량을 지속적으로 강화하고, 각종 공모전 참여를 통해 실력을 검증받고자 합니다. 궁극적으로는 이러한 기술들을 융합하여 데이터의 신뢰성과 보안을 보장하고, 효율적인 시스템을 설계하는 전문가로 성장하고 싶습니다.\n\n\n\n 맨 위로",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Scholarships",
      "자기 소개서"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/product/01.html#수업-요약",
    "href": "posts/01_projects/bs_3_1/notes/product/01.html#수업-요약",
    "title": "Matching Supply with Demand",
    "section": "수업 요약",
    "text": "수업 요약\n\n생산시스템관리를 어떤 관점에서 바라보며 학습하는지\n\n수요와 공급 관점에서(운영 o, 제조 x)\n기업: 유/무형의 제품을 생산해서 수요(양, timing, 품질)에 맞게 공급하기 위해 노력하는 집단\n\n수요와 공급이 뭔지\n\n수요 공급 법칙: 경제학 기본적인 법칙. 운영 관리자(OM)인 우리는 이거랑 다르게 바라봄. 가격 조정만으로 수요와 공급 맞추기 어려움\n\n수요 곡선, 공급 곡선, surplus, shortage, equilibrium(균형 가격)\n\n\n수요와 공급이 안 맞는 사례\n\n마스크, 먹태깡: 수요는 빠르게 변하는데, 공급은 느리게 변함\n\n수요를 예측하고, 설비를 미리 준비하는 과학적 도구가 필요\n\n철광석:\n\n공급: 철광석\n수요: 철강\n공급이 많으면 가격 떨어짐\n수요가 많으면 가격 올라감\n수요와 공급을 맞추기 위해 철광석 공급을 안함\n\n응급실:\n\n공급: 의사\n수요: 환자\n공급이 많으면 underutilized(활용률이 떨어짐)\n수요가 많으면 치료를 못 받음\n수요와 공급을 맞추기 위해 수요를 잘 예측해야 하고, 우선순위를 잘 파악해야함\n\nAir Travel\n\n공급: 비행기 자리\n수요: 특정 시간과 장소에 여행\n공급이 많으면 자리가 빔\n수요가 많으면 승객이 다른 여객기 탐\n수요와 공급을 맞추기 위해 가격을 조정함, 예약을 받음\n\n끊임없이 변하는 수요로 인해 예측이 불확실함\n공급이 탄력적이지 않음\n\n과학적 도구로 최대한 예측하고, 탄력적인 공급을 하는 관점으로 학습할 예정\n다음부터 본격적으로 재고에 대해 설명할 예정\n생산 시스템의 performance: 서로 상충됨. business 목표에 맞게 balance를 잘 맞춰야함\n\ncost\nquality: 품질이 얼마나 좋고 일관되냐\nvariety: 다양한 사용자의 니즈를 얼마나 잘 맞추냐\ntime",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Product",
      "Matching Supply with Demand"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/computer/00.html",
    "href": "posts/01_projects/bs_3_1/notes/computer/00.html",
    "title": "intro",
    "section": "",
    "text": "개별 과제는 없음\n8주차 ,9주차도 안나옴\n8주차는 중간프로젝트 업로드\n11주차 시험. LMS로 봄\n15주차 학교 안나옴 발표는 유튜브로 찍어서\n\n\n\n 맨 위로",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Computer",
      "intro"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/00.html#process-of-conducting-an-or-study",
    "href": "posts/01_projects/bs_3_1/notes/OR/00.html#process-of-conducting-an-or-study",
    "title": "Overview",
    "section": "process of conducting an OR study",
    "text": "process of conducting an OR study\n\n\n\n\n\nflowchart TD\n  A(Collect data) --&gt; B(Define the problem)\n  B --&gt; C{Data are sufficient?}\n  C --&gt;|No| A\n  C --&gt;|Yes| D(Formulate a model)\n  D --&gt; E(Solve the model)\n  E --&gt; F{Model is good?}\n  F --&gt;|Yes| G(Interpret results make suggestions)\n  F --&gt;|No| D\n\n\n\n\n\n\n\nOR cant solve everything\nAim of course: know what may be solved by OR and what cannot be solve by OR",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Overview"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/00.html#model",
    "href": "posts/01_projects/bs_3_1/notes/OR/00.html#model",
    "title": "Overview",
    "section": "model",
    "text": "model\n\ndescision variables\nobjective function\nconstraints\n\n\nKnapSack(backpack) Problem\n\nLinear Programming\n\n\\[\\begin{aligned}\nmax & \\sum_{i=1}^{n} v_i x_i \\\\\ns.t. & \\sum_{i=1}^{n} w_i x_i \\leq B \\\\\n& 0 \\leq x_i \\leq 1\n\\end{aligned}\\]\n\nInteger Programming\n\n\\[\\begin{aligned}\nmax & \\sum_{i=1}^{n} v_i x_i \\\\\ns.t. & \\sum_{i=1}^{n} w_i x_i \\leq B \\\\\n& x_i \\in \\{0, 1\\}\n\\end{aligned}\\]",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Overview"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/05.html#algorithm",
    "href": "posts/01_projects/bs_3_1/notes/OR/05.html#algorithm",
    "title": "Linear Programming",
    "section": "Algorithm",
    "text": "Algorithm\n\nSimplex Method\n\nInitialization: Collect 1 CFP\nOptimality test: find better adj\n\nObj * Adj &gt; 0: better\nObj * Adj = 0: not changed\nObj * Adj &lt; 0: worse",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Linear Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/04.html#business-analytics",
    "href": "posts/01_projects/bs_3_1/notes/OR/04.html#business-analytics",
    "title": "Intro",
    "section": "Business Analytics",
    "text": "Business Analytics\n\nData Analysis\n\nDescriptive Analytics: What happened?\nPredictive Analytics: What will happen?\n\nOperations Research\n\nPrescriptive Analytics: What should we do? (Optimization)",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Intro"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/04.html#process-of-or-study",
    "href": "posts/01_projects/bs_3_1/notes/OR/04.html#process-of-or-study",
    "title": "Intro",
    "section": "Process of OR Study",
    "text": "Process of OR Study\n\n\n\n\n\nflowchart LR\n  A(Collect data) --&gt; B(Define the problem)\n  B --&gt; C{Data are sufficient?}\n  C --&gt;|No| A\n  C --&gt;|Yes| D(Formulate a model)\n  D --&gt; E(Solve the model)\n  E --&gt; F{Model is good?}\n  F --&gt;|Yes| G(Interpret results make suggestions)\n  F --&gt;|No| D",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Intro"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/04.html#model",
    "href": "posts/01_projects/bs_3_1/notes/OR/04.html#model",
    "title": "Intro",
    "section": "Model",
    "text": "Model\n\nLinear Programming\n\n\\[\\begin{aligned}\nmax & \\sum_{i=1}^{n} v_i x_i \\\\\ns.t. & \\sum_{i=1}^{n} w_i x_i \\leq B \\\\\n& \\color{red}{0 \\leq x_i \\leq 1}\n\\end{aligned}\\]\n\nInteger Programming\n\n\\[\\begin{aligned}\nmax & \\sum_{i=1}^{n} v_i x_i \\\\\ns.t. & \\sum_{i=1}^{n} w_i x_i \\leq B \\\\\n& \\color{red}{x_i \\in \\{0, 1\\}}\n\\end{aligned}\\]",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Intro"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/statistics/00.html#통계학",
    "href": "posts/01_projects/bs_3_1/notes/statistics/00.html#통계학",
    "title": "확률과 통계 1 정리",
    "section": "통계학",
    "text": "통계학\n\n불확실한 상황 하에서 데이터에 근거하여 과학적인 의사결정을 도출하기 위한 이론과 방법의 체계\n모집단으로 부터 수집된 데이터(sample)를 기반으로 모집단의 특성을 추론하는 것을 목표로 한다.\n\n\n\n\n통계적 의사결정 과정",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Statistics",
      "확률과 통계 1 정리"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/statistics/00.html#확률",
    "href": "posts/01_projects/bs_3_1/notes/statistics/00.html#확률",
    "title": "확률과 통계 1 정리",
    "section": "확률",
    "text": "확률\n\n고전적 의미: 표본공간에서 특정 사건이 차지하는 비율\n통계적 의미: 특정 사건이 발생하는 상대도수의 극한\n\n각 원소의 발생 가능성이 동일하지 않아도 무한한 반복을 통해 수렴하는 값을 구할 수 있다.",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Statistics",
      "확률과 통계 1 정리"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/statistics/00.html#확률-분포-정의-단계",
    "href": "posts/01_projects/bs_3_1/notes/statistics/00.html#확률-분포-정의-단계",
    "title": "확률과 통계 1 정리",
    "section": "확률 분포 정의 단계",
    "text": "확률 분포 정의 단계\n\n\nExperiment(확률실험): 동일한 조건에서 독립적으로 반복할 수 있는 실험이나 관측\nSample space(표본공간): 모든 simple event의 집합\nEvent(사건): 실험에서 발생하는 결과 (부분 집합)\nSimple event(단순사건): 원소가 하나인 사건\n확률 변수: 확률실험의 결과를 수치로 나타낸 변수",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Statistics",
      "확률과 통계 1 정리"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/statistics/00.html#확률-분포",
    "href": "posts/01_projects/bs_3_1/notes/statistics/00.html#확률-분포",
    "title": "확률과 통계 1 정리",
    "section": "확률 분포",
    "text": "확률 분포\n\n이산 확률 분포: 이산 표본 공간, 연속 표본공간에서 정의 가능포\n\n베르누이 분포: 각 시행은 서로 독립적이고, 실패와 성공 두 가지 결과만 존재.\n\n단 모집단의 크기가 충분히 크고, 표본의 크기가 충분히 작다면 비복원 추출에서도 유효\n\n이항 분포: n번의 독립적인 베르누이 시행을 수행하여 성공 횟수를 측정\n기하 분포: 성공 확률이 p인 베르누이 시행에서 첫 성공까지의 시행 횟수\n초기하 분포: 베르누이 시행이 아닌 시행에서 성공하는 횟수\n포아송 분포: 임의의 기간동안 어떤 사건이 간헐적으로 발생할 때, 사건이 발생하는 횟수\n\nn이 매우 크고, p가 매우 작을 때, 이항 분포를 포아송 분포로 근사할 수 있다.\n\n\n연속 확률 분포: 연속 표본 공간에서 정의 가능\n\n균일 분포\n정규 분포\n\n\\(X + Y \\sim N(μ_1 + μ_2, σ_1^2 + σ_2^2)\\)\n\nt 분포\n\n자유도가 커질수록 표준 정규분포에 근사함.\n t(n)\n\nf 분포\n\n\\(F = \\frac{X_1/ν_1}{X_2/ν_2}\\), \\(X_1 \\sim χ^2(ν_1)\\), \\(X_2 \\sim χ^2(ν_2)\\)\n\n감마 분포\n\n카이제곱 분포: α = v/2, θ = 2 인 감마분포\n\n\\(Z_i \\sim N(0,1)\\)일 때, \\(Z_1^2 + Z_2^2 + ...  + Z_n^2 \\sim χ^2(n)\\)\n\\(X_i\\)가 서로 독립이고, 자유도가 \\(ν_i\\)인 카이제곱분포를 따른다면, \\(X_1 + X_2 + ... + X_n \\sim x^2(ν_1 + ν_2 + ... + ν_n)\\)\n\n지수 분포: 포아송 분포에서 사건 발생 간격의 분포\n\n\\(\\sum_{i=1}^{n} X_i \\sim Γ(n, θ)\\), \\(θ = 1/λ\\)",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Statistics",
      "확률과 통계 1 정리"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/statistics/00.html#표본의-분포",
    "href": "posts/01_projects/bs_3_1/notes/statistics/00.html#표본의-분포",
    "title": "확률과 통계 1 정리",
    "section": "표본의 분포",
    "text": "표본의 분포\n\n샘플링에 따라 통계량이 다른 값을 가질 수 있다. 따라서 통계량의 분포를 이용한 통계적 추론이 가능하다.\n통계량: 표본의 특성을 나타내는 값\n추정량: 아래의 조건을 만족하는 통계량\n\n불편성: 추정량의 기대값이 추정하려는 모수와 같아야 한다.\n효율성: 분산이 작아야 한다. 표본의 갯수가 많아질수록 분산이 작아져야 한다.\n\n\n\n표본 평균의 분포\n\n모집단의 분포와 관계없이, 모집단의 평균이 μ이고, 분산이 \\(σ^2\\)이면, \\(\\bar{X}\\)의 평균은 μ이고, 분산은 \\(σ^2/n\\)인 정규분포를 따른다.\n\n단 모집단의 분포에 따라 표본의 크기가 충분히 커야함. (중심극한정리)\n\n만약 모집단의 분산을 모를 경우, σ를 s로 대체하여, t분포를 따르는 표본 평균의 분포를 구할 수 있다.\n\n\n\n표본 분산의 분포\n\n정규 모집단으로 부터 나온 표본의 분산 S에 대하여, \\(\\frac{(n-1)S^2}{σ^2}\\)은 자유도가 n-1인 카이제곱 분포를 따른다.\n\n모집단이 정규분포를 따르지 않을 경우, 비모수적인 방법을 사용해야 한다.\n\n두 정규 모집단으로부터 계산되는 표본분산의 비율은 f-분포를 따른다.",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Statistics",
      "확률과 통계 1 정리"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/07.html#data-and-information",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/07.html#data-and-information",
    "title": "Data Modeling and the Entity-Relationship Model",
    "section": "Data and information",
    "text": "Data and information\n\nData: raw facts. recorded facts\nInformation: meaningful context\nKnowledge: information + 가치",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Data Modeling and the Entity-Relationship Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/07.html#what-is-information-system",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/07.html#what-is-information-system",
    "title": "Data Modeling and the Entity-Relationship Model",
    "section": "What is information system?",
    "text": "What is information system?\n\nSystem: a set of components that interact to achieve some purpose or goal\nInformation System: composed of hardware, software, data, procedures, people",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Data Modeling and the Entity-Relationship Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/07.html#system-analysis-and-design",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/07.html#system-analysis-and-design",
    "title": "Data Modeling and the Entity-Relationship Model",
    "section": "System Analysis and Design",
    "text": "System Analysis and Design\n\nSystem analysis and design: process of creating and maintaining information systems\nclassic methodology: SDLC\n\n\nSDLC (System Development Life Cycle)\n\n\n\nSDLC\n\n\n\nSystem definitions: 예산 편상, 위험 분석, …\nRequirements analysis\nComponent design\nImplementation\nSystem maintenance\n\n\ndatabase development process\n\nRequirements analysis\ninput: the project plan\noutput: a set of approved requirements -&gt; data model (ER model로 conceptual design)\nsource: Use cases, Business rules\nComponent Design: Relational Database Design (상세 설계)\nImplementation",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Data Modeling and the Entity-Relationship Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/07.html#er-model",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/07.html#er-model",
    "title": "Data Modeling and the Entity-Relationship Model",
    "section": "ER model",
    "text": "ER model\n\nEntities\n\nEntity class\nEntity instance\n\nAttributes: Data type, Properties(default, constraints)\nIdentifiers\n\nunique\nNonunique: identifies a set of instances\n\nRelationships\n\nbinary relationship\n\nMaximum cardinality: 1:1(A has a B), 1:N(A has a set of B), M:N\nMinimum cardinality: 0, 1\n\nternary relationship",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Data Modeling and the Entity-Relationship Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/07.html#entit-relationship-diagram",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/07.html#entit-relationship-diagram",
    "title": "Data Modeling and the Entity-Relationship Model",
    "section": "Entit-Relationship Diagram",
    "text": "Entit-Relationship Diagram\n\nEntity classes: rectangle\nRelationships: diamond\nmaximum cardinality: inside the diamond\nminimum cardinality: oval or hash mark next to diamond\nstrong entity: 독자적으로 존재 가능. 강한개체 관계는 점선\nNon-ID-dependent: identifier에 다른 entity의 identifier가 포함되어 있지 않음. 점선으로 표기(non-identifying relationship)\nweak entity: 약, 강 관계는 실선. IS: rounded square, traditional: 2 layer square\nID-dependent: identifier에 다른 entity의 identifier가 포함되어 있음. 실선으로 표기(identifying relationship)\nassociative entity: relationship이 entity로 변환된 것.\nMany-to-many relationship을 2개의 1:N으로 변환\nsuper type, sub type: 상속관계. sub type is a super type\n\nexclusive: Discriminator attribute가 필요함\ninclusive\n\nrecursive relationship\nBusiness rule: build-in constraints, trigger, stored procedure, application code로 구현 가능\ndata model validation: form, report를 이용한 prototyping",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Data Modeling and the Entity-Relationship Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#the-importance-of-dbs-today",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#the-importance-of-dbs-today",
    "title": "An Overview of Database",
    "section": "The Importance of DBs Today",
    "text": "The Importance of DBs Today\n\nDepend upon database: Internet, Web 2.0, IOT",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#why-and-how-databases-are-used",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#why-and-how-databases-are-used",
    "title": "An Overview of Database",
    "section": "Why and How Databases are Used?",
    "text": "Why and How Databases are Used?\n\nThe purpose of a database is to keep track of thing\ndb store information that is more complicated than a simple spread sheet",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#problems-with-lists-spread-sheet",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#problems-with-lists-spread-sheet",
    "title": "An Overview of Database",
    "section": "Problems with Lists (spread sheet)",
    "text": "Problems with Lists (spread sheet)\n\nRedundancy\n\n\n\n\n필요없는 column들이 중복됨\n\n\n\nMultiple Themes\n\n\n그 결과로, list에 나타날 때만 존재하는 informartion이 생김\n\n\nList Modification Issues\n\n\n\n\ndeletion problems, update problems, insertion problems",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#relational-databases",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#relational-databases",
    "title": "An Overview of Database",
    "section": "Relational Databases",
    "text": "Relational Databases\n\nRelationa Model is methodology used as a solution for database design\nA relational database stores information in tables\n\nEach informational topic is stored in its own table\n\nEach theme in the list can be stored in a table\n\nTable = file = relation\ncolumn = fields = attribute\nrow = record = tuple",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#sql-structured-query-language",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#sql-structured-query-language",
    "title": "An Overview of Database",
    "section": "SQL (Structured Query Language)",
    "text": "SQL (Structured Query Language)\n\ninternational standard for creating, processing, querying databases and their tables\ndb applications use SQL to retrieve, format, report, insert, delete, modify data for users\ncan combine table by join operation\n\nSELECT  CUSTOMER.CustomerLastName, \n        CUSTOMER.CustomerFirstName, \n        CUSTOMER.Phone,\n        COURSE.CourseDate, \n        ENROLLMENT.AmountPaid,\n        COURSE.Course, \n        COURSE.Fee\nFROM    CUSTOMER, ENROLLMENT, COURSE\nWHERE   CUSTOMER.CustomerNumber = ENROLLMENT.CustomerNumber -- join condition\n        AND  COURSE.CourseNumber = ENROLLMENT.CourseNumber; -- join condition",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#database-system-dbs",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#database-system-dbs",
    "title": "An Overview of Database",
    "section": "Database System (DBS)",
    "text": "Database System (DBS)\n\n\n\nThe four components of database system\n\n\n\nUser: Employ database application to keep track of things\nUse forms to read, enter, query data\nproduce reports\nDatabase Application: web/mobile database applications, Forms, Reports\nDBMS: used to create, process, administer the database\nDatabase: self-describing collection of related tables\nuser data, metadata, index and other overhead data, application metadata(form, reports) are stored in db\nmetadata = about the structure of the database. &lt;-&gt; user data\n\n\nFunction of DBMS\n\nDB administration\n\nControl concurrency\nProvide security\nPerform backup and recovery\n\n\n\n\nReferential Integrity Constraints",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#personal-vs-enterprise-class-database-systems",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#personal-vs-enterprise-class-database-systems",
    "title": "An Overview of Database",
    "section": "Personal vs Enterprise-class Database Systems",
    "text": "Personal vs Enterprise-class Database Systems\n\nPersonal: Access\nEnterprise-class(Organizational): Microsoft SQL server",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#nosql-databases",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#nosql-databases",
    "title": "An Overview of Database",
    "section": "NoSQL databases",
    "text": "NoSQL databases\n\nNoSQL database = non-relational database",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#cloud-databases",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#cloud-databases",
    "title": "An Overview of Database",
    "section": "Cloud databases",
    "text": "Cloud databases\nMain frame -&gt; Client/server -&gt; Cloud",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/13.html#tier-layers-of-database-system",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/13.html#tier-layers-of-database-system",
    "title": "ASP.NET",
    "section": "3-Tier Layers of Database System",
    "text": "3-Tier Layers of Database System\n\npresentation layer: user interface\napplication layer: web server(IIS)\ndata layer: database server",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "ASP.NET"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/13.html#api-interface-standards-for-db-access",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/13.html#api-interface-standards-for-db-access",
    "title": "ASP.NET",
    "section": "API Interface Standards for DB Access",
    "text": "API Interface Standards for DB Access\nDBMS에 접근하기 위한 표준 API\n\nODBC Open Database Connectivity\nDBMS-independent API\nJDBC: Java Database Connectivity\n\n&lt;a target=\"_blank\"&gt;",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "ASP.NET"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/13.html#asp-active-server-pages",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/13.html#asp-active-server-pages",
    "title": "ASP.NET",
    "section": "ASP (Active Server Pages)",
    "text": "ASP (Active Server Pages)\nserver side scripting(VBScript) language\nCGI: &lt;% %&gt;는 server에서 실행되는 코드",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "ASP.NET"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/13.html#asp-데이터베이스-연동",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/13.html#asp-데이터베이스-연동",
    "title": "ASP.NET",
    "section": "ASP 데이터베이스 연동",
    "text": "ASP 데이터베이스 연동\n&lt;%\n  Dim conn, connCmd, rs\n  Set connCmd = \"DSN=dsn_name; Database=dbname; UID=user;PWD=password\"\n  Set conn = Server.CreateObject(\"ADODB.Connection\")\n  Set rs = Server.CreateObject(\"ADODB.Recordset\")\n  conn.Open connCmd\n  rs.Open \"SELECT * FROM table_name\", conn\n%&gt;\n\n&lt;%\n  rs.getRows()\n\n  conn.Execute SQL\n%&gt;",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "ASP.NET"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/13.html#오류-메세지-한글-설정",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/13.html#오류-메세지-한글-설정",
    "title": "ASP.NET",
    "section": "오류 메세지 한글 설정",
    "text": "오류 메세지 한글 설정\n&lt;meta charset=\"UTF-8\"&gt;\n&lt;%\n  Session.CodePage = 949\n  Response.CharSet = \"euc-kr\"\n  Response.AddHeader \"Pragma\",\"no-cache\"\n  Response.AddHeader \"cache-control\", \"no-staff\"\n  Response.Expires = -1\n%&gt;\n\nform tag 한글 깨짐 문제\n&lt;%\nSession.CodePage=\"65001\"\nResponse.CharSet=\"UTF-8\"\n%&gt;",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "ASP.NET"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/09.html",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/09.html",
    "title": "Database Design",
    "section": "",
    "text": "MS access is prototyping tool for mock-ups",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Design"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/09.html#purpose-of-a-database-design",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/09.html#purpose-of-a-database-design",
    "title": "Database Design",
    "section": "Purpose of a Database Design",
    "text": "Purpose of a Database Design\nset of database specifications that can be implemented as a database in a DBMS\n\nconceptual design: non-DBMS specific\nlogical design: DBMS specific\nphysical design: DBMS specific but not implemented directly by humans",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Design"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/09.html#logical-designrelational-design",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/09.html#logical-designrelational-design",
    "title": "Database Design",
    "section": "Logical Design(Relational Design)",
    "text": "Logical Design(Relational Design)\n\nCreate a table(relation) for each entity\n\nspecify primary key\nspecify properties for each column\n\ndata type\nconstraints\ndefault value\nnull status\n\nverify normalization: data structure의 complexity를 증가시킬 수도 있다 → denormalization: 조인 불필요, 조회 시 성능 향상 → datastructure complexity vs modification problems\n\nCreate relationships by placing foreign keys:\n\nStrong entity relationships\nID-dependent / non-ID-dependent weak entity relationships\nSubtypes\nRecursive",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Design"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/09.html#representing-relationships",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/09.html#representing-relationships",
    "title": "Database Design",
    "section": "Representing Relationships",
    "text": "Representing Relationships\nid-dependent의 경우 부모의 primary key로 composite key 생성\nMaximum cardinality의 유형에 따라 관계 표현 방법이 달라짐\n\n1:1: foreign key를 어디에 두어도 상관 없음\nCREATE UNIQUE INDEX idx_1_1 ON table(foriegn_key);\n1:N: many(child) 쪽에 foreign key를 두는 것이 일반적\n1 side is called parent, many side is called child\nM:N\nData Modeling에서만 쓰임. database design에서는 intersection table을 사용하여 표현. intersection table은 두 entity의 primary key를 포함하는 composite key를 가짐\n만약 두 primary key 외의 attribute를 가진다면, association entity로 표현\nSupertype / Subtype: Supertype의 primary key를 Subtype의 primary key로 사용\nRecursive Relationship: 방향 이거 다시 보자\nN:M의 경우 virtual table을 생성하여 표현\n\n설문조사는\ndescriptive statistics\n남녀 비율, 경험 비율 등등도 포함되어야 한다.\n가중 평균으로 보여준다\n도서관 예약 시스템\n\n퇴설 처리 미흡\n좌석 이용 정보 파악\n앱 알림\n\n좌석 배치도 감이 안온다. 잔여시간도 안뜬다",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Design"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html#standard-normal-distribution",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html#standard-normal-distribution",
    "title": "연속형 확률분포",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\nμ = 0, σ = 1인 정규분포",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "연속형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html#chi-square-distribution",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html#chi-square-distribution",
    "title": "연속형 확률분포",
    "section": "Chi-square Distribution",
    "text": "Chi-square Distribution\nα = ν/2, θ = 2인 감마분포\n자유도 ν에 따라 모양이 변함: 커질수록 정규분포에 가까워짐\n표기: \\(X \\sim χ^2(ν)\\)\n\\(E(x) = ν\\)\n\\(Var(x) = 2ν\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "연속형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html#exponential-distribution",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html#exponential-distribution",
    "title": "연속형 확률분포",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\nα = 1, \\(λ = \\frac{1}{\\theta}\\)인 감마분포\nPoisson 분포에서 사건 발생 사이의 시간을 나타낼 수 있음\n표기: \\(X \\sim Exp(λ)\\)\n\\(f(x) = λe^{-λx}, x \\geq 0\\)\n\\(E(x) = \\frac{1}{λ}\\)\n\\(Var(x) = \\frac{1}{λ^2}\\)\n\\(P(X &gt; x) = e^{-λx}\\)\n\\(P(X &gt; x + y | X &gt; x) = P(X &gt; y) = e^{-λy}\\)\n포아송분포에서의 \\(\\frac{1}{λ}\\)와 동일\n비기억 특성을 가짐\n독립적으로 동일한 지수분포의 합은 감마분포 \\(Γ(n, \\frac{1}{\\lambda})\\)를 따름",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "연속형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html",
    "title": "이산형 확률분포",
    "section": "",
    "text": "확률분포 정의 단계",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행",
    "title": "이산형 확률분포",
    "section": "시행",
    "text": "시행\n각 시행의 결과는 성공(A) 또는 실패(B)\n성공 확률은 p, 실패 확률은 1-p\n각 시행은 서로 독립적 → 모집단의 크기가 충분히 크고, 표본의 크기가 충분히 작다면, 비복원 추출에서도 유효\n∴ S = {A,B}, f(1) = P(X=1) = p, f(0) = P(X=0) = 1-p\n\n\n\n베르누이 시행 예시",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포",
    "title": "이산형 확률분포",
    "section": "분포",
    "text": "분포\n표기: \\(B(1,p)\\)\n\\(f(x) = p^x(1-p)^{1-x}, x = 0, 1\\)\n\\(E(x) = p\\)\n\\(Var(x) = p(1-p)\\)\n\\(m(t) = 1 - p + pe^t\\)\np = 0.5일 때, 분산은 0.25로 가장 큰 값을 가짐",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-1",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-1",
    "title": "이산형 확률분포",
    "section": "시행",
    "text": "시행\nn번의 독립적인 베르누이 시행을 했을 때 성공 횟수 X\n서로 독립인 n개의 베르누이 분포의 합과 같다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-1",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-1",
    "title": "이산형 확률분포",
    "section": "분포",
    "text": "분포\n표기: \\(X \\sim B(n,p)\\)\n\\(f(x) = {_n}C_x\\) \\(p^x(1-p)^{n-x}, x = 0, 1, 2, ..., n\\)\n\\(E(x) = np\\)\n\\(Var(x) = np(1-p)\\)\n\\(m(t) = (1-p + pe^t)^n\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-2",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-2",
    "title": "이산형 확률분포",
    "section": "시행",
    "text": "시행\n성공 확률 p인 베르누이 시행을 반복하여 처음 성공할 때까지의 시행 횟수 X\n지수분포와 유사하다\n기하분포는 비기억 속성을 가진다",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-2",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-2",
    "title": "이산형 확률분포",
    "section": "분포",
    "text": "분포\n표기: \\(X \\sim G(p)\\)\n\\(f(x) = (1-p)^{x-1}p, x = 1, 2, 3, ...\\)\n\\(E(x) = \\frac{1}{p}\\)\n\\(Var(x) = \\frac{1-p}{p^2}\\)\n\\(m(t) = \\frac{pe^t}{1-qe^t}, (qe^t&lt;1), (q=1-p)\\)\n\\(P(X &gt; x + y | X &gt; x) = P(X &gt; y) = (1-p)^y\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-3",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-3",
    "title": "이산형 확률분포",
    "section": "시행",
    "text": "시행\n모집단의 크기에 비해 샘플의 크기가 작지 않은 경우, 비 복원 추출시 각각의 선택이 베르누이 시행이라 할 수 없다.\n\\(\\frac{r}{N} = p\\)로 일정할 때, N을 증가시키면, \\(HG(n, N, r)\\)은 \\(B(n, p)\\)로 수렴한다",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-3",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-3",
    "title": "이산형 확률분포",
    "section": "분포",
    "text": "분포\n표기: \\(X \\sim HG(n, N, r)\\)\n\\(f(x) = \\frac{\\binom{r}{x}\\binom{N-r}{n-x}}{\\binom{N}{n}}, x = 0, 1, 2, ..., n\\)\n\\(E(x) = \\frac{nr}{N}\\)\n\\(Var(x) = \\frac{nr(N-r)(N-n)}{N^2(N-1)}\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-4",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-4",
    "title": "이산형 확률분포",
    "section": "시행",
    "text": "시행\n임의의 기간동안 어떤 사건이 간헐적으로 발생할 때, 사건이 발생하는 횟수 X\n임의의 기간을 n 등분하여 각 등분에서 사건이 발생할 확률이 p라고 할 때, 발생횟수 기댓값 λ를 고정시킨 채로 n을 무한히 증가시킴\nn이 매우 크고 p가 매우 작을 때 이항분포를 포아송분포로 근사할 수 있다\n포아송 분포 + 포아송 분포 = 포아송 분포: \\(P(λ) + P(λ) = P(2λ)\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-4",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-4",
    "title": "이산형 확률분포",
    "section": "분포",
    "text": "분포\n표기: \\(X \\sim P(\\lambda)\\)\n\\(f(x) = \\frac{e^{-\\lambda}\\lambda^x}{x!}, x = 0, 1, 2, ...\\)\n\\(E(x) = \\lambda\\)\n\\(Var(x) = \\lambda\\)\n\\(m(t) = e^{\\lambda(e^t-1)}\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#확률변수",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#확률변수",
    "title": "확률변수와 확률분포",
    "section": "확률변수",
    "text": "확률변수\nsample space의 원소를 상호 배반인 event들로 분할하여 실수 값으로 대응시키는 함수\n\n이산확률변수: 확률변수가 취할 수 있는 값이 유한개 또는 무한개이지만 셀 수 있는 경우\n연속확률변수: 확률변수가 취할 수 있는 값이 실수의 구간이고 셀 수 없는 경우\n\n이산 표본공간 -&gt; 이산 확률변수\n연속 표본공간 -&gt; 연속 확률변수\n연속 표본공간 -&gt; 이산 확률변수",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#확률-분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#확률-분포",
    "title": "확률변수와 확률분포",
    "section": "확률 분포",
    "text": "확률 분포\n\n표본공간 S에 정의된 확률변수 X의 모든 함수값들이 발생할 확률. 모집단의 확률구조를 나타냄\n확률 실험 -&gt; 표본공간 -&gt; 확률변수 -&gt; 확률분포\n\n\n이산확률분포\n확률 질량 함수(pmf): P(X=x) = f(x) =&gt; X가 x일 확률\n- 기하분포: 성공확률 p인 베르누이 시행을 독립적으로 반복했을 때 첫 번째 성공이 나타날 때까지의 시행횟수\n\n\n연속확률분포\n\n확률 밀도 함수(pdf): \\(\\int{f(x)}dx = 1\\)\n\\(\\int_a^b {f(x)}dx = P(a ≤ x ≤ b)\\) =&gt; x가 a와 b사이에 있을 확률\nP(X=x) = 0 (연속형 데이터여서 특정값을 가질 확률은 0)\nf(x) ≠ P(X=x)\nf(x)는 1보다 큰 값을 가질 수 있음\n누적분포함수(cdf): \\(F(x) = P(X ≤ x)\\) =&gt; \\(\\int_{-∞}^x{f(y)}dy\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#결합-확률분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#결합-확률분포",
    "title": "확률변수와 확률분포",
    "section": "결합 확률분포",
    "text": "결합 확률분포\n\npmf: \\(P(X=x, Y=y) = f(x, y)\\)\npdf: \\(P(a ≤ X ≤ b, c ≤ Y ≤ d) = \\int_{a}^{b}\\int_{c}^{d}{f(x, y)}dydx\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#주변-확률분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#주변-확률분포",
    "title": "확률변수와 확률분포",
    "section": "주변 확률분포",
    "text": "주변 확률분포\n\npmf: \\(f_X(x) = \\sum_y{f(x,y)}\\)\npdf: \\(f_X(x) = \\int_{-∞}^{∞}{f(x, y)}dy\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#조건부-확률분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#조건부-확률분포",
    "title": "확률변수와 확률분포",
    "section": "조건부 확률분포",
    "text": "조건부 확률분포\n\n\\(f(x|y)\\) = \\(\\frac{joint}{marginal}\\) = \\(\\frac{f(x, y)}{f_Y(y)}\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#독립-확률변수",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#독립-확률변수",
    "title": "확률변수와 확률분포",
    "section": "독립 확률변수",
    "text": "독립 확률변수\n\n모든 \\(x, y\\)에 대해 \\(f(x, y) = f_X(x)f_Y(y)\\)\n\n\n\n\\(f(x, y) = g(x) * h(y)\\)\n\nx, y 의 구간이 서로 간섭받지 않는다.\nX,Y는 독립이다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#확률변수의-변환",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#확률변수의-변환",
    "title": "확률변수와 확률분포",
    "section": "확률변수의 변환",
    "text": "확률변수의 변환\n\ncdf를 이용한 변환\ncdf를 미분해서 pdf\n\n\n역함수가 존재할 경우\n\\(g(y) = f(u^{-1}(y)) * |\\frac{du^{-1}}{dy}|\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/8-central-limit-theorem.html#중심-극한-정리",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/8-central-limit-theorem.html#중심-극한-정리",
    "title": "중심 극한 정리",
    "section": "중심 극한 정리",
    "text": "중심 극한 정리\n평군이 μ이고, 분산이 \\(σ^2\\)인 모집단으로부터 추출한 확률표본 \\(X_1, X_2, ..., X_n\\)의 표본평균 \\(\\bar{X}\\)의 분포\n\n모집단의 분포와 상관 없이 \\(E(\\bar{X}) = μ\\), \\(Var(\\bar{X}) = \\frac{σ^2}{n}\\)\n정규 모집단일 경우 \\(\\bar{X}\\)가 정규분포를 따름\n정규 모집단이 아닐 경우\n\\(n \\geq 30\\) 이면 중심극한정리에 의해 \\(\\bar{X}\\)는 정규분포에 근사됨. (모집단의 skewed에 따라 더 큰 n이 필요할 수 있음)\n∴ \\(\\bar{X} \\sim N(μ, \\frac{σ^2}{n}), \\frac{\\bar{X} - μ}{σ/\\sqrt{n}} \\sim N(0, 1^2)\\)\n모집단의 분포가 이산, 연속 분포일 때 모두 적용 가능하다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "중심 극한 정리"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/8-central-limit-theorem.html#이항분포의-정규근사",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/8-central-limit-theorem.html#이항분포의-정규근사",
    "title": "중심 극한 정리",
    "section": "이항분포의 정규근사",
    "text": "이항분포의 정규근사",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "중심 극한 정리"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#overview",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#overview",
    "title": "Signal Detection Theory",
    "section": "Overview",
    "text": "Overview\n\n인간의 정보 처리 과정 중 perception에 관련된 것\nperception 단계에서 자극 뿐 아니라 노이즈도 같이 들어옴\n여러가지 신호 중 무엇이 중요한지 판단하는 것\nsiganal 탐지 과정을 정량적 모델로 분석하고 성능 평가가 목표\n인공지능 분야에서 중요성이 대두되고 있음",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#example",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#example",
    "title": "Signal Detection Theory",
    "section": "Example",
    "text": "Example\n\nQuality control inspector\n빵이나 과자가 찌그러졌는지 검사, 반도체 품질 검사. 요즘에는 기계가 대부분 담당\nDetection of a flashing warning light (or cctv)\n거수자 탐지\nAirport security guard\nDetecting peculiar patterns in medical imaging (x-ray)\n종양, 암세포 탐지\nMobile phone rings (sound)\nphantoms vibration\nMorning alarm is active or not (visual)\n\n주변의 제품, 서비스 문제 파악, 해결 디자인 제시, 검증",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#signal-detection-theory",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#signal-detection-theory",
    "title": "Signal Detection Theory",
    "section": "Signal Detection Theory",
    "text": "Signal Detection Theory\n\nTrials\n\nSignal case(signal + noise): target이 존재\nNoise case(noise only): target이 없음\n\nResponse\n\nYes\nNo\n\n\n\n\nHit rate: P(Hit) = Number of Hits / Number of Signal Trials\nFalse alarm rate: P(FA) = Number of False Alarms / Number of Noise Trials\nMiss rate: P(Miss) = 1 - P(Hit)\nCorrect rejection rate: P(CR) = 1 - P(FA)\n\n\nWhat does it mean to detect?\n\nsignal is digital (exist / not exist)\nAbsolute threshold is exist\n\n\n\nAssumptions\n\n관찰자가 관찰할 수 있는 signal은 숫자나 변수로 표현할 수 있어야함\nsignal이 random variation이 있다\n피험자가 signal이 있는지 없는지 단순하게 표시할 수 있다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#distribution-of-signal-and-noise",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#distribution-of-signal-and-noise",
    "title": "Signal Detection Theory",
    "section": "Distribution of signal and noise",
    "text": "Distribution of signal and noise\n\n\nsensitivity index (d')\n\n값이 작으면 분간 힘듦\n값이 크면 분간 쉬움\nsignal의 성격에 따라 결정됨\n\nresponse bias (β)\n\ncriterion에 따라 yes라고 대답하는 비중과 no라고 대답하는 비중\n평가자에 따라 결정됨\n\nd′이 0, β가 50%면 그냥 랜덤으로 대답한 것과 같음\n\n\nd′ 계산\n\nP(M), P(CR) 계산\n표준 정규분포를 그림\nM과 CR의 z값을 찾음\nd′ = (0 - z(M)) + (z(CR) - 0)\n\n\n\nβ 계산\n\nd′과 관계 없이 조절\n\n\\(β = \\frac{P(X/(S+N))}{P(X/N)}\\)\n\\(\\ln β = d′λ_{center}\\)\nβ ~ 1: neutral\n\n\n\n\\(λ_{center}\\) 계산\n\\(λ_{center} = -\\frac{1}{2}(Z(FA)+Z(H))\\)\n\n\\(λ_{center}\\) = 0: ideal observer\n\\(λ_{center}\\) &lt; 0: liberal. yes라고 대답하는 비중이 늘어, hit rate가 높아지지만 false alarm rate도 높아짐\nex) 용의자를 찾는 경찰, 암세포 탐지\n\\(λ_{center}\\) &gt; 0: conservative. no라고 대답하는 비중이 늘어, correct rejection rate가 높아지지만 miss rate도 높아짐\nex) 억울한 죄인을 만들지 않으려는 범원 판결",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#optimal-response-criterion",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#optimal-response-criterion",
    "title": "Signal Detection Theory",
    "section": "Optimal Response Criterion",
    "text": "Optimal Response Criterion\nsignal이 더 많은 환경, noise가 더 많은 환경이 있음. 즉, probability가 다를 수 있음\n또, Effects of payoffs가 있음\n\nsignal이 많은 환경 -&gt; criterion을 낮추는게 좋음. \\(β_{opt} &lt; 1\\)\nnoise가 많은 환경 -&gt; criterion을 높이는게 좋음. \\(β_{opt} &gt; 1\\)\n\\(β_{opt} = \\frac{P(N)}{P(S)} * \\frac{V(CR) + C(FA)}{V(H) + C(M)}\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#sluggish-β",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#sluggish-β",
    "title": "Signal Detection Theory",
    "section": "Sluggish β",
    "text": "Sluggish β\n\n\n\nprobability 혹은 payoffs의 변화에 따라 bias가 optimal이랑 다르게 나옴\n\n\n\n\\(β_{opt}\\)가 낮은 경우, ideal보다 덜 conservative함.\n\\(β_{opt}\\)가 높은 경우, ideal보다 덜 risky함.\n확률에 의해 b가 조정될 때 더 많이 발생함.\n\n확률에 대한 계산이 잘못되는 경우\n평가자가 반복되는 반응에 bored해지는 경우",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#roc-curve",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#roc-curve",
    "title": "Signal Detection Theory",
    "section": "ROC Curve",
    "text": "ROC Curve\n\n\n\nd′이 높아질 수록 false alarm 비중이 낮아지고, hit 비중이 높아짐",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#signal-detection-performance",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#signal-detection-performance",
    "title": "Signal Detection Theory",
    "section": "Signal Detection Performance",
    "text": "Signal Detection Performance\n\nResponse Bias (β)\n\n잘 맞추면 보상을 준다\nfalse signals to raise signal rate\nFalse Alarm에서도 incentive를 준다.\n\n\n\nSensitivity (d′)\n\ngive feedback\nsignal을 조금 더 오래 보여줌\nsignal을 강조\nsignal을 움직이게\n휴식 시간을 충분히 줌\nsignal이 어떠넌지 잘 보여줌\n온갖 감각으로 signal을 보여줌",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/8_control.html#basic-control-task-and-device",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/8_control.html#basic-control-task-and-device",
    "title": "Control",
    "section": "Basic Control Task and Device",
    "text": "Basic Control Task and Device\n\n\n\n상태를 체크할 때는 toggle switch, 눌렀다 떼는 건 push button\n레버도 상태를 체크할 때 사용. 그 중 큰 힘이 필요한 경우. continuous setting에서는 slider가 쓰임\nselector switch는 lever랑은 다르게 discrete한 상태가 있음 (선풍기 버튼)\n조이스틱은 보통 가속도(2D, 멀리 밀면 빨리 가는 애)를 제어하거나 속도(1D, 버튼 조이스틱)를 제어하는데 사용. 마우스는 위치를 제어.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Control"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/8_control.html#principles-to-design-of-control-device",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/8_control.html#principles-to-design-of-control-device",
    "title": "Control",
    "section": "15 principles to design of control device",
    "text": "15 principles to design of control device\n\nAttention principles\n\nProximity compatibility\n\n컨트롤 하고자 하는 대상과 컨트롤이 가까워야 한다.\n비상 스위치는 가까이 있어야 한다.\n\n\n\nAvoid resource competition\n\n같은 physical or cognitive resource를 사용하는 control은 피해야한다.\nex) 레버로 속도, 방향 모두 제어\n\n\n\n\nPerceptual principles\n\nMake accessible\n\nphysical accessibility: 손이 닿아야 한다.\ncognitive accessibility: 뭐 하는 control인지 이해하기 쉬워야 한다.\nex) 미는 손잡이는 flat하게 만든다.\n다양한 환경을 고려해야한다. (빛이나 소음이 많은 환경)\n\n\n\nMake discriminable\n\nvisual differentiation: 각각의 컨트롤 장비를 구분할 수 있게\nlogical grouping: 비슷한 기능을 하는 것끼리 묶어놓기\n\n\n\nExploit(활용) redundancy gain\n\n두개의 독립적인 정보를 제공하면 성능이 좋아진다.\n한 가지 정보가 없어도 다른 정보로 대체할 수 있다.\n\n\n\nAvoid absolute judgement limits\n\nworking memory limit(7)를 넘기지 말라.\ncontinuous vs with detents: 연속적인 조절에서 anchor point를 만들어주면 좋다.\n\n\n\n\nMemory Principles\n\nKnowledge in the world\n보편적으로 아는 표현을 사용\n\n\nBe consistent\n\n다른 상황에서도 예상 가능하고 일정한 방법으로 control이 가능해야한다.\n\n\n\nmake discriminable vs be consistent\n\n\n\n\nMental model principles\n\nLocation Compatibility\n\nSpatial Compatibility / physical similarity\n\n\n\nMovement Compatibility\n\n\n\n\nPopulation Stereotypes\n\nrotary controls: 시계방향으로 돌리면 커진다\nUp is on\nIncrease is right, Forward is faster\n\n\n\nResponse selection principles\n\nAvoid accidental activation\n\n사고로 눌리는 것을 방지해야한다.\n\n\n\nHick-Hyman Law\n\\(RT = a + b \\log_2(n+1)\\)\nN is the number of choices\n종류가 많아져도 그냥 몇개만 고민함\n\n\nDecision complexity advantage\n\n일반적으로 복잡한 선택을 적게 하는게 간단한 선택을 여러번 하는것보다 효율적이다\n\n\n\nFitt’s Law\n\n\nIndex of Difficulty: \\(ID = \\log_2(\\frac{2A}{W})\\)\nMovement Time: \\(MT = a + bID\\)\n\navoid accidental vs Fitt’s Law - target width가 구석에 있으면 width가 무한대가 된다.\n\n\nprovide feedback\ntouch screen은 haptic feedback이 없어서 불편함",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Control"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#attention의-정의",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#attention의-정의",
    "title": "Attention",
    "section": "Attention의 정의",
    "text": "Attention의 정의\n\nAttention acts as a means of focusing limited mental resources on the information and cognitive processes that are most salient at a given moment\nFocusing most salient at a given moment:\n\n주의는 Search light로 비유됨\n한 영역에 집중하면 다른 부분은 배제.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Attention"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#attention의-네-가지-주요-측면",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#attention의-네-가지-주요-측면",
    "title": "Attention",
    "section": "Attention의 네 가지 주요 측면",
    "text": "Attention의 네 가지 주요 측면\n\nSelective, Focused, Divided, Sustained Attention은 독립적이지 않으며, 상호작용하여 주의 과정 형성.\n\n\nFocused Attention (집중적 주의)\n\n특정 과업에 집중하고, 외부 방해 요인을 배제하는 능력.\n방해 요소(Distraction)를 최소화하여 현재 작업에 주의 집중.\n예시:\n\n냉장고에서 음식을 꺼내려는 도중 질문을 받으면 집중력이 분산되어 원래 작업을 잊어버릴 수 있음.\n\n\n\n\nDivided Attention (분할 주의)\n\n여러 작업을 동시에 수행하며 주의를 분배.\nSelective Attention과의 차이:\n\nSelective Attention: 특정 자극을 선택적으로 받아들임.\nDivided Attention: 여러 작업 간 우선순위를 메기고 주의 자원 분배.\n\n예시:\n\n운전 중 대화하며 라디오 듣기.\n각 작업에 필요한 시간과 노력을 어떻게 배분할지를 결정.\n\n\n\n\nSustained Attention (지속적 주의)\n\n주의가 높거나 낮거나보다는, 장시간 동안 주의를 유지하는 능력.\n높은 주의 레벨 필요 시:\n\n정보를 놓치는 경우가 발생할 가능성이 높음.\n여러 정보와 자극을 동시에 처리.\n예: 주식 거래에서 여러 종목을 모니터링.\n\n낮은 주의 레벨 시:\n\n자극 부족으로 주의 산만 발생.\n예: CCTV 감시 업무.\n\n\n\n\nSelective Attention (선택적 주의)\n\n여러 감각 자극 중 중요한 정보를 선택적으로 처리.\n시각, 청각, 촉각 등 다양한 감각 경로를 통해 들어오는 자극에서 의미 있는 정보 선별.\n예시:\n\n운전 중:\n\n표지판, 신호등, 앞차의 움직임 → 중요한 정보.\n옆 보행자의 얼굴이나 주변 불필요한 자극 → 중요하지 않은 정보.\n\n\n\n\n\nMental Workload (정신적 작업 부하)\n\n동시에 수행할 수 있는 과업이 몇 개인지 혹은 이 과업이 수행하기에 attention scale을 넘어가는 것인지 분석 용도\n측정 방법:\n\n주관적 설문:\n\n작업자가 느끼는 주관적 부담을 평가.\n\n생체 반응 분석:\n\n심박수, 뇌파 등 생리적 데이터를 활용.\n\n부과 과업(parallel tasking):\n\n추가 과업을 부여하여 작업 부하 평가.\n예시:\n\n운전 중 숫자 거꾸로 세기.\n특정 숫자를 기억하고 응답(예: N-back 테스트).\n\n\n\n워크로드 증가의 결과 특정 작업의 실패 확률 증가한다.\n\n\n\nAttention의 결정 요인\n\n의지\n\n개인의 목표와 필요에 따라 주의 집중.\n예: 차선 변경 시 후방 차량 확인.\n\ncaptured by salience and grouping\n\n공간, 강도, 색상, 크기, 음조 등 외부 요인.\n강렬한 자극이 주의를 끌 가능성 높음.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Attention"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#selective-attention",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#selective-attention",
    "title": "Attention",
    "section": "Selective Attention",
    "text": "Selective Attention\n\n특정한 자극(예: 시각적 또는 청각적 정보)에 주의를 집중하며, 다른 자극을 배제하는 과정.\n중요도에 따라 특정 정보를 선택적으로 처리하며 불필요한 정보는 억제.\nattention이 sensory memory로 부터 들어온 정보의 filter나 gateway나 bottle neck으로 작용한다고 봄\n\n\n작동 원리\n\nTop-down Processing (Mental model):\n\n개인의 경험과 목표에 기반하여 주의 집중 전략을 개발.\n예: 초보 운전때 앞만 보고 가다가 숙련이 되면 사이드미러 같은 주변도 보게 됨.\n\nBottom-up Processing (자극 기반 처리):\n\n강렬하거나 눈에 띄는 자극에 주의가 끌림.\n예: 갑작스러운 소리나 반짝이는 신호등.\n결정 요인\n\nSalience Source: 자극의 강도(밝기, 소리 크기 등).\n\nInformation Access Trade-offs: 특정 정보를 처리함으로써 얻는 이득.\n\n\n\n\nBottleneck Model\nEarly Selection Theory\n- sensory memory까지는 잘 오지만, Attention filter에 선택이 된게 처리가 되고 나머지는 처리가 안 된다.\n- 감각 단계에서 물리적 특성(의미가 아닌)을 기준으로 정보 필터링.\n- 폐기된 정보는 행동에 미치는 영향 없음.\n- 한계: 칵테일 파티 현상(의미 정보 처리 설명 불가).\n\nLate Selection Theory\n- 모든 정보가 cognition / working memory까지 전달 후 선택.\n- 식별되지 않은 정보는 작업 기억의 제한된 용량으로 인해 빠르게 잊혀짐.\n- 선택되지 않은 정보도 행동에 영향을 미침.\n- 광고 실험 - 인지하지 못하는 정보(빠르게 잊어버려서)에 의해서도 행동의 변화가 있을 것이다.\n\n\nTask\nGeneral orientation and scene scanning\n- 그림을 보거나 웹 브라우징\n감독 제어 (Supervisory Control)\n- 자동화된 시스템에서 이상 징후를 탐지.\n- 주로 AOI(Area of Interests)를 스캐닝 함.\nAOI는 여러개가 있음. 시간, 중요도, 과업의 컨텍스트에 따라서 다르게 설정됨\nspecific task-related information이 있는 물리적 위치\nAOI를 몇개를 만들고, 이들에 대한 시선의 이동을 어떻게 만들것인가가 중요한 issue - 예시:\n자율주행 차량 또는 산업 기계 감독.\n제어 패널에서 비정상적인 지표 확인 (예: 전력 공급 문제, 자원 부족).\n탐지 (Noticing)\n- 예상치 못한 사건이나 환경 변화 감지.\n- 예시:\n- CCTV로 비정상적인 활동 탐지.\n- 주요 시스템 성능의 갑작스러운 변화 인식.\n탐색 (Searching)\n- 방해 요소 속에서 특정 목표를 찾는 활동.\n- 예시:\n- 공항에서 수하물의 X-ray 검색.\n읽기 (Reading)\n- 책이나 디스플레이에서 정보를 읽고 이해.\n- 예시:\n- 계기판의 게이지 읽기.\n확인 (Confirming)\n- 작업이나 과정의 결과를 확인.\n- 예시:\n- 비행기 바퀴가 잘 내려왔는지 확인\n선택적 주의 과업 실패는 중요 정보를 놓치거나 잘못 해석하는 경우 발생할 수 있다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Attention"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#seev-model",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#seev-model",
    "title": "Attention",
    "section": "SEEV Model",
    "text": "SEEV Model\nvisual attention에 영향을 주는 요소들을 설명\n\nBottom-up factors\n\nSalience: cue의 특징\nEffort: AOI로 이동하는데 드는 비용\n선형적으로 증가하는건 아니고, 그룹핑 할 수 있음.\n(Within foveal vision) 중심시에서 초점 변화. 멀리있는거에서 가까이 있는거 보는거 &lt; Eye movement &lt; Head movement &lt; Body\n중요한 정보는 cost가 작은 쪽에 배치를 해야함.\n\n\n\nTop-down factors\n\nExpectancy: 일어날 것 같은거에 주의를 더 많이 집중. mental model에 의해 예측 능력이 생길 수 있음.\nValue: 이것에 집중했을 때 얻는 이득, 보지 않았을 때 지불하는 비용\n\n\n\nGuidline\n\n중요한 AOI는 salience가 높아야함\n사용 빈도가 높은 AOI 사이의 거리는 가까워야함\n순차적인 디스플레이도 서로 가깝게 배치해야함.\n\n\n\nChange Blindness\n\n발생 원인\n\n멘탈 워크로드가 높은 경우\n눈에 띄는 변화(Slient change)는 발견하기 쉬움\n중심시에서 멀리 떨어진 곳에서 변화가 발생하면 탐지하기 어렵다.\n시야 밖에서 일어나는 변화는 인지하기 어려움(화면이 깜빡이면서 변하면 animation 효과가 안나타남)\n예상치 못한 변화는 탐지하기 어려움.(top-down processing)\n특정 위치를 응시(fixation)하고 있어도 집중(attention)이 부족하면 변화를 인지하지 못함.\n\n\n\n\nSearch Task의 유형\n\nSerial Search\n\n하나씩 순차적으로 탐색, 탐색 시간이 항목 수에 비례.\n\n예: 긴 텍스트 리스트에서 특정 단어 찾기. 같은 그림 2개 찾기\n\nParallel Search\n\n눈에 띄는 단서(pop-out effect)를 이용해 한 번에 탐색.\n\n5 search items is the same for 50 search items\n\npreattentive process로 유발됨\n\nParallel Search를 유도하는 방법\n\n색상, 크기, 대비(contrast), 회전\n\nmotion\n\nfeature를 adding하는건 찾기 쉬운데 missing하는건 찾기 어려움\n\nO안에서 Q 찾기 vs Q안에서 O 찾기\n\n깜빡이는 곳에서 안깜빡이는거 찾기 vs 안깜빡이는거에서 깜빡이는거 찾기",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Attention"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#divided-attention",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#divided-attention",
    "title": "Attention",
    "section": "Divided Attention",
    "text": "Divided Attention\n\n개념\n\n일반적으로 단순 작업보다는 멀티 태스킹이 많이 일어남.\n\n단순 작업: 라면 끓일 때 진짜 라면만 순서대로 끓임. (멀티테스킹 x)\n\n복잡 작업: 라면을 끓이면서 설거지도 하고, 반찬도 만들고, 카톡도 하고, … (멀티테스킹 o)\n\n여러 작업을 동시에 수행하면서 주의를 분배.\nAttention을 한계가 있는 자원으로 바라봄\n\n\n\nResource Model\n\nCentral Resource Theory:\n주의 자원을 단일 통으로 간주. 예: 교차로 진입 시 운전에만 집중, 라디오 듣기같은 다른 작업은 집중을 못함.\nMultiple Resource Theory:\n주의 자원이 감각기관의 특성, 과업의 특성에 따라 별개로 존재\n예: 시각(도로), 청각(라디오) 자원을 분리 사용.\n작업 간 유사성이 높을수록 분배 어려움.\n예: 운전 중 영화 감상(둘 다 시각 자원 사용).\n\n\n\n주의 자원과 훈련의 문제\n주의 자원은 고정인가, 훈련으로 확장 가능한가?\n\n리소스 차이는 명확히 증명되지 않았음.\n전략을 통한 과업 배분 및 우선순위 설정 → 성능 향상.\n반복적 학습과 자동화 → 개별 과업 및 주의 배분이 자연스럽게 효율화.\n\n\n\nAttention as capacity\n\n어떤 정보를 얼마나 주의 깊게 받아들일지 결정\n어떤 정보를 선택할 것인지는 disposition(형태), intentions, arousal, evaluation에 의존\n받아들이는 정보의 특성(visual, auditory), 반응(manual, vocal)에 따라 리소스 풀을 나눌 수 있다.\ntasks interfere to the degree that they tap into the same pool of resources\n\n\n\nUnitary Resource Model (단일 자원 모델)\n\n\n주의(attention)를 제한된 자원으로 봄\n과업 수행에 필요한 자원의 양이 가용 자원을 초과하면 성능 저하\n\n\n\nMultiple Resource Model (다중 자원 모델)\n\n서로 다른 유형의 과업은 다른 자원을 사용\n하지만 한쪽의 workload가 높으면 다른쪽에 영향을 미칠 수 있음.\n비주얼 테스트 두 개를 수행하는 것이 비주얼-청각 테스트보다 더 어려움\n한 객체의 두 가지 특징에 주의를 기울이는 것이 두 객체의 한 가지 특징에 주의를 기울이는 것보다 쉬움\nEx) 특성을 여러 막대로 보여주는것보다 육각형으로 보여주는게 더 보기 쉬움\n\n\n\nPerceptual Modalities\n\nAuditory,Visual, and Tactile Perceptual modalities에 사용하는 resource가 전부 다름\nVisual은 Focal과 Ambient가 서로 다른 자원을 사용함\nCross-modality가 15%정도 더 효과가 있음\ntactile은 auditory랑 비슷함.\n\n\n\ncoding\n\nspatial, verbal\nauditory verbal verbal and visual spatial manual is efficient\nverbal은 단 너무 길면 좋지 않다.\n모든 채널에서 다 쓸 수는 없다. (tactile 같은 경우에는 verbal 코딩이 없음)\n\n\n\nAttentional Allocation during Time-sharing: Skill or Ability?\n\nIf skill:\nAttentional allocation should be trainable\nSkills developed in one task transfer to unrelated tasks.\nIf ability:\nNo evidence supports the existence of a universal “multitasking ability.”\nPeople excel at specific tasks due to familiarity and automation, not inherent multitasking talent.\n\n\nPractical Implications\n\nOperator training:\nTraining must develop automaticity in single-task skills to reduce resource demand\nTraining of attentional allocation and time-sharing will help dual-task performance\nOperator selection:\ntime-sharing ability가 좋은 사람을 선택하는 것보다는 single-task performance가 좋고 자동화가 잘 사람을 선택하는 것이 더 좋음\n\n\n\n\nSystem design이나 multi-task performance를 측정할 때 좋은 것\n\nTask analysis나 multiple resource model를 사용하는 것이 좋다.\nTask의 어떤 면이 효율적으로 time-shared 될 것인가?\nTask의 어떤 면이 interference를 일으킬 것인가?\ninterference를 최소화하기 위해 어떻게 디자인 해야하나?\nex) driving할 때 손과 발을 따로 사용하게 하기\nTime-sharing efficiency, task performance, and mental workload를 고려해야한다\n(멘탈 워크로드 측정은 아직도 쉽지 않다.)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Attention"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/1_reaserch_method.html#reaserch-meathods",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/1_reaserch_method.html#reaserch-meathods",
    "title": "Research Method in Human Factors",
    "section": "reaserch meathods",
    "text": "reaserch meathods\n\ndescriptive Research\n관찰을 통해 데이터 묘사\n\n무엇을 측정할지\n어떻게 숫자로 표현할지\n\n\n대부분 평균, 표준편차를 대푯값으로 사용\n변수들 간의 관계를 파악하기 위해 상관분석, 회귀분석을 사용\n\n\ntypes of descriptive research\n\nobservational research\n\n\n관찰 연구를 계획할 때, 측정할 변수, 각 변수를 기록할 방법, 관찰이 이루어지는 조건, 관찰 기간 등을 식별\n\n\nsurvey research\n\n\n설문조사를 통해 데이터 수집\n\n\nincident and accident analysis\n\n\n사고나 오류를 분석하여 원인을 찾음\n사고나 오류를 줄이기 위한 대책을 마련\n\n\n\n\nexperimanetal Research\n하나 이상의 독립변수에 의도적인 변화를 주고, 그 변화가 하나 이상의 종속변수에 미치는 인과관계를 측정\n이때 다른 변수들은 통제한다\n\n예시\n\n휴대전화를 사용하는 것이 운전에 미치는 영향\n인센티브를 미리 주고 잘못 할 때마다 차감하는 것과, 잘할 때마다 인센티브를 주는 것의 차이\n\n\n\ntype of variables\n\nindependent(predictor, stratification) variable\ndependent(descriptive, criterion) variable\ncontrol variable: 이 값은 고정시키고 실험을 진행한다. 일반화하기 어렵게 한다.\nrandom variable (sigma): 통제할 수 없는 변수. 일반화하기 용이하다.\nconfounding variable: 수식에는 포함되지 않지만 주의해야하는 변수.\n\n\ndecide variables\noperational definition: 변수를 관찰 가능하고 측정 가능한 형태로 정의\n\nindependent variable\n\nRange: realistic / select a range taht will show the effect / pilot experiment\n\ndependent variable\n\nreliability: consistent. solution: increase the number of observations\nvalidity: measure what was intended\n\n\n\n\n\n\nwhy use experimental research?\n\nhumans are variable\n\n\nintra individual variability\ninter individual variability\n\n\nways to handle variability\n\n\nuse statistical techniques\ncontrol variability as much as possible\n\n\n\ntypes of experimental design\n\nsingle variable experiment\n\n\ntwo levels\nmulti levels\n\n\nfactorial design: 두개 이상의 독립변수를 조합하여 실험군을 만든다.\n\n\n변수 간 interaction effect을 확인할 수 있다.\nmore difficult to analyze\n2 x 2, 3 x 3, 2 x 2 x 2 등으로 설계한다.\nbetween-subject, within-subject를 모두 사용하는 mixed designs를 사용할 수 있음.\n\n\nbetween-subjects design: 각각의 실험군에 다른 사람들을 넣는다.\n\n\ngeneralibility 높다, intra person variability를 제거할 수 있다.\n\n\nwithin-subjects design: 같은 사람들을 다른 실험군에 넣는다.\n\n\ncost-effective, less variability, inter person variability를 제거할 수 있다.\n\n\n\n\nevaluation research\n시스템이나 제품이 목적을 충족하는지 평가\n\nusability testing: 사용자가 제품을 실제로 사용하면서 발생하는 문제점 파악\n\n태스크 완료 시간, 오류율, 사용자 만족도 등을 측정\n\ncost-benefit analysis: 제품 또는 시스템 도입의 경제성 평가\n\n직접 비용(하드웨어, 소프트웨어 구입비, training cost 등)\n예상되는 이익(생산성 향상, 오류 감소 등)을 비교 분석",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Research Method in Human Factors"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/1_reaserch_method.html#research-design",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/1_reaserch_method.html#research-design",
    "title": "Research Method in Human Factors",
    "section": "research design",
    "text": "research design\n\nqualitative research\n\n보통 마케팅에서 진행.\n\n\n\nquantitative research\n\nexperiments\ncorrelational observation\nsurveys and questionnaires\n\nsample: 랜덤하게 샘플링하는게 중요\nrating\nbias: 질문의 순서, 질문의 내용, 질문의 방향\n\narchival research\n\n\nfield study\n\nuncontrolled\nresults may be more generalizable to real-world situations\nhigher cost\ndifficult to replicate\ndifficult to control extraneous variables\n\n\n\nlab experiment\n\ncontrolled\nprecise replication\nlower cost\nmore flexibility\nreal-world generalizability may be limited",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Research Method in Human Factors"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/0_intro.html#what-is-human-factors",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/0_intro.html#what-is-human-factors",
    "title": "Introduction to Human Factors",
    "section": "what is human factors",
    "text": "what is human factors\n\nhuman factors = Ergonomics\na human-centered design philosophy &lt;-&gt; technology-centered design",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Introduction to Human Factors"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/0_intro.html#component-of-human-factors",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/0_intro.html#component-of-human-factors",
    "title": "Introduction to Human Factors",
    "section": "component of human factors",
    "text": "component of human factors\n\nhuman: physical, cognitive, group\ntask: physical + cognitive + group\nenvirnment: working environment, systems",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Introduction to Human Factors"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/0_intro.html#goal-of-human-factors",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/0_intro.html#goal-of-human-factors",
    "title": "Introduction to Human Factors",
    "section": "Goal of human factors",
    "text": "Goal of human factors\n\nReduce errors\nIncrease productivity\nEnhance safety\nEnhance comfort",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Introduction to Human Factors"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html",
    "title": "Amazon CloudWatch",
    "section": "",
    "text": "every service sends metrics to CloudWatch\nnamespace is a container for metrics\nmetric is a variable to monitor\ndimension is a name/value pair that is attributed to a metric\nup to 30 dimensions per metric\ntimestamp is the time of the data point\nstream data to destination near real-time\n\n\n\n\n\nlog data is stored indefinitely\nlog group is a container for logs\nlog stream is a sequence of log events\nlog event is a record of some activity\nSDK, Elastic Beanstalk, ECS, Lambda, CloudTrail, VPC Flow Logs, Route 53, API Gateway, CloudWatch Unified Agent can send logs to CloudWatch Logs\nlog subscription: send logs to Lambda, Kinesis, ElasticSearch, S3\n\n\n\n\n\ncollect more system-level metrics \n\n\n\n\n\nalarm is a notification that is sent when a metric is in breach of the threshold\nstate: OK, ALARM, INSUFFICIENT_DATA\ntarget: stop, terminate, reboot, recover, start, or snapshot an instance / trigger an Auto Scaling action / send a notification to an SNS topic\nsingle metric alarm, composite alarm, anomaly detection alarm\n\n\n\n\n\ncron jobs\nevent is a change in state\nrule is a description of an event pattern\ntarget is a resource that is invoked when a rule is triggered\nevent bus is a container for events\nevent pattern is a JSON object that describes a set of events to match",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html#matrics",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html#matrics",
    "title": "Amazon CloudWatch",
    "section": "",
    "text": "every service sends metrics to CloudWatch\nnamespace is a container for metrics\nmetric is a variable to monitor\ndimension is a name/value pair that is attributed to a metric\nup to 30 dimensions per metric\ntimestamp is the time of the data point\nstream data to destination near real-time",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html#logs",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html#logs",
    "title": "Amazon CloudWatch",
    "section": "",
    "text": "log data is stored indefinitely\nlog group is a container for logs\nlog stream is a sequence of log events\nlog event is a record of some activity\nSDK, Elastic Beanstalk, ECS, Lambda, CloudTrail, VPC Flow Logs, Route 53, API Gateway, CloudWatch Unified Agent can send logs to CloudWatch Logs\nlog subscription: send logs to Lambda, Kinesis, ElasticSearch, S3",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html#cloudwatch-agent",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html#cloudwatch-agent",
    "title": "Amazon CloudWatch",
    "section": "",
    "text": "collect more system-level metrics",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html#cloudwatch-alarms",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html#cloudwatch-alarms",
    "title": "Amazon CloudWatch",
    "section": "",
    "text": "alarm is a notification that is sent when a metric is in breach of the threshold\nstate: OK, ALARM, INSUFFICIENT_DATA\ntarget: stop, terminate, reboot, recover, start, or snapshot an instance / trigger an Auto Scaling action / send a notification to an SNS topic\nsingle metric alarm, composite alarm, anomaly detection alarm",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html#cloudwatch-events-eventbridge",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html#cloudwatch-events-eventbridge",
    "title": "Amazon CloudWatch",
    "section": "",
    "text": "cron jobs\nevent is a change in state\nrule is a description of an event pattern\ntarget is a resource that is invoked when a rule is triggered\nevent bus is a container for events\nevent pattern is a JSON object that describes a set of events to match",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html#insights-events",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html#insights-events",
    "title": "Amazon CloudWatch",
    "section": "Insights Events",
    "text": "Insights Events\n\ninsights events provide insights into the performance and availability of your AWS Account",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/00_region.html",
    "href": "posts/04_archives/aws_saa/notes/00_region.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "regions:\ncluster of data center\navailability zone (AZ)\n\n\nusually 3, min 3, max 6\none or more discrete data center\nseparate from each others, so that isolated from disasters\n\n\nData center\n\n\nrack\nhost\ninstance\n\n\n\naws edge locations / points of presence\n\n400+ points of presence(400+ edge locations, 10+ regional cathes) in 90+ cities across 40+ contries\n\n\n\n\n\n\n\nglobal\n\n\nIAM\nDNS services\nCDN\nWAF\n\n\nregion\n\n\nec2\nlambda\nrekognition\n\n\n\n\n\ncompliance with data governance and legal requirements\nproximity to customers\navailable services within a region\npricing",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "aws global infrastructure"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/00_region.html#aws-global-infrastructure",
    "href": "posts/04_archives/aws_saa/notes/00_region.html#aws-global-infrastructure",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "regions:\ncluster of data center\navailability zone (AZ)\n\n\nusually 3, min 3, max 6\none or more discrete data center\nseparate from each others, so that isolated from disasters\n\n\nData center\n\n\nrack\nhost\ninstance\n\n\n\naws edge locations / points of presence\n\n400+ points of presence(400+ edge locations, 10+ regional cathes) in 90+ cities across 40+ contries\n\n\n\n\n\n\n\nglobal\n\n\nIAM\nDNS services\nCDN\nWAF\n\n\nregion\n\n\nec2\nlambda\nrekognition\n\n\n\n\n\ncompliance with data governance and legal requirements\nproximity to customers\navailable services within a region\npricing",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "aws global infrastructure"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/01_IAM.html",
    "href": "posts/04_archives/aws_saa/notes/01_IAM.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": ": identity access management (Global service)\n\n\n\ngroup by users (not group itself)\n\n\n\nroot account created by default each users can have multi groups",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Define IAM"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/01_IAM.html#define-iam",
    "href": "posts/04_archives/aws_saa/notes/01_IAM.html#define-iam",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": ": identity access management (Global service)\n\n\n\ngroup by users (not group itself)\n\n\n\nroot account created by default each users can have multi groups",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Define IAM"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/01_IAM.html#iampolicies",
    "href": "posts/04_archives/aws_saa/notes/01_IAM.html#iampolicies",
    "title": "김형훈의 학습 블로그",
    "section": "IAM:Policies",
    "text": "IAM:Policies\n\nUsers or Groups can be assigned JSON documents called policies\npolicies define permissions of the users(inline) or groups\nAWS apply the least privilege principle\n\n\nJSON exe\n{\n    {\n        \"Version\": \"2012-10-17\",\n        // optional: \"id\": \"...\",\n        \"Statement\": [\n            {\n                // optional: \"Sid\": \"...\",\n                \"Effect\": \"Allow\",\n                \"Action\": \"s3:ListBucket\",\n                \"Resource\": \"arn:aws:s3:::example-bucket\"\n            },\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"s3:GetObject\",\n                    \"s3:PutObject\"\n                ],\n                \"Resource\": \"arn:aws:s3:::example-bucket/*\"\n            }\n        ]\n    }\n}\n\nEffect: Allow/Deny\nPrinciple: who can perform the action (account, user, role)\nAction: list of actions that are allowed or denied\nResource: list of resources that are allowed or denied\nCondition: when the policy is in effect (optional)",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Define IAM"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/01_IAM.html#iamroles-for-services",
    "href": "posts/04_archives/aws_saa/notes/01_IAM.html#iamroles-for-services",
    "title": "김형훈의 학습 블로그",
    "section": "IAM:Roles for Services",
    "text": "IAM:Roles for Services\n\nRoles are used to delegate permissions to entities that you trust\n\n\ntrusted entities\n\nAWS account\n\nAWS services\n\nEC2, Lambda, CodeBuild, CodePipeline, etc.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Define IAM"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/01_IAM.html#iamsecurity-tools",
    "href": "posts/04_archives/aws_saa/notes/01_IAM.html#iamsecurity-tools",
    "title": "김형훈의 학습 블로그",
    "section": "IAM:Security Tools",
    "text": "IAM:Security Tools\n\nIAM Credentials Report (account level):\nlist of all users and their various credentials\nIAM Access Advisor (user level):\nhow long each service has been active and when it was last used",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Define IAM"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html",
    "href": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html",
    "title": "Amazon RDS",
    "section": "",
    "text": "Amazon RDS is a managed relational database service that provides a highly available, scalable, and secure database.\nAmazon RDS supports multiple database engines:\n\nAmazon Aurora\nMySQL\nMariaDB\nPostgreSQL\nOracle\nMicrosoft SQL Server\n\nAmazon RDS provides the following features:\n\nAutomated backups\nMulti-AZ deployments\nRead replicas\nMonitoring\nSecurity\nScalability\nHigh availability ### auto scaling\n\nmust set maximum storage threshold\n\n\nfree storage is less then 10% of allocated storage\nlow-storage lasts at least 5 minutes\n6 hours have passed since last modification\n\n\n\n\nup to 15 read replicas\nwithin AZ, cross AZ, cross region (dont pay for data transfer across AZ, not across region)\nread replicas can be promoted to a standalone database\n\n\n\n\nused for disaster recovery(not used for scaling)\nsynchronous replication\nfailover to standby in case of primary failure\nno manual intervention ### from single AZ to multi AZ\nzero downtime\njust modify for the database instance\n\n\n\n\n\n\nMySQL and PostgreSQL compatible\ncloud optimized (5 times faster than MySQL, 3 times faster than PostgreSQL)\nstorage auto scaling\n15 read replicas (cross region)\nfailover instantaneously (less than 30 seconds through master node)\ncost more but effective ### High Availability and Read Scalability\n6 copies of data across 3 AZs (4 copies is needed for write, 3 copies is needed for read)\nself-healing storage\nstorage is striped across 100s of volumes\n\n\n\n\n1 primary region\n5 read-only secondary regions\nreplication lag is less than 1 second\nup to 16 read replicas per secondary region\nfailover to secondary region\ncross-region replication takes less than 1 second\n\n\n\n\n\n\n\n\nAutomated backup (can disable, 5 minutes backup window)\nManual snapshot (retention as log as you want)\nsnapshot restore =&gt; new database\ns3 restore\n\n\n\n\n\nAutomated backup (cannot disable, point-in-time recovery)\nManual snapshot (retention as log as you want)\nsnapshot restore =&gt; new database\nPercona XtraBackup, s3 restore\n\n\n\n\n\n\n\n\n\nin-memory caching service\nRedis or Memcached (no high availability and backup)\nheavy application code change",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon RDS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#rds-read-replicas-for-read-scalibity",
    "href": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#rds-read-replicas-for-read-scalibity",
    "title": "Amazon RDS",
    "section": "",
    "text": "up to 15 read replicas\nwithin AZ, cross AZ, cross region (dont pay for data transfer across AZ, not across region)\nread replicas can be promoted to a standalone database\n\n\n\n\nused for disaster recovery(not used for scaling)\nsynchronous replication\nfailover to standby in case of primary failure\nno manual intervention ### from single AZ to multi AZ\nzero downtime\njust modify for the database instance",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon RDS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#amazon-aurora",
    "href": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#amazon-aurora",
    "title": "Amazon RDS",
    "section": "",
    "text": "MySQL and PostgreSQL compatible\ncloud optimized (5 times faster than MySQL, 3 times faster than PostgreSQL)\nstorage auto scaling\n15 read replicas (cross region)\nfailover instantaneously (less than 30 seconds through master node)\ncost more but effective ### High Availability and Read Scalability\n6 copies of data across 3 AZs (4 copies is needed for write, 3 copies is needed for read)\nself-healing storage\nstorage is striped across 100s of volumes\n\n\n\n\n1 primary region\n5 read-only secondary regions\nreplication lag is less than 1 second\nup to 16 read replicas per secondary region\nfailover to secondary region\ncross-region replication takes less than 1 second",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon RDS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#backup",
    "href": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#backup",
    "title": "Amazon RDS",
    "section": "",
    "text": "Automated backup (can disable, 5 minutes backup window)\nManual snapshot (retention as log as you want)\nsnapshot restore =&gt; new database\ns3 restore\n\n\n\n\n\nAutomated backup (cannot disable, point-in-time recovery)\nManual snapshot (retention as log as you want)\nsnapshot restore =&gt; new database\nPercona XtraBackup, s3 restore",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon RDS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#elasticcache",
    "href": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#elasticcache",
    "title": "Amazon RDS",
    "section": "",
    "text": "in-memory caching service\nRedis or Memcached (no high availability and backup)\nheavy application code change",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon RDS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/04_elb_asg.html",
    "href": "posts/04_archives/aws_saa/notes/04_elb_asg.html",
    "title": "ELB",
    "section": "",
    "text": "HTTP, HTTPS, WebSockets\n\nLayer 7\nfixed hostname in every AZ\nclient IP address preservation in the X-Forwarded-For header\ncan use sticky sessions through cookies #### target group\nEC2 instances\nECS tasks\nLambda functions\nIP addresses (private) #### routing routing to diffrent target or same machine different application based on:\nrouting based on URL\nrouting based on hostname\nrouting based on path\nrouting based on query string\nrouting based on HTTP header\nrouting based on port\n\n\n\n\n\nTCP, TLS, UDP\n\nLayer 4\nfixed IP address per AZ and support assigning Elastic IP address\nhigh throughput and low latency #### target group\nEC2 instances\nIP addresses (private)\nLambda functions\nALB\n\n\n\n\n\nip\nLayer 3\nDeploy, scale, and manage third-party virtual appliances\nexample: firewall, intrusion detection and prevention, deep packet inspection, and security analytics\nTransparent Network Gateway: single endpoint for all traffic\nLoad Balancer Gateway: distribute traffic across multiple virtual appliances\nUse GENEVE tunneling protocol on port 6081 #### target group\nEC2 instances\nIP addresses (private)\n\n\n\n\n\n\ndistribute traffic evenly across all registered instances in all enabled AZs\nenabled by default for ALB and no charge for inter AZ data transfer (can be disabled in target group)\ndisabled by default for NLB, GWLB and charge for inter AZ data transfer\n\n\n\n\n\n\n\nServer Name Indication\nALB and NLB and cloudFront support SNI\n\n\n\n\n\n\nALB and NLB support connection draining (deregestration delay)\n\n\n\n\n\n\n\nTarget tracking scaling policy\nSimple / Step scaling policy\nScheduled scaling policy\nPredictive scaling policy",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "ELB"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/04_elb_asg.html#types-of-elb",
    "href": "posts/04_archives/aws_saa/notes/04_elb_asg.html#types-of-elb",
    "title": "ELB",
    "section": "",
    "text": "HTTP, HTTPS, WebSockets\n\nLayer 7\nfixed hostname in every AZ\nclient IP address preservation in the X-Forwarded-For header\ncan use sticky sessions through cookies #### target group\nEC2 instances\nECS tasks\nLambda functions\nIP addresses (private) #### routing routing to diffrent target or same machine different application based on:\nrouting based on URL\nrouting based on hostname\nrouting based on path\nrouting based on query string\nrouting based on HTTP header\nrouting based on port\n\n\n\n\n\nTCP, TLS, UDP\n\nLayer 4\nfixed IP address per AZ and support assigning Elastic IP address\nhigh throughput and low latency #### target group\nEC2 instances\nIP addresses (private)\nLambda functions\nALB\n\n\n\n\n\nip\nLayer 3\nDeploy, scale, and manage third-party virtual appliances\nexample: firewall, intrusion detection and prevention, deep packet inspection, and security analytics\nTransparent Network Gateway: single endpoint for all traffic\nLoad Balancer Gateway: distribute traffic across multiple virtual appliances\nUse GENEVE tunneling protocol on port 6081 #### target group\nEC2 instances\nIP addresses (private)",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "ELB"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/04_elb_asg.html#cross-zone-load-balancing",
    "href": "posts/04_archives/aws_saa/notes/04_elb_asg.html#cross-zone-load-balancing",
    "title": "ELB",
    "section": "",
    "text": "distribute traffic evenly across all registered instances in all enabled AZs\nenabled by default for ALB and no charge for inter AZ data transfer (can be disabled in target group)\ndisabled by default for NLB, GWLB and charge for inter AZ data transfer",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "ELB"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/04_elb_asg.html#ssltls",
    "href": "posts/04_archives/aws_saa/notes/04_elb_asg.html#ssltls",
    "title": "ELB",
    "section": "",
    "text": "Server Name Indication\nALB and NLB and cloudFront support SNI",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "ELB"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/04_elb_asg.html#connection-draining",
    "href": "posts/04_archives/aws_saa/notes/04_elb_asg.html#connection-draining",
    "title": "ELB",
    "section": "",
    "text": "ALB and NLB support connection draining (deregestration delay)",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "ELB"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/04_elb_asg.html#asg",
    "href": "posts/04_archives/aws_saa/notes/04_elb_asg.html#asg",
    "title": "ELB",
    "section": "",
    "text": "Target tracking scaling policy\nSimple / Step scaling policy\nScheduled scaling policy\nPredictive scaling policy",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "ELB"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html",
    "title": "VPC",
    "section": "",
    "text": ": AWS managed NAT instance, use specific AZ, elastic IP only for another subnet\n\n\n\n: stateless, allow/deny traffic in/out of subnet default, it allows all traffic \n\n\n\n\n\n\nVPC\n\n\n\n\n\n: private connection between VPC and AWS services - Gateway endpoint: S3, DynamoDB. taget of route table - Interface endpoint: API Gateway, CloudWatch, KMS, SSM, S3, DynamoDB, etc.\n\n\n\n: VPC flow logs, capture information about IP traffic going to and from network interfaces in your VPC\n\n\n\n: connect on-premises network to AWS VPC \n\n\n\n: dedicated network connection between on-premises and AWS\n\n\n\n: IPv6 only, allow outbound traffic to the internet",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#nat-gateway",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#nat-gateway",
    "title": "VPC",
    "section": "",
    "text": ": AWS managed NAT instance, use specific AZ, elastic IP only for another subnet",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#nacls",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#nacls",
    "title": "VPC",
    "section": "",
    "text": ": stateless, allow/deny traffic in/out of subnet default, it allows all traffic",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#vpc-peering",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#vpc-peering",
    "title": "VPC",
    "section": "",
    "text": "VPC",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#vpc-endpoint",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#vpc-endpoint",
    "title": "VPC",
    "section": "",
    "text": ": private connection between VPC and AWS services - Gateway endpoint: S3, DynamoDB. taget of route table - Interface endpoint: API Gateway, CloudWatch, KMS, SSM, S3, DynamoDB, etc.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#vpc-flow-logs",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#vpc-flow-logs",
    "title": "VPC",
    "section": "",
    "text": ": VPC flow logs, capture information about IP traffic going to and from network interfaces in your VPC",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#site-to-site-vpn",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#site-to-site-vpn",
    "title": "VPC",
    "section": "",
    "text": ": connect on-premises network to AWS VPC",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#direct-connectdx",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#direct-connectdx",
    "title": "VPC",
    "section": "",
    "text": ": dedicated network connection between on-premises and AWS",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#egress-only-internet-gateway",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#egress-only-internet-gateway",
    "title": "VPC",
    "section": "",
    "text": ": IPv6 only, allow outbound traffic to the internet",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/16_IAM.html",
    "href": "posts/04_archives/aws_saa/notes/16_IAM.html",
    "title": "AWS Organization",
    "section": "",
    "text": "global service\ncontrol over multiple AWS accounts\nconsolidated billing\nshared reserved instances and savings plans across accounts ## service control policies (SCPs)\nIAM policy applied to OU or account except management account\n\n\n\n\ncloudwatch agent\n\n\n\n\n\ncloudwatch agent\n\n\n\n\n\nIAM role: cross-account access\nResource-based policy: cross-service access \n\n\n\n\n\nsupported for users and roles(not groups)\nmaximum permissions that an entity can have\nIAM policy + permission boundary = effective permissions \n\n\n\n\n\n\n\n\nAD Connector: on-premises AD, redirect to on-premises AD (proxy)\nSimple AD: standalone AD\nAWS Managed Microsoft AD: managed AD, trust relationship",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Organization"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/16_IAM.html#iam-role-vs-resource-based-policy",
    "href": "posts/04_archives/aws_saa/notes/16_IAM.html#iam-role-vs-resource-based-policy",
    "title": "AWS Organization",
    "section": "",
    "text": "IAM role: cross-account access\nResource-based policy: cross-service access",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Organization"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/16_IAM.html#iam-permission-boundaries",
    "href": "posts/04_archives/aws_saa/notes/16_IAM.html#iam-permission-boundaries",
    "title": "AWS Organization",
    "section": "",
    "text": "supported for users and roles(not groups)\nmaximum permissions that an entity can have\nIAM policy + permission boundary = effective permissions",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Organization"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/16_IAM.html#aws-directory-service",
    "href": "posts/04_archives/aws_saa/notes/16_IAM.html#aws-directory-service",
    "title": "AWS Organization",
    "section": "",
    "text": "AD Connector: on-premises AD, redirect to on-premises AD (proxy)\nSimple AD: standalone AD\nAWS Managed Microsoft AD: managed AD, trust relationship",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Organization"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/08_cloudfront.html",
    "href": "posts/04_archives/aws_saa/notes/08_cloudfront.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "CDN: Content Delivery Network\nedge location: cache content\nTTL: Time To Live. Cache Invalidation\norigin: source of the file the CDN will distribute\n\nS3 bucket: also used as ingress\nEC2 instance\nELB\nany HTTP server\n\ndistribution: the name given to the CDN which consists of a collection of edge locations  ### price class\nprice class: the number of edge locations used\n\nall: all edge locations\n200: all edge locations except the most expensive\n100: only the least expensive edge locations\n\n\n\n\n\nAWS Global Accelerator: improve the availability and performance of your applications with local or global users\nAnycast IP: route user traffic to the nearest edge location\nstatic IP: anycast IP",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "CloudFront"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/08_cloudfront.html#cloudfront",
    "href": "posts/04_archives/aws_saa/notes/08_cloudfront.html#cloudfront",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "CDN: Content Delivery Network\nedge location: cache content\nTTL: Time To Live. Cache Invalidation\norigin: source of the file the CDN will distribute\n\nS3 bucket: also used as ingress\nEC2 instance\nELB\nany HTTP server\n\ndistribution: the name given to the CDN which consists of a collection of edge locations  ### price class\nprice class: the number of edge locations used\n\nall: all edge locations\n200: all edge locations except the most expensive\n100: only the least expensive edge locations\n\n\n\n\n\nAWS Global Accelerator: improve the availability and performance of your applications with local or global users\nAnycast IP: route user traffic to the nearest edge location\nstatic IP: anycast IP",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "CloudFront"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "managed service to create and control encryption keys\nAble to audit key usage with CloudTrail\nattached to region =&gt; can replicate across regions\n\n\n\n\nsymmetric key: same key for encryption and decryption\nasymmetric key: public and private key\n\n\n\n\n\nAWS owned key: managed by AWS\nAWS Managed key: managed by AWS but you have control over the key policy\nCustomer managed key: managed by you, but AWS manages the underlying infrastructure, not free\n\n\n\n\n\nkey policy is attached to the key\nDefault key policy: complete access to the key\ncustom key policy: define who can use the key and roles and who can administer the key",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#kmskey-management-service",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#kmskey-management-service",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "managed service to create and control encryption keys\nAble to audit key usage with CloudTrail\nattached to region =&gt; can replicate across regions\n\n\n\n\nsymmetric key: same key for encryption and decryption\nasymmetric key: public and private key\n\n\n\n\n\nAWS owned key: managed by AWS\nAWS Managed key: managed by AWS but you have control over the key policy\nCustomer managed key: managed by you, but AWS manages the underlying infrastructure, not free\n\n\n\n\n\nkey policy is attached to the key\nDefault key policy: complete access to the key\ncustom key policy: define who can use the key and roles and who can administer the key",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#aws-wafweb-application-firewall",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#aws-wafweb-application-firewall",
    "title": "김형훈의 학습 블로그",
    "section": "AWS WAF(Web Application Firewall)",
    "text": "AWS WAF(Web Application Firewall)\n\ndeploy on\n\nCloudFront (global)\nApplication Load Balancer (regional)\nAPI Gateway (regional)\nAppSync GraphQL API (regional)\ncognito (regional)\n\n\n\nfeatures\n\nprotect from SQL injection, cross-site scripting, and other web attacks\nIP blacklisting and whitelisting\nfilter HTTP headers / body / URI\nlimit the size of requests\ngeo-blocking\nrate limiting (DDoS protection)",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#aws-shield",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#aws-shield",
    "title": "김형훈의 학습 블로그",
    "section": "AWS Shield",
    "text": "AWS Shield\n\nDDoS protection service\nStandard and Advanced plan",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#aws-firewall-manager",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#aws-firewall-manager",
    "title": "김형훈의 학습 블로그",
    "section": "AWS Firewall Manager",
    "text": "AWS Firewall Manager\n\ncentral management service to configure and manage WAF rules across accounts and applications",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#amazon-guardduty",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#amazon-guardduty",
    "title": "김형훈의 학습 블로그",
    "section": "Amazon GuardDuty",
    "text": "Amazon GuardDuty\n\nthreat detection service\ngood for detect crypto currency mining",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#amazon-inspector",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#amazon-inspector",
    "title": "김형훈의 학습 블로그",
    "section": "Amazon Inspector",
    "text": "Amazon Inspector\n\nsecurity assessment service\ncontinuous assessment of applications for vulnerabilities and deviations from best practices",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#amazon-macie",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#amazon-macie",
    "title": "김형훈의 학습 블로그",
    "section": "Amazon Macie",
    "text": "Amazon Macie\n\ndata security and data privacy service\ndetect and protect sensitive data",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/12_database.html",
    "href": "posts/04_archives/aws_saa/notes/12_database.html",
    "title": "database choice in aws",
    "section": "",
    "text": "RDBMS(RDS, aurora): SQL, OLTP\nNoSQL: DynamoDB(JSON), ElasticCache(key / value), Neptune(graphs), DocumentDB(MongoDB), Keyspaces(Cassandra)\nObject storage: S3(for big), Glacier(for backup, archive)\nData warehouse: SQL analytics, Redshift(OLAP), athena, EMR\nSearch: openSearch(JSON)\nGraphs: Amazon Neptune\nLedger: QLDB\nTime series: Timestream\n\n\n\n\nMongoDB compatible\nFully managed\nhighly available with replication across 3 AZs\nAutomatically scales up to 10GB storage, millions of requests per seconds workloads\n\n\n\n\n\nGraph database\nFully managed\nHighl available with replication across 3 AZs, up to 15 read replicas\nSupports up to billions of relations\n\n\n\n\n\nCassandra compatible\nFully managed\nAutomatically scale tables based on traffic\ntables replicated across 3 times across multiple AZs\nondemand, provisioned\n\n\n\n\n\nLedger database\nFully managed\nimmutable, transparent, cryptographically verifiable transaction log\nhigh performance, low latency\nserverless, pay as you go\nno decentralized consensus, no blockchain\n\n\n\n\n\nTime series database\nFully managed\nstore and analyze trillions of events per day",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "database choice in aws"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/12_database.html#database-types",
    "href": "posts/04_archives/aws_saa/notes/12_database.html#database-types",
    "title": "database choice in aws",
    "section": "",
    "text": "RDBMS(RDS, aurora): SQL, OLTP\nNoSQL: DynamoDB(JSON), ElasticCache(key / value), Neptune(graphs), DocumentDB(MongoDB), Keyspaces(Cassandra)\nObject storage: S3(for big), Glacier(for backup, archive)\nData warehouse: SQL analytics, Redshift(OLAP), athena, EMR\nSearch: openSearch(JSON)\nGraphs: Amazon Neptune\nLedger: QLDB\nTime series: Timestream\n\n\n\n\nMongoDB compatible\nFully managed\nhighly available with replication across 3 AZs\nAutomatically scales up to 10GB storage, millions of requests per seconds workloads\n\n\n\n\n\nGraph database\nFully managed\nHighl available with replication across 3 AZs, up to 15 read replicas\nSupports up to billions of relations\n\n\n\n\n\nCassandra compatible\nFully managed\nAutomatically scale tables based on traffic\ntables replicated across 3 times across multiple AZs\nondemand, provisioned\n\n\n\n\n\nLedger database\nFully managed\nimmutable, transparent, cryptographically verifiable transaction log\nhigh performance, low latency\nserverless, pay as you go\nno decentralized consensus, no blockchain\n\n\n\n\n\nTime series database\nFully managed\nstore and analyze trillions of events per day",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "database choice in aws"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/index.html",
    "href": "posts/04_archives/adp_실기/index.html",
    "title": "ADP 실기 준비",
    "section": "",
    "text": "FAILED\n    \n    \n        시작일: 2024-12-21\n        종료일: 2025-02-05\n    \n    \n        \n            \n        \n        계산 중...\n    \n    \n    \n        자격증데이터 분석python",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/index.html#details",
    "href": "posts/04_archives/adp_실기/index.html#details",
    "title": "ADP 실기 준비",
    "section": "Details",
    "text": "Details",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/index.html#tasks",
    "href": "posts/04_archives/adp_실기/index.html#tasks",
    "title": "ADP 실기 준비",
    "section": "Tasks",
    "text": "Tasks\n\n\n\n    \n    \n    \n            \n                \n                \n                    파이썬 한권으로 끝내기 완독\n                \n                \n            \n            \n            \n                \n                    \n                    원서 접수 (2025.03.24 10 am)",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/index.html#why-failed",
    "href": "posts/04_archives/adp_실기/index.html#why-failed",
    "title": "ADP 실기 준비",
    "section": "Why failed?",
    "text": "Why failed?\nTOFEL이 더 급하다.\n4학년 때 도전하자.",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/index.html#related-posts",
    "href": "posts/04_archives/adp_실기/index.html#related-posts",
    "title": "ADP 실기 준비",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/04.html",
    "href": "posts/04_archives/adp_실기/notes/04.html",
    "title": "머신 러닝",
    "section": "",
    "text": "맨 위로",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "머신 러닝"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#edaexploratory-data-analysis",
    "href": "posts/04_archives/adp_실기/notes/02.html#edaexploratory-data-analysis",
    "title": "EDA와 시각화",
    "section": "EDA(Exploratory Data Analysis)",
    "text": "EDA(Exploratory Data Analysis)\n: 데이터의 특징과 데이터에 내재된 관계를 알아내기 위해 그래프와 통계적 분석 방법을 활용하여 탐구하는 것\n\n주제\n\n저항성 강조: 부분적 변동(이상치 등)에 대한 민감성 확인\n잔차 계산\n자료변수의 재표현: 변수를 적당한 척도로 바꾸는 것\n그래프를 통한 현시성",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#막대-그래프",
    "href": "posts/04_archives/adp_실기/notes/02.html#막대-그래프",
    "title": "EDA와 시각화",
    "section": "막대 그래프",
    "text": "막대 그래프\n범주형 데이터를 요약하고 시각적으로 비교하는 데 활용\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_wine\n\nwine_load = load_wine()\nwine = pd.DataFrame(wine_load.data, columns=wine_load.feature_names)\nwine_load\nwine['Class'] = wine_load.target\nwine['Class'] = wine['Class'].map({0: 'class_0', 1: 'class_1', 2: 'class_2'})\n\nwine_type = wine['Class'].value_counts()\nwine_type\n\nClass\nclass_1    71\nclass_0    59\nclass_2    48\nName: count, dtype: int64\n\n\n\n# 수직 막대\nplt.bar(wine_type.index, wine_type.values, width=0.8, bottom=None, align = 'center')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 수평 막대\nplt.barh(wine_type.index, wine_type.values, height=0.8, left=None, align = 'center')\nplt.show()\n\n\n\n\n\n\n\n\n각 범주의 값의 갯수 차이가 극단적인지 확인한다. 극단적일 경우, 전처리 과정에서 업/다운 샘플링 등을 통해 갯수가 유사해지도록 조정해야한다.",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#히스토그램",
    "href": "posts/04_archives/adp_실기/notes/02.html#히스토그램",
    "title": "EDA와 시각화",
    "section": "히스토그램",
    "text": "히스토그램\n연속형 데이터의 분포를 확인하는 데 활용\n\nplt.title('Wine alcohol histogram')\nplt.hist('alcohol', bins=8, range=(11, 15), color='purple', data=wine)\nplt.show()",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#box-plot",
    "href": "posts/04_archives/adp_실기/notes/02.html#box-plot",
    "title": "EDA와 시각화",
    "section": "box plot",
    "text": "box plot\n수치형 변수의 분포를 확인하는 그래프\n\nfrom sklearn.datasets import load_iris\n\niris_load = load_iris()\niris = pd.DataFrame(iris_load.data, columns=iris_load.feature_names)\niris['class'] = iris_load.target\niris['class'] = iris['class'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n\nplt.boxplot(iris.drop(columns='class'))\nplt.show()\n\n\n\n\n\n\n\n\n\nimport seaborn as sns\n\nsns.boxplot(x=\"class\", y=\"sepal width (cm)\", data=iris)\nplt.show()",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#산점도",
    "href": "posts/04_archives/adp_실기/notes/02.html#산점도",
    "title": "EDA와 시각화",
    "section": "산점도",
    "text": "산점도\n두 개의 수치형 변수의 분포와 관계를 확인하는 그래프\n\nplt.title('iris scatter')\nplt.xlabel('sepal length (cm)')\nplt.ylabel('sepal width (cm)')\n\nplt.scatter('sepal length (cm)', 'sepal width (cm)', data=iris, alpha=0.5)\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.scatterplot(x='sepal length (cm)', y='sepal width (cm)', hue='class', data=iris, style='class')\nplt.show()",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#선그래프",
    "href": "posts/04_archives/adp_실기/notes/02.html#선그래프",
    "title": "EDA와 시각화",
    "section": "선그래프",
    "text": "선그래프\n\n수평 / 수직 선\n\nplt.hlines(y=-6, xmin=-10, xmax=10, colors='red', linestyles='solid')\nplt.vlines(x=0, ymin=-10, ymax=10, colors='blue', linestyles='dashed')\n\n\n\n\n\n\n\n\n\n\n함수식\n\ndef linear_func(x):\n    return 2*x + 1\n\nX = iris['sepal length (cm)']\nplt.plot(X, linear_func(X), c='red')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n회귀선\n\nimport numpy as np\n\nX, Y = iris['sepal length (cm)'], iris['sepal width (cm)']\nplt.scatter(X, Y, alpha=0.5)\na, b = np.polyfit(X, Y, 1)\nplt.plot(X, a*X + b, c='red')\nplt.show()\n\n\n\n\n\n\n\n\n2차 이상의 그래프는 X값에 대하여 정렬해야 한다.\n\niris2 = iris.sort_values(by='sepal length (cm)')\nX, Y = iris2['sepal length (cm)'], iris2['petal length (cm)']\nb2, b1, b0 = np.polyfit(X, Y, 2)\nplt.scatter(X, Y, alpha=0.5)\nplt.plot(X, b0 + b1*X + b2*X**2, color='red')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n꺾은선\n\nplt.plot('sepal length (cm)', 'petal length (cm)', data=iris2)\nplt.show()",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#상관관계-시각화",
    "href": "posts/04_archives/adp_실기/notes/02.html#상관관계-시각화",
    "title": "EDA와 시각화",
    "section": "상관관계 시각화",
    "text": "상관관계 시각화\n\n산점도 행렬\n\nfrom pandas.plotting import scatter_matrix\n\nscatter_matrix(iris, alpha=0.5, figsize= (8, 8), diagonal='hist')\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.pairplot(iris, diag_kind='auto', hue='class')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n상관계수 행렬 그래프\n\niris_corr = iris.drop(columns='class').corr(method='pearson')\nsns.heatmap(iris_corr, xticklabels=iris_corr.columns, yticklabels=iris_corr.columns, cmap=\"RdBu_r\", annot=True)",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#pandas-profiling",
    "href": "posts/04_archives/adp_실기/notes/02.html#pandas-profiling",
    "title": "EDA와 시각화",
    "section": "Pandas Profiling",
    "text": "Pandas Profiling\n\n# from pandas_profiling import ProfileReport\n#\n# ProfileReport(iris)",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/3_cluster_maintainance.html",
    "href": "posts/04_archives/k8s/notes/3_cluster_maintainance.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "k8s wait for 5 minutes to mark a node as ‘dead’ in default\nif a node is marked as ‘dead’, the pods on the node will be rescheduled to other nodes\ndrain: remove all the pods from a node and reschedule them to other nodes\ncordon: mark a node as ‘unschedulable’ so that no new pods will be scheduled to the node\nuncordon: mark a node as ‘schedulable’ so that new pods can be scheduled to the node but the original pods will not be rescheduled",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "fail tolerance"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/3_cluster_maintainance.html#fail-tolerance",
    "href": "posts/04_archives/k8s/notes/3_cluster_maintainance.html#fail-tolerance",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "k8s wait for 5 minutes to mark a node as ‘dead’ in default\nif a node is marked as ‘dead’, the pods on the node will be rescheduled to other nodes\ndrain: remove all the pods from a node and reschedule them to other nodes\ncordon: mark a node as ‘unschedulable’ so that no new pods will be scheduled to the node\nuncordon: mark a node as ‘schedulable’ so that new pods can be scheduled to the node but the original pods will not be rescheduled",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "fail tolerance"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/3_cluster_maintainance.html#cluster-upgrade-process",
    "href": "posts/04_archives/k8s/notes/3_cluster_maintainance.html#cluster-upgrade-process",
    "title": "김형훈의 학습 블로그",
    "section": "cluster upgrade process",
    "text": "cluster upgrade process\n - k8s supports up to recent 3 minor versions  ### kubeadm upgrade 1. upgrade kubeadm 2. command: kubeadm upgrade apply 3. upgrade kubelet and kubectl",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "fail tolerance"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/7_design_cluster.html",
    "href": "posts/04_archives/k8s/notes/7_design_cluster.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "api-server: multiple instances, active-active, load balancer\ncontroller-manager: multiple instances, active-standby, leader election",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "HA in master node"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/7_design_cluster.html#ha-in-master-node",
    "href": "posts/04_archives/k8s/notes/7_design_cluster.html#ha-in-master-node",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "api-server: multiple instances, active-active, load balancer\ncontroller-manager: multiple instances, active-standby, leader election",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "HA in master node"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "if scheduler is not exist, user can mannually schedule pods to nodes - in pod spec, set nodeName field to the name of the node - if the node is not exist, the pod will be in Pending state - bind request",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#manual-scheduling",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#manual-scheduling",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "if scheduler is not exist, user can mannually schedule pods to nodes - in pod spec, set nodeName field to the name of the node - if the node is not exist, the pod will be in Pending state - bind request",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#taints-and-tolerations",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#taints-and-tolerations",
    "title": "김형훈의 학습 블로그",
    "section": "taints and tolerations",
    "text": "taints and tolerations\n\ntaints: a taint is a key-value pair that is applied to a node\ntolerations: a toleration is a key-value pair that is applied to a pod  \nnot garantee that the pod will be scheduled to the node",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#node-affinity",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#node-affinity",
    "title": "김형훈의 학습 블로그",
    "section": "node affinity",
    "text": "node affinity\n\n\n\nnode affinity",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#resource-limits-requests",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#resource-limits-requests",
    "title": "김형훈의 학습 블로그",
    "section": "resource limits, requests",
    "text": "resource limits, requests\n\nresource limits: the maximum amount of resources that a container can use\nresource requests: the amount of resources that a container is guaranteed to have\nresource quotas: the maximum amount of resources that a namespace can use\nlimit range: the minimum and maximum amount of resources that a container can use when it is created",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#static-pod",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#static-pod",
    "title": "김형훈의 학습 블로그",
    "section": "static pod",
    "text": "static pod\n\nstatic pod is a pod that is created by the kubelet on a node\nif kube-api is available, the kubelet will create the mirror pod in the api server. that is read-only  or in /etc/kubernetes/manifests",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#multiple-shedulers",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#multiple-shedulers",
    "title": "김형훈의 학습 블로그",
    "section": "multiple shedulers",
    "text": "multiple shedulers",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#configuring-sheduler-profile",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#configuring-sheduler-profile",
    "title": "김형훈의 학습 블로그",
    "section": "configuring sheduler profile",
    "text": "configuring sheduler profile\n: single sheduler, multi profile",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/5_storage.html",
    "href": "posts/04_archives/k8s/notes/5_storage.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "A persistant volume is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using a storage class.\nuser can create a persistant volume claim to request a persistant volume with specific storage capacity and access modes.\n1:1 mapping between a persistant volume and a persistant volume claim.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Persistant volume"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/5_storage.html#persistant-volume",
    "href": "posts/04_archives/k8s/notes/5_storage.html#persistant-volume",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "A persistant volume is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using a storage class.\nuser can create a persistant volume claim to request a persistant volume with specific storage capacity and access modes.\n1:1 mapping between a persistant volume and a persistant volume claim.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Persistant volume"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/5_storage.html#storage-class",
    "href": "posts/04_archives/k8s/notes/5_storage.html#storage-class",
    "title": "김형훈의 학습 블로그",
    "section": "storage class",
    "text": "storage class\n\ndynamically provisioned persistant volumes.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Persistant volume"
    ]
  },
  {
    "objectID": "posts/04_archives/vault/index.html",
    "href": "posts/04_archives/vault/index.html",
    "title": "vault",
    "section": "",
    "text": "vault 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Archives",
      "vault"
    ]
  },
  {
    "objectID": "posts/04_archives/vault/index.html#details",
    "href": "posts/04_archives/vault/index.html#details",
    "title": "vault",
    "section": "",
    "text": "vault 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Archives",
      "vault"
    ]
  },
  {
    "objectID": "posts/04_archives/vault/index.html#tasks",
    "href": "posts/04_archives/vault/index.html#tasks",
    "title": "vault",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Archives",
      "vault"
    ]
  },
  {
    "objectID": "posts/04_archives/vault/index.html#참고-자료",
    "href": "posts/04_archives/vault/index.html#참고-자료",
    "title": "vault",
    "section": "참고 자료",
    "text": "참고 자료\n\nvault Udemy 강의",
    "crumbs": [
      "PARA",
      "Archives",
      "vault"
    ]
  },
  {
    "objectID": "posts/04_archives/vault/index.html#related-posts",
    "href": "posts/04_archives/vault/index.html#related-posts",
    "title": "vault",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Archives",
      "vault"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/index.html",
    "href": "posts/04_archives/adp_필기/index.html",
    "title": "ADP 필기 준비",
    "section": "",
    "text": "COMPLETED\n    \n    \n        시작일: 2025-02-02\n        종료일: 2025-02-22\n    \n    \n        \n            \n        \n        계산 중...\n    \n    \n    \n        자격증데이터 분석",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/index.html#details",
    "href": "posts/04_archives/adp_필기/index.html#details",
    "title": "ADP 필기 준비",
    "section": "Details",
    "text": "Details\n1회차 시도는 실패했지만, 이번엔 잘 되겠죠",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/index.html#참고-자료",
    "href": "posts/04_archives/adp_필기/index.html#참고-자료",
    "title": "ADP 필기 준비",
    "section": "참고 자료",
    "text": "참고 자료\n\n왜 2025버전 안내주는지 모르겠는 참고서\n이 통계 유튜브\n이 통계 유튜브2\n이 통계 유튜브3\n이 통계 유튜브4\n이 딥러닝 유튜브\n이 블로그 글",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/index.html#tasks",
    "href": "posts/04_archives/adp_필기/index.html#tasks",
    "title": "ADP 필기 준비",
    "section": "Tasks",
    "text": "Tasks\n\n\n\n    \n    \n    \n            \n                \n                    \n                    원서 접수 (2025.01.20 10 am)\n                \n                2025.02.22 10:00 수원공업고등학교\n            \n\n            \n            \n                \n                    \n                    경기도 자격증 응시료 지원 신청\n                \n                아마도 5월 쯤 뜨지 않을까",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/index.html#related-posts",
    "href": "posts/04_archives/adp_필기/index.html#related-posts",
    "title": "ADP 필기 준비",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/06.html#마스터-플랜-수립-프레임-워크",
    "href": "posts/04_archives/adp_필기/notes/06.html#마스터-플랜-수립-프레임-워크",
    "title": "3 - 분석 마스터 플랜",
    "section": "마스터 플랜 수립 프레임 워크",
    "text": "마스터 플랜 수립 프레임 워크\n\n\n\n마스터 플랜 수립 개요\n\n\n\n2. 수행 과제 도출 및 우선순위 평가\n\n\n\n일반적인 IT 프로젝트 우선순위 평가\n\n\n\n\n\nROI 관점\n\n\n위 기준에 따라 시급성과 난이도를 평가한 후, 아래 그림에 맞게 우선순위를 정한다.\n\n우선순위 기준을 시급성에 둔다면, 3 → 4 → 2 순, 난이도에 둔다면 3 → 1 → 2 순으로 우선순위를 정한다.\n\n\n3. 이행계획 수립\n\n\n\n로드맵 수립\n\n\n\n세부 이행계획 수립",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "3 - 분석 마스터 플랜"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/06.html#분석-거버넌스-체계-수립",
    "href": "posts/04_archives/adp_필기/notes/06.html#분석-거버넌스-체계-수립",
    "title": "3 - 분석 마스터 플랜",
    "section": "분석 거버넌스 체계 수립",
    "text": "분석 거버넌스 체계 수립\n\n1. 거버넌스 체계\n\n\n\n2. 데이터 분석 수준진단\n\n\n분석 준비도\n\n\n\n분석 성숙도\n\n\n\n\nCMMI(Capability Maturity Model Integration)\n\n\n분석 준비도와 성숙도를 통해 현재 분석 수준을 파악한다. 이후 아래의 그림에 맞춰 목표 방향을 설정한다.\n\n\n\n4. 데이터 거버넌스 체계 수립\n\n구성 요소:\n\n원칙\n조직\n프로세스\n\n\n\n\n\n체계\n\n\n\n데이터 표준화: 규칙같은거 통일하는거\n데이터 관리 체계: 라이프사이클 같은거 관리하는거\n레포지토리: 너가 아는 그거\n표준화 활동: 잘 지켜지는지 지속적으로 모니터링하는거\n\n\n\n5. 데이터 조직 및 인력방안 수립\n\n\n\n분석 조직 구조\n\n\n\n\n\n분석 조직 인력 구성\n\n\n\n\n6. 분석과제 관리 프로세스 수립\n\n\n\n분석 과제 관리 프로세스",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "3 - 분석 마스터 플랜"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/02.html#빅데이터-분석과-전략-인사이트",
    "href": "posts/04_archives/adp_필기/notes/02.html#빅데이터-분석과-전략-인사이트",
    "title": "1 - 가치 창조를 위한 데이터 사이언스와 전략 인사이트",
    "section": "빅데이터 분석과 전략 인사이트",
    "text": "빅데이터 분석과 전략 인사이트\n빅테이터 분석은 분석을 통해 가치를 창출하는 것이 목적이다.\n\n일차원적인 분석: 해당 부서나 업무 영역에만 효과가 있다. 변화하는 환경에서 새로운 기회를 포착하기 어려움.\n전략도출 가치기반 분석: 일차원적인 분석을 통해 얻은 가치를 기반으로 활용 범위를 더 넓고 전략적으로 확장해야한다.",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "1 - 가치 창조를 위한 데이터 사이언스와 전략 인사이트"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/02.html#전략-인사이트-도출을-위한-필요-역량",
    "href": "posts/04_archives/adp_필기/notes/02.html#전략-인사이트-도출을-위한-필요-역량",
    "title": "1 - 가치 창조를 위한 데이터 사이언스와 전략 인사이트",
    "section": "전략 인사이트 도출을 위한 필요 역량",
    "text": "전략 인사이트 도출을 위한 필요 역량\n\n\n\n데이터 사이언티스트의 요구 역량\n\n\n외부 환경이 다음과 같이 변화함에 따라 인사이트 도출을 위한 인문학적 역량이 요구됨.\n\n컨버전스 → 디버전스\n생산 → 서비스\n생산 → 시장창조",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "1 - 가치 창조를 위한 데이터 사이언스와 전략 인사이트"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/10.html#통계분석의-이해",
    "href": "posts/04_archives/adp_필기/notes/10.html#통계분석의-이해",
    "title": "4 - 통계분석",
    "section": "통계분석의 이해",
    "text": "통계분석의 이해\n\n1. 표본 추출 방법\n\n단순랜덤 추출법\n계통추출법: k개씩 띄어서 랜덤으로 추출\n집락 추출법: 군집을 나눈 후, 군집 안에서 단순랜덤 추출\n층화 추출법: 이질적인 모집단에서, 비슷한 특성을 가진 층을 나눈 후, 각 층에서 단순랜덤 추출\n\n\n\n2. 척도\n\n명목척도\n순서척도\n구간척도: 더하기, 빼기 가능. 곱셈 나눗셈 불가능\n비율척도: 절대적 기준인 0이 존재, 사칙연산 가능\n\n\n\n3. 비모수 검정\n\n모집단에 대한 가정이 없이, 서열관계나 차이를 검정하는 방법\n분포의 형태가 동일하다, 동일하지 않다로 가정\n관측값들의 순위나 차이의 부호에 의존\n\n\n\n\n비모수 검정 예시",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 통계분석"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/10.html#기초-통계분석",
    "href": "posts/04_archives/adp_필기/notes/10.html#기초-통계분석",
    "title": "4 - 통계분석",
    "section": "기초 통계분석",
    "text": "기초 통계분석\n\n\n\n상관 분석 유형",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 통계분석"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/10.html#통계분석의-방법론",
    "href": "posts/04_archives/adp_필기/notes/10.html#통계분석의-방법론",
    "title": "4 - 통계분석",
    "section": "통계분석의 방법론",
    "text": "통계분석의 방법론\n\nt 검정\n\n일표본\n대응표본\n독립표본\n\nANOVA\n\n일원분산분석\n이원분산분석\n다원분산분석\n\n다변량분석\n실험계획법\n\n요인배치법\n분할법\n교락법\n난괴법\n\n교차분석\n\n적합성 검정: k개의 범주들에 대한 관측값 갯수가 기댓값과 일치하는지 검정\n\n자유도: k-1\n각 집단의 \\(\\frac{(관측도수 - 기대도수)^2}{기대도수}\\)의 합이 카이제곱 분포를 따름\n\n독립성 검정\n\n자유도: (r - 1)(c - 1)\n\n동질성 검정: 독립성 검정이랑 유사",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 통계분석"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/10.html#회귀분석",
    "href": "posts/04_archives/adp_필기/notes/10.html#회귀분석",
    "title": "4 - 통계분석",
    "section": "회귀분석",
    "text": "회귀분석\n\n1. 가정\n\n선형성\n정규성: qq-plot, 대각선에 가까워야함\n등분산성: 수평선에 가까워야함\n독립성: 더빈 왓슨 검정(0~4), 2에 가까울수록 독립성이 있다.\n\n→ 가정을 충족하지 않을 경우, 회귀모델을 수정해야함\n\n이상치 → 관측값 제거\n선형성 → 독립변수 변환\n정규성, 등분산성 미충족 → 종속변수 변환\n\n변환: \\(x\\) → \\(x^λ\\)\n\n\n2. 회귀식\n\n\n\\(R^2 = \\frac{SSR}{SST}\\)\n\\(R^2_{adj} = 1 - \\frac{(1 - R^2)(n - 1)}{n - k - 1}\\)\n\n\n\n3. 다중공선성\n\n독립변수들 간에 강한 상관관계가 존재하는 경우\n\n상관계수: 변수간 상관계수를 직접 계산\n허용오차: 1 - \\(R^2\\). 0.1 이하면 다중공선성이 존재한다고 판단\nVIF: 허용 오차의 역수. 10 이상이면 다중공선성이 존재한다고 판단 → 변수 제거\n\n\n\n\n4. 최적화 회귀방정식\n\nAIC, BIC나 F-value를 크게 만드는 변수 제거\n\n\n전진 선택법: 상수항부터 시작해, 한번에 한개씩 독립변수 추가\n\n전체 변수 사용할 수 있지만 안정성이 낮음\n\n후진 선택법: 모든 독립변수를 포함한 후, 하나씩 제거. AIC가 더 이상 작아지지 않을 때까지\n\n안정성이 높지만 변수가 많을 때 시간이 오래 걸림\n\n단계 선택법: 전진, 후진 선택법을 혼합.\n\n이미 선택된 변수를 제거할 수 있음\n변수가 많으면 시간이 오래 걸림",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 통계분석"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/10.html#고급-회귀분석",
    "href": "posts/04_archives/adp_필기/notes/10.html#고급-회귀분석",
    "title": "4 - 통계분석",
    "section": "고급 회귀분석",
    "text": "고급 회귀분석\n\n1. 패널티 회귀분석\n지나치게 많은 독립변수를 갖는 모델에 페널티를 부과하는 방식\n\n릿지: 모델의 설명력에 기여하지 못하는 독립변수의 계수 크기를 0에 근접하게 축소 (\\(l_2\\) 규제)\n\n회귀 계수가 비슷하고, 독립변수가 많을 때 효과가 좋다.\n\n라쏘: 모델의 설명력에 기여하지 못하는 독립변수의 계수 크기를 0으로 만듦 (\\(l_1\\) 규제)\n\n회귀 계수 차이가 클 때 효과가 좋다.\n\n엘라스틱넷: 릿지와 라쏘를 혼합한 방법 (\\(l_1\\) + \\(l_2\\) 규제)\n\n\n\n2. 일반화 회귀분석\n\n종속변수가 연속형이면서 정규분포를 따르지 않을 때 사용\n\n\nlogistic 회귀모형\npoisson 회귀모형",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 통계분석"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/10.html#시계열-분석",
    "href": "posts/04_archives/adp_필기/notes/10.html#시계열-분석",
    "title": "4 - 통계분석",
    "section": "시계열 분석",
    "text": "시계열 분석\n\n시계열 데이터 생성\n탐색적 분석을 통해 데이터 이해\n\n시각화 작업으로 변통 패턴 관찰\n성분분해 작업으로 추세, 계절성분, 불규칙성분 분리\n\n추세(장기)\n계절(단기)\n순환(중장기)\n불규칙(설명 불가)\n\n\n미래 관측값에 대한 예측\n\n이동 평균법\n지수 평활법\nARIMA 기법\n\nAR모델: P시점 전의 자료가 현재에 주는 영향을 시계열 모형으로 구축. 과거 관측값을 이용하여 예측모델 생성. 감절\nMA모델: 시간이 지날수록 관측치의 평균값이 지속적으로 증가하거나 감소하는 경향 표현. 과거 오차항을 이용하여 예측모델 생성. 절감\nARIMA모델: 비정상 시계열. 차분이나 변환을 통해 정상시계열로 변환",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 통계분석"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/13.html#시각화-인사이트-프로세스의-의미",
    "href": "posts/04_archives/adp_필기/notes/13.html#시각화-인사이트-프로세스의-의미",
    "title": "5 - 시각화 인사이트 프로세스",
    "section": "시각화 인사이트 프로세스의 의미",
    "text": "시각화 인사이트 프로세스의 의미\n\n1. 인사이트란 무엇인가\n상위 개념을 발견하기 위해, 각 단계의 관계를 이해해야 한다.\n이를 위해 시각화 인사이트 방법이 필요하다.\n\n\n\nDIKW 피라미드와 시각화 관계\n\n\n\n\n2. 시각화와 인사이트",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "5 - 시각화 인사이트 프로세스"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/13.html#탐색",
    "href": "posts/04_archives/adp_필기/notes/13.html#탐색",
    "title": "5 - 시각화 인사이트 프로세스",
    "section": "탐색",
    "text": "탐색\n\n상위 개념을 발견하기 위해, 각 단계의 관계를 이해하는 과정\n객관적인 패턴을 찾는 용도\n\n\n1. 사용 가능한 데이터 확인\n\n데이터 접근\n\n이벤트 기록으로서 접근: 데이터로부터 통찰을 이끌어 내기 위해서 데이터 생성 원리를 파악해야 한다고 간주\n객체지향 관점에서의 접근: 데이터로부터 통찰을 이끌어 내기 위해서 전체 구조를 파악해야 한다고 간주\n\n데이터 명세화\n\n모든 데이터는 하나 이상의 차원과 측정값을 가지고 있다.\n이는 분석 형태에 따라, 차원이 될 수도 있고, 측정값이 될 수도 있다.\n\n\n\n\n2. 연결 고리의 확인\n데이터 명세서를 이용해 2개 이상의 데이터간 연결 고리를 확인해 봄\n\n공통 요소 찾기\n공통 요소로 변환하기: 데이터 타입이 달라도 공통 요소로 묶을 수 있다 (더 자세한 데이터를 덜 자세한 데이터로 변환. 반대는 불가)\n\n시간 데이터의 변환\n공간 데이터의 변환(지오코딩, 코로플레스 지도, X-Ray Map 사용 가능)\n계층 관계 변환: 상위 수준(덜 자세한)이라는 공통 요소로 변환. replace, lookup, vlookup 함수 사용 가능\n\n탐색 범위 설정: 차원과 측정값의 전체 조합 종류가 탐색 범위가 됨. 데이터를 구성하는 항목이 늘어날 수록 탐색 범위가 늘어남\n\n여러 데이터를 보유한 경우, 개별 데이터 안에서 먼저 탐색\n측정값 하나의 차원만 연결해 탐색\n같은 데이터 안에서 차원과 측정값을 맞바꾸면 다른 통찰을 얻을 수 있음\n어떤 통찰을 얻기 위해 비주얼 인사이트 프로세스를 사용하는 것인지 살펴본 후, 목표와 관련 있을 법한 조합을 만듦\n상식적으로 의미나 연계성이 없는 조합은 배제\n\n\n\n\n3. 관계의 탐색\n상관관계와 인과관계를 탐색\n\n이상값 처리: 시각화 도구를 통해 전체 구조를 파악한 후 처리\n차원과 측정값 유형에 따른 관계 파악 시각화\n\n시각화 도구 선정\n시간 데이터에서의 관계 파악: 구글 모션차트 사용 가능\n공간 데이터에서의 관계 파악: Arc GIS, X-Ray Map, 파워 맵 사용 가능\n비정형 데이터에서의 관계 파악\n\n워들: 주어진 텍스트에서 형태소 단위를 추출(NLP)해 빈도에 따라 시각화\n\n\n잘라보고 달리보기: 둘 이상의 차원과 측정값으로 이루어진 데이터를 여러 관점으로 살펴본다.\n\n잘라보기(slice): ex) 연령별, 성별 평균 체중 데이터 → 20세 이상, 40세 미만 남성들의 체중 패턴\n달리보기(dice): ex) 연령별, 성별 평균 체중 데이터 → 남성의 연령별 체중 패턴, 여성의 연령별 체중 패턴\nMS excel의 pivot, powerview, spreadsheet의 pivot table report 사용 가능\n\n내려다보고 올려보기\n\n내려다보기(Drill Down): 데이터를 하위 계층으로 세분화한다.\n올려보기(Reverse Driil Down): 데이터를 상위 계층으로 통합한다.\nTree map, Hyperbolic Tree\n\n척도의 조정: 스파크라인 차트 사용 가능",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "5 - 시각화 인사이트 프로세스"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/13.html#분석",
    "href": "posts/04_archives/adp_필기/notes/13.html#분석",
    "title": "5 - 시각화 인사이트 프로세스",
    "section": "분석",
    "text": "분석\n\n탐색을 통해 발견된 패턴을 분석하는 과정\n\n\n1. 분석 대상의 구체화\n\n2차 탐색: 관계들의 분석 우선순위 결정. 궁극적인 목표는 그냥 다시 한 번 더 검토하는 것\n분석 목표에 따른 분석 기법\n\n \n\n\n2. 분석 시각화 도구\n통계적 도구와 시각적 도구는 상호보완 관계\n\n\n3. 지표 설정과 분석\n\n지표: 어떤 현상의 강도를 평가하는 기준이 되는 수치\n\nex) KPI(Key Performance Indicator): 핵심 성과 지표. 목표 달성을 위한 세부적인 활동 결과물의 추진 정도나 수준을 측정하고 평가\n주로 함수식 구조를 가짐 (ex. 매출액 = 판매단가 * 판매량)\n요인 분석(factor analysis)를 통해 지표가 다른 요인과 설명력이 겹치는지 여부 확인할 수 있다.\n어떤 변화요인에 의해 지표의 흐름에 영향을 미쳤는지 파악하기 어렵다는 단점이 있다.",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "5 - 시각화 인사이트 프로세스"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/13.html#활용",
    "href": "posts/04_archives/adp_필기/notes/13.html#활용",
    "title": "5 - 시각화 인사이트 프로세스",
    "section": "활용",
    "text": "활용\n\n도출한 인사이트를 활용하는 과정\n\n\n1. 내부에서 적용\n\n기존 문제 해결 방식이나 설명 모델의 수정\n새로운 문제 해결 방식의 도입\n새롭게 발견한 가능성에 대한 구체적인 탐색과 발전\n\n\n\n2. 외부에 대한 설명, 설득과 시각화 도구\n설득이 필요하기 때문에 스토리텔링이 감미된 시각화 자료나, 인터렉티브 인포그래픽 활용\n\n\n3. 인사이트의 발전과 확장\n계속 잘 검토해 나가야함",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "5 - 시각화 인사이트 프로세스"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/12.html#텍스트-마이닝",
    "href": "posts/04_archives/adp_필기/notes/12.html#텍스트-마이닝",
    "title": "4 - 비정형 데이터 마이닝",
    "section": "텍스트 마이닝",
    "text": "텍스트 마이닝\n\n비정형 데이터를 구조화해서 패턴을 도출한 후 결과를 평가 및 해석하는 일련의 과정\n\n\n기능\n\n목표 기능: 문서 분류, 군집, 정보 추출, 문서 요약\n사용 기술: 자연어 처리, 컴퓨터 언어학\n\n\n\n과정\n\n\n텍스트 수집\n텍스트 전처리\n\ntm 패키지: 문서를 Corpus 객체로 변환해서 관리\n\nVCorpus: 문서를 Corpus로 변환해서 메모리에 저장\nPCorpus: 문서를 Corpus로 변환해서 디스크에 저장\nDirSource, DataframeSource, VectorSource: 데이터 소스 지정\ntm_map(x, FUN): x에 FUN을 적용\nDocumentTermMatrix: 문서-단어 빈도표 생성\nTermDocumentMatrix: 단어-문서 빈도표 생성\n\n전처리\n\n정제: 노이즈 제거\n토큰화\n\n단어 토큰화\n어절 토큰화\n형태소 토큰화\n품사 태깅\n\n불용어 처리: 불필요한 토큰 제거\n정제 / 정규화\n\n표기가 다른 같은 단어 통일\n대소문자 통일\n불필요한 단어 제거\n정규표현식으로 특수문자 제거\n\n어간 / 어근 추출\n텍스트 인코딩\n\none hot 인코딩\n말뭉치(BoW): 단어의 빈도수를 벡터로 표현\nTF-IDF: 문서 내 단어의 빈도 수 / 단어가 등장한 문서 수\n워드 임베딩\n\n\n텍스트 분석\n\n토픽 모델링\n감성 분석\n텍스트 분류\n텍스트 군집화\n\n텍스트 시각화\n\n워드 클라우드\n의미 연결망 분석\n\n\n\n\n\n정보 검색의 적절성",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 비정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/12.html#사회연결망-분석",
    "href": "posts/04_archives/adp_필기/notes/12.html#사회연결망-분석",
    "title": "4 - 비정형 데이터 마이닝",
    "section": "사회연결망 분석",
    "text": "사회연결망 분석\n\n2. 기법\n\n개인을 노드, 관계를 엣지로 해서 그래프 생성\n아래의 기준에 따라 구조 파악",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 비정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/15.html",
    "href": "posts/04_archives/adp_필기/notes/15.html",
    "title": "시험을 보고 왔습니다.",
    "section": "",
    "text": "높게 솟은 수원 공고의 모습",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "시험을 보고 왔습니다."
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/15.html#intro",
    "href": "posts/04_archives/adp_필기/notes/15.html#intro",
    "title": "시험을 보고 왔습니다.",
    "section": "Intro",
    "text": "Intro\n수원 공고에서 진행된 adp 시험을 보고 왔습니다.\n고등학교 치고는 왠만한 대규모 성당급으로 상당히 넓다는 느낌이 들었습니다. 그냥 제가 나온 인문계 고등학교가 좁아서 그렇게 느껴진 것일 수도 있고요.",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "시험을 보고 왔습니다."
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/15.html#시험",
    "href": "posts/04_archives/adp_필기/notes/15.html#시험",
    "title": "시험을 보고 왔습니다.",
    "section": "시험",
    "text": "시험\n저번 시험에서는 서술형에서 20점 만점에 4점을 받아서 굉장히 아쉬운 성적이 나와버렸죠. 사실 그렇다고 이번 시험에서 서술형을 엄청 잘 준비하거나 하진 않았습니다. 제가 게을러서 그렇다는걸 딱히 부정하는건 아니지만, 가장 큰 이유는 뭐가 나올지 예상을 할 수 없기 때문입니다.\n서술형에 나올 수 있는 주제 자체는 참고서에 나와있는 내용 안에서 등장하지만, 시험에서는 더 구체적인 수식과 구현 과정을 요구하는 경우가 많습니다. 아마도 adp 시험에서 서술형을 더 잘 대비하려면, 더 많은 외부 자료를 참고하거나, 배경지식을 더 쌓은 상태에서 도전해봐야 할 것 같습니다.\n하지만, 만약 서술형이 0점이 나온다고 해도 객관식을 80 문제중 70개 이상만 맞춘다면 통과할 수 있다는 사실. 뭐.. 그렇게까지 불가능한 것도 아니긴 합니다. 객관식은 참고서 내용으로 잘 커버할 수 있으니까요.",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "시험을 보고 왔습니다."
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/15.html#outro",
    "href": "posts/04_archives/adp_필기/notes/15.html#outro",
    "title": "시험을 보고 왔습니다.",
    "section": "Outro",
    "text": "Outro\n실제로 꽤 느낌이 좋긴 합니다. 이번에도 서술형은 모르는 내용이 나오긴 했지만 말입니다.\n결과가 3월 중순에 나올 예정인데, 그 전까지는 smart contract 쪽으로 공부를 해볼 예정입니다.\n더 자세한 감상은 결과가 나온 후에 작성해보겠습니다.",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "시험을 보고 왔습니다."
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/11.html#데이터-마이닝-개요",
    "href": "posts/04_archives/adp_필기/notes/11.html#데이터-마이닝-개요",
    "title": "4 - 정형 데이터 마이닝",
    "section": "데이터 마이닝 개요",
    "text": "데이터 마이닝 개요\n\n데이터 마이닝 분석 방법\n\n지도 학습\n\n의사결정 나무\n인공신경망\n회귀 분석\n사례기반 추론\nk-최근접 이웃\n\n비지도 학습\n\nOLAP\n연관성 규칙\n군집 분석\nSOM\n\n\n\n\n데이터 마이닝 추진 단계\n\n목표 설정\n데이터 준비\n가공\n기법 적용\n검증\n\n\n\n데이터 분할\n\n구축용(추정용, 훈련용): 50%\n검정용: 30%\n시험용: 20%\nfold-out\nk-fold\nleave-one-out\n\n\n\n성과 분석\n\n정분류율\n오분류율\n민감도(재현율): 실제 True인데 True라고 예측한 비율\n특이도: 실제 False인데 False라고 예측한 비율\n정밀도: True라고 예측했는데 True인 비율\nF1-score: \\(\\frac{정밀도 * 재현율}{정밀도 + 재현율}\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/11.html#앙상블-기법",
    "href": "posts/04_archives/adp_필기/notes/11.html#앙상블-기법",
    "title": "4 - 정형 데이터 마이닝",
    "section": "앙상블 기법",
    "text": "앙상블 기법\n\n여러 개의 분석 모델을 결합하여 하나의 모델을 구축하는 기법\n\n\n배깅\n\n여러 부트스트랩(복원 추출된 샘플)에 대해 동일한 모델을 독립적으로 학습시키고, 결과를 투표하여 최종 결과를 결정\n\n\n\n부스팅\n\n부트스트랩을 순차적으로 학습시키며, 이전 모델의 오차를 보완하는 방식\nGradient Boosting\nXGBoost\nLightGBM",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/11.html#분류-분석",
    "href": "posts/04_archives/adp_필기/notes/11.html#분류-분석",
    "title": "4 - 정형 데이터 마이닝",
    "section": "분류 분석",
    "text": "분류 분석\n\n지도학습. 데이터의 범주형 속성 값을 예측\n\n\n의사결정 나무\n\n이상치에 민감하지 않다.\n대용량 데이터에 대해 적합하다.\n과적합 문제 발생 가능성\n\n\n성장\n\n분리\n\n이산형 변수\n\n카이제곱량\n지니지수: \\(1 - \\sum_{i=1}^{n} p_i^2\\). 낮춰주는 변수 선택\n엔트로피: \\(-\\sum_{i=1}^{n} p_i \\log_2 p_i\\). 낮춰주는 변수 선택\n\n범주형 변수\n\n분산\nF 통계량\n\n\n정지 기준: 의사경정 나무의 높이, 리프 노드의 최소 갯수\n\n가지치기\n타당성 평가\n예측\n\n\n\n인공신경망 분석",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/11.html#som",
    "href": "posts/04_archives/adp_필기/notes/11.html#som",
    "title": "4 - 정형 데이터 마이닝",
    "section": "SOM",
    "text": "SOM\n\n고차원의 데이터를 이해하기 쉬운 저차원의 데이터로 변환\n구성\n\n입력층\n경쟁층",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/11.html#군집-분석",
    "href": "posts/04_archives/adp_필기/notes/11.html#군집-분석",
    "title": "4 - 정형 데이터 마이닝",
    "section": "군집 분석",
    "text": "군집 분석\n\n사전정보가 없는 상태에서 관측값들의 거리 또는 유사성을 이용하여 군집을 형성하는 분석 방법\n군집분석은 알고리즘에 따라 결과가 매번 다르고, 명확한 정답이나 정답을 찾기 위한 p-value가 없다.\noutlier에 민감하다.\n\n\n계층적 군집 분석\n\n군집의 갯수를 모를 때, 우선적으로 갯수를 정하기 위해 사용\n가까운 개체끼리 차례로 묶거나 멀리 떨어진 개체를 분리해 가는 방식\n한 번 분류된 개체는 재분류되지 않음\n계층적 군집분석 단계\n\nDistance Measure 결정\n\n연속형 변수\n\n유클리디안 거리\n맨하탄 거리\n민코우스키 거리: 유클리디안 거리(L2)와 맨하탄 거리(L1)의 일반화된 공식.\n표준화 거리: 표준편차로 표준화된 길이의 유클리디안 거리\n마할라노비스 거리: 공분산으로 표준화된 길이의 유클리디안 거리\n체비셰프 거리: x 좌표 차이와 y 좌표 차이 중 최댓 값\n캔버라 거리: 두 벡터의 각 차이의 비율\n\n범주형 변수\n\n자카드 거리: \\(1 - \\frac{A \\cap B}{A \\cup B}\\)\n코사인 거리: \\(1 - \\frac{A \\cdot B}{||A|| \\cdot ||B||}\\)\n\n\nClustering Algorithm 결정\n\n합병에 의한 방법: 가장 가까운 거리를 가진 두 군집을 합침\n\n단일 연결법: 군집의 개체들 사이의 모든 거리 조합 중 최솟값 사용\n완전 연결법: 군집의 개체들 사이의 모든 거리 조합 중 최댓값 사용\n평균 연결법: 군집의 개체들 사이의 모든 거리 조합의 평균 사용\n와드 연결법: ESS(군집 내 제곱합)의 증가량이 최소가 되는 두 군집을 합침\n\n분할에 의한 방법\n\n다이아나 연결법\n\n\n군집의 갯수 결정: 1, 2번 단계에서 나온 dendrogram을 보고 알아서 결정\n분석의 타당성 검토\n\n\n\n\n비계층적(분할적) 군집 분석\n\n군집의 갯수를 알고 있을 때 사용\n판정기준을 최적화 시키는 방법으로 군집을 나눔\n한 번 분류된 개체도 재분류될 수 있음\nk-means\n\nk개의 군집을 사전에 설정\n군집의 초기 시작 포인트를 설정\n각 군집의 중심을 계산하여, 개체들을 다시 가장 가까운 군집에 재할당\n3 반복\n\n혼합분포군집\n\nk-means와 비슷하지만, 군집의 형태가 원형이 아닐 때도 사용 가능\n\nPAM\n\nk-means와 비슷하지만, 중심을 평균이 아닌 중앙값으로 설정\n연속형이 아닌 여러 종류의 변수가 혼합된 경우에도 사용할 수 있음\n\n\n\n\n타당성 지표\n\nsilhouette\nDunn index",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/11.html#연관-분석",
    "href": "posts/04_archives/adp_필기/notes/11.html#연관-분석",
    "title": "4 - 정형 데이터 마이닝",
    "section": "연관 분석",
    "text": "연관 분석\n\n지지도: \\(\\frac{A \\cap B}{전체}\\)\n신뢰도: \\(\\frac{지지도}{A}\\)\n향상도: \\(\\frac{신뢰도}{B}\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/06.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/06.html#preprocessing",
    "title": "Decision Tree Regression",
    "section": "Preprocessing",
    "text": "Preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndataset = pd.read_csv('_data/04.csv')\nx = dataset.iloc[:, 1:-1].values\ny = dataset.iloc[:, -1].values",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Decision Tree Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/06.html#modeling",
    "href": "posts/02_areas/machine_learning/notes/06.html#modeling",
    "title": "Decision Tree Regression",
    "section": "Modeling",
    "text": "Modeling\n\nfrom sklearn.tree import DecisionTreeRegressor\n\nregressor = DecisionTreeRegressor()\n\n# 모델 학습\nregressor.fit(x, y)\n\nDecisionTreeRegressor()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeRegressor?Documentation for DecisionTreeRegressoriFittedDecisionTreeRegressor()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Decision Tree Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/06.html#visualization",
    "href": "posts/02_areas/machine_learning/notes/06.html#visualization",
    "title": "Decision Tree Regression",
    "section": "Visualization",
    "text": "Visualization\n\nx_grid = np.arange(min(x), max(x), 0.1)\nx_grid = x_grid.reshape((len(x_grid), 1))\nplt.scatter(x, y, color='red')\nplt.plot(x_grid, regressor.predict(x_grid), color='blue')\nplt.show()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Decision Tree Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/01.html#load-library-and-data",
    "href": "posts/02_areas/machine_learning/notes/01.html#load-library-and-data",
    "title": "data preprocessing",
    "section": "Load Library and data",
    "text": "Load Library and data\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndataset = pd.read_csv('_data/00-data.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n\nx\n\narray([['France', 44.0, 72000.0],\n       ['Spain', 27.0, 48000.0],\n       ['Germany', 30.0, 54000.0],\n       ['Spain', 38.0, 61000.0],\n       ['Germany', 40.0, nan],\n       ['France', 35.0, 58000.0],\n       ['Spain', nan, 52000.0],\n       ['France', 48.0, 79000.0],\n       ['Germany', 50.0, 83000.0],\n       ['France', 37.0, 67000.0]], dtype=object)\n\n\n\ny\n\narray(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n      dtype=object)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "data preprocessing"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/01.html#taking-care-of-missing-data",
    "href": "posts/02_areas/machine_learning/notes/01.html#taking-care-of-missing-data",
    "title": "data preprocessing",
    "section": "Taking care of Missing data",
    "text": "Taking care of Missing data\n\ndelete\nreplace\n\n\nfrom sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(x[:, 1:3])\nx[:, 1:3] = imputer.transform(x[:, 1:3])\nprint(x)\n\n[['France' 44.0 72000.0]\n ['Spain' 27.0 48000.0]\n ['Germany' 30.0 54000.0]\n ['Spain' 38.0 61000.0]\n ['Germany' 40.0 63777.77777777778]\n ['France' 35.0 58000.0]\n ['Spain' 38.77777777777778 52000.0]\n ['France' 48.0 79000.0]\n ['Germany' 50.0 83000.0]\n ['France' 37.0 67000.0]]",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "data preprocessing"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/01.html#encoding-cagegorical-data",
    "href": "posts/02_areas/machine_learning/notes/01.html#encoding-cagegorical-data",
    "title": "data preprocessing",
    "section": "Encoding Cagegorical data",
    "text": "Encoding Cagegorical data\n\n단순히 categorical 변수를 1, 2, 3으로 변형하면 순서가 고려된 것으로 간주될 수 있다.\n그래서 [0, 0, 1], [1, 0, 1] 이런 식으로 one hot encoding을 진행한다.\n\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nx = np.array(ct.fit_transform(x))\nprint(x)\n\n[[1.0 0.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [0.0 1.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [0.0 1.0 0.0 40.0 63777.77777777778]\n [1.0 0.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [1.0 0.0 0.0 48.0 79000.0]\n [0.0 1.0 0.0 50.0 83000.0]\n [1.0 0.0 0.0 37.0 67000.0]]\n\n\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ny = le.fit_transform(y)\nprint(y)\n\n[0 1 0 0 1 1 0 1 0 1]",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "data preprocessing"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/01.html#split-dataset-into-training-set-and-test-set",
    "href": "posts/02_areas/machine_learning/notes/01.html#split-dataset-into-training-set-and-test-set",
    "title": "data preprocessing",
    "section": "Split dataset into training set and test set",
    "text": "Split dataset into training set and test set\n\nfeature scaling 이전에 진행되어야함. (test set은 모델이 모르는 정보가 되야하기 때문)\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "data preprocessing"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/01.html#feature-scaling",
    "href": "posts/02_areas/machine_learning/notes/01.html#feature-scaling",
    "title": "data preprocessing",
    "section": "feature scaling",
    "text": "feature scaling\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\nX_test[:, 3:] = sc.transform(X_test[:, 3:])\n\n\nprint(X_train)\n\n[[0.0 0.0 1.0 0.19110270542139415 -0.9096096045953487]\n [1.0 0.0 0.0 -0.36187533579795855 -0.3569354144614659]\n [0.0 1.0 0.0 -1.0937580374118077 -0.7253848745507211]\n [0.0 0.0 1.0 -1.532887658380117 -1.278059064684604]\n [0.0 0.0 1.0 0.07725428517035085 -0.08059831939452457]\n [1.0 0.0 0.0 0.9555135271069697 0.9326376958509272]\n [0.0 1.0 0.0 1.8337727690435885 1.9458737110963789]\n [1.0 0.0 0.0 -0.06912225515241896 0.4720758707393582]]\n\n\n\nprint(X_test)\n\n[[0.0 1.0 0.0 0.37000736581589044 0.17526936122301404]\n [1.0 0.0 0.0 1.541019688398049 1.5774242510071237]]",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "data preprocessing"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/11.html#독립성-가정이-필요한-수학적-이유",
    "href": "posts/02_areas/machine_learning/notes/11.html#독립성-가정이-필요한-수학적-이유",
    "title": "Naive Bayes",
    "section": "독립성 가정이 필요한 수학적 이유",
    "text": "독립성 가정이 필요한 수학적 이유\nNaive Bayes는 베이즈 정리를 기반으로 합니다. 클래스 \\(C\\)와 특성 벡터 \\(X = (x_1, x_2, ..., x_n)\\)이 있을 때, 베이즈 정리는 다음과 같습니다:\n\\[P(C|X) = \\frac{P(X|C) \\cdot P(C)}{P(X)}\\]\n여기서 \\(P(C|X)\\)는 특성 \\(X\\)가 주어졌을 때 클래스 \\(C\\)일 확률입니다. 문제는 \\(P(X|C)\\)를 계산하기가 어렵다는 점입니다. 특성이 많을수록 가능한 \\(X\\) 조합의 수가 기하급수적으로 증가하기 때문입니다.\n이 문제를 해결하기 위해 Naive Bayes는 모든 특성이 서로 조건부 독립이라고 가정합니다. 즉:\n\\[P(x_i|C, x_1, x_2, ..., x_{i-1}, x_{i+1}, ..., x_n) = P(x_i|C)\\]\n이 독립성 가정을 통해 \\(P(X|C)\\)를 다음과 같이 단순화할 수 있습니다:\n\\[P(X|C) = P(x_1, x_2, ..., x_n|C) = P(x_1|C) \\cdot P(x_2|C) \\cdot ... \\cdot P(x_n|C) = \\prod_{i=1}^{n} P(x_i|C)\\]\n이렇게 특성 간 독립성을 가정함으로써 복잡한 결합 확률을 개별 특성의 확률들의 곱으로 계산할 수 있게 되어 계산이 매우 단순해집니다. 이것이 바로 Naive Bayes에서 “naive(순진한)” 독립성 가정이 반드시 필요한 이유입니다.\n이제 Naive Bayes에서 독립성 가정이 필요한 이유가 수학적으로 명확하게 설명되었습니다. 이 설명을 통해 알 수 있듯이:\n\nNaive Bayes는 베이즈 정리를 사용하여 P(C|X)를 계산합니다.\n문제는 P(X|C)를 계산하는 것이 복잡하다는 점입니다.\n독립성 가정을 통해 P(X|C)를 개별 특성들의 조건부 확률 곱으로 단순화할 수 있습니다.\n이 단순화가 없다면, 특성의 조합이 많아질수록 계산이 기하급수적으로 복잡해집니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Naive Bayes"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/11.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/11.html#preprocessing",
    "title": "Naive Bayes",
    "section": "preprocessing",
    "text": "preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndataset = pd.read_csv('_data/08.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Naive Bayes"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/11.html#modeling---linear",
    "href": "posts/02_areas/machine_learning/notes/11.html#modeling---linear",
    "title": "Naive Bayes",
    "section": "Modeling - linear",
    "text": "Modeling - linear\n\nfrom sklearn.naive_bayes import GaussianNB\n\nclassifier = GaussianNB()\nclassifier.fit(x_train, y_train)\n\nGaussianNB()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  GaussianNB?Documentation for GaussianNBiFittedGaussianNB()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Naive Bayes"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/11.html#predict",
    "href": "posts/02_areas/machine_learning/notes/11.html#predict",
    "title": "Naive Bayes",
    "section": "Predict",
    "text": "Predict\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ny_pred = classifier.predict(x_test)\nprint(confusion_matrix(y_test, y_pred))\naccuracy_score(y_test, y_pred)\n\n[[58  7]\n [ 4 31]]\n\n\n0.89",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Naive Bayes"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/11.html#predict-1",
    "href": "posts/02_areas/machine_learning/notes/11.html#predict-1",
    "title": "Naive Bayes",
    "section": "Predict",
    "text": "Predict\n\ny_pred = classifier.predict(x_test)\nprint(confusion_matrix(y_test, y_pred))\naccuracy_score(y_test, y_pred)\n\n[[58  7]\n [ 4 31]]\n\n\n0.89",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Naive Bayes"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/12.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/12.html#preprocessing",
    "title": "Decision Tree Classification",
    "section": "preprocessing",
    "text": "preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndataset = pd.read_csv('_data/08.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Decision Tree Classification"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/12.html#modeling---linear",
    "href": "posts/02_areas/machine_learning/notes/12.html#modeling---linear",
    "title": "Decision Tree Classification",
    "section": "Modeling - linear",
    "text": "Modeling - linear\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nclassifier = DecisionTreeClassifier(criterion='entropy')\nclassifier.fit(x_train, y_train)\n\nDecisionTreeClassifier(criterion='entropy')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFittedDecisionTreeClassifier(criterion='entropy')",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Decision Tree Classification"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/12.html#predict",
    "href": "posts/02_areas/machine_learning/notes/12.html#predict",
    "title": "Decision Tree Classification",
    "section": "Predict",
    "text": "Predict\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ny_pred = classifier.predict(x_test)\nprint(confusion_matrix(y_test, y_pred))\naccuracy_score(y_test, y_pred)\n\n[[64  5]\n [ 3 28]]\n\n\n0.92",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Decision Tree Classification"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/12.html#predict-1",
    "href": "posts/02_areas/machine_learning/notes/12.html#predict-1",
    "title": "Decision Tree Classification",
    "section": "Predict",
    "text": "Predict\n\ny_pred = classifier.predict(x_test)\nprint(confusion_matrix(y_test, y_pred))\naccuracy_score(y_test, y_pred)\n\n[[64  5]\n [ 3 28]]\n\n\n0.92",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Decision Tree Classification"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/00.html#machine-learning-process",
    "href": "posts/02_areas/machine_learning/notes/00.html#machine-learning-process",
    "title": "overview",
    "section": "Machine Learning Process",
    "text": "Machine Learning Process\n\nData Pre-Processing\n\nimport data\nclean data\nsplit data trainig and testing\nfeature scailing\n\nnormalization: \\(\\frac{x - min(x)}{max(x) - min(x)}\\)\nstandardization: \\(\\frac{x - μ}{σ}\\)\n\n\nModeling\n\nbuild / train model\nmake predictions\n\nEvaluation\n\ncalculate performance metrix\nmake a verdict",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "overview"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/03.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/03.html#preprocessing",
    "title": "Multiple Linear Regression",
    "section": "preprocessing",
    "text": "preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndataset = pd.read_csv('_data/03.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\n# model automatically avoid dummy variable trap\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\nx = np.array(ct.fit_transform(x))\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.2)\n\n# in multiple linear regression, we don't need to apply feature scaling",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Multiple Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/03.html#modeling",
    "href": "posts/02_areas/machine_learning/notes/03.html#modeling",
    "title": "Multiple Linear Regression",
    "section": "modeling",
    "text": "modeling\n\nfrom sklearn.linear_model import LinearRegression\n\n# model automatically choose best model (dont need to apply 후진제거법)\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Multiple Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/03.html#predict",
    "href": "posts/02_areas/machine_learning/notes/03.html#predict",
    "title": "Multiple Linear Regression",
    "section": "predict",
    "text": "predict\n\ny_pred = regressor.predict(X_test)\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred.reshape(len(y_pred), 1), \n                      y_test.reshape(len(y_test), 1)), 1))\n\n[[111813.65 122776.86]\n [ 95699.48  99937.59]\n [184907.17 155752.6 ]\n [ 78802.93  96479.51]\n [100843.27  96712.8 ]\n [146888.87 125370.37]\n [218604.51 192261.83]\n [116785.74 118474.03]\n [ 99506.01 107404.34]\n [ 68433.62  78239.91]\n [ 84243.    97427.84]\n [121338.93 144259.4 ]\n [ 62668.72  81005.76]\n [  8623.87  35673.41]\n [131386.6  105008.31]\n [ 73331.54  49490.75]\n [167008.37 156991.12]\n [102430.77  97483.56]\n [178195.4  166187.94]\n [ 33508.33  42559.73]\n [ 49845.24  81229.06]\n [ 53331.51  71498.49]\n [171088.84 152211.77]\n [154014.85 156122.51]\n [ 52473.16  69758.98]\n [131508.44 110352.25]\n [173610.03 132602.65]\n [185856.16 182901.99]\n [212558.77 191792.06]\n [ 36495.61  64926.08]\n [127095.8  103282.38]\n [139838.61 111313.02]\n [151074.04 149759.96]\n [100051.87  96778.92]\n [108073.15 101004.64]\n [121375.61 105733.54]\n [100223.73 108552.04]\n [151051.13 129917.04]\n [ 57370.23  89949.14]\n [120372.67 108733.99]]",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Multiple Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/03.html#evaluate",
    "href": "posts/02_areas/machine_learning/notes/03.html#evaluate",
    "title": "Multiple Linear Regression",
    "section": "evaluate",
    "text": "evaluate\n\nfrom sklearn.metrics import r2_score\n\nr2_score(y_test, y_pred)\n\n0.7415736514362701",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Multiple Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/15.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/15.html#preprocessing",
    "title": "hierarchical clustering",
    "section": "preprocessing",
    "text": "preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndataset = pd.read_csv('_data/14.csv')\nx = dataset.iloc[:, [3, 4]].values",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "hierarchical clustering"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/15.html#modeling",
    "href": "posts/02_areas/machine_learning/notes/15.html#modeling",
    "title": "hierarchical clustering",
    "section": "Modeling",
    "text": "Modeling\n\nimport scipy.cluster.hierarchy as sch\n\ndendogram = sch.dendrogram(sch.linkage(x, method='ward'))\nplt.title('dendogram')\nplt.xlabel('Customers')\nplt.ylabel('Distance')\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.cluster import AgglomerativeClustering\n\nhc = AgglomerativeClustering(n_clusters=5, metric='euclidean', linkage='ward')\nyh = hc.fit_predict(x)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "hierarchical clustering"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/15.html#visualize",
    "href": "posts/02_areas/machine_learning/notes/15.html#visualize",
    "title": "hierarchical clustering",
    "section": "Visualize",
    "text": "Visualize\n\nplt.scatter(x[yh == 0, 0], x[yh == 0, 1], c='red', label='Cluster 1')\nplt.scatter(x[yh == 1, 0], x[yh == 1, 1], c='pink', label='Cluster 2')\nplt.scatter(x[yh == 2, 0], x[yh == 2, 1], c='blue', label='Cluster 3')\nplt.scatter(x[yh == 3, 0], x[yh == 3, 1], c='purple', label='Cluster 4')\nplt.scatter(x[yh == 4, 0], x[yh == 4, 1], c='cyan', label='Cluster 5')\nplt.legend()\nplt.show()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "hierarchical clustering"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/14.html#k-means-algorithm",
    "href": "posts/02_areas/machine_learning/notes/14.html#k-means-algorithm",
    "title": "k-means clustering",
    "section": "K-means++ algorithm",
    "text": "K-means++ algorithm\n\n시작점을 잘 선택하여 수렴 속도를 높이는 알고리즘\n초기 중심점을 선택할 때, 멀리 떨어진 중심점을 선택하도록 함\n\n첫 번째 중심점을 랜덤하게 선택\n나머지 중심점을 선택할 때, 각 데이터 포인트와 가장 먼 중심점을 선택\nk개의 중심점을 선택할 때까지 반복",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "k-means clustering"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/14.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/14.html#preprocessing",
    "title": "k-means clustering",
    "section": "preprocessing",
    "text": "preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndataset = pd.read_csv('_data/14.csv')\nx = dataset.iloc[:, [3, 4]].values",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "k-means clustering"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/14.html#modeling",
    "href": "posts/02_areas/machine_learning/notes/14.html#modeling",
    "title": "k-means clustering",
    "section": "Modeling",
    "text": "Modeling\n\nfrom sklearn.cluster import KMeans\n\nwcss = []\nfor i in range(1, 11):\n  cluster = KMeans(n_clusters=i, init='k-means++')\n  cluster.fit(x)\n  wcss.append(cluster.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('Elbow Method')\nplt.xlabel('Number of Cluster')\nplt.ylabel('WCSS')\nplt.show()\n\n\n\n\n\n\n\n\n\ncluster = KMeans(n_clusters=5, init='k-means++')\ny_kmeans = cluster.fit_predict(x)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "k-means clustering"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/14.html#visualize",
    "href": "posts/02_areas/machine_learning/notes/14.html#visualize",
    "title": "k-means clustering",
    "section": "Visualize",
    "text": "Visualize\n\nplt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], c='red', label='Cluster 1')\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], c='pink', label='Cluster 2')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], c='blue', label='Cluster 3')\nplt.scatter(x[y_kmeans == 3, 0], x[y_kmeans == 3, 1], c='purple', label='Cluster 4')\nplt.scatter(x[y_kmeans == 4, 0], x[y_kmeans == 4, 1], c='cyan', label='Cluster 5')\nplt.scatter(cluster.cluster_centers_[:, 0], cluster.cluster_centers_[:, 1], s=100, c='black', label='Centroids')\nplt.legend()\nplt.show()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "k-means clustering"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/index.html",
    "href": "posts/02_areas/선형대수/index.html",
    "title": "선형대수",
    "section": "",
    "text": "선형대수를 공부해봅시다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/index.html#details",
    "href": "posts/02_areas/선형대수/index.html#details",
    "title": "선형대수",
    "section": "",
    "text": "선형대수를 공부해봅시다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/index.html#tasks",
    "href": "posts/02_areas/선형대수/index.html#tasks",
    "title": "선형대수",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/index.html#참고-자료",
    "href": "posts/02_areas/선형대수/index.html#참고-자료",
    "title": "선형대수",
    "section": "참고 자료",
    "text": "참고 자료\n\nKhan Academy 강의\n3Blue1Brown 강의",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/index.html#related-posts",
    "href": "posts/02_areas/선형대수/index.html#related-posts",
    "title": "선형대수",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/06.html#linear-independence",
    "href": "posts/02_areas/선형대수/notes/06.html#linear-independence",
    "title": "linear independence",
    "section": "Linear independence",
    "text": "Linear independence\n\nDefinition\n\nDependence: one of the vectors in the set can be written as a linear combination of the others.\nIndependence: ⫬ dependence\n\n\n\nTheorem\nS = \\({v_1, v_2, ..., v_n}\\)\n\\(S\\) is linearly dependent ⟺ ∃(\\(c_i\\) is not 0) \\(c_1v_1 + c_2v_2 + ... + c_nv_n = 0\\) is \\(c_1 = c_2 = ... = c_n = 0\\).\n\nif \\(c_1 = c_2 = ... = c_n = 0\\), then \\(S\\) is linearly independent.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "linear independence"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/05.html#선형결합",
    "href": "posts/02_areas/선형대수/notes/05.html#선형결합",
    "title": "선형결합과 생성",
    "section": "선형결합",
    "text": "선형결합\n벡터들의 상수배 합으로 만들 수 있는 벡터의 집합",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "선형결합과 생성"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/07.html#subspaces",
    "href": "posts/02_areas/선형대수/notes/07.html#subspaces",
    "title": "Subspaces and the basis",
    "section": "Subspaces",
    "text": "Subspaces\n\n\\(S\\) is a subset of \\(V\\).\n\nS ⊆ V\nS is a vector space\n\ninclude zero vector\nclosed under addition\nclosed under scalar multiplication",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "Subspaces and the basis"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/07.html#basis",
    "href": "posts/02_areas/선형대수/notes/07.html#basis",
    "title": "Subspaces and the basis",
    "section": "Basis",
    "text": "Basis\n\nminimum set of vectors that spans the subset\n\\(S\\) is a basis of \\(V\\) ⟺\n\nelements of \\(S\\) are linearly independent\n\\(S\\) spans \\(V\\)\n\n특정 부분집합의 basis의 linear combination으로 표현되는 모든 벡터는 유일하다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "Subspaces and the basis"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/02.html#행렬의-곱을-바라보는-관점",
    "href": "posts/02_areas/선형대수/notes/02.html#행렬의-곱을-바라보는-관점",
    "title": "2-기초(2)",
    "section": "행렬의 곱을 바라보는 관점",
    "text": "행렬의 곱을 바라보는 관점\n\n내적으로 바라보기\n\n\\[\nA = \\begin{bmatrix}\na_1^T \\\\\na_2^T \\\\\na_3^T\n\\end{bmatrix}\n\\quad (a_x = \\text{column vector})\n\\]\n\\[\nAB = \\begin{bmatrix}\na_1^T \\\\\na_2^T \\\\\na_3^T\n\\end{bmatrix}\n\\begin{bmatrix}\nb_1 & b_2 & b_3\n\\end{bmatrix} =\n\\begin{bmatrix}\na_1^Tb_1 & a_1^Tb_2 & a_1^Tb_3 \\\\\na_2^Tb_1 & a_2^Tb_2 & a_2^Tb_3 \\\\\na_3^Tb_1 & a_3^Tb_2 & a_3^Tb_3\n\\end{bmatrix}\n\\]\n\nrank-1 matrix의 합\n\n\\[\nAB = \\begin{bmatrix}\na_1 & a_2 & a_3\n\\end{bmatrix}\n\\begin{bmatrix}\nb_1^T \\\\\nb_2^T \\\\\nb_3^T\n\\end{bmatrix} =\na_1^Tb_1 + a_2^Tb_2 + a_3^Tb_3\n\\]\n\nColumn space로 바라보기\n\n\\[\nAx = \\begin{bmatrix}\na_1 & a_2 & a_3\n\\end{bmatrix}\n\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{bmatrix} = a_1x_1 + a_2x_2 + a_3x_3\n\\]\n\nRow space로 바라보기\n\n\\[\nx^TA = \\begin{bmatrix}\nx_1 & x_2 & x_3\n\\end{bmatrix}\n\\begin{bmatrix}\na_1^T \\\\\na_2^T \\\\\na_3^T\n\\end{bmatrix} = x_1a_1^T + x_2a_2^T + x_3a_3^T\n\\]",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/02.html#span과-column-space",
    "href": "posts/02_areas/선형대수/notes/02.html#span과-column-space",
    "title": "2-기초(2)",
    "section": "span과 column space",
    "text": "span과 column space\n\ncolumn space: column vector들이 span하는 영역\nspan: linear combination으로 만들어지는 모든 벡터들의 집합\nlinear combination: vector들을 scalar 배 하고 더한 것\nlinear independent: span하는 vector들이 서로 독립적인 경우\n수학적 정의: \\(a_1v_1 + a_2v_2 + \\cdots + a_nv_n = 0\\) 일 때 \\(a_1 = a_2 = \\cdots = a_n = 0\\) 인 경우\nbasis: 어떤 공간을 이루는 필수적인 구성요소 (linear independent, span)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/02.html#항등행렬",
    "href": "posts/02_areas/선형대수/notes/02.html#항등행렬",
    "title": "2-기초(2)",
    "section": "항등행렬",
    "text": "항등행렬\n\\(AI = IA = A\\)를 만족하는 행렬 \\(I\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/02.html#역행렬",
    "href": "posts/02_areas/선형대수/notes/02.html#역행렬",
    "title": "2-기초(2)",
    "section": "역행렬",
    "text": "역행렬\n\\(Ax = b\\)를 만족하는 \\(x\\)를 찾는 것은 \\(A^{-1}Ax = A^{-1}b\\)를 만족하는 \\(x\\)를 찾는 것과 같다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/02.html#대각-행렬",
    "href": "posts/02_areas/선형대수/notes/02.html#대각-행렬",
    "title": "2-기초(2)",
    "section": "대각 행렬",
    "text": "대각 행렬\ndiagonal을 제외한 모든 요소가 0인 행렬 (square, rectangular 모두 가능)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/02.html#orthogonal-행렬",
    "href": "posts/02_areas/선형대수/notes/02.html#orthogonal-행렬",
    "title": "2-기초(2)",
    "section": "Orthogonal 행렬",
    "text": "Orthogonal 행렬\n행렬의 모든 column들이 orthonormal vector인 경우\n\\(Q^{-1} = Q^T\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/02.html#행렬의-rank",
    "href": "posts/02_areas/선형대수/notes/02.html#행렬의-rank",
    "title": "2-기초(2)",
    "section": "행렬의 rank",
    "text": "행렬의 rank\nrank: 행렬이 가지는 independent한 column의 개수 → column space의 차원\nrank(A) = rank(A^T)\n\nfull-column rank: 해가 없거나 한 개 존재\nfull-row rank: 해가 무한하다\nfull rank: 해가 한 개 있다.\nrank-deficient: b가 column space에 속하지 않는 경우 해가 없고, 그렇지 않으면 해가 무한하다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/02.html#null-space",
    "href": "posts/02_areas/선형대수/notes/02.html#null-space",
    "title": "2-기초(2)",
    "section": "Null space",
    "text": "Null space\n\\(Ax = 0\\)을 만족하는 모든 \\(x\\)의 집합\nA가 m x n 행렬이라면, dim(N(A)) = n - rank(A)\nnull space와 row space는 orthogonal하다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/index.html",
    "href": "posts/02_areas/42_seoul/index.html",
    "title": "42 Seoul",
    "section": "",
    "text": "42 seoul에서 진행한 프로젝트들에 대한 노트 모음입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/index.html#details",
    "href": "posts/02_areas/42_seoul/index.html#details",
    "title": "42 Seoul",
    "section": "",
    "text": "42 seoul에서 진행한 프로젝트들에 대한 노트 모음입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/index.html#tasks",
    "href": "posts/02_areas/42_seoul/index.html#tasks",
    "title": "42 Seoul",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/index.html#related-posts",
    "href": "posts/02_areas/42_seoul/index.html#related-posts",
    "title": "42 Seoul",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/01.html#intro",
    "href": "posts/02_areas/42_seoul/notes/01.html#intro",
    "title": "ft_transcendence - github action",
    "section": "intro",
    "text": "intro\n\n\n\n42 seoul 공통과정 6서클 과제\n\n\n42 Seoul 공통과정의 마지막 과제입니다. 이 프로젝트는 개발자가 선호하는 라이브러리와 프레임워크를 자유롭게 선택하여 구현할 수 있다는 점이 특징입니다.\n대형 협업 과제인 만큼, 과제에 명시되어있지 않지만 협업을 위한 툴도 공부해서 다양하게 적용해볼 수 있는 좋은 과제인것 같습니다. 저같은 경우에는 coursera, udemy 강의를 통해 agile 협업 방식과 github에서의 적용 방법에 대해 공부를 했고, 프로젝트 진행에 있어서 꽤 도움이 됐던걸로 기억합니다. 사실 프로젝트를 진행하다보니, agile 방식을 온전히 다 적용하기엔 적합하지 않다고 판단했지만, Kanban Board로 프로젝트를 관리하는 것 같은 부분은 꽤 유용하게 활용할 수 있었습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "ft_transcendence - github action"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/01.html#프로젝트-및-구현-설명",
    "href": "posts/02_areas/42_seoul/notes/01.html#프로젝트-및-구현-설명",
    "title": "ft_transcendence - github action",
    "section": "프로젝트 및 구현 설명",
    "text": "프로젝트 및 구현 설명\n\n개요\n과제 명세서\n해당 과제는 실시간 Pong 게임 매칭 웹사이트를 만드는게 목표입니다. 저는 이번 프로젝트에서 github action 설정, User Management Backend 설계와 42 API를 이용한 OAuth 인증, JWT 구현, Game History를 Block Chain으로 저장하는 파트를 담당했습니다.\n참고한 자료는 다음과 같습니다:\n\nGoogle Agile Project 관리\nGithub Action Docs\nGithub CLI Docs\nDjango udemy 강좌\nDjango Rest Framework Docs\nDjango Simple JWT\nJWT Token 탈취 대응 시나리오\nmicro service에서 JWT 활용 방법\nRefresh Token을 사용해야 하는 이유\nCookie에서의 same site 옵션\nBitcoin 백서\nSolidity Udemy 강의\nSolidity Docs\nnomad coder 블록체인 시리즈\n블록체인 강의\n\n\n\n\n\n\n\n이 포스팅에서는 github action setting, jwt, block chain 부분만 다루겠습니다.\n전체 코드는 비공개 되어있는 상태입니다.\n\n\n\n\n\nGithub Action Setting\ngithub를 이용해서 agile 방법론을 적용할 수 있도록 의도했고, 자동화와 template을 이용해 통일성 있는 구조를 유지하려고 했습니다.\n1. 회의를 통해 진행해야 하는 작업을 Kanban board에 정리한다.\n\n\n\nGithub Kanban Board\n\n\n각각의 column에는 다음과 같은 내용이 들어갑니다.\n\nDiscussion: 논의가 필요한 작업. 개개인이 자유롭게 올릴 수 있습니다\nBacklog: Discussion에 있는 내용 중 구현하기로 회의에서 정한 작업\nReady: Back log에 있는 작업 중 이번 Sprint에서 구현할 작업들\nIn Progress: Ready에 있는 작업 중 누군가가 작업중인 것\nDone: master branch에 merge가 완료된 작업\n\n자세한 내용은 meeting 부분을 참고해 주세요.\n참고로 Disccusion에 작업을 올리는 방법은 template에 맞게 issue를 올리면 됩니다.\n\n\n\nDiscussion template\n\n\n아래와 같이 설정 파일을 만들어서 ‘.github/ISSUE_TEMPLATE/’ 폴더 안에 저장하면 issue create 시 자동으로 template이 뜨게 할 수 있습니다.\nname: New discussion\ndescription: new discussion\ntitle: \"[DISCUSSION]\"\nlabels: [\"enhancement\"]\nprojects: [\"org_name/5\"]\nbody:\n  - type: markdown\n    attributes:\n      value: |\n        해당 기능과 관련된 request가 이미 존재하는지 확인해주세요.\n  - type: textarea\n    id: story\n    attributes:\n      label: Story\n      description: 해당 기능에 대한 설명이나 필요한 배경을 작성해주세요.\n      placeholder: 자유로운 양식으로 작성해주세요.\n    validations:\n      required: true\n2. Kanban board를 보고 개인이 능동적으로 고유 브랜치에 작업을 진행한다.\n\n\n\n빨간 밑줄 부분을 설정해줍니다.\n\n\nKanban board의 Ready section에 있는 작업을 클릭해서 들어간 후, assignees를 본인으로 선택해서 작업하면 됩니다. task completion criteria라는 내용이 보이는데, 이는 회의를 통해 결정하는 것으로, 나중에 작업이 완료되고 pull request 시, 평가자가 작업에 완성도에 대해 판단할 수 있는 기준으로 제공됩니다.\n자동화 코드는 아래와 같이 구현했습니다.\nname: Create branch\non:\n  issues:\n    types: [ assigned ]\n  pull_request:\n    types: [ opened, closed ]\njobs:\n  create_issue_branch_job:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Generate token\n        id: generate_token\n        uses: tibdex/github-app-token@v2\n        with:\n          app_id: ${{ secrets.APP_ID }}\n          private_key: ${{ secrets.PRIVATE_KEY }}\n\n      # gh 명령어를 이용해 project의 상태를 In progress로 수정해줍니다.\n      - name: Project in-progress\n        if: github.event.action == 'assigned'\n        run: |\n          PROJECT_ID=$(gh project view 5 --owner organization-for-practice --format=json --jq '.id')\n          ITEM_ID=$(gh project item-list 5 --owner organization-for-practice --format=json --jq \".items[] | select(.content.number == ${NUMBER}) | .id\")\n          FIELD_ID=$(gh project field-list 5 --owner organization-for-practice --format=json --jq '.fields[2].id')\n          SINGLE_ID=$(gh project field-list 5 --owner organization-for-practice --format=json --jq '.fields[2].options[] | select(.name == \"In progress\") | .id')\n          gh project item-edit --id ${ITEM_ID} --field-id ${FIELD_ID} --single-select-option-id ${SINGLE_ID} --project-id ${PROJECT_ID}\n        env:\n          GH_TOKEN: ${{ steps.generate_token.outputs.token }}\n          NUMBER: ${{ github.event.issue.number }}\n\n      # assign한 작업에 대한 branch를 새로 만들어줍니다.\n      - name: Create Issue Branch\n        uses: robvanderleek/create-issue-branch@main\n        env:\n          GITHUB_TOKEN: ${{ steps.generate_token.outputs.token }}\n위의 코드는 assign한 작업을 Ready column에서 In progress column으로 옮겨주고, 자동으로 작업할 branch를 만들어줍니다.\nbranch 자동 생성은 이 workflow를 사용하였고, 적용 시 아래와 같이 브랜치가 생성됩니다.\nautoLinkIssue: true\nautoCloseIssue: true\nbranchName: tiny\ncommentMessage: |\n  \\\"${branchName}\\\" branch 생성 완료.\n  해당 branch를 통해서 main에 pull request 올려주세요.\nbranches:\n  - label: 'task list'\n    prefix: feature/${issue.title[12,27],}/\n    copyIssueAssigneeToPR: true\n  - label: 'bug'\n    prefix: hot_fix/${issue.title[6,21],}/\n    copyIssueAssigneeToPR: true\n  - label: '*'\n    skip: true\n위의 config 파일을 작성해주면 아래와 같이 브랜치가 생성됩니다.\n\n\n\n자동 생성된 branch\n\n\n이름도 자동으로 생성되게 해서 convention을 지켜야 한다는 부담을 줄여줬습니다.\n3. 작업이 완료되면, 모든 조건을 충족하는지 확인한 후, master에 merge 한다.\n\n\n\npull request 화면\n\n\n작업이 완료됬다고 판단되면 위 화면과 같이 pull request를 생성하고, Reviewer를 설정해주면 됩니다.\n\n\n\ntask completion criteria\n\n\n그러면 이전에 설정했던 기준들이 자동으로 불러와지고, 모든 항목에 체크가 완료되어야 merge를 할 수 있게 설정했습니다. 구현 코드는 아래와 같습니다.\nname: Master merge rutine\non:\n  pull_request_target:\n    types: [ opened, synchronize ]\n    branches:\n      - master\nenv:\n  PR_NUM: ${{ github.event.pull_request.number }}\n  GH_REPO: ${{ github.repository }}\njobs:\n  get_checklist:\n    runs-on: ubuntu-latest\n    if: github.event.action == 'opened'\n    steps:\n      - name: Generate token\n        id: generate_token\n        uses: tibdex/github-app-token@v2\n        with:\n          app_id: ${{ secrets.APP_ID }}\n          private_key: ${{ secrets.PRIVATE_KEY }}\n      - name: Get issue\n        id: issue_num\n        env:\n          BRANCH: ${{ github.event.pull_request.head.ref }}\n        run: |\n          echo $BRANCH | grep -o 'feature\\/.*\\/i[0-9]\\+' || echo $BRANCH | grep -o 'hot_fix\\/.*\\/i[0-9]\\+'\n          TMP=$(echo $BRANCH | grep -o 'i[0-9]\\+')\n          echo \"NUMBER=${TMP#i}\" &gt;&gt; $GITHUB_OUTPUT\n      - name: Get issue body\n        id: issue_body\n        env:\n          GH_TOKEN: ${{ steps.generate_token.outputs.token }}\n          NUM: ${{ steps.issue_num.outputs.number }}\n        run: |\n          echo \"CONTENTS&lt;&lt;EOF\" &gt;&gt; $GITHUB_OUTPUT\n          gh issue view ${NUM} --json body --jq '.body' &gt;&gt; $GITHUB_OUTPUT\n          echo \"EOF\" &gt;&gt; $GITHUB_OUTPUT\n      - name: Update checklist\n        run: |\n          gh pr comment $PR_NUM --body \"${BODY}\"\n        env:\n          GH_TOKEN: ${{ steps.generate_token.outputs.token }}\n          BODY: \"${{ steps.issue_body.outputs.contents }}\"\nmerge가 완료된 branch는 자동으로 삭제가 되도록 설정을 해주었습니다.\n이제 아래는 실제 프로젝트를 진행할 때 만들었던 rule들입니다.\n\n1. work flow\ngithub flow로 진행됩니다.\n\n\n\ngithub flow\n\n\n\n매 작업은 master branch의 HEAD를 기반으로 이루어집니다.\npr을 올리지 않는 개인 작업용 local branch는 자유롭게 생성해주세요.\nmaster에 직접적인 push는 관리자를 제외하고는 불가능합니다.\nmaster에 대한 merge는 squash merge로 진행됩니다.\n그 외의 merge는 rebase로 진행해주세요.\n\n\n\n2. work\n\nkanban board의 'Ready' 섹션에서 하나를 정해서 새로운 기능에 대한 작업을 진행해주세요.\n선택한 작업은 assignees에 자신의 팀원을 등록 후, Start Date를 해당 날짜로 설정해주세요.\nassignees 등록이 완료되면 자동으로 target branch가 생성됩니다.\n해당 branch에 팀원들이 필요한 기능들을 자유로운 방식으로 구현한 후, master branch에 merge 해주세요.\n단, 해당 branch에 대한 merge는 rebase로 진행해주세요.\nhot_fix issue나, new feature request issue는 discussion의 필요성이 있을 경우에 등록해주세요.\n작업 중, 현재 작업하는 범위 외에서 추가적인 기능이 필요할 경우 관련 issue에 comment를 남기거나, reopen 해주세요.\n\n\n\n3. commit message convention\n아래의 명령어를 입력해주세요\ngit config commit.template .github/COMMIT_MESSAGE_TEMPLATE\n이후, -m 옵션 없이 ’git commit’으로 message를 입력해주세요.\n\n\nCOMMIT_MESSAGE_TEMPLATE\n\n# commit message template\n# ▼ &lt;Title&gt; 작성\n\n# ▼ &lt;빈 줄&gt;\n\n# ▼ &lt;body&gt; 작성\n\n# ▼ &lt;빈 줄&gt;\n\n# ▼ &lt;footer&gt; 작성\n\n\n# About Convention\n#   &lt;Title&gt;\n#       - 필수로 입력해주세요\n#       - 형식: &lt;type&gt;: &lt;short summary&gt;\n#\n#       &lt;type&gt;\n#           - config: 설정 관련 파일 작성 또는 변경\n#           - docs: 문서 변경사항\n#           - feat: 새로운 기능\n#           - fix: 버그 수정\n#           - refactor: 기능 추가나 버그 수정이 아닌 변경 사항\n#           - remove: 코드나 파일 제거\n#           - style: 스타일 작성 또는 수정\n#           - test: 누락된 테스트 추가 또는 기존 테스트 수정\n#           - core: 기능 구현 외 시스템 관련 작업\n#\n#       &lt;short summary&gt;\n#           - 변경 사항에 대한 간단한 설명\n#           - 첫글자 소문자, 현재 시제, 명령문으로 마지막에 .(마침표) 없이 작성\n#\n#   &lt;body&gt;\n#       - 선택적으로 입력 해주세요\n#       - 현재 시제, 명령문으로 작성\n#       - 변경 사항의 동기(왜)를 설명\n#       - 변경 효과를 설명하기 위해 이전 동작과 현재 동작의 비교를 포함할 수 있음\n#\n#   &lt;footer&gt;\n#       - 선택적으로 입력 해주세요\n#       - 해당 commit과 관련된 task의 issue 번호들을 적어주세요\n#       - 'bug'나 'task list' label이 붙은 issue는 제외해주세요\n#       - ex) closes #&lt;issue 번호&gt; closes #&lt;issue 번호&gt; ...\n\n\n\n\n\n\n\ncommit message template은 이 사이트를 참고해서 만들었습니다.\n\n\n\n\n\n4. pull request\n\npull request는 500줄의 코드를 넘어가지 않게 작성 바랍니다.\n모든 check list를 통과한 request만 master에 merge 가능합니다.\nreviewers에는 해당 작업과 관련된 domain의 팀원을 선택해주세요. 최소 1명 이상의 동료에게 평가를 받은 request만 merge 가능합니다.\n\n\n\n5. meeting\n\ndaily meeting\n\n매일 정해진 시간에 팀원들은 각각 다음과 같은 사안에 대해 논의합니다.\n\n개인이 어제 작업한 내용\n개인이 오늘 작업할 내용\n개인이 현재 도움이 필요한 내용\n\n이후, 새로운 내용이 추가된 ('Disccusion' 섹션에 있는) issue 중 다음과 같은 내용에 대해 논의합니다.\n\n해당 issue가 유효한가\n추가적으로 필요하거나 필요 없는 내용\n해당 issue의 priority (매우 급함 / 급함 / 안 급함)\n해당 issue의 estimate (작업하는데 필요한 노력의 정량적인 수치)\n\n추가적으로, project의 'Back log' 항목에서 'Ready' 항목으로 추가해야 할 작업에 대해 논의하거나 'Ready' 항목에서 'Back log' 항목으로 제외할 작업에 대해 논의할 수 있습니다.\n\nsprint planning / retrospective\n\n2주에 한번 진행.\n이전 sprint에 대한 평가와 이후 sprint를 위한 계획을 세웁니다.\n\nplanning\n\nProject의 'Back log' 항목 중 본격적으로 작업을 진행할 항목을 정합니다.\ndaily meeting 시간을 조정할 수 있습니다.\n\nretrospective\n\n이전 sprint의 문제점에 대해 서로 의논해봅니다.\n\n\n\n\n\n\n\n\n\n프로젝트를 하다보니, 생각보다 진행 속도가 빨라서 2주에 한번 진행하는 sprint는 유명무실해져버렸습니다. 실제로는 daily meeting만 진행을 했습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "ft_transcendence - github action"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/01.html#outro",
    "href": "posts/02_areas/42_seoul/notes/01.html#outro",
    "title": "ft_transcendence - github action",
    "section": "outro",
    "text": "outro\n내용이 너무 길어져서 2편에 계속 포스팅 하겠습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "ft_transcendence - github action"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/09.html#intro",
    "href": "posts/02_areas/42_seoul/notes/09.html#intro",
    "title": "cloud-1 코드 설명",
    "section": "intro",
    "text": "intro\n\n\n\n42 seoul outer 과제\n\n\n개념 설명에 이어서 진행하도록 하겠습니다.\n\n\n\n\n\n\n전체 코드는 github repo에서 확인하실 수 있습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 코드 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/09.html#프로젝트-및-구현-설명",
    "href": "posts/02_areas/42_seoul/notes/09.html#프로젝트-및-구현-설명",
    "title": "cloud-1 코드 설명",
    "section": "프로젝트 및 구현 설명",
    "text": "프로젝트 및 구현 설명\n\npre requirements\n이 프로젝트를 진행하기 위해 필요한 것들은 다음과 같습니다.\n\nAWS IAM 계정\nPacker\nTerraform\nAnsible\njq\nboto3\n\n\n\nbuild\n최종 build는 (42 seoul 사람에게 익숙한) makefile을 사용했습니다.\n\n\n\n\n\n\n제가 아직 로컬에서 돌려볼만한 다른 build 툴을 배우지 않아서 makefile을 사용하긴 했지만, 사실 c언어도 아니고..이 과제 구현에서 이 tool이 그렇게 어울리진 않은거 같긴 합니다.\n\n\n\n\n\n.env\n\n# only 1 line variable is allowed\n\nAWS_REGION=\nAWS_ACCESS_KEY_ID=\nAWS_SECRET_ACCESS_KEY=\nSERVER_INSTANCE_COUNT=\n\n# public subnet에 접근할 수 있는 ip address를 지정해줍니다.\nSSH_IP=\n\n# public subnet에 접근할 때 사용할 ssh key path를 지정해줍니다.\nSSH_PUBLIC_KEY_PATH=\nSSH_PRIVATE_KEY_PATH=\n\n# docker compose setting\nMYSQL_USER=\nMYSQL_PASSWORD=\nMYSQL_ROOT_PASSWORD=\nDATABASE_NAME=\nSITE_TITLE=\nADMIN_NAME=\nADMIN_PASSWORD=\nADMIN_EMAIL=\nUSER_NAME=\nUSER_PASSWORD=\nUSER_EMAIL=\n\n\n\nMakefile\n\n# .env의 내용들을 makefile의 변수로 load 해줍니다.\n\ninclude .env\nexport\n\n먼저 필요한 변수들을 모두 .env에 저장해 한번에 관리할 수 있게 구현했습니다. 저장된 .env 내용은 makefile에서 위의 명령어로 불러와 build 명령어 실행시 사용할 수 있게 했습니다.\nmakefile이 .env 파일을 읽을 때 한 줄씩 읽기 때문에, 위의 방식으로 구현하면 여러 줄에 걸친 환경변수는 사용하기 어려울 수 있습니다. (그럴땐 그냥 makefile 말고 다른 tool을 쓰면 됩니다)\n\n\nMakefile\n\n.PHONY: provision deploy all destroy re build_ami\n\nall: build_ami provision deploy\n\nbuild_ami: packer\n    packer init $(PACKER_PATH)/database.pkr.hcl\n    @PKR_VAR_AWS_REGION=$(AWS_REGION) \\\n    PKR_VAR_MYSQL_USER=$(MYSQL_USER) \\\n    PKR_VAR_MYSQL_PASSWORD=$(MYSQL_PASSWORD) \\\n    PKR_VAR_DATABASE_NAME=$(DATABASE_NAME) \\\n    PKR_VAR_MYSQL_ROOT_PASSWORD=$(MYSQL_ROOT_PASSWORD) \\\n    packer build $(PACKER_PATH)/database.pkr.hcl\n\nprovision: build_ami terraform\n    terraform -chdir=$(PROVISION_PATH) init\n    @TF_VAR_AWS_REGION=$(AWS_REGION) \\\n    TF_VAR_SERVER_INSTANCE_COUNT=$(SERVER_INSTANCE_COUNT) \\\n    TF_VAR_SSH_IP=$(SSH_IP) \\\n    TF_VAR_SSH_PUBLIC_KEY_PATH=$(SSH_PUBLIC_KEY_PATH) \\\n    terraform -chdir=$(PROVISION_PATH) apply -auto-approve\n\ndeploy: ansible\n    @DB_PRIVATE_IP=\"$(shell terraform -chdir=$(PROVISION_PATH) output -json db_private_ip | jq -r '.[]' | tr '\\n' ' ')\" \\\n    ANSIBLE_HOST_KEY_CHECKING=False \\\n    ANSIBLE_REMOTE_USER=ubuntu \\\n    AWS_DEFAULT_REGION=$(AWS_REGION) \\\n    ANSIBLE_PYTHON_INTERPRETER=auto_silent \\\n    ansible-playbook \\\n    -i $(DEPLOY_PATH)/inventories \\\n    --private-key=$(SSH_PRIVATE_KEY_PATH) \\\n    $(DEPLOY_PATH)/server.yml \n\nbuild 과정은 ami 생성, provision, ansible deploy 순서로 진행됩니다.\n각 과정에 필요한 변수들은 명령어 수행 시 환경변수로 제공해줍니다. 대표적으로 ansible의 경우, provision 이후 생성된 database ec2의 private ip를 전달하고 있습니다.\n\n\nPacker 코드\n이 프로젝트에서는 데이터베이스 서버를 Private subnet에 위치시키고, Public subnet의 EC2만 이 데이터베이스에 접근할 수 있도록 설계했습니다. Private subnet에 있는 서버는 SSH 접근이 제한되기 때문에 Ansible로 직접 설정하기는 어렵습니다. 이런 경우 Packer로 미리 설정된 AMI를 생성하는 방법을 생각해볼 수 있습니다.\n구현한 Packer 파일 구조는 아래와 같습니다.\npacker/\n├── database.pkr.hcl\n└── ansible/\n    ├── _requirements/                      # docker compose setting files\n    ├── roles/setting_docker/tasks\n    │   └── main.yml\n    └── database.yml                        # playbook\n먼저 기본 이미지로 Ubuntu 20.04를 사용하도록 작성했습니다.\n\n\ndatabase.pkr.hcl\n\nsource \"amazon-ebs\" \"database\" {\n  region  = var.AWS_REGION\n  profile = \"default\"\n\n  ami_name      = \"hyunghki-database-${formatdate(\"YYYYMMDDhhmmss\", timestamp())}\"\n  instance_type = \"t2.micro\"\n  source_ami_filter {\n    filters = {\n      name                = \"ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*\"\n      root-device-type    = \"ebs\"\n      virtualization-type = \"hvm\"\n    }\n    most_recent = true\n    owners      = [\"099720109477\"]\n  }\n  ssh_username = \"ubuntu\"\n}\n\nPacker는 기본적으로 이미지 생성을 위한 최소한의 기능만 제공하지만, 다양한 플러그인을 지원합니다. 여기서는 Ansible 플러그인을 사용하여 데이터베이스 서버 설정을 자동화했습니다.\n\n\ndatabase.pkr.hcl\n\nbuild {\n  sources = [\"source.amazon-ebs.database\"]\n\n  provisioner \"ansible\" {\n    playbook_file = \"${path.root}/ansible/database.yml\"\n    user = \"ubuntu\"\n    ansible_env_vars = [\n      \"ANSIBLE_HOST_KEY_CHECKING=False\",\n      \"MYSQL_USER=${var.MYSQL_USER}\",\n      \"MYSQL_PASSWORD=${var.MYSQL_PASSWORD}\",\n      \"DATABASE_NAME=${var.DATABASE_NAME}\",\n      \"MYSQL_ROOT_PASSWORD=${var.MYSQL_ROOT_PASSWORD}\",\n      \"ANSIBLE_PYTHON_INTERPRETER=auto_silent\"\n    ]\n  }\n}\n\n\n\nansible/database.yml\n\n- hosts: all\n  gather_facts: false\n  become: true\n  roles:\n    # docker compose를 machine에 설치해줍니다.\n    - role: setting_docker\n\n  tasks:\n    # docker compose에 필요한 파일들을 옮겨줍니다.\n    - name: copy_requirements\n      copy:\n        src: \"./_requirements/\"\n        dest: \"/home/{{ ansible_user }}/app/\"\n        mode: '0755'\n        directory_mode: '0755'\n\n    # 적절한 환경변수와 함께 docker compose 명령어를 실행합니다.\n    - name: execute docker compose\n      shell:\n        cmd: docker-compose up -d\n        chdir: \"/home/{{ ansible_user }}/app/\"\n      environment:\n        MYSQL_USER: \"{{ lookup('env', 'MYSQL_USER') }}\"\n        MYSQL_PASSWORD: \"{{ lookup('env', 'MYSQL_PASSWORD') }}\"\n        DATABASE_NAME: \"{{ lookup('env', 'DATABASE_NAME') }}\"\n        MYSQL_ROOT_PASSWORD: \"{{ lookup('env', 'MYSQL_ROOT_PASSWORD') }}\"\n\n이렇게 Ansible과 Packer를 조합하면 멱등성이 보장되는 안정적인 서버 이미지를 생성할 수 있습니다.\n참고로 packer에서 ansible plugin을 사용할 때 taget host를 ami가 build되는 임시 EC2로 간주하기 때문에, inventory는 사용하지 않습니다. 자세한 내용은 ansible part를 참고해주세요.\n\n\nTerraform 코드\n이제 본격적으로 provision을 해보겠습니다. 잠시 전체적인 구조를 다시 한번 보겠습니다.\n\n\n\n구현 aws 구조\n\n\n필요한 리소스는 VPC, subnet, security group, ec2 입니다.\nserver ec2와 database ec2는 환경변수 SERVER_INSTANCE_COUNT에 지정된 갯수 만큼 생성됩니다. database ec2는 이전 단계에서 생성한 ami를 사용해줍니다.\npublic, private subnet의 갯수는 임의로 생성했습니다.\n파일 구조는 아래와 같습니다.\nterraform/\n├── main/\n│   ├── main.tf\n│   ├── data.tf\n│   ├── output.tf\n│   └── variables.tf\n└── modules/network/\n    ├── main.tf\n    ├── output.tf\n    └── variables.tf\nmain.tf에서는 aws_instance를 생성하고, 그 외 VPC, subnet과 같은 리소스는 network module로 분리해서 생성했습니다.\n\n\nmodules/network/main.tf\n\nresource \"aws_vpc\" \"main_vpc\" {\n  cidr_block           = \"10.0.0.0/16\"\n  instance_tenancy     = \"default\"\n  enable_dns_hostnames = \"true\"\n}\n\nresource \"aws_subnet\" \"public-1\" {\n  vpc_id                  = aws_vpc.main_vpc.id\n  cidr_block              = \"10.0.1.0/24\"\n  map_public_ip_on_launch = \"true\"\n  availability_zone       = \"${var.AWS_REGION}a\"\n}\n\nresource \"aws_subnet\" \"public-2\" {\n  vpc_id                  = aws_vpc.main_vpc.id\n  cidr_block              = \"10.0.2.0/24\"\n  map_public_ip_on_launch = \"true\"\n  availability_zone       = \"${var.AWS_REGION}c\"\n}\n\nresource \"aws_subnet\" \"private\" {\n  vpc_id                  = aws_vpc.main_vpc.id\n  cidr_block              = \"10.0.3.0/24\"\n  map_public_ip_on_launch = \"false\"\n  availability_zone       = \"${var.AWS_REGION}a\"\n}\n\n먼저 VPC와 subnet을 생성합니다.\ncidr_block은 private ip 중에서 겹치지 않는 범위로 지정해줍니다.\n\n\n\n\n\n\nPrivate IP ranges\n\n\n\n\nClass A: 10.0.0.0–10.255.255.255\nClass B: 172.16.0.0–172.31.255.255\nClass C: 192.168.0.0–192.168.255.255\n\n\n\nPublic subnet이 인터넷과 통신하기 위해서는 Internet Gateway와 Route Table이 필요합니다.\n\n\nmodules/network/main.tf\n\nresource \"aws_internet_gateway\" \"gate_way\" {\n  vpc_id = aws_vpc.main_vpc.id\n}\n\nresource \"aws_route_table\" \"public_route_table\" {\n  vpc_id = aws_vpc.main_vpc.id\n\n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.gate_way.id\n  }\n}\n\nresource \"aws_route_table_association\" \"public-1\" {\n  subnet_id      = aws_subnet.public-1.id\n  route_table_id = aws_route_table.public_route_table.id\n}\n\nresource \"aws_route_table_association\" \"public-2\" {\n  subnet_id      = aws_subnet.public-2.id\n  route_table_id = aws_route_table.public_route_table.id\n}\n\n모든 외부 트래픽을 Internet Gateway로 보내도록 Route Table을 설정하고, 이를 두 개의 Public subnet에 연결했습니다.\n참고로 VPC 내부 통신은 자동으로 라우팅됩니다. 같은 VPC 안에 있는 리소스들은 VPC의 기본 라우팅 테이블을 통해 서로 통신할 수 있기 때문에 내부 통신을 위한 route table은 따로 생성하지 않았습니다.\n\n\nmodules/network/main.tf\n\nresource \"aws_security_group\" \"server_sg\" {\n  vpc_id = aws_vpc.main_vpc.id\n  name   = \"server_sg\"\n\n  ingress {\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = var.SSH_CIDR_BLOCKS\n  }\n\n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  ingress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\nresource \"aws_security_group\" \"database_sg\" {\n  vpc_id = aws_vpc.main_vpc.id\n  name   = \"efs_sg\"\n\n  ingress {\n    from_port       = 3306\n    to_port         = 3306\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.server_sg.id]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\n마지막으로 security group입니다.\nserver ec2의 ssh 접근은 환경변수를 통해 ansible을 실행하는 머신의 ip에서만 접근 가능하도록 설정해줬습니다.\ndatabase ec2는 server ec2만 접근할 수 있도록 설정했습니다.\n\n\nmain/main.tf\n\n# 사용자가 지정한 경로의 ssh key를 사용해 ec2에 접근 가능하도록 설정했습니다.\nresource \"aws_key_pair\" \"my_labtop\" {\n  key_name   = \"my_labtop\"\n  public_key = file(var.SSH_PUBLIC_KEY_PATH)\n}\n\nmodule \"network\" {\n  source = \"../modules/network\"\n\n  AWS_REGION           = var.AWS_REGION\n  SSH_CIDR_BLOCKS      = [\"${var.SSH_IP}/32\"]\n}\n\nresource \"aws_instance\" \"server\" {\n  count         = var.SERVER_INSTANCE_COUNT\n  ami           = data.aws_ami.latest_ubuntu.id\n  instance_type = \"t2.micro\"\n\n  vpc_security_group_ids = [module.network.server_sg_id]\n  # subnet은 2개를 번걸아가면서 사용하도록 설정했습니다.\n  subnet_id              = module.network.public_subnets[count.index % 2]\n\n  key_name = aws_key_pair.my_labtop.key_name\n  tags = {\n    Name = \"serverNode\"\n  }\n}\n\nresource \"aws_instance\" \"database\" {\n  count         = var.SERVER_INSTANCE_COUNT\n  ami           = data.aws_ami.database_ami.id\n  instance_type = \"t2.micro\"\n\n  vpc_security_group_ids = [module.network.database_sg_id]\n  subnet_id              = module.network.private_subnets\n\n  key_name = aws_key_pair.my_labtop.key_name\n  tags = {\n    Name = \"dbNode\"\n  }\n}\n\n최종적으로 main.tf에서 network module을 불러와서 필요한 리소스를 생성한 후, server와 database ec2를 생성했습니다.\n\n\nmain/data.tf\n\ndata \"aws_ami\" \"latest_ubuntu\" {\n  most_recent = true\n\n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n\n  owners = [\"099720109477\"]\n}\n\ndata \"aws_ami\" \"database_ami\" {\n  most_recent = true\n  owners = [\"self\"]\n  filter {\n    name = \"name\"\n    values = [\"hyunghki-database-*\"]\n  }\n  filter {\n    name = \"root-device-type\"\n    values = [\"ebs\"]\n  }\n  filter {\n    name = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n}\n\nserver ec2는 기본 ubuntu 20.04 이미지를 사용하고, database ec2는 이전에 생성한 ami를 사용했습니다.\n\n\nansible 코드\n이제 필요한 설정을 진행하겠습니다.\n파일 구조는 아래와 같습니다.\nterraform/\n├── _requirements/                      # docker compose setting files\n├── inventories/\n│   └── aws_ec2.yml\n├── roles/setting_docker/tasks\n│   └── main.yml\n└── server.yml\n먼저 용어를 알아야 합니다.\n\nInventory (인벤토리)\n인벤토리는 Ansible이 관리할 호스트(서버)의 목록입니다. 호스트를 그룹으로 묶어 관리할 수 있습니다.\nPlaybook (플레이북)\n플레이북은 Ansible에서 작업을 정의하는 YAML 파일입니다. 플레이북은 하나 이상의 플레이로 구성되며, 각 플레이는 특정 호스트 그룹에 대해 수행할 작업(task)을 정의합니다.\nRole (롤)\n롤은 Ansible에서 재사용 가능한 구성 단위입니다. 플레이북을 모듈화하고 구조화하여 재사용성을 높이는 데 사용됩니다.\n\nInventory에서 server 그룹을 정의한 후, playbook으로 docker compose 환경을 설정하겠습니다.\n\n\naws_ec2.yml\n\nplugin: aws_ec2\nkeyed_groups:\n  - key: tags\ncompose:\n  ansible_host: public_ip_address\nleading_separator: False\nfilters:\n  instance-state-name: running\n\nAWS EC2 동적 인벤토리 설정입니다. Terraform으로 생성한 EC2 인스턴스들을 자동으로 관리할 수 있습니다.\n\n\nserver.yml\n\n- hosts: \"Name_serverNode\"\n  gather_facts: false\n  become: true\n  roles:\n    - role: setting_docker\n  tasks:\n    - name: copy_requirements\n      copy:\n        src: \"./_requirements/\"\n        dest: \"/home/{{ ansible_user }}/app/\"\n        mode: '0755'\n        directory_mode: '0755'\n\n    - name: Split array values from DB_PRIVATE_IP\n      set_fact:\n        target: \"{{ lookup('env', 'DB_PRIVATE_IP') | split(' ') }}\"\n\n    - name: execute docker compose\n      shell:\n        cmd: docker-compose up -d\n        chdir: \"/home/{{ ansible_user }}/app/\"\n      environment:\n        DOMAIN_NAME: \"{{ ansible_host }}\"\n        MYSQL_USER: \"{{ lookup('env', 'MYSQL_USER') }}\"\n        MYSQL_PASSWORD: \"{{ lookup('env', 'MYSQL_PASSWORD') }}\"\n        DATABASE_NAME: \"{{ lookup('env', 'DATABASE_NAME') }}\"\n        SITE_TITLE: \"{{ lookup('env', 'SITE_TITLE') }}\"\n        ADMIN_NAME: \"{{ lookup('env', 'ADMIN_NAME') }}\"\n        ADMIN_PASSWORD: \"{{ lookup('env', 'ADMIN_PASSWORD') }}\"\n        ADMIN_EMAIL: \"{{ lookup('env', 'ADMIN_EMAIL') }}\"\n        USER_NAME: \"{{ lookup('env', 'USER_NAME') }}\"\n        USER_PASSWORD: \"{{ lookup('env', 'USER_PASSWORD') }}\"\n        USER_EMAIL: \"{{ lookup('env', 'USER_EMAIL') }}\"\n        DB_PRIVATE_IP: \"{{ target[ansible_play_hosts.index(inventory_hostname)] }}\"\n\n    - name: all done message\n      debug:\n        msg: \"https://{{ ansible_host }}\"\n\n’Name’이 ’serverNode’인 인스턴스들만 선택하여 설정을 진행하겠습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 코드 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/09.html#실행",
    "href": "posts/02_areas/42_seoul/notes/09.html#실행",
    "title": "cloud-1 코드 설명",
    "section": "실행",
    "text": "실행\n먼저 .env 파일에 환경변수를 설정해줍니다.\nip 정보도 알아낸 후, SSH_IP에 설정해줍니다.\n\n\n\nnaver에 내 ip 검색\n\n\n\n\n.env\n\n# only 1 line variable is allowed\nAWS_REGION=ap-northeast-2\nAWS_ACCESS_KEY_ID=********************\nAWS_SECRET_ACCESS_KEY=********************\nSERVER_INSTANCE_COUNT=2\nSSH_IP=121.135.181.56\nSSH_PUBLIC_KEY_PATH=~/.ssh/id_rsa.pub\nSSH_PRIVATE_KEY_PATH=~/.ssh/id_rsa\nMYSQL_USER=dudu\nMYSQL_PASSWORD=secret\nMYSQL_ROOT_PASSWORD=secret\nDATABASE_NAME=cloud\nSITE_TITLE='hyunghki blog'\nADMIN_NAME=admin\nADMIN_PASSWORD=secret\nADMIN_EMAIL=admin@example.com\nUSER_NAME=user\nUSER_PASSWORD=secret\nUSER_EMAIL=user@example.com\n\n그후 make 명령어를 입력하면 자동으로 build가 진행됩니다.\n\n\n\n명령어 실행 결과\n\n\nbuild가 완료되면 완료 메세지의 ip로 접속해줍니다.\n\n\n\n접속 페이지\n\n\nwordpress 접속 페이지가 잘 뜨는 것을 확인할 수 있습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 코드 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/09.html#결과",
    "href": "posts/02_areas/42_seoul/notes/09.html#결과",
    "title": "cloud-1 코드 설명",
    "section": "결과",
    "text": "결과\n\n\n\n최종 점수\n\n\n\n\n\n최종 평가",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 코드 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/09.html#outro",
    "href": "posts/02_areas/42_seoul/notes/09.html#outro",
    "title": "cloud-1 코드 설명",
    "section": "outro",
    "text": "outro\n솔직히 일반적으로 사용되는 cloud 구조를 적용한건 아니긴 하지만, 과제에 맞춰서 진행하기 위해 고민하는 과정에서 다양한 구조를 적용해봤는데, 그 과정이 나름 학습에 도움이 된거 같습니다. 이 분야에 공부를 꽤 했고, 그 내용들을 다양하게 고민하며 적용해보고 싶다면 이 프로젝트가 괜찮은 선택지가 될 수도 있어 보입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 코드 설명"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/index.html",
    "href": "posts/03_resources/quantum_programming/index.html",
    "title": "Quantum Programming",
    "section": "",
    "text": "Quantum Programming 정리 노트입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/index.html#details",
    "href": "posts/03_resources/quantum_programming/index.html#details",
    "title": "Quantum Programming",
    "section": "",
    "text": "Quantum Programming 정리 노트입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/index.html#tasks",
    "href": "posts/03_resources/quantum_programming/index.html#tasks",
    "title": "Quantum Programming",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/index.html#참고-자료",
    "href": "posts/03_resources/quantum_programming/index.html#참고-자료",
    "title": "Quantum Programming",
    "section": "참고 자료",
    "text": "참고 자료\n\n인프런 양자 프로그래밍 강의",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/index.html#related-posts",
    "href": "posts/03_resources/quantum_programming/index.html#related-posts",
    "title": "Quantum Programming",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/00.html#양자-프로그래밍이란",
    "href": "posts/03_resources/quantum_programming/notes/00.html#양자-프로그래밍이란",
    "title": "Quantum Programming",
    "section": "양자 프로그래밍이란?",
    "text": "양자 프로그래밍이란?\n양자 프로그래밍은 양자 컴퓨터의 힘을 활용해 알고리즘과 소프트웨어를 개발하는 것으로, 중첩(superposition), 얽힘(entanglement), 양자 병렬성(quantum parallelism)과 같은 양자 역학 원리를 사용합니다. 이는 양자 회로를 설계하고, 양자 게이트를 적용하며, 큰 수를 인수분해하는 쇼어(Shor) 알고리즘이나 데이터베이스 검색을 위한 그로버(Grover) 검색 알고리즘과 같은 양자 알고리즘을 구현하는 작업을 포함합니다.\n양자 프로그래밍은 아직 초기 단계에 있지만 암호학, AI, 최적화, 과학적 시뮬레이션 등에서 잠재적인 응용 가능성을 가지고 있습니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/00.html#양자-프로그래밍-언어",
    "href": "posts/03_resources/quantum_programming/notes/00.html#양자-프로그래밍-언어",
    "title": "Quantum Programming",
    "section": "양자 프로그래밍 언어",
    "text": "양자 프로그래밍 언어\n양자 프로그래밍 언어는 정의상 양자 컴퓨터용 프로그램을 작성하기 위해 설계된 언어입니다. 양자 프로그래밍 언어를 고전 프로그래밍 언어와 구분 짓는 요소는 양자 시스템의 원리(큐비트, 얽힘, 중첩 법칙 등)에 기반해 양자 알고리즘을 평가하는 방식입니다.\n양자 컴퓨팅에 널리 사용되는 프로그래밍 언어로는 Qiskit, Cirq, Q# 등이 있으며, 이들은 고전 컴퓨팅보다 훨씬 빠르게 복잡한 문제를 해결할 수 있는 양자 알고리즘 개발을 가능하게 합니다. 특히 암호학, 최적화, 머신러닝 분야에서 두각을 나타냅니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/00.html#양자-프로그래밍-vs-고전-프로그래밍",
    "href": "posts/03_resources/quantum_programming/notes/00.html#양자-프로그래밍-vs-고전-프로그래밍",
    "title": "Quantum Programming",
    "section": "양자 프로그래밍 vs 고전 프로그래밍",
    "text": "양자 프로그래밍 vs 고전 프로그래밍\n양자 프로그래밍과 고전 프로그래밍 사이에는 근본적인 차이가 있습니다. 각각의 논리, 언어, 응용 분야가 다르며, 이는 양자 컴퓨팅과 고전 컴퓨팅의 차이와 비슷합니다.\n\n고전 프로그래밍\n고전 프로그래밍은 이진 논리에 기반하며, 정보는 비트(0과 1)로 표현되고 계산은 결정론적 단계를 따릅니다. 프로그램은 CPU나 GPU와 같은 고전 하드웨어에서 실행되며, AND, OR, NOT 같은 부울 논리 게이트를 사용해 순차적이거나 병렬적으로 연산을 수행합니다. Python, C++, Java 같은 전통적인 프로그래밍 언어를 사용하며, 주어진 입력에 대해 출력은 항상 예측 가능합니다.\n고전 컴퓨터는 웹 개발부터 과학적 시뮬레이션까지 일상적인 대부분의 응용 프로그램을 처리합니다. 하지만 암호학이나 복잡한 최적화와 같이 대규모 계산이 필요한 문제에서는 한계를 보입니다.\n\n\n양자 프로그래밍\n양자 프로그래밍은 양자 역학 원리에 기반하며, 중첩 상태에 존재하고 얽힐 수 있는 큐비트를 사용해 훨씬 빠른 계산을 수행합니다. 고전 프로그램과 달리 양자 프로그램은 확률적(probabilistic)입니다. 즉, 출력은 큐비트를 반복적으로 측정해 얻어지며, 이 과정에서 큐비트는 확정된 상태로 붕괴합니다.\n양자 프로그래밍은 Qiskit(Python 기반), Quipper(Haskell 기반), Cirq 같은 특수 양자 언어를 필요로 하며, IBM Quantum이나 Google Sycamore 같은 양자 프로세서에서 작동합니다. 양자 회로는 Hadamard, CNOT, Pauli-X 등의 양자 게이트를 사용하며, 암호학, 최적화, 양자 시뮬레이션과 같은 분야에서 전례 없는 능력을 제공합니다. 다만 기술은 아직 개발 중입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/00.html#집에서-양자-프로그래밍-가능할까",
    "href": "posts/03_resources/quantum_programming/notes/00.html#집에서-양자-프로그래밍-가능할까",
    "title": "Quantum Programming",
    "section": "집에서 양자 프로그래밍: 가능할까?",
    "text": "집에서 양자 프로그래밍: 가능할까?\n과거에는 양자 프로그래밍이 복잡성과 양자 컴퓨팅 하드웨어의 접근성 문제로 인해 대부분의 개인에게 불가능해 보였을 수 있습니다. 하지만 BlueQubit의 등장으로 양자 개발은 열정가와 초보자 모두에게 현실이 되었습니다.\nBlueQubit은 누구나 언제 어디서나 양자 컴퓨팅의 힘을 경험할 수 있게 하는 고급스럽고 사용자 친화적인 플랫폼입니다. BlueQubit이 양자 컴퓨팅 입문자에게 최고의 선택인 이유 중 하나는 사용 편의성입니다. 더 나은 사용자 경험을 제공하는 데 초점을 맞춘 이 플랫폼은 기술적 세부 사항에 깊이 들어가지 않아도 양자 컴퓨터의 능력을 활용할 수 있게 합니다.\nCirq와 Qiskit 같은 오픈소스 라이브러리와 매끄럽게 통합되어 사용자는 집에서도 양자 프로그램을 실행할 수 있습니다. 이 기능은 인프라 투자 없이 양자 컴퓨팅의 잠재력을 탐구하고자 하는 개발자와 연구자에게 무한한 가능성을 열어줍니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/00.html#양자-컴퓨팅-언어의-유형",
    "href": "posts/03_resources/quantum_programming/notes/00.html#양자-컴퓨팅-언어의-유형",
    "title": "Quantum Programming",
    "section": "양자 컴퓨팅 언어의 유형",
    "text": "양자 컴퓨팅 언어의 유형\n양자 컴퓨팅 언어는 양자 알고리즘을 프로그래밍하고 실행하는 데 각기 다른 역할을 하며 다양한 형태로 존재합니다. 여기에는 고급 양자 프로그래밍 언어, 저수준 명령어 세트, 소프트웨어 개발 키트가 포함됩니다.\n\n양자 프로그래밍 언어\n양자 프로그래밍 언어는 양자 알고리즘을 표현하고 큐비트, 양자 게이트, 측정을 제어하기 위해 설계되었습니다. 양자 프로그램 작성을 위한 고수준 추상화를 제공합니다. 고전 언어와 달리 중첩, 얽힘, 양자 병렬성과 같은 양자 특유의 연산을 지원합니다.\n예로는 Qiskit(Python 기반), Quipper(Haskell 기반), Silq(고수준 양자 언어), Q#(Microsoft의 양자 언어)가 있습니다. 이 언어들은 연구자와 개발자가 양자 응용 프로그램을 구축하고 고전 코드와 통합해 하이브리드 양자-고전 계산을 가능하게 합니다.\n\n\n양자 명령어 세트\n양자 명령어 세트는 양자 하드웨어를 직접 제어하는 저수준 명령을 정의합니다. 이는 고전 컴퓨팅의 어셈블리 언어와 비슷합니다. Hadamard, CNOT, 위상 게이트 같은 양자 연산을 위한 게이트 수준 명령을 제공하며, 서로 다른 양자 하드웨어 아키텍처에서 효율적인 실행을 보장합니다.\n예로는 OpenQASM(IBM), Quil(Rigetti), Blackbird(Xanadu)가 있습니다. 이들은 양자 알고리즘과 물리적 큐비트 간의 인터페이스 역할을 합니다.\n\n\n양자 소프트웨어 개발 키트\n양자 SDK는 양자 프로그램을 개발하고, 테스트하고, 실행하기 위한 도구, 라이브러리, 시뮬레이터를 제공합니다. 고수준 프로그래밍 언어와 양자 하드웨어 간의 간극을 메웁니다. 대표적인 SDK로는 Qiskit(IBM), Cirq(Google), PennyLane(Xanadu), Braket(AWS)이 있습니다. 이 SDK들은 양자 회로 시뮬레이션, 실제 양자 장치에서 알고리즘 실행, 기존 응용 프로그램에 양자 컴퓨팅 통합을 가능하게 해 연구와 실용적 채택을 가속화합니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/00.html#인기-있는-양자-프로그래밍-언어와-라이브러리",
    "href": "posts/03_resources/quantum_programming/notes/00.html#인기-있는-양자-프로그래밍-언어와-라이브러리",
    "title": "Quantum Programming",
    "section": "인기 있는 양자 프로그래밍 언어와 라이브러리",
    "text": "인기 있는 양자 프로그래밍 언어와 라이브러리\n양자 시스템의 힘을 활용하기 위해 다양한 프로그래밍 언어와 라이브러리가 개발되었습니다. 이들은 양자 회로를 생성, 조작, 실행하도록 특별히 설계되었으며 고전 프로그래밍 언어와는 다릅니다. 다음은 익숙해질 만한 최고의 양자 프로그래밍 언어 목록입니다:\n\nQiskit\nQiskit은 IBM에서 만든 오픈소스 양자 컴퓨팅 프레임워크입니다. 양자 회로 설계 및 실행을 위한 사용하기 쉬운 인터페이스와 양자 시스템 시뮬레이션 및 양자 알고리즘 최적화 도구를 제공합니다. 널리 채택된 도구로, 초보자와 숙련된 개발자 모두에게 최고의 양자 프로그래밍 언어 중 하나입니다.\n\n\nCirq\nCirq는 Google Quantum AI에서 개발한 인기 있는 양자 프로그래밍 라이브러리입니다. 개발자가 시뮬레이터와 실제 양자 하드웨어에서 양자 회로를 생성, 편집, 실행할 수 있게 합니다. 사용자 친화적인 인터페이스와 강력한 기능으로 양자 프로그래밍을 탐구하려는 이들에게 최고의 선택입니다.\n\n\nPyQuil\nPyQuil은 Rigetti Computing에서 만든 독창적인 양자 명령어 언어로, 양자 프로그래밍에 독특한 접근 방식을 제공합니다. 양자 알고리즘 생성 과정을 단순화하도록 설계된 PyQuil은 Rigetti의 양자 프로세서 및 시뮬레이터와의 호환성을 유지하며 양자 응용 프로그램 개발을 간소화합니다.\n\n\nQ\nMicrosoft에서 개발한 Q#은 양자 프로그래밍을 위해 특화된 도메인별 언어입니다. Quantum Development Kit(QDK)와 통합되어 개발자가 양자 알고리즘을 고전 및 양자 하드웨어에서 작성, 테스트, 디버깅하기 쉽게 합니다. 고수준 문법과 풍부한 라이브러리로 Q#은 양자 응용 프로그램 생성을 단순화합니다.\n\n\nQasm과 OpenQasm\nQasm(Quantum Assembly Language)과 그 오픈소스 버전인 OpenQasm은 양자 회로를 위한 중급 표현입니다. 이 언어들은 양자 명령을 위한 표준 형식을 제공하여 다양한 플랫폼에서 양자 회로를 설계하고 시뮬레이션하기 쉽게 합니다. 특히 OpenQasm은 모듈성과 확장성을 지원해 복잡한 양자 프로그램을 효율적으로 작성할 수 있게 합니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/00.html#마무리",
    "href": "posts/03_resources/quantum_programming/notes/00.html#마무리",
    "title": "Quantum Programming",
    "section": "마무리",
    "text": "마무리\n양자 프로그래밍은 산업을 변화시킬 엄청난 잠재력을 가진 흥미로운 분야입니다. 쇼어 알고리즘과 그로버 알고리즘 같은 핵심 알고리즘을 이해하고, Qiskit, Cirq, PyQuil, Q#, OpenQasm과 같은 인기 언어와 라이브러리를 사용하면 초보자도 자신 있게 양자 세계에 입문할 수 있습니다.\n양자 컴퓨팅 회사인 BlueQubit은 사용자 친화적인 인터페이스, 강력한 양자 시뮬레이터, 실제 양자 하드웨어 접근성을 제공하여 개발자가 양자 컴퓨팅의 힘을 활용하고 혁신을 이끌어내기에 이상적인 선택입니다. 지금 가입하고 프로그래밍을 시작하세요.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/00.html#자주-묻는-질문",
    "href": "posts/03_resources/quantum_programming/notes/00.html#자주-묻는-질문",
    "title": "Quantum Programming",
    "section": "자주 묻는 질문",
    "text": "자주 묻는 질문\n\n양자 컴퓨팅을 위한 C 언어란 무엇인가요?\nC 자체는 양자 컴퓨팅에 일반적으로 사용되지 않지만, QCOR(Quantum Computing ORchestration)은 C++의 확장으로 양자 프로그래밍과 고전 컴퓨팅을 통합합니다. 이 언어는 양자 하드웨어와 시뮬레이터와 함께 작동하도록 설계되어 개발자가 하이브리드 양자-고전 알고리즘을 효율적으로 작성할 수 있게 합니다. 그러나 오늘날 대부분의 양자 프로그래밍은 Qiskit(Python), Cirq(Python), Q#(Microsoft의 양자 언어)와 같은 고수준 언어에 의존합니다. 이는 사용 편의성과 양자 특유의 기능을 제공하기 때문입니다.\n\n\nPython은 양자 컴퓨팅에 사용되나요?\n네, Python은 Qiskit, Cirq, PennyLane과 같은 강력한 양자 컴퓨터 프로그래밍 라이브러리 덕분에 양자 컴퓨팅에 널리 사용됩니다. 이 라이브러리들은 직관적인 API, 양자 회로 시뮬레이터, 실제 양자 하드웨어에서 프로그램을 실행할 수 있는 도구를 제공합니다. Python의 유연성과 단순함은 양자 연구에 이상적이며, 양자 알고리즘을 구축, 테스트, 배포하면서 고전 계산과 통합하기 쉽게 합니다. IBM Quantum Experience와 Amazon Braket 같은 많은 양자 컴퓨팅 플랫폼도 Python 기반 프레임워크를 지원합니다.\n\n\n양자 컴퓨팅에 가장 적합한 프로그래밍 언어는 무엇인가요?\n양자 컴퓨팅에 가장 적합한 프로그래밍 언어는 사용 사례와 하드웨어 호환성에 따라 다릅니다. Qiskit(Python 기반)은 사용자 친화적인 인터페이스와 IBM Quantum의 강력한 지원으로 초보자와 연구자에게 널리 사용됩니다. Cirq(역시 Python 기반)는 Google의 양자 하드웨어에 최적화되어 있으며, Q#(Microsoft)는 고전 통합과 함께 양자 알고리즘 개발에 설계되었습니다.\n기타 주목할 만한 양자 컴퓨팅 프로그래밍 언어로는 Silq(고수준 양자 프로그래밍), Quipper(Haskell 기반), OpenQASM(어셈블리 스타일 양자 언어)이 있습니다. Python 기반 프레임워크가 이 분야를 지배하고 있으므로 Qiskit과 Cirq가 가장 인기 있는 선택입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Quantum Programming"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#금융-행동의-개인차",
    "href": "posts/03_resources/금융/notes/00.html#금융-행동의-개인차",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "1. 금융 행동의 개인차",
    "text": "1. 금융 행동의 개인차\n금융 시장에서 개인의 행동 차이는 단순히 정보의 우위나 지적 능력의 차이가 아닌, 개인의 경험과 가치관에서 비롯된다. 우리는 각자의 경험을 바탕으로 나름의 합리적인 의사결정을 내린다. 따라서 겉보기에 비합리적으로 보이는 행동도 개인의 맥락에서는 충분히 이해될 수 있다. 돈 문제에 있어서 누구나 미친짓을 한다. 거의 모두가 이 게임이 처음이기 때문이다. 하지만 실제로 미친사람은 없다. 누구나 자신만의 경험에 근거해서 합리적으로 보이는 의사결정을 내릴 뿐이다",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#운과-리스크의-역할",
    "href": "posts/03_resources/금융/notes/00.html#운과-리스크의-역할",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "2. 운과 리스크의 역할",
    "text": "2. 운과 리스크의 역할\n금융 시장에서의 결과는 우리의 행동만으로 결정되지 않는다. 운의 영향력을 인정하고, 리스크를 적절히 관리하는 것이 중요하다. 이를 위해 우리는 다음과 같은 질문들을 스스로에게 던져야 한다\n\n추가적인 수익이 정말 필요한가?\n타인과의 비교가 판단을 흐리고 있지는 않은가?\n’충분함’의 기준은 무엇인가?\n돈보다 우선시해야 할 가치는 무엇인가?\n\n어느 정도가 충분한지 깨닫고 리스크를 멈출줄 알아야 한다",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#지속가능한-투자의-원칙",
    "href": "posts/03_resources/금융/notes/00.html#지속가능한-투자의-원칙",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "3. 지속가능한 투자의 원칙",
    "text": "3. 지속가능한 투자의 원칙\n일회성 수익보다는 지속가능한 수익이 더 가치있다. 투자에는 두 가지 다른 기술이 필요하다\n\n수익 창출: 리스크 감수, 낙관적 사고, 적극적 태도\n자산 보존: 신중함, 위험 관리, 절제\n\n최고의 수익률은 일회성이어서 반복할 수 없는 경향이 있다. 꽤 괜찮은 수익률을 오랫동안 반복할 수 있는게 훌륭한 투자다. 성공적인 투자자는 대중이 비이성적일 때도 침착함을 유지할 수 있는 사람이다.",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#돈과-시간의-관계",
    "href": "posts/03_resources/금융/notes/00.html#돈과-시간의-관계",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "4. 돈과 시간의 관계",
    "text": "4. 돈과 시간의 관계\n돈의 진정한 가치는 그것이 우리에게 주는 시간의 자유에 있다. 돈이 주는 가장 큰 배당금은 시간이다 단순히 부자(rich)가 되는 것과 진정한 부(wealthy)를 이루는 것은 다르다. 진정한 부자들은 겉으로 보이는 치장(rich)에 돈을 쓰기 보다는 부를 축적(wealthy)하여 자유를 얻는다.",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#금융시장의-불변요소와-가변요소",
    "href": "posts/03_resources/금융/notes/00.html#금융시장의-불변요소와-가변요소",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "5. 금융시장의 불변요소와 가변요소",
    "text": "5. 금융시장의 불변요소와 가변요소\n금융 시장에서 인간의 기본적인 행동 패턴은 크게 변하지 않는다. 탐욕, 공포, 스트레스 상황에서의 반응 등은 시대가 바뀌어도 유사하다. 반면, 시장 트렌드, 산업 구조, 투자 방식 등은 끊임없이 진화한다.",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#리스크-관리의-중요성",
    "href": "posts/03_resources/금융/notes/00.html#리스크-관리의-중요성",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "6. 리스크 관리의 중요성",
    "text": "6. 리스크 관리의 중요성\n\n파산 위험이 있는 리스크는 절대 감수하지 않는다\n계획이 실패했을 때를 대비한 백업 플랜이 필수적이다\n시장의 변동성은 피해야 할 벌금이 아닌, 수수료로 인식해야 한다",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#현실적인-목표-설정",
    "href": "posts/03_resources/금융/notes/00.html#현실적인-목표-설정",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "7. 현실적인 목표 설정",
    "text": "7. 현실적인 목표 설정\n\n이상적인 목표와 현실적인 스트레스 상황은 큰 차이가 있다\n과거의 비현실적 목표는 과감히 버려야 한다\n내가 지금과 다른 사람일 때 세웠던 목표는 생명 유지 장치를 달고 시간을 질질 끌 게 아니라 가차 없이 버리는 편이 낫다",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#시장의-본질-이해",
    "href": "posts/03_resources/금융/notes/00.html#시장의-본질-이해",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "8. 시장의 본질 이해",
    "text": "8. 시장의 본질 이해\n\n극단적 상황은 오래 지속되지 않는다\n투자 성공의 대가를 이해하고 지불할 준비가 필요하다\n시장을 완벽히 통제할 수 있다는 환상을 버려야 한다",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/smart_contract/notes/block_chain_basic/00.html",
    "href": "posts/03_resources/smart_contract/notes/block_chain_basic/00.html",
    "title": "what is a blockchain?",
    "section": "",
    "text": "oracle(회사 아님): a trusted third party that provides data to the blockchain\nchain link: a decentralized oracle network that connects smart contracts to external data sourcesa\nsmart contract: trust minimized agreements, unbrakable promises\nmetamask는 nimonics를 이용해 private key를 생성. 다계정을 만들 때는 nimonics + &lt;index&gt;를 이용해 계정 생성\nprivate key는 transaction을 sign할 때 사용. public key는 transaction을 verify할 때 사용\nverify된 transaction은 miner에 의해 블록에 추가됨\ngas price: Base Fee + Priority Fee\ntransaction fee: 실제로 지불하는 금액. Gas Prics * used gas (&lt; gas limit). transaction fee - burnt fee만큼 즉, priority fee * used gas만큼 miner에게 지급됨\ngas fee: transaction을 처리하는데 필요한 비용. gas fee가 높을수록 빨리 처리됨\n\nBase fee: network congestion에 따라 변동. Base fee * used gas 만큼 소각됨\nMax fee: 사용자가 지불할 수 있는 최대 gas price\nMax Priority: 사용자가 지불할 수 있는 최대 fee + tip\n\nconsensus algorithm: 블록체인 네트워크의 모든 노드가 동의하는 방식 (nakamoto consensus: proof of work + longest chain)\n\nChain selection:\n\nlongest chain: 가장 긴 체인을 선택\n\nsybil resistance: 한 사람이 여러 개의 가짜 계정을 만들고 시스템을 조작하는 Sybil 공격을 방어하는 능력\n\nproof of works: hash를 0으로 만드는 nonce를 찾음. 제일 먼저 찾은 사람이 블록을 추가할 수 있음 (transaction fee + block reward(네트워크에서 새로 발행하는 코인. 갈수록 줄어듦))\nproof of stake\n\n\nL1: base layer of blockchain ecosystem\nL2: application built outside of the L1 and hooks back into the L1\nroll up: L2에서 발생한 transaction을 L1에 기록하는 방식\n\noptimistic roll up: L2에서 transaction을 처리하고 L1에 기록함. L1에 기록되기 전까지는 롤백 가능\nzk roll up: L2에서 transaction을 처리하고 L1에 기록함. L1에 기록되면 롤백 불가능\n\n\n\n\n\n 맨 위로",
    "crumbs": [
      "PARA",
      "Resources",
      "Smart Contract",
      "Notes",
      "Block Chain Basic",
      "what is a blockchain?"
    ]
  },
  {
    "objectID": "posts/03_resources/terraform/index.html",
    "href": "posts/03_resources/terraform/index.html",
    "title": "Terraform",
    "section": "",
    "text": "terraform 정리 노트입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Terraform"
    ]
  },
  {
    "objectID": "posts/03_resources/terraform/index.html#details",
    "href": "posts/03_resources/terraform/index.html#details",
    "title": "Terraform",
    "section": "",
    "text": "terraform 정리 노트입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Terraform"
    ]
  },
  {
    "objectID": "posts/03_resources/terraform/index.html#tasks",
    "href": "posts/03_resources/terraform/index.html#tasks",
    "title": "Terraform",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Resources",
      "Terraform"
    ]
  },
  {
    "objectID": "posts/03_resources/terraform/index.html#참고-자료",
    "href": "posts/03_resources/terraform/index.html#참고-자료",
    "title": "Terraform",
    "section": "참고 자료",
    "text": "참고 자료\n\nKodeKloud - Terraform cloud",
    "crumbs": [
      "PARA",
      "Resources",
      "Terraform"
    ]
  },
  {
    "objectID": "posts/03_resources/terraform/index.html#related-posts",
    "href": "posts/03_resources/terraform/index.html#related-posts",
    "title": "Terraform",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Resources",
      "Terraform"
    ]
  },
  {
    "objectID": "posts/03_resources/tofel_준비/index.html",
    "href": "posts/03_resources/tofel_준비/index.html",
    "title": "TOFEL 준비",
    "section": "",
    "text": "BEFORE-START\n    \n    \n        시작일: None\n        종료일: None\n    \n    \n        \n            \n        \n        계산 중...\n    \n    \n    \n        English",
    "crumbs": [
      "PARA",
      "Resources",
      "TOFEL 준비"
    ]
  },
  {
    "objectID": "posts/03_resources/tofel_준비/index.html#details",
    "href": "posts/03_resources/tofel_준비/index.html#details",
    "title": "TOFEL 준비",
    "section": "Details",
    "text": "Details\nTOFEL을 준비해 봅시다.",
    "crumbs": [
      "PARA",
      "Resources",
      "TOFEL 준비"
    ]
  },
  {
    "objectID": "posts/03_resources/tofel_준비/index.html#tasks",
    "href": "posts/03_resources/tofel_준비/index.html#tasks",
    "title": "TOFEL 준비",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Resources",
      "TOFEL 준비"
    ]
  },
  {
    "objectID": "posts/03_resources/tofel_준비/index.html#related-posts",
    "href": "posts/03_resources/tofel_준비/index.html#related-posts",
    "title": "TOFEL 준비",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Resources",
      "TOFEL 준비"
    ]
  },
  {
    "objectID": "posts/03_resources/blog/notes/1.html#second-brain의-핵심-기능",
    "href": "posts/03_resources/blog/notes/1.html#second-brain의-핵심-기능",
    "title": "Second Brain - 티아고 포르테",
    "section": "Second Brain의 핵심 기능",
    "text": "Second Brain의 핵심 기능\n\n아이디어를 구체화한다\n머릿속에서 아이디어를 분리하여 구체적인 형태로 만들어야 한다.\n아이디어 사이의 연관성을 새롭게 밝혀낸다.\n다양한 자료를 한곳에 보관하면 자료간 연결 작업이 촉진되며, 생각지 못한 연관성을 찾아낼 가능성을 높일 수 있다.\n시간을 두고 아이디어를 발전시킨다.\n사람들은 줄곧 아이디어를 떠올릴 때 최신 정보에 중요성을 더 부여하는 경향이 있다.\n몇년 간 축적된 아이디어를 마음껏 이용할 수 있다면 더 좋을 것이다.\n나만의 독특한 관점을 정교하게 다듬는다.\n작가의 벽에 부딪히는 것은 적절한 단어를 떠올릴 수 없다는 것이 아니라, 글을 쓸 탄약이 부족하다는 것이다.\n자신의 견해를 지지할 수 있는 자료를 지속적으로 모아야한다.\n\n\n머리는 아이디어를 생각하는 곳이지 보관하는 곳이어선 안된다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Blog",
      "Notes",
      "Second Brain - 티아고 포르테"
    ]
  },
  {
    "objectID": "posts/03_resources/blog/notes/1.html#중요한-것을-기억하는-4-단계-code",
    "href": "posts/03_resources/blog/notes/1.html#중요한-것을-기억하는-4-단계-code",
    "title": "Second Brain - 티아고 포르테",
    "section": "중요한 것을 기억하는 4 단계 (CODE)",
    "text": "중요한 것을 기억하는 4 단계 (CODE)\n\nCapture: 공명하는 내용을 수집하라\n당신과 마음에 닿는 내용을 분별하여 보관하고 나머지는 버려라\nOrganazie: 실행을 목표로 정리하라\n실행을 염두에 두고 정리하라.\nDistill: 핵심을 찾아 추출하라\n메모의 요점을 정리하라.\n메모를 저장한 이유, 생각하던 내용, 무엇이 당신의 관심을 끌었는지에 대한 설명\nExpress: 작업한 결과물을 표현하라\n개인적이고 구체적이며 검증된 정보는 실제로 사용할 때에 비로소 지식이 된다.\n당신이 아는 내용을 다른 사람과 공유하기 전까지는 그저 이론에 불과하다.\n\n\nCapture\n미래에 어떻게 될지 전혀 모르는데 무엇을 저장할지 어떻게 결정할 수 있을까? 어떤 정보가 보관할 가치가 있는지 정확히 알아내도록 통찰력을 키우기 위해 리처드 파인만의 좋아하는 12가지 문제 방법을 제시한다. 자신에게 흥미를 불러일으키는 열린 질문들을 자유롭게 적어보자. 그후 해당 질문들을 학습의 방향을 제시하는 북극성으로 삼아 활용한다.\n\n\n\n\n\n\n직접 적어본 질문들\n\n\n\n\n쇠퇴하지 않는 사람이 되기 위해 꾸준히 해야하는 활동에는 어떤게 있을까?\n운에 좌절하지 않기 위해 어떤걸 준비해야 할까?\n학점을 잘 받으려면 어떻게 공부해야 할까?\n소중한 인연은 무엇인가?\n무엇을 위해 발전해야 하는가?\n시간이 지나도 가치있는건 무엇일까?\n공명하는 지식이 매번 진실일까?\n돈을 잘 벌려면 어떻게 해야할까?\n\n\n\n그런 다음, 해당 주제와 관련된 자료에서 아래의 기준에 해당하는 내용들을 선별한다. 수집하는 자료는 외부에 존재하는 자료뿐만 아니라 자료를 수집하면서 얻은 내면 세계의 아이디어 역시 그 대상이될 수 있다.\n\n영감을 불러일으키는가\n나와 내 일에 유용한가\n개인적인 정보인가\n가족이나 친구들과 나눈 문자 메세지들도 수집의 대상이 될 수 있다.\n놀랄 만한 사실인가\n기존의 알고있는 자료만 수집하면 확증편향의 위험이 있다.\nsecond brain은 이미 알고 있는 내용을 또 확인하는 방법이 되어서는 안 된다.\n\n다음과 같은 유형들은 보관하기에 적합하지 않다.\n\n민감한 정보\n포토샵 파일이나 비디오 영상처럼 전용 앱이 필요한 경우\n대용량 파일\n공동 편집이 필요한 경우\n\n\n\nOrganize\n수집한 자료를 정리할 때, 종류별로 나누지 않고, 얼마나 실행 가능한지에 따라 정리할 수 있다. 주제와 하위 항목으로 연달아 이루어진 복잡한 계층 체계에 따라 메모를 정리하는 대신, 이것은 어떤 프로젝트에 가장 도움이 될까?라는 간단한 질문 하나에만 답하면 된다.\n\nPARA\n\nProject: 일이나 생활에서 현재 진행 중이며 단기간 노력이 필요한 일\n시작과 끝이 존재. 완성, 승인, 착수, 발표처럼 구체적이고 확실한 결과가 있어야 한다.\nArea: 오랫동안 관리하고 싶고 장기적으로 책임지는 일\n정해진 종료 날짜와 최종 목표가 없음.\nResource: 향후 도움이 될 수 있는 주제 혹은 관심사\n현재 진행하는 프로젝트 혹은 영역과 관련 없는 자료, 당분간 실행할 수 없는 메모나 파일 등을 보관할 수 있다.\nArchive: 전에는 위의 세 가지 유형에 속했지만, 지금은 비활성화된 항목\n완료하거나 취소된 프로젝트, 이제는 관리하지 않는 책임 영역, 흥미를 잃은 자원 등을 보관할 수 있다.\n\nPARA 정리 방식은 부엌 정리 방식과 유사하다. 부엌에 있는 물건들은 전부 식사를 준비하도록 설계되고 정리된다. 각각의 상위 폴더들을 비유하면, archive는 냉동고, resource는 식료품 저장고, 영역은 냉장고, 프로젝트는 불 위에서 끓고 있는 냄비나 팬과 같다.\n부엌을 음식 종류에 따라 정리하면 얼마나 터무니없을지 상상해보라. 신선한 과일과 말린 과일, 과일 주스와 냉동 과일은 모두 과일로 만들었다는 이유로 같은 장소에 보관될 것이다. 그런데 이것이 바로 대부분의 사람들이 파일과 메모를 정리하는 방식이다. 책을 읽으며 메모했다는 이유만으로 책 메모는 책 메모끼리, 다른 사람의 말을 인용했다는 이유만으로 인용문은 인용문끼리 보관한다.\n\n\n\nDistill\n메모는 단순한 수집을 넘어 실제 활용이 가능한 형태로 정제되어야 한다. 이를 위해 다음과 같은 단계별 요약 과정을 거친다.\n\n메모 수집: 먼저 빠르게 수집, 정리 이후 정제는 나중에 진행\n굵게 처리: 중요한 문장이나 구절을 표시\n하이라이트 처리: 굵게 처리된 내용 중 핵심을 강조\n핵심 요약: 최종적으로 메모의 핵심을 추출\n\n이 과정에서 주의할 점들\n\n과다 하이라이트 처리: 이전 단계 내용의 10-20% 정도만 선별\n목적 없는 하이라이트 처리: 무작정 시작하지 않고, 메모를 어떻게 사용할지 알게 될 때까지 기다린 후, 필요에 따라 하이라이트 한다.\n어려운 방식의 하이라이트 처리: 본인의 직관에 맞게 흥미로운 구절들을 하이라이트 한다.\n\n\n\n\n\n\n\n메모의 생존 여부는 ’얼마나 쉽게 찾을 수 있는가’에 달려있다.\n\n\n\n\n\nExpress\n맡은일을 중간 단계로 나누어서 최대한 빠르게 결과물을 도출하라 도출한 작업물들을 중간단계로써 다른 프로젝트에 사용할 때, 도움을 얻을 수 있다. 도출한 결과물들을 다른사람들과 공유를 해서 피드백을 받아라",
    "crumbs": [
      "PARA",
      "Resources",
      "Blog",
      "Notes",
      "Second Brain - 티아고 포르테"
    ]
  },
  {
    "objectID": "posts/03_resources/blog/notes/1.html#창조력을-완성하는-과정",
    "href": "posts/03_resources/blog/notes/1.html#창조력을-완성하는-과정",
    "title": "Second Brain - 티아고 포르테",
    "section": "창조력을 완성하는 과정",
    "text": "창조력을 완성하는 과정\n언제든 참신한 아이디어를 떠올릴 수 있다고 기대해서는 안된다. 혁신과 문제 해결은 흥미로운 아이디어를 체계적으로 불러일으켜 우리가 인식하게 하는 일상에 달려 있다.\n세컨드브레인은 창의적인 과정들을 아이디어 수집, 정리, 핵심 추출, 조립의 단계로 표준화하여 우리의 뇌 활동을 돕는다.\n\n창의적인 프로젝트를 완료할 때 도움이 되는 전략\n\n아이디어 군도: 프로젝트 수행에 필요한 모든 문서를 모은다. 그리고 해당 문서들을 연결하라.\n헤밍웨이 다리: 현재 진행중인 프로젝트에서 다음과 같은 사항들을 메모에 기록하라.\n\n다음 단계에는 어떤 이야기를 쓸 지\n현재 상황\n잊어버리기 쉬운 세부 사항\n다음 작업 시간의 목표\n\n범위 조금씩 축소하기: 프로젝트의 복잡한 문제가 드러나면 과감하게 범위를 축소하라\n\n\n\n효율적인 실행을 위한 세 가지 습관\n\n\n\n\n\n\n정리정돈은 타고난 특성이 아닌 습관이다.\n\n\n\n\n체크리스트 습관\n\n수집: 프로젝트에 대한 내 생각을 수집하라\n\n이 프로젝트에 대해 이미 알고 있는 것은 무엇인가?\n알아내야 하지만 아직 모르는 것은 무엇인가?\n목표나 목적은 무엇인가?\n통찰력을 얻으려면 누구와 대화해야 하는가?\n아이디어를 얻으려면 어떤 것을 읽거나 들어야 하는가?\n\n검토: 관련 메모가 있을 만한 폴더나 태그를 검토하라\n검색: 모든 폴더에서 관련 용어를 검색하라\n이동: 관련 메모를 프로젝트 폴더로 이동하거나 태그를 설정하라\n작성: 수집한 메모로 개요를 작성하고 프로젝트를 계획하라\n\n\n\n리뷰 습관\n\n주간 리뷰\n일주일 동안 작업한 모든 메체의 메모를 검토하라 그리고 이번 주 할 과제를 정하라\n월간 리뷰\n솔직히 이런건 잘 안할거 같다.\n\n\n\n알아차리는 습관",
    "crumbs": [
      "PARA",
      "Resources",
      "Blog",
      "Notes",
      "Second Brain - 티아고 포르테"
    ]
  },
  {
    "objectID": "all.html",
    "href": "all.html",
    "title": "전체 게시글",
    "section": "",
    "text": "정렬\n       디폴트\n         \n          날짜 - 날짜(오름차순)\n        \n         \n          날짜 - 날짜(내림차순)\n        \n         \n          제목\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n제목\n\n\n날짜\n\n\n분류\n\n\n\n\n\n\nOR 과제 - 1\n\n\n2025-03-13\n\n\n보고서, OR\n\n\n\n\n통계적 추정\n\n\n2025-03-13\n\n\n확률과 통계\n\n\n\n\npandas\n\n\n2025-03-12\n\n\ndata mining\n\n\n\n\norganization을 process 관점에서 바라보기\n\n\n2025-03-12\n\n\n생산시스템관리\n\n\n\n\nNumpy-2\n\n\n2025-03-12\n\n\ndata mining\n\n\n\n\n자료구조와 알고리즘\n\n\n2025-03-11\n\n\n데이터구조및알고리즘\n\n\n\n\n가감법으로 연립방정식을 풀기 위한 행렬\n\n\n2025-03-11\n\n\n선형 대수\n\n\n\n\nintro\n\n\n2025-03-10\n\n\npython\n\n\n\n\nNumpy\n\n\n2025-03-10\n\n\ndata mining\n\n\n\n\nMatching Supply with Demand\n\n\n2025-03-10\n\n\n생산시스템관리\n\n\n\n\nvector dot product, cross product\n\n\n2025-03-09\n\n\n선형 대수\n\n\n\n\nk-means clustering\n\n\n2025-03-09\n\n\nmachine learning\n\n\n\n\nhierarchical clustering\n\n\n2025-03-09\n\n\nmachine learning\n\n\n\n\nLinear Programming\n\n\n2025-03-08\n\n\nOperational Research\n\n\n\n\nIntro\n\n\n2025-03-07\n\n\nOR, 학부 정리\n\n\n\n\n확률과 통계 1 정리\n\n\n2025-03-06\n\n\n확률과 통계\n\n\n\n\nQuantum Programming\n\n\n2025-03-06\n\n\nQuantum Programming\n\n\n\n\nQiskit\n\n\n2025-03-06\n\n\nQuantum Programming\n\n\n\n\nRandom Forest\n\n\n2025-03-05\n\n\nmachine learning\n\n\n\n\nNaive Bayes\n\n\n2025-03-05\n\n\nmachine learning\n\n\n\n\nIntro\n\n\n2025-03-05\n\n\n생산시스템관리\n\n\n\n\nDecision Tree Classification\n\n\n2025-03-05\n\n\nmachine learning\n\n\n\n\nSubspaces and the basis\n\n\n2025-03-03\n\n\n선형 대수\n\n\n\n\nlinear independence\n\n\n2025-03-02\n\n\n선형 대수\n\n\n\n\nSupport Vector Machine\n\n\n2025-03-02\n\n\nmachine learning\n\n\n\n\nK Nearest Neighbors\n\n\n2025-03-02\n\n\nmachine learning\n\n\n\n\nrandom forest\n\n\n2025-03-01\n\n\nmachine learning\n\n\n\n\nSupport Vector Regression\n\n\n2025-03-01\n\n\nmachine learning\n\n\n\n\nLogistic Regression\n\n\n2025-03-01\n\n\nmachine learning\n\n\n\n\nDecision Tree Regression\n\n\n2025-03-01\n\n\nmachine learning\n\n\n\n\nPolynorminal Linear Regression\n\n\n2025-02-27\n\n\nmachine learning\n\n\n\n\noverview\n\n\n2025-02-26\n\n\nmachine learning\n\n\n\n\ndata preprocessing\n\n\n2025-02-26\n\n\nmachine learning\n\n\n\n\nSimple Linear Regression\n\n\n2025-02-26\n\n\nmachine learning\n\n\n\n\nMultiple Linear Regression\n\n\n2025-02-26\n\n\nmachine learning\n\n\n\n\n머신 러닝\n\n\n2025-02-25\n\n\n데이터 분석\n\n\n\n\n시험을 보고 왔습니다.\n\n\n2025-02-22\n\n\nadp, 후기\n\n\n\n\nwhat is a blockchain?\n\n\n2025-02-22\n\n\n블록 체인\n\n\n\n\n4 - 정형 데이터 마이닝\n\n\n2025-02-20\n\n\nadp\n\n\n\n\n4 - 비정형 데이터 마이닝\n\n\n2025-02-18\n\n\nadp\n\n\n\n\ninception-of-things part 1\n\n\n2025-02-17\n\n\nvagrant, k8s, argoCD, gitlab, 42 seoul\n\n\n\n\n4 - 통계분석\n\n\n2025-02-16\n\n\nadp\n\n\n\n\n4 - 데이터 마트\n\n\n2025-02-15\n\n\nadp\n\n\n\n\nTerraform Cloud\n\n\n2025-02-11\n\n\nterraform, terraform cloud, devops, IaC\n\n\n\n\n5 - 시각화 인사이트 프로세스\n\n\n2025-02-11\n\n\nadp\n\n\n\n\n5 - 시각화 디자인\n\n\n2025-02-11\n\n\nadp\n\n\n\n\n3 - 분석 마스터 플랜\n\n\n2025-02-10\n\n\nadp\n\n\n\n\n3 - 데이터 분석 기획의 이해\n\n\n2025-02-10\n\n\nadp\n\n\n\n\n2 - 데이터 처리 프로세스\n\n\n2025-02-08\n\n\nadp\n\n\n\n\n2 - 데이터 처리 기술\n\n\n2025-02-08\n\n\nadp\n\n\n\n\n성적 장학금\n\n\n2025-02-05\n\n\n장학금\n\n\n\n\n1 - 데이터의 가치와 미래\n\n\n2025-02-04\n\n\nadp\n\n\n\n\n1 - 데이터 이해\n\n\n2025-02-04\n\n\nadp\n\n\n\n\n1 - 가치 창조를 위한 데이터 사이언스와 전략 인사이트\n\n\n2025-02-04\n\n\nadp\n\n\n\n\n인간 관계론 - 데일 카네기\n\n\n2025-02-02\n\n\n독서, 인간 관계\n\n\n\n\n선형결합과 생성\n\n\n2025-01-31\n\n\n선형 대수\n\n\n\n\n벡터와 공간\n\n\n2025-01-30\n\n\n선형 대수\n\n\n\n\ncloud-1 코드 설명\n\n\n2025-01-30\n\n\naws, packer, terraform, ansible, 42 seoul\n\n\n\n\ncloud-1 개념 설명\n\n\n2025-01-28\n\n\naws, packer, terraform, ansible, 42 seoul\n\n\n\n\n3-몰라\n\n\n2025-01-22\n\n\n선형 대수\n\n\n\n\n자기 소개서\n\n\n2025-01-17\n\n\n자기 소개서\n\n\n\n\nft_transcendence - github action\n\n\n2025-01-17\n\n\nagile, github action, 42 seoul\n\n\n\n\n2-기초(2)\n\n\n2025-01-11\n\n\n선형 대수\n\n\n\n\nNonlinear Programming\n\n\n2025-01-10\n\n\nOperational Research, 1차\n\n\n\n\n2-기초(1)\n\n\n2025-01-10\n\n\n선형 대수\n\n\n\n\nSecond Brain - 티아고 포르테\n\n\n2025-01-09\n\n\n학습, 독서\n\n\n\n\nwhat is linear algebra\n\n\n2025-01-07\n\n\n선형 대수\n\n\n\n\n돈의 심리학 - 모건 하우절\n\n\n2025-01-02\n\n\n금융, 독서\n\n\n\n\n데이터 전처리\n\n\n2025-01-02\n\n\n데이터 분석\n\n\n\n\nInteger Programming\n\n\n2024-12-31\n\n\nOperational Research, 1차\n\n\n\n\nEDA와 시각화\n\n\n2024-12-30\n\n\n데이터 분석\n\n\n\n\nPARA Blog 제작\n\n\n2024-12-26\n\n\n블로그\n\n\n\n\nLinear Programming\n\n\n2024-12-23\n\n\nOperational Research, 1차\n\n\n\n\nOverview\n\n\n2024-12-21\n\n\nOperational Research, 1차\n\n\n\n\npandas data 구조\n\n\n2024-12-20\n\n\n데이터 분석\n\n\n\n\n맥도날드 키오스크 UI 개선 보고서\n\n\n2024-11-27\n\n\n보고서, 인간 공학\n\n\n\n\n숭실대학교 학생식당 식자제 SCM 설계\n\n\n2024-11-26\n\n\n보고서, database\n\n\n\n\nControl\n\n\n2024-11-21\n\n\n인간 공학\n\n\n\n\n표본의 분포\n\n\n2024-11-18\n\n\n확률과 통계\n\n\n\n\n중심 극한 정리\n\n\n2024-11-18\n\n\n확률과 통계\n\n\n\n\n정규 분포\n\n\n2024-11-18\n\n\n확률과 통계\n\n\n\n\nDisplay\n\n\n2024-11-14\n\n\n인간 공학\n\n\n\n\n연속형 확률분포\n\n\n2024-11-05\n\n\n확률과 통계\n\n\n\n\nAttention\n\n\n2024-11-05\n\n\n인간 공학\n\n\n\n\nDatabase Design\n\n\n2024-10-31\n\n\ndatabase\n\n\n\n\nDatabase Administration\n\n\n2024-10-31\n\n\ndatabase\n\n\n\n\nASP.NET\n\n\n2024-10-31\n\n\ndatabase\n\n\n\n\n4조 기말과제 제안서\n\n\n2024-10-30\n\n\n보고서, database\n\n\n\n\n이산형 확률분포\n\n\n2024-10-28\n\n\n확률과 통계\n\n\n\n\n데이터베이스설계및활용 개인과제 #2\n\n\n2024-10-27\n\n\n보고서, database\n\n\n\n\n확률변수의 기댓값\n\n\n2024-10-16\n\n\n확률과 통계\n\n\n\n\nSignal Detection Theory\n\n\n2024-10-15\n\n\n인간 공학\n\n\n\n\nAuditory Haptic\n\n\n2024-10-15\n\n\n인간 공학\n\n\n\n\nData Modeling and the Entity-Relationship Model\n\n\n2024-10-14\n\n\ndatabase\n\n\n\n\nSQL\n\n\n2024-09-27\n\n\ndatabase\n\n\n\n\nSensor System (Visual)\n\n\n2024-09-24\n\n\n인간 공학\n\n\n\n\nDatabase Normalization\n\n\n2024-09-24\n\n\ndatabase\n\n\n\n\nThe Relational Model\n\n\n2024-09-17\n\n\ndatabase\n\n\n\n\nHuman Information Processing Model\n\n\n2024-09-17\n\n\n인간 공학\n\n\n\n\nResearch Method in Human Factors\n\n\n2024-09-10\n\n\n인간 공학\n\n\n\n\n확률변수와 확률분포\n\n\n2024-09-03\n\n\n확률과 통계\n\n\n\n\nIntroduction to Human Factors\n\n\n2024-09-03\n\n\n인간 공학\n\n\n\n\nAn Overview of Database\n\n\n2024-09-03\n\n\ndatabase\n\n\n\n\n확률과 통계의 정의\n\n\n2024-09-02\n\n\n확률과 통계\n\n\n\n\nmetrics server\n\n\n2024-05-15\n\n\n \n\n\n\n\nmanual scheduling\n\n\n2024-05-15\n\n\n \n\n\n\n\nk8s cluster architecture\n\n\n2024-05-15\n\n\n \n\n\n\n\nfail tolerance\n\n\n2024-05-15\n\n\n \n\n\n\n\ncore DNS\n\n\n2024-05-15\n\n\n \n\n\n\n\nPersistant volume\n\n\n2024-05-15\n\n\n \n\n\n\n\nHA in master node\n\n\n2024-05-15\n\n\n \n\n\n\n\nAuthentication\n\n\n2024-05-15\n\n\n \n\n\n\n\nwhat is ebs\n\n\n2024-04-30\n\n\n \n\n\n\n\nwhat is EC2\n\n\n2024-04-30\n\n\n \n\n\n\n\ndatabase choice in aws\n\n\n2024-04-30\n\n\n \n\n\n\n\naws global infrastructure\n\n\n2024-04-30\n\n\n \n\n\n\n\nVPC\n\n\n2024-04-30\n\n\n \n\n\n\n\nRoute53\n\n\n2024-04-30\n\n\n \n\n\n\n\nPerformance Improvement\n\n\n2024-04-30\n\n\n \n\n\n\n\nOverview\n\n\n2024-04-30\n\n\nvault, devops\n\n\n\n\nKMS(Key Management Service)\n\n\n2024-04-30\n\n\n \n\n\n\n\nELB\n\n\n2024-04-30\n\n\n \n\n\n\n\nDisaster Recovery(DR)\n\n\n2024-04-30\n\n\n \n\n\n\n\nDefine IAM\n\n\n2024-04-30\n\n\n \n\n\n\n\nCloudFront\n\n\n2024-04-30\n\n\n \n\n\n\n\nAmazon Rekognition\n\n\n2024-04-30\n\n\n \n\n\n\n\nAmazon RDS\n\n\n2024-04-30\n\n\n \n\n\n\n\nAmazon CloudWatch\n\n\n2024-04-30\n\n\n \n\n\n\n\nAWS Snow Family\n\n\n2024-04-30\n\n\n \n\n\n\n\nAWS SQS\n\n\n2024-04-30\n\n\n \n\n\n\n\nAWS S3\n\n\n2024-04-30\n\n\n \n\n\n\n\nAWS Organization\n\n\n2024-04-30\n\n\n \n\n\n\n\nAWS Lambda\n\n\n2024-04-30\n\n\n \n\n\n\n\n\n일치 없음"
  },
  {
    "objectID": "posts/00_inboxes/notes/01.html#사람을-대하는-기본-기술",
    "href": "posts/00_inboxes/notes/01.html#사람을-대하는-기본-기술",
    "title": "인간 관계론 - 데일 카네기",
    "section": "사람을 대하는 기본 기술",
    "text": "사람을 대하는 기본 기술\n\n꿀을 얻으려면 벌집을 걷어차지 마라\n남을 비난하고 원망하며 불평하는 것은 어떤 바보라도 할 수 있다. 실제로 바보들은 그렇게 한다. 하지만 남을 이해하고 용서하려면 인격과 자제력이 필요하다.\n사람을 비난하는 대신 그들을 이해하려고 노력해 보자. 그들이 왜 그런 행동을 하는지 곰곰이 생각해 보자. 그편이 비난하는 것보다 훨씬 이롭고 흥미롭다.\n\n\n사람을 대하는 핵심 비결\n누군가에게 어떤 일을 하게 만드는 방법은 상대방이 그 일을 하고 싶게 만드는 것 뿐이다. 강제적인 방법들은 반드시 역효과를 일으킨다.\n타인에게 어떤 일을 하게 하려면 그 사람이 원하는 것을 주는 방법밖에 없다. 인간의 본성이 지닌 가장 깊은 충동이 바로 중요한 사람이 되고자 하는 욕망이다.\n이러한 갈망을 제대로 충족시켜 주는 사람은 다른 사람의 마음을 사로잡을 수 있다. 타인을 진실된 마음으로 칭찬하자. 이는 이기적이고 거짓인 아첨과는 다르다.\n\n\n이 일을 해내는 사람은 세상을 얻을 것이고, 그렇지 못한 사람은 외로운 길을 걸을 것이다.\n상대방에게 영향을 미치는  방법은 그사람이 원하는 것을 이야기하고, 이를 얻는 방법을 보여 주는 것이다.\n\n\n\n\n\n\n…이 부분 예시로 드는 것들이 조금 오버스럽다고 느껴진다.\n문화가 달라서 그런가? 아니면 번역 이슈인가?\n무슨 말을 하는진 알겠는데, 몇몇 부분은 별로 공감이 안 된다.",
    "crumbs": [
      "PARA",
      "Inboxes",
      "Notes",
      "인간 관계론 - 데일 카네기"
    ]
  },
  {
    "objectID": "posts/00_inboxes/notes/01.html#사람들에게-호감을-얻는-6가지-방법",
    "href": "posts/00_inboxes/notes/01.html#사람들에게-호감을-얻는-6가지-방법",
    "title": "인간 관계론 - 데일 카네기",
    "section": "사람들에게 호감을 얻는 6가지 방법",
    "text": "사람들에게 호감을 얻는 6가지 방법\n\n이렇게 하면 어디서든 환영받을 것이다.\n다른 사람에게 관심이 없는 사람은 인생에서 가장 큰 어려움을 겪고, 다른 사람에게 가장 큰 상처를 준다. 상대방에게 진심으로 관심을 가져라\n\n\n좋은 첫인상을 남기는 간단한 방법\n미소를 지어라\n\n\n이렇게 하지 않으면 문제가 생길 것이다.\n사람의 이름을 기억하라\n\n\n좋은 대화 상대가 되는 쉬운 방법\n상대의 이야기를 경청하고, 상대가 자신에 관해 이야기하도록 격려하라\n\n\n사람들의 관심을 얻는 방법\n상대방의 관심사에 대해 이야기하라\n\n\n사람들에게 즉시 호감을 얻는 방법\n모든 사람은 자신이 상대보다 우월하다고 생각한다. 항상 상대방이 자신을 중요하다고 느끼게 하라",
    "crumbs": [
      "PARA",
      "Inboxes",
      "Notes",
      "인간 관계론 - 데일 카네기"
    ]
  },
  {
    "objectID": "posts/00_inboxes/notes/01.html#사람들의-마음을-사로잡는-12가지-방법",
    "href": "posts/00_inboxes/notes/01.html#사람들의-마음을-사로잡는-12가지-방법",
    "title": "인간 관계론 - 데일 카네기",
    "section": "사람들의 마음을 사로잡는 12가지 방법",
    "text": "사람들의 마음을 사로잡는 12가지 방법\n\n논쟁으로는 이길 수 없다\n자기 의사에 반하여 설득당한 사람은 여전히 자기 생각을 바꾸지 않는 법이다. 논쟁에서 최선의 결과를 얻는 유일한 방법은 논쟁을 피하는 것뿐이다.\n\n\n적을 만드는 확실한 방법과 이를 피하는 방법\n되도록 남들보다 지혜로운 사람이 되거라. 하지만 남들에게 그렇다고 말하지 않도록 해라.\n상대가 틀린 말을 해도 굳이 지적하지 마라\n\n\n틀렸다면, 인정하라\n조금 잘못했는데, 상대가 비난할거 같으면 오바해서 자기 잘못을 시인하라\n\n\n이성에 호소하는 확실한 방법\n우호적인 방식으로 시작하라\n\n\n소크라테스의 비결\n상대방이 동의할 수 밖에 없는 질문을 유도하라.\n\n\n불만을 잠재우는 안전밸브\n여기부터 읽어야함",
    "crumbs": [
      "PARA",
      "Inboxes",
      "Notes",
      "인간 관계론 - 데일 카네기"
    ]
  },
  {
    "objectID": "posts/03_resources/blog/notes/0.html#overview",
    "href": "posts/03_resources/blog/notes/0.html#overview",
    "title": "PARA Blog 제작",
    "section": "Overview",
    "text": "Overview\n유튜브에서 ‘제2의 두뇌’ 관련 영상을 보고 이 구조로 제 학습 블로그에 적용하면 좋겠다는 생각이 들었습니다. Quarto로 만들어진 제 블로그에 이 구조를 적용하는 것이 생각보다 쉽지 않긴 했지만, 나름 해볼만 했습니다.\n사실 이 글을 작성하는 시점에는 이미 블로그 리뉴얼이 어느 정도 완료된 상태입니다. 코드가 최적화되지 않아 따로 제작 과정을 상세히 공유하지는 않으려 합니다만, 제 GitHub 레포에서 전체 코드를 확인하실 수 있습니다. 이전 블로그는 여기에서 확인할 수 있습니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Blog",
      "Notes",
      "PARA Blog 제작"
    ]
  },
  {
    "objectID": "posts/03_resources/blog/notes/0.html#이후-목표",
    "href": "posts/03_resources/blog/notes/0.html#이후-목표",
    "title": "PARA Blog 제작",
    "section": "이후 목표",
    "text": "이후 목표\n블로그를 완성하고 보니 Quarto의 필요성에 대해 다시 한번 생각해보게 되었습니다. 데이터 분석을 공부하는 입장에서 Quarto는 분명 대체 불가능한 장점들이 있지만, 웹사이트 구조를 구축하는 데에는 일정 부분 한계가 있어 보입니다.\nDocument를 읽어보던 중 Quarto와 Hugo를 통합하는 방법이 있다는 것을 알게 되었습니다. 이를 통해 Hugo로 블로그의 기본 구조를 만들고, R과 Python 코드 실행 환경으로 Quarto를 활용하는 방안을 고려하고 있습니다.\n이번이 jekyll, framer 블로그에 이어서 세번째로 만드는 블로그입니다. 저는 웹 개발보다는 다른 분야에 집중하고 싶기 때문에, 다음 리뉴얼을 마지막으로 블로그 구조 개선을 마무리해보려 합니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Blog",
      "Notes",
      "PARA Blog 제작"
    ]
  },
  {
    "objectID": "posts/03_resources/blog/index.html",
    "href": "posts/03_resources/blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "블로그 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Blog"
    ]
  },
  {
    "objectID": "posts/03_resources/blog/index.html#details",
    "href": "posts/03_resources/blog/index.html#details",
    "title": "Blog",
    "section": "",
    "text": "블로그 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Blog"
    ]
  },
  {
    "objectID": "posts/03_resources/blog/index.html#tasks",
    "href": "posts/03_resources/blog/index.html#tasks",
    "title": "Blog",
    "section": "Tasks",
    "text": "Tasks\n\n\n\n    \n    \n    \n            \n                \n                    \n                    PARA 구조에 맞게 블로그 구조 변경\n                \n                \n            \n\n            \n            \n                \n                    \n                    게시글에 관련 게시글, 관련 directory 추가\n                \n                별로 마음에 들진 않지만 일단 완성\n            \n\n            \n            \n                \n                    \n                    Hugo 적용\n                \n                \n            \n\n            \n            \n                \n                    \n                    google analytics 적용\n                \n                \n            \n\n            \n            \n                \n                    \n                    about me 페이지 작성\n                \n                \n            \n\n            \n            \n                \n                    \n                    link 미리보기 기능 추가\n                \n                \n            \n\n            \n            \n                \n                    \n                    task 리스트 캘린더 추가\n                \n                \n            \n\n            \n            \n                \n                    \n                    종합 task 캘린더 추가",
    "crumbs": [
      "PARA",
      "Resources",
      "Blog"
    ]
  },
  {
    "objectID": "posts/03_resources/blog/index.html#참고-자료",
    "href": "posts/03_resources/blog/index.html#참고-자료",
    "title": "Blog",
    "section": "참고 자료",
    "text": "참고 자료\n\nHugo vs Quarto",
    "crumbs": [
      "PARA",
      "Resources",
      "Blog"
    ]
  },
  {
    "objectID": "posts/03_resources/blog/index.html#related-posts",
    "href": "posts/03_resources/blog/index.html#related-posts",
    "title": "Blog",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Resources",
      "Blog"
    ]
  },
  {
    "objectID": "posts/03_resources/terraform/notes/tfc/00.html#what-is-terraform-cloud",
    "href": "posts/03_resources/terraform/notes/tfc/00.html#what-is-terraform-cloud",
    "title": "Terraform Cloud",
    "section": "What is Terraform Cloud?",
    "text": "What is Terraform Cloud?\n\nTerraform Open-Source를 확장해주는 서비스\n\n\n\n\nTerraform Open-Source의 한계\n\n\n\n기존의 terraform을 대규모 팀 단위에서 사용하기엔 무리가 있음 → TFC\non-premise 환경을 위한 Terraform Enterpise 서비스도 존재함.\nTACOS: Terraform Automation & Collaboration Software",
    "crumbs": [
      "PARA",
      "Resources",
      "Terraform",
      "Notes",
      "Tfc",
      "Terraform Cloud"
    ]
  },
  {
    "objectID": "posts/03_resources/terraform/notes/tfc/00.html#what-is-organization",
    "href": "posts/03_resources/terraform/notes/tfc/00.html#what-is-organization",
    "title": "Terraform Cloud",
    "section": "What is Organization?",
    "text": "What is Organization?\n\nworkspaces, policies, terraform modules를 공유하는 공간\n\n\n\n\nOrganization level에서 모든 setting이 이루어짐\n\n\n\n하나의 조직을 운용하는 것이 일반적이나, 조직 구조에 따라 여러 조직을 생성해서 운용할 수 있다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Terraform",
      "Notes",
      "Tfc",
      "Terraform Cloud"
    ]
  },
  {
    "objectID": "posts/03_resources/terraform/notes/tfc/00.html#authenticating-to-tfc",
    "href": "posts/03_resources/terraform/notes/tfc/00.html#authenticating-to-tfc",
    "title": "Terraform Cloud",
    "section": "Authenticating to TFC",
    "text": "Authenticating to TFC\n\nweb interface\nCLI\n\n\nToken\n\nUser Tokens\nTeam Tokens: CI/CD pipeline에 주로 사용됨\nOrganization Tokens",
    "crumbs": [
      "PARA",
      "Resources",
      "Terraform",
      "Notes",
      "Tfc",
      "Terraform Cloud"
    ]
  },
  {
    "objectID": "posts/03_resources/problem_solve/index.html",
    "href": "posts/03_resources/problem_solve/index.html",
    "title": "Problem Solving",
    "section": "",
    "text": "Problem Solving에 대한 노트 모음입니다.\n이전 포스팅은 이곳에서 확인 가능합니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Problem Solving"
    ]
  },
  {
    "objectID": "posts/03_resources/problem_solve/index.html#details",
    "href": "posts/03_resources/problem_solve/index.html#details",
    "title": "Problem Solving",
    "section": "",
    "text": "Problem Solving에 대한 노트 모음입니다.\n이전 포스팅은 이곳에서 확인 가능합니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Problem Solving"
    ]
  },
  {
    "objectID": "posts/03_resources/problem_solve/index.html#tasks",
    "href": "posts/03_resources/problem_solve/index.html#tasks",
    "title": "Problem Solving",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Resources",
      "Problem Solving"
    ]
  },
  {
    "objectID": "posts/03_resources/problem_solve/index.html#related-posts",
    "href": "posts/03_resources/problem_solve/index.html#related-posts",
    "title": "Problem Solving",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Resources",
      "Problem Solving"
    ]
  },
  {
    "objectID": "posts/03_resources/smart_contract/index.html",
    "href": "posts/03_resources/smart_contract/index.html",
    "title": "Smart Contract",
    "section": "",
    "text": "smart contract 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Smart Contract"
    ]
  },
  {
    "objectID": "posts/03_resources/smart_contract/index.html#details",
    "href": "posts/03_resources/smart_contract/index.html#details",
    "title": "Smart Contract",
    "section": "",
    "text": "smart contract 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Smart Contract"
    ]
  },
  {
    "objectID": "posts/03_resources/smart_contract/index.html#tasks",
    "href": "posts/03_resources/smart_contract/index.html#tasks",
    "title": "Smart Contract",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Resources",
      "Smart Contract"
    ]
  },
  {
    "objectID": "posts/03_resources/smart_contract/index.html#참고-자료",
    "href": "posts/03_resources/smart_contract/index.html#참고-자료",
    "title": "Smart Contract",
    "section": "참고 자료",
    "text": "참고 자료\n\nblock chain 강의 사이트",
    "crumbs": [
      "PARA",
      "Resources",
      "Smart Contract"
    ]
  },
  {
    "objectID": "posts/03_resources/smart_contract/index.html#related-posts",
    "href": "posts/03_resources/smart_contract/index.html#related-posts",
    "title": "Smart Contract",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Resources",
      "Smart Contract"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/index.html",
    "href": "posts/03_resources/금융/index.html",
    "title": "금융",
    "section": "",
    "text": "금융 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "금융"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/index.html#details",
    "href": "posts/03_resources/금융/index.html#details",
    "title": "금융",
    "section": "",
    "text": "금융 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "금융"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/index.html#tasks",
    "href": "posts/03_resources/금융/index.html#tasks",
    "title": "금융",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Resources",
      "금융"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/index.html#related-posts",
    "href": "posts/03_resources/금융/index.html#related-posts",
    "title": "금융",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Resources",
      "금융"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/01.html#qiskit-sdk",
    "href": "posts/03_resources/quantum_programming/notes/01.html#qiskit-sdk",
    "title": "Qiskit",
    "section": "Qiskit SDK",
    "text": "Qiskit SDK\nQiskit SDK(패키지 이름: qiskit)는 확장된(정적, 동적, 스케줄된) 양자 회로, 연산자, 프리미티브 수준에서 양자 컴퓨터를 다루기 위한 오픈소스 소프트웨어 개발 키트입니다. 이 라이브러리는 Qiskit의 핵심 구성 요소로, 양자 계산을 위한 가장 광범위한 도구 모음을 제공하며, 다른 많은 구성 요소가 여기에 연결됩니다.\nQiskit SDK의 가장 유용한 기능은 다음과 같습니다:\n\n회로 구축 도구(qiskit.circuit): 레지스터, 회로, 명령, 게이트, 매개변수, 제어 흐름 객체를 초기화하고 조작하기 위한 도구.\n회로 라이브러리(qiskit.circuit.library): 회로, 명령, 게이트의 방대한 범위 - 회로 기반 양자 계산의 핵심 구성 요소.\n양자 정보 라이브러리(qiskit.quantum_info): 샘플링 노이즈 없이 정확한 계산을 통해 양자 상태, 연산자, 채널을 다루는 툴킷. 입력 관측 가능 항목을 지정하고 프리미티브 쿼리의 출력 충실도를 분석하는 데 사용.\n트랜스파일러(qiskit.transpiler): 특정 장치 토폴로지에 맞게 양자 회로를 변환 및 적응시키고, 실제 양자 처리 장치(QPU)에서 실행을 최적화.\n프리미티브(qiskit.primitives): Sampler와 Estimator 프리미티브의 기본 정의와 참조 구현을 포함하는 모듈로, 다양한 양자 하드웨어 제공자가 이를 기반으로 자체 구현을 파생할 수 있음. Qiskit Runtime 프리미티브에 대한 자세한 내용은 문서에서 확인 가능.\n\n\n설치\nQiskit SDK 설치에 대한 자세한 소개는 설치 페이지를 확인하세요. 지금 설치할 준비가 되었다면 다음 명령어를 실행하세요:\npip install qiskit",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Qiskit"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/01.html#벤치마킹과-benchpress-패키지",
    "href": "posts/03_resources/quantum_programming/notes/01.html#벤치마킹과-benchpress-패키지",
    "title": "Qiskit",
    "section": "벤치마킹과 Benchpress 패키지",
    "text": "벤치마킹과 Benchpress 패키지\n벤치마킹은 개발 워크플로우의 여러 단계에서 양자 소프트웨어의 상대적 성능을 비교하는 데 중요합니다. 예를 들어, 양자 소프트웨어 벤치마킹 테스트는 회로 구축, 조작, 트랜스파일링의 속도와 품질을 평가할 수 있습니다. IBM Quantum은 가능한 한 성능이 뛰어난 SDK를 제공하기 위해 노력하며, 이를 위해 Qiskit SDK는 주요 대학, 국립 연구소, IBM 연구원들이 개발한 1,000개 이상의 테스트를 통해 벤치마킹됩니다. 이러한 테스트에 사용되는 벤치마킹 스위트는 Benchpress라는 이름으로 오픈소스 패키지로 제공됩니다. 이제 Benchpress 패키지를 사용해 양자 SDK 성능을 직접 분석할 수 있습니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Qiskit"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/01.html#qiskit-runtime",
    "href": "posts/03_resources/quantum_programming/notes/01.html#qiskit-runtime",
    "title": "Qiskit",
    "section": "Qiskit Runtime",
    "text": "Qiskit Runtime\nQiskit Runtime은 IBM Quantum® 하드웨어에서 양자 계산을 실행하기 위한 클라우드 기반 서비스입니다. qiskit-ibm-runtime 패키지는 이 서비스의 클라이언트로, Qiskit IBM Provider의 후속 버전입니다. Qiskit Runtime 서비스는 양자 계산을 간소화하고 IBM Quantum 하드웨어에 최적화된 Qiskit 프리미티브 구현을 제공합니다. Qiskit Runtime 프리미티브를 시작하려면 문서를 방문하세요.\nQiskit Runtime은 추가적인 고전 및 양자 컴퓨팅 자원을 활용하도록 설계되었으며, 오류 억제(error suppression)와 오류 완화(error mitigation) 같은 기술을 사용해 양자 회로 실행에서 더 높은 품질의 결과를 반환합니다. 예로는 오류 억제를 위한 동적 디커플링(dynamical decoupling), 오류 완화를 위한 판독 완화(readout mitigation)와 제로 노이즈 외삽(ZNE)이 있습니다. 이러한 옵션 설정 방법은 오류 완화 설정 페이지에서 확인할 수 있습니다.\nQiskit Runtime은 IBM 하드웨어에서 양자 프로그램을 실행하기 위해 세 가지 실행 모드(Job, Session, Batch)를 제공하며, 각각은 서로 다른 사용 사례와 양자 작업 큐에 대한 영향을 가집니다: - Job: 지정된 샷 수로 실행되는 단일 프리미티브 쿼리. - Session: 양자 컴퓨터에서 반복 작업 부하를 여러 작업으로 효율적으로 실행. - Batch: 모든 작업을 한 번에 제출해 병렬 처리. 참고: Open Plan 사용자는 세션 작업을 제출할 수 없습니다.\nQiskit Runtime을 빠르게 설치하려면 다음 명령어를 실행하세요:\npip install qiskit-ibm-runtime\n개발 환경 설정에 대한 자세한 내용은 설치 페이지에서 확인할 수 있습니다.\n\nQiskit Runtime은 오픈소스인가요?\n간단히 답하면, 전부는 아닙니다. IBM Quantum 장치에서 양자 프로그램을 실행하는 기술적 세부 사항(오류 완화 및 억제 포함)을 처리하는 Qiskit Runtime 서비스 소프트웨어는 오픈소스가 아닙니다. 그러나 Qiskit Runtime 클라이언트(사용자가 Qiskit Runtime 서비스에 접근하는 인터페이스), 서버 측에서 실행되는 Qiskit SDK, 오류 완화에 사용되는 일부 소프트웨어는 오픈소스입니다. Qiskit 오픈소스 활동에 참여하려면 GitHub 조직(github.com/Qiskit 및 github.com/Qiskit-Extensions)을 방문하세요.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Qiskit"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/01.html#qiskit-serverless",
    "href": "posts/03_resources/quantum_programming/notes/01.html#qiskit-serverless",
    "title": "Qiskit",
    "section": "Qiskit Serverless",
    "text": "Qiskit Serverless\n유틸리티 규모의 양자 응용 프로그램을 만들려면 일반적으로 다양한 컴퓨팅 자원 요구 사항이 필요합니다. Qiskit Serverless(qiskit-ibm-catalog.QiskitServerless)는 양자-고전 자원 전반에 걸쳐 작업 부하를 실행하기 위한 간단한 인터페이스를 제공합니다. 여기에는 IBM Quantum Platform에 프로그램 배포, 원격 작업 부하 실행, 멀티 클라우드 및 양자 중심 슈퍼컴퓨팅 사용 사례를 위한 쉬운 자원 관리가 포함됩니다. 자세한 내용은 Qiskit Serverless 문서에서 확인할 수 있습니다: - 고전 작업(전처리, 후처리 등) 병렬화. - 노트북이 꺼져 있어도 클라우드에서 장기 작업 유지. - 클라우드에 재사용 가능한 프로그램 배포.\nQiskit Serverless를 바로 사용하려면 다음 명령어로 설치하세요:\npip install qiskit_serverless",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Qiskit"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/01.html#qiskit-functions",
    "href": "posts/03_resources/quantum_programming/notes/01.html#qiskit-functions",
    "title": "Qiskit",
    "section": "Qiskit Functions",
    "text": "Qiskit Functions\nQiskit Functions(qiskit-ibm-catalog.QiskitFunctionsCatalog)는 알고리즘 발견과 응용 프로토타이핑을 가속화하도록 설계된 추상화된 서비스입니다. Qiskit Functions Catalog를 탐색해보세요: - Circuit Functions: 트랜스파일링, 오류 억제, 오류 완화, 후처리 기술을 포함하며, 추상 회로와 원하는 측정 관측 가능 항목을 입력으로 받는 서비스. 사용자는 하드웨어 성능 관리를 신경 쓰지 않고 새로운 알고리즘과 응용을 탐구 가능. - Application Functions: 고전에서 양자로의 매핑, 하드웨어 최적화, 하드웨어 실행, 후처리를 포함한 전체 양자 워크플로우를 제공. 사용자는 산업별 친숙한 입력과 출력으로 응용 프로토타이핑 가능.\nPremium Plan 회원은 IBM 제공 함수에 즉시 접근하거나 파트너가 제공하는 함수를 파트너로부터 직접 라이선스 구매 가능합니다. 카탈로그는 다음 명령어로 설치 가능:\npip install qiskit-ibm-catalog",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Qiskit"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/01.html#qiskit-transpiler-as-a-service",
    "href": "posts/03_resources/quantum_programming/notes/01.html#qiskit-transpiler-as-a-service",
    "title": "Qiskit",
    "section": "Qiskit Transpiler as a Service",
    "text": "Qiskit Transpiler as a Service\nQiskit Transpiler Service(패키지 이름: qiskit-ibm-transpiler)는 IBM Quantum Premium Plan 사용자에게 클라우드에서 원격 트랜스파일링 기능을 제공하는 새로운 실험적 서비스입니다. 로컬 Qiskit SDK 트랜스파일러 기능 외에도, 이 서비스를 통해 트랜스파일링 작업은 IBM Quantum 클라우드 자원과 AI 기반 트랜스파일러 패스를 활용할 수 있습니다. 클라우드 기반 트랜스파일링을 Qiskit 워크플로우에 통합하는 방법은 문서에서 확인하세요.\n트랜스파일러 서비스는 다음 명령어로 설치 가능:\npip install qiskit-ibm-transpiler",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Qiskit"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/01.html#qiskit-addons",
    "href": "posts/03_resources/quantum_programming/notes/01.html#qiskit-addons",
    "title": "Qiskit",
    "section": "Qiskit Addons",
    "text": "Qiskit Addons\nQiskit Addons는 유틸리티 규모 알고리즘 발견을 위한 연구 기능 모음입니다. 이러한 기능은 Qiskit의 고성능 기반 위에 양자 알고리즘 생성 및 실행 도구를 구축합니다. Addons는 워크플로우에 연결되어 새로운 양자 알고리즘을 확장하거나 설계하는 모듈형 소프트웨어 구성 요소입니다. 사용 가능한 Qiskit Addons 세트와 시작 방법은 문서에서 확인하세요.\n관심 있는 연구 기능에 따라 여러 Addons가 있으며, 각기 pip로 설치 가능: - Sample-based Quantum Diagonalization (SQD): pip install qiskit-addon-sqd - Approximate Quantum Compilation (AQC): pip install qiskit-addon-aqc-tensor[quimb-jax] - Operator Backpropagation (OBP): pip install qiskit-addon-obp - Multi-product Formulas (MPF): pip install qiskit-addon-mpf",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Qiskit"
    ]
  },
  {
    "objectID": "posts/03_resources/quantum_programming/notes/01.html#qiskit-생태계",
    "href": "posts/03_resources/quantum_programming/notes/01.html#qiskit-생태계",
    "title": "Qiskit",
    "section": "Qiskit 생태계",
    "text": "Qiskit 생태계\nQiskit 외에도 “Qiskit” 이름을 사용하는 많은 오픈소스 프로젝트가 있으며, 이는 Qiskit 자체의 일부는 아니지만 Qiskit과 인터페이스를 이루며 핵심 Qiskit 워크플로우를 보완하는 유용한 추가 기능을 제공합니다. 일부 프로젝트는 IBM Quantum 팀이 유지 관리하며, 다른 일부는 더 넓은 오픈소스 커뮤니티에서 지원됩니다. Qiskit SDK는 모듈화되고 확장 가능한 방식으로 설계되어 개발자들이 이를 확장하는 프로젝트를 쉽게 만들 수 있습니다.\nQiskit 생태계의 인기 있는 프로젝트: - Qiskit Aer(qiskit-aer): 현실적인 노이즈 모델을 포함한 양자 컴퓨팅 시뮬레이터 패키지. 여러 시뮬레이션 방법으로 노이즈 유무에 따라 양자 회로 실행 가능. IBM Quantum 유지 관리. - qBraid SDK(qbraid): 양자 소프트웨어 및 하드웨어 제공자를 위한 플랫폼 독립적 양자 런타임 프레임워크로, 프로그램 사양 정의부터 작업 제출, 후처리 및 결과 시각화까지 양자 작업의 전체 수명 주기 관리를 간소화. qBraid 유지 관리. - mthree: M3(Matrix-free Measurement Mitigation) 측정 완화 기술을 구현하는 패키지로, 차원 축소 후 직접 LU 분해 또는 O(1) 단계로 수렴하는 전처리 반복 방법을 사용해 수정된 측정 확률을 계산하며 병렬 처리 가능. IBM Quantum 유지 관리.\nQiskit 생태계 페이지에서 프로젝트 카탈로그와 자신의 프로젝트를 추천하는 방법에 대한 정보를 확인할 수 있습니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Quantum Programming",
      "Notes",
      "Qiskit"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/08.html#intro",
    "href": "posts/02_areas/42_seoul/notes/08.html#intro",
    "title": "cloud-1 개념 설명",
    "section": "intro",
    "text": "intro\n\n\n\n42 seoul outer 과제\n\n\n다음 학기 시작 전까지 개념공부만 하면서 시간을 보내려고 하니까 프로젝트가 하고 싶어졌습니다. 원래는 python 과제를 하려고 했는데, 이전에 cloud 과제를 진행하다가 말았던게 기억나서 이어서 해보면 괜찮겠다 생각했습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 개념 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/08.html#프로젝트-및-구현-설명",
    "href": "posts/02_areas/42_seoul/notes/08.html#프로젝트-및-구현-설명",
    "title": "cloud-1 개념 설명",
    "section": "프로젝트 및 구현 설명",
    "text": "프로젝트 및 구현 설명\n\n개요\n과제 명세서\n참고한 자료는 다음과 같습니다:\n\nAWS SAA Udemy 강의\nansible terraform Udemy 강의\n\n이 강의들도 본 지 1년이 다되어가긴 하지만..과제할 때 사용한 제 배경지식이 여기서 나온거니까요. 과제를 진행하실 분들은 한번 수강해보시면 도움이 될 것 같습니다.\n\n\n\n\n\n\n이 포스팅에서 docker와 nginx, wordpress, mysql 구조에 대한 설명은 생략하겠습니다.\n전체 코드는 github repo에서 확인하실 수 있습니다.\n\n\n\n\n\nWhat is IaC?\n이 프로젝트의 목표는 IaC(Infrastructure as Code) tool을 이용하여 wordpress 사이트를 cloud에 자동으로 배포하는 것입니다.\nIaC는 인프라 구성을 코드로 관리하는 방식으로, 수동으로 리소스를 생성하고 설정하는 방식에 비해 버전 관리가 간편하고, 동일한 환경을 쉽게 재현하거나, 코드 리뷰 등의 방식으로 휴먼 에러를 줄이는 데 용이하게 사용할 수 있습니다.\n이번 프로젝트에서는 Packer, Terraform, Ansible 세 가지 IaC tool을 조합해 사용했습니다\n\n\nPacker: 인프라 생성 전, 상세 설정이 되어있는 image를 build할 수 있는 tool 입니다.\nTerraform: cloud 인프라를 생성하는 tool입니다. packer에서 생성한 ami를 사용할 수 있습니다.\nAnsible: 서버 내부의 상세 설정을 자동화합니다. 일반적인 bash script와는 다르게 멱등성 있는 설정이 가능하다는 점이 큰 장점입니다. 이때, 서버는 python이 설치되어 있어야 하고, ssh로 접근 가능해야 합니다.\n\n위의 이미지 처럼, packer로 필요한 설정이 완료된 image를 생성한 뒤, 그 이미지를 기반으로 cloud infra를 terraform으로 생성하고, 생성된 infra의 상세 설정을 ansible을 이용해서 구현해줄 것입니다.\nPacker와 Ansible은 서버 설정 자동화라는 동일한 기능을 수행하는 도구입니다. 두 도구는 각각 다양한 특징과 장단점이 있지만, 이 과제에서 알아야 하는 차이점은 아래와 같습니다.\nPacker는 임시 EC2 인스턴스를 생성하여 그 위에서 필요한 설정을 완료한 후, 해당 인스턴스를 AMI로 변환하는 방식으로 동작합니다. 이렇게 생성된 AMI는 이후 실제 인프라 구축 시 그대로 사용할 수 있습니다. 따라서 최종 목적지 서버가 SSH 접근이 제한되는 환경이더라도, 미리 필요한 모든 설정이 완료된 이미지를 사용할 수 있다는 장점이 있습니다.\n반면에 Ansible은 SSH 접근이 가능한 서버에서만 동작하지만, Packer와 달리 인프라 구축 후에 얻을 수 있는 정보(예: EC2의 IP)를 활용할 수 있습니다.\n이러한 특성을 고려하여 이 프로젝트에서는 두 도구를 상황에 맞게 조합하여 사용했습니다.\n\n\n전체적인 구조\n\n\n\n구현 aws 구조\n\n\nPublic subnet의 EC2들에 대한 ssh 접근은 관리용 컴퓨터에서만(terraform, ansible 코드가 실행되는 컴퓨터) 접근이 가능하도록 제한했고, MySQL의 데이터는 Private subnet의 EC2에 저장한 뒤 Public subnet의 EC2만 접근할 수 있도록 설정했습니다. Public subnet의 EC2는 사용자가 원하는 갯수를 설정할 수 있고, 그 갯수에 맞춰서 private subnet의 dbms EC2가 생성되도록 설계했습니다.\n실제 프로덕션 환경이라면 위와 같은 구조로는 설계하지 않습니다. 일단 EC2 머신들을 Auto Scaling Group으로 묶고, 그 앞에 Network Load Balancer를 두어 단일 엔드포인트로 관리하는 것이 좋습니다. 또한 Database는 AWS RDS를 이용하고, WordPress의 파일 시스템은 EFS나 S3를 활용해 Stateless하게 구현하는게 좋습니다.\n\n\n\n조금 더 일반적인 구조(물론 docker compose는 잘 안쓸것 같긴 합니다)\n\n\n제 구현에서는 각 서버가 독립적인 상태와 엔드포인트를 가지고 있습니다.\n그렇게 한 이유는 일단 aws free tier 서비스만으로 과제를 구현하려고 했던게 제일 크고요..(NLB는 사용할 수 없었습니다.) 나머지는 과제 제약사항 때문인데,\n\n\n\n과제 제약사항\n\n\n모든 프로세스는 컨테이너 안에서 동작해야 한다는 제약때문에, aws RDS는 사용할 수 없었습니다. 그리고 database는 public internet에서 접근할 수 없다고 해서, db는 private subnet의 ec2에서 돌아가게 설계했습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 개념 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/08.html#outro",
    "href": "posts/02_areas/42_seoul/notes/08.html#outro",
    "title": "cloud-1 개념 설명",
    "section": "outro",
    "text": "outro\n여기서 구현된 infra 구조는 사실 별로 근본있는 구조는 아니니까, 이것보다는 IaC 툴을 얼마나 편리하게 사용할 수 있는지에 초점을 맞춰서 봐주시길 바라고 있습니다.\n이어서 코드에 대한 설명은 다음 게시글에 포스팅하겠습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 개념 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/04.html#intro",
    "href": "posts/02_areas/42_seoul/notes/04.html#intro",
    "title": "inception-of-things part 1",
    "section": "Intro",
    "text": "Intro\n\n\n\n42 seoul outer 과제\n\n\n42 Seoul의 공통 과정을 마무리하면, 원하는 분야를 선택하여 심화 과제를 수행할 수 있습니다. 그중에서도 ’Inception-of-Things’는 인프라 관련 심화 과제로, 가장 많은 경험치를 얻을 수 있는 과제입니다.\n얼핏 보면 매우 어려운 과제처럼 느껴질 수 있지만, 개념을 확실히 이해하고 공부한다면 누구나 빠르게 완료할 수 있다고 생각합니다. 저의 경우, CKA 자격증 취득을 목표로 k8s를 공부하던 중 우연히 팀원을 구하게 되어 이 과제를 수행하게 되었습니다. 배경지식이 어느 정도 있는 상태에서 진행하다 보니, 크게 어렵지 않게 잘 마무리할 수 있었던 것 같습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "inception-of-things part 1"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/04.html#개요",
    "href": "posts/02_areas/42_seoul/notes/04.html#개요",
    "title": "inception-of-things part 1",
    "section": "개요",
    "text": "개요\n과제 명세서\n참고한 자료는 다음과 같습니다:\n\nCKA Udemy 강의\nArgoCD Udemy 강의\ngitlab helm 베포 Docs\nVagrant Docs\n\n\n\n\n\n\n\n전체 코드는 비공개 되어있는 상태입니다",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "inception-of-things part 1"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/04.html#개념-설명",
    "href": "posts/02_areas/42_seoul/notes/04.html#개념-설명",
    "title": "inception-of-things part 1",
    "section": "개념 설명",
    "text": "개념 설명\ncluster는 노드(컴퓨터)들의 논리적인 집합을 의미합니다. 일반적으로, 하나의 컴퓨터로 처리하기 어려운 방대한 양의 작업을 처리하기 위해 도입을 합니다.\n클러스터는 특정한 목적을 가지고 있고, 그 안의 노드들을 각자 맡은 역할을 수행합니다. (보통 클러스터 내부의 노드들을 관리하는 master, 작업을 수행하는 worker로 구분할 수 있습니다.) 이때, k8s는 분산된 노드(컴퓨터)들을 하나의 클러스터로 묶어주고, 관리해주는 도구로써 사용할 수 있습니다.\n\n\n\n\n\n\n노트\n\n\n\n컴퓨팅 능력을 확장할 목적으로 수직적 확장과 수평적 확장을 고려할 수 있습니다.\n수직적 확장은 cpu나 memmory 성능을 높여서 단일 노드의 성능을 향상시키는 것을 의미하고, 수평적 확장은 작업을 분산시킬 수 있는 여러 노드를 추가하는 것을 의미합니다.\n클러스터링은 수평적으로 확장된 컴퓨팅 리소스들을 그룹화 해주는 것을 의미합니다.\n\n\n한 가지 주의해야 하는 것은, k8s 자체는 노드를 생성(provision)해주는 도구가 아니라는 것입니다. 즉, provision 단계는 k8s clustering 이전에 진행되어야 합니다.\n\n\n\nPart 1 구조\n\n\nPart 1에서는 vagrant tool을 이용해서 master, agent 역할을 하는 두 대의 가상 머신을 local에서 provision하고, k3s를 이용해서 clustering 하는 것을 요구합니다. 참고로 k3s는 k8s의 경량화 버전입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "inception-of-things part 1"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/04.html#코드-설명",
    "href": "posts/02_areas/42_seoul/notes/04.html#코드-설명",
    "title": "inception-of-things part 1",
    "section": "코드 설명",
    "text": "코드 설명\n파일 구조는 아래와 같습니다.\np1/\n├── scripts/\n│   ├── agent.yml\n│   └── server.yml\n└── Vagrantfile\nvagrant는 local에서 가상 머신을 생성하고, provision을 할 수 있는 도구입니다. 사용자가 원하는 스펙을 Vagrantfile 이름의 파일에 정의하면, vagrant up 명령어를 통해 간단하게 가상머신을 생성할 수 있습니다.\n과제 요구사항에 맞게 spec을 정의해줍니다.\n\n\nVagrantfile\n\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"bento/ubuntu-24.04\"\n  config.vm.box_version = \"202404.26.0\"\n\n  config.vm.define \"hyunghkiS\" do |control|\n    control.vm.hostname = \"hyunghkiS\"\n    control.vm.network \"private_network\", ip: \"192.168.56.110\"\n    control.vm.provider \"virtualbox\" do |v|\n      v.customize [\"modifyvm\", :id, \"--name\", \"hyunghkiS\"]\n      v.memory = \"1024\"\n      v.cpus = \"1\"\n    end\n    # just for evaluation\n    control.vm.provision \"shell\", inline: &lt;&lt;-SHELL\n      sudo apt-get update\n      sudo apt-get install -y net-tools\n    SHELL\n    control.vm.provision \"shell\", path: \"scripts/server.sh\"\n  end\n  config.vm.define \"hyunghkiSW\" do |control|\n    control.vm.hostname = \"hyunghkiSW\"\n    control.vm.network \"private_network\", ip: \"192.168.56.111\"\n    control.vm.provider \"virtualbox\" do |v|\n      v.customize [\"modifyvm\", :id, \"--name\", \"hyunghkiSW\"]\n      v.memory = \"1024\"\n      v.cpus = \"1\"\n    end\n    # just for evaluation\n    control.vm.provision \"shell\", inline: &lt;&lt;-SHELL\n      sudo apt-get update\n      sudo apt-get install -y net-tools\n    SHELL\n    control.vm.provision \"shell\", path: \"scripts/agent.sh\"\n  end\nend\n\n저 just for evaluation 부분은 아마 과제 명세서에 ifconfig 명령어를 입력해보는 부분 때문에 추가한 것 같습니다. (사실 이 글을 쓰는 시점은 과제를 수행하고 1년이 지난 시점이라 기억이 가물가물 합니다.)\n\n\nserver.sh\n\n#!/bin/bash\n\necho 'alias k=kubectl' &gt;&gt; /home/vagrant/.bashrc\nsource /home/vagrant/.bashrc\n\ncurl -sfL https://get.k3s.io | K3S_KUBECONFIG_MODE=\"644\" sh -s - server --node-ip 192.168.56.110\nK3S_TOKEN=$(sudo cat /var/lib/rancher/k3s/server/node-token)\necho $K3S_TOKEN &gt; /vagrant/k3s_token # vagrant 공유 폴더에 master token 정보를 저장해주었습니다.\n\n\n\nagent.sh\n\n#!/bin/bash\n\necho 'alias k=kubectl' &gt;&gt; /home/vagrant/.bashrc\nsource /home/vagrant/.bashrc\n\nK3S_TOKEN=$(cat /vagrant/k3s_token) # vagrant 공유 폴더에 저장된 master token 정보를 읽어옵니다.\ncurl -sfL https://get.k3s.io | K3S_URL=https://192.168.56.110:6443 K3S_TOKEN=$K3S_TOKEN sh -s - --node-ip 192.168.56.111\n\nk3s 공식 문서를 참고해서 master와 agent를 clustering 해주는 스크립트를 작성해주었습니다. 각각 노드 안에서 로직이 실행되어, 하나는 master로, 하나는 agent로 역할을 수행하게 됩니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "inception-of-things part 1"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/04.html#outro",
    "href": "posts/02_areas/42_seoul/notes/04.html#outro",
    "title": "inception-of-things part 1",
    "section": "Outro",
    "text": "Outro\n오랜만에 해당 과제의 로직을 다시 보니까 기억이 잘 안납니다.\n남은 부분은 천천히 포스팅하겠습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "inception-of-things part 1"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/08.html#dot-product",
    "href": "posts/02_areas/선형대수/notes/08.html#dot-product",
    "title": "vector dot product, cross product",
    "section": "Dot Product",
    "text": "Dot Product\n\n\\(v ⋅ w = \\sum_{i=1}^{n} v_i w_i\\)\n\n\nProperties\n\n\\(v ⋅ w = w ⋅ v\\)\n\\(v ⋅ (w + u) = v ⋅ w + v ⋅ u\\)\n\\(v ⋅ (c w) = c (v ⋅ w)\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "vector dot product, cross product"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/08.html#length-of-vector",
    "href": "posts/02_areas/선형대수/notes/08.html#length-of-vector",
    "title": "vector dot product, cross product",
    "section": "Length of vector",
    "text": "Length of vector\n\n\\(||v|| = \\sqrt{v ⋅ v}\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "vector dot product, cross product"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/08.html#some-properties",
    "href": "posts/02_areas/선형대수/notes/08.html#some-properties",
    "title": "vector dot product, cross product",
    "section": "Some properties",
    "text": "Some properties\nfor non-zero vectors \\(v\\) and \\(w\\):\n\ncauchy-schwarz inequality\n\n\\(|v ⋅ w| ≤ ||v|| ||w||\\)\n\\(|v ⋅ w| = ||v|| ||w||\\) ⟺ \\(v = cw\\)\n\n\n\nTriangle inequality\n\n\\(||v + w|| ≤ ||v|| + ||w||\\)\n\n\n\nAngle between vectors\n\n\\(cosθ = \\frac{v ⋅ w}{||v|| ||w||}\\)\nif \\(v\\) and \\(w\\) are orthogonal, then \\(v ⋅ w = 0\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "vector dot product, cross product"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/08.html#cross-product",
    "href": "posts/02_areas/선형대수/notes/08.html#cross-product",
    "title": "vector dot product, cross product",
    "section": "Cross Product",
    "text": "Cross Product\n\nonly for 3D vectors\nget a vector that is orthogonal to both \\(v\\) and \\(w\\)\n\\(v × w = (v_2 w_3 - v_3 w_2, v_3 w_1 - v_1 w_3, v_1 w_2 - v_2 w_1)\\)\n\\(sinθ = \\frac{||v × w||}{||v|| ||w||}\\)\n\\(v × w = 0\\) ⟺ \\(v\\) and \\(w\\) are parallel\nv와 w로 이루어진 평행사변형의 넓이는 \\(||v × w||\\)이다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "vector dot product, cross product"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/08.html#triple-productlagrange-identity",
    "href": "posts/02_areas/선형대수/notes/08.html#triple-productlagrange-identity",
    "title": "vector dot product, cross product",
    "section": "Triple product(lagrange identity)",
    "text": "Triple product(lagrange identity)\n\n\\(a x (b x c) = b(a ⋅ c) - c(a ⋅ b)\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "vector dot product, cross product"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/08.html#차원의-평면에서-직선의-방정식",
    "href": "posts/02_areas/선형대수/notes/08.html#차원의-평면에서-직선의-방정식",
    "title": "vector dot product, cross product",
    "section": "3차원의 평면에서 직선의 방정식",
    "text": "3차원의 평면에서 직선의 방정식\n\n평면에 대한 법선벡터 \\((a, b, c)\\)와 평면 위의 한 점 \\((x_p, y_p, z_p)\\)이 주어졌을 때, 평면의 방정식은 다음과 같다.\n\\(ax + by + cz = D\\), \\(D = ax_p + by_p + cz_p\\)\n평행한 평면은 a, b, c의 계수가 같은 평면이다.\n\\(\\frac{Ax_0 + By_0 + Cz_0 + D}{\\sqrt{A^2 + B^2 + C^2}}\\)은 평면과 점 \\((x_0, y_0, z_0)\\) 사이의 거리이다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "vector dot product, cross product"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/00.html#what-is-linear-algebra",
    "href": "posts/02_areas/선형대수/notes/00.html#what-is-linear-algebra",
    "title": "what is linear algebra",
    "section": "what is linear algebra",
    "text": "what is linear algebra\n선형 방정식을 matrix와 vector로 표현해서 다루는 수학\n\\(ax^2 + bx + c = 0\\) (x)\n\\(ax_1 + bx_2 + c = 0\\) (0)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "what is linear algebra"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/00.html#what-is-vector",
    "href": "posts/02_areas/선형대수/notes/00.html#what-is-vector",
    "title": "what is linear algebra",
    "section": "what is vector",
    "text": "what is vector\nvector는 크기(magnitude)와 방향(direction)을 가지고 있다.\n2, 3, 4 차원 너머를 수학적으로 표현할 수 있다.\nvector는 수학적으로, 아래와 같이 표현할 수 있다.\n\\[\n\\vec{v} =\n\\begin{bmatrix}\n3 \\\\\n4\n\\end{bmatrix}\n\\]",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "what is linear algebra"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/00.html#example",
    "href": "posts/02_areas/선형대수/notes/00.html#example",
    "title": "what is linear algebra",
    "section": "Example",
    "text": "Example\n\\[\\begin{aligned}\nx + 2y \\quad  &= 4 \\\\\n2x + 5y \\quad &= 9\n\\end{aligned}\\]\n위의 연립 1차 방정식을 matrix와 vector로 표현해보자\n\\[\n\\underset{A}{\\begin{bmatrix}\n1 & 2 \\\\\n2 & 5\n\\end{bmatrix}}\n\\underset{x}{\\begin{bmatrix}\nx \\\\\ny\n\\end{bmatrix}} =\n\\begin{bmatrix}\n1x + 2y \\\\\n2x + 5y\n\\end{bmatrix} =\n\\underset{b}{\\begin{bmatrix}\n4 \\\\\n9\n\\end{bmatrix}}\n\\]",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "what is linear algebra"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/04.html#what-is-vector",
    "href": "posts/02_areas/선형대수/notes/04.html#what-is-vector",
    "title": "벡터와 공간",
    "section": "what is vector",
    "text": "what is vector\nvector는 크기(magnitude)와 방향(direction)을 가지고 있고, 2, 3, 4 차원 너머를 수학적으로 표현할 수 있다.\n\nvector의 수학적 표현\nvector는 ordered list인 tuple 형태로 표현할 수 있다.\n\\[\n\\vec{v} =\n\\begin{bmatrix}\n3 \\\\\n4\n\\end{bmatrix}\n\\]\ndomain과 dimension에 따라 vector는 다음과 같이 표현할 수 있다.\n\\[\n\\vec{v} ∈ R^2\n\\]\n\n1차원: \\(R^1\\)\n2차원: \\(R^2\\)\n3차원: \\(R^3\\)\nn차원: \\(R^n\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "벡터와 공간"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/04.html#vector의-합",
    "href": "posts/02_areas/선형대수/notes/04.html#vector의-합",
    "title": "벡터와 공간",
    "section": "vector의 합",
    "text": "vector의 합\nvector의 합은 각 성분별로 더한 결과를 반환한다.\n\n기하학적 의미\n\\[\n\\begin{bmatrix}\n3 \\\\\n2\n\\end{bmatrix} +\n\\begin{bmatrix}\n-2 \\\\\n1\n\\end{bmatrix}\n\\]\n위의 수식을 좌표평면에 나타나면 다음과 같다.\n\n\n\n\n\n\n\n\n\n끝점을 다 더한 좌표와 시작 점을 연결한 벡터인 초록색 화살표가 두 벡터의 합이 된다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "벡터와 공간"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/04.html#vector의-scalar-곱",
    "href": "posts/02_areas/선형대수/notes/04.html#vector의-scalar-곱",
    "title": "벡터와 공간",
    "section": "vector의 scalar 곱",
    "text": "vector의 scalar 곱\nvector에 scalar, 즉 숫자 하나를 곱하면 무슨 일이 생길까?\n\\[\n2 * \\begin{bmatrix}\n2 \\\\\n1\n\\end{bmatrix} =\n\\begin{bmatrix}\n4 \\\\\n2\n\\end{bmatrix}\n\\] \\[\n-2 * \\begin{bmatrix}\n2 \\\\\n1\n\\end{bmatrix} =\n\\begin{bmatrix}\n-4 \\\\\n-2\n\\end{bmatrix}\n\\]",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "벡터와 공간"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/04.html#vector의-차",
    "href": "posts/02_areas/선형대수/notes/04.html#vector의-차",
    "title": "벡터와 공간",
    "section": "vector의 차",
    "text": "vector의 차\nvector의 차는 각 성분별로 뺀 결과를 반환한다.\n기하학적으로는 두 벡터의 끝점을 연결한 벡터가 된다.\n\\(\\vec{x} - \\vec{y}\\)는 y에서 x를 연결한 벡터가 된다.\n\\(\\vec{y} - \\vec{x}\\)는 x에서 y를 연결한 벡터가 된다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "벡터와 공간"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/04.html#단위-벡터",
    "href": "posts/02_areas/선형대수/notes/04.html#단위-벡터",
    "title": "벡터와 공간",
    "section": "단위 벡터",
    "text": "단위 벡터\n\\[\n\\vec{v} = \\begin{bmatrix}\n3 \\\\\n4\n\\end{bmatrix}\n\\]\n위의 벡터를 단위 벡터의 합으로 만들면 다음과 같다.\n\\[\n\\hat{i} = \\begin{bmatrix}\n1 \\\\\n0\n\\end{bmatrix},\n\\hat{j} = \\begin{bmatrix}\n0 \\\\\n1\n\\end{bmatrix}\n\\]\n\\[\n\\vec{v} = 3\\hat{i} + 4\\hat{j}\n\\]\n\n\n\n\n\n\nScalar 배를 한 기저 벡터끼리 더하면 모든 2차원 좌표를 표현할 수 있다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "벡터와 공간"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/01.html#vector",
    "href": "posts/02_areas/선형대수/notes/01.html#vector",
    "title": "2-기초(1)",
    "section": "Vector",
    "text": "Vector\nvector는 크기와 방향을 가지고 있다.\n\nExample\n\\[\\begin{bmatrix}\n3 \\\\\n2\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\n\n크기: \\(\\sqrt{9 + 4} = \\sqrt{13}\\)\n방향: \\(tan^{-1}(\\frac{2}{3})\\)\n\n크기와 방향이 같으면 같은 벡터이다.\n\n\n덧셈\n벡터의 덧셈을 기하학적으로 알아보자\n\\[\n\\begin{bmatrix}\n3 \\\\\n2\n\\end{bmatrix} +\n\\begin{bmatrix}\n-2 \\\\\n1\n\\end{bmatrix}\n\\]\n위의 수식을 좌표평면에 나타나면 다음과 같다.\n\n\n\n\n\n\n\n\n\n끝점을 다 더한 좌표와 시작 점을 연결한 벡터인 초록색 화살표가 두 벡터의 합이 된다.\n\n\nScalar 배\nvector에 scalar, 즉 숫자 하나를 곱하면 무슨 일이 생길까?\n\\[\n2 * \\begin{bmatrix}\n2 \\\\\n1\n\\end{bmatrix} =\n\\begin{bmatrix}\n4 \\\\\n2\n\\end{bmatrix}\n\\] \\[\n-2 * \\begin{bmatrix}\n2 \\\\\n1\n\\end{bmatrix} =\n\\begin{bmatrix}\n-4 \\\\\n-2\n\\end{bmatrix}\n\\]\n마찬가지로 좌표평면으로 나타내는건 귀찮아서 생략하겠다.\n\n\n\n\n\n\nScalar 배를 한 벡터끼리 더하면 모든 2차원 좌표를 표현할 수 있다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(1)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/01.html#전치-transpose",
    "href": "posts/02_areas/선형대수/notes/01.html#전치-transpose",
    "title": "2-기초(1)",
    "section": "전치 (Transpose)",
    "text": "전치 (Transpose)\n행렬 \\(A\\)의 요소 \\(a_{ij}\\)는 A의 Transpose인 \\(A^T\\)의 \\(a_{ji}\\)가 된다. 즉, 행렬 \\(A\\)를 전치하면 diagnal(대각선 요소)를 제외한 모든 요소가 대각선을 기준으로 서로 뒤바뀐다.\n\nSymmetrix matrix: \\(A = A^T\\)인 행렬, 즉 대각선을 기준으로 값이 전부 같은 행렬 Hermitian matrix: \\((A^*)^T = A^H(conjugate transpose) = A\\)를 만족하는 행렬\n\nVector의 경우에는 Column Vector의 경우, Transpose시 Row Vector로, Row Vector의 경우도 반대로 작용한다.\n\nProperties\n\n\\((A^T)^T = A\\)\n\\((A+B)^T = A^T + B^T\\)\n\\(\\color{red}{(AB)^T = B^TA^T}\\)\n\\((A^TA)^T\\)와 \\((AA^T)^T\\)의 결과는 항상 자기 자신이 된다. → Symmetrix matrix\n\\(C(A)^T = CA^T\\)\n\\(det(A^T) = det(A)\\)\n\\((A^T)^{-1} = (A^{-1})^T\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(1)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/01.html#inner-product-projection",
    "href": "posts/02_areas/선형대수/notes/01.html#inner-product-projection",
    "title": "2-기초(1)",
    "section": "Inner Product & Projection",
    "text": "Inner Product & Projection\n\\[\n\\underset{a}{\\begin{bmatrix}\n1 \\\\\n3\n\\end{bmatrix}} *\n\\underset{b}{\\begin{bmatrix}\n5 \\\\\n1\n\\end{bmatrix}} = 1 * 5 + 3 * 1 = 8 = a^Tb = b^Ta\n\\]\n갑자기 등장한 \\(a^Tb\\)가 의미하는건 아래와 같다.\n\\(a^Tb = ||a||*||b||cosθ\\)\n\n||a||는 a 벡터의 크기를 의미한다.\n\n위의 식을 그림으로 표현해보자\n\n\n\n\n\n\n\n\n\n내적은 초록색 화살표와 파란색 화살표의 곱으로 표현할 수 있다.\n이는 a 벡터가 b 벡터의 방향에 대해 얼마나 투영되었는지를 나타낸다.\n두 벡터의 방향이 일치할 때 내적의 값이 가장 크고, 수직일 때 0 (안 닮음을 의미), 반대 방향일 때 가장 작은 값이 된다.\n\n단위 벡터(크기가 1인 벡터) 계산\n위의 식으로 부터 다음의 추론 과정을 통해 단위 벡터를 계산할 수 있다.\n\\(a^Ta = ||a||^2\\)\n∴ \\(||a|| = \\sqrt{a^Ta}\\)\n∴ 단위 벡터는 \\(\\frac{a}{||a||}\\) = \\(\\frac{a}{\\sqrt{a^Ta}}\\)\n\n\n정사형 벡터의 좌표 계산\n벡터의 좌표는 방향과 크기의 곱으로 표현할 수 있다.\n\\(a^Tb = ||a||*||b||cosθ\\)\n정사형 벡터의 크기는 \\(\\frac{a^Tb}{||b||} = \\frac{a^Tb}{\\sqrt{b^Tb}}\\)\n장사형 벡터의 방향은 b의 단위 벡터와 같다.\n즉, 정사형 벡터의 좌표는 \\(\\frac{a^Tb}{\\sqrt{b^Tb}} * \\frac{b}{\\sqrt{b^Tb}} = \\frac{a^Tb}{b^Tb}b\\)\n\\(a^T\\frac{b}{\\sqrt{b^Tb}}*\\frac{b}{\\sqrt{b^Tb}}\\)로도 구할 수 있다.\n\na와 수직으로 연결되는 정사형 벡터 \\(\\hat{x}\\)\n\\((a-b\\hat{x})^Tb\\hat{x} = 0\\)\n\\(a^Tb - b^Tbb\\hat{x} = 0\\)\n\\(\\hat{x} = \\frac{a^Tb}{b^Tb}\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(1)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/01.html#norm",
    "href": "posts/02_areas/선형대수/notes/01.html#norm",
    "title": "2-기초(1)",
    "section": "Norm",
    "text": "Norm\n크기를 나타내는 것(0 포함, 양 음수 scalar)\n\n2-Norm (\\(l_2\\)-norm)\n벡터의 물리적인 길이.\n\\[\na = \\begin{bmatrix}\n1 \\\\\n2 \\\\\n3\n\\end{bmatrix}\n\\]\n\\(||a||_2 = \\sqrt{1^2+2^2+3^2} = (|1|^{\\color{red}{2}}+|2|^{\\color{red}{2}}+|3|^{\\color{red}{2}})^{\\color{red}{\\frac{1}{2}}}\\)\n2 제곱에, \\(\\frac{1}{2}\\)여서 2-norm이다.\n\n두 벡터 사이의 거리는 두 벡터의 차이의 2-norm이다.\n\n\n\n1-Norm (\\(l_1\\)-norm)\n1 제곱에 \\(\\frac{1}{1}\\)을 계산해주면 된다.\n\\(||a||_1 = (|1|^1+|2|^1+|3|^1)^{\\frac{1}{1}}\\)\n\n\np-Norm (\\(l_p\\)-norm)\n\\(||a||_p = (|x_1|^p+|x_2|^p+|x_3|^p+...)^{\\frac{1}{p}} = (\\underset{t}{\\Sigma} |x_t|^p)^{\\frac{1}{p}} \\quad (p ≥ 1)\\)\n\n\ninfinity-Norm\n\\(||a||_∞ = \\underset{t}{max}|x_t|\\)\n1-norm, 2-norm, infinity-norm의 값이 1이 되는 모든 벡터들을 좌표평면에 나타내면 다음과 같다.\n\n\n\n\n\n\n\n\n\n같은 벡터일 때, 1-norm ≥ 2-norm ≥ ∞-norm 순으로 크다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(1)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/03.html#가우스-조던-소거법",
    "href": "posts/02_areas/선형대수/notes/03.html#가우스-조던-소거법",
    "title": "3-몰라",
    "section": "가우스 조던 소거법",
    "text": "가우스 조던 소거법\n\n선형대수의 목표는 \\(Ax = b\\)에서 x를 찾는 것이다.\n\n\\[\\begin{aligned}\nx + 2y \\quad  &= 4 \\\\\n2x + 5y \\quad &= 9\n\\end{aligned}\\]\n이 수식을 다시 살펴보자. 위의 수식은 아래와 같이 적용할 수 있다.\n\\[\\begin{aligned}\n2x + 4y \\quad  &= 8 \\\\\n2x + 5y \\quad &= 9\n\\end{aligned}\\]\n위의 열립방정식을 풀면 \\(y = 1\\)이라는 결과를 얻는다. 다시 \\(y=1\\)을 대입해서 \\(x=2\\)라는 값을 구할 수 있다.\n이제 이를 matrix와 vector로 풀어보자.\n\\[\n\\begin{bmatrix}\n1 & 2 \\\\\n2 & 5\n\\end{bmatrix}\n\\begin{bmatrix}\nx \\\\\ny\n\\end{bmatrix} =\n\\begin{bmatrix}\n4 \\\\\n9\n\\end{bmatrix}\n\\]\n이를 확장행렬로 표현하면 다음과 같다\n\\[\n[A|b] = \\begin{bmatrix}\n1 & 2 & | & 4 \\\\\n2 & 5 & | & 9\n\\end{bmatrix}\n\\]\n이제 가우스 조던 소거법을 적용해보자\n적용 순서는 다음과 같다.\n\n양 변에 0이 아닌 상수배를 해준다.\n상수배를 한 행을 다른행에 더하거나 뺀다.\n행끼리 자리 바꾼다.\n\n이에 맞춰서 위의 식을 풀이하면,\n\n두 번째 행에서 첫 번째 행의 2배를 빼면\n\n\\[\n\\begin{bmatrix}\n1 & 2 & | & 4 \\\\\n0 & 1 & | & 1\n\\end{bmatrix}\n\\]\n\n첫 번째 행에서 두 번째 행의 2배를 빼면\n\n\\[\n\\begin{bmatrix}\n1 & 0 & | & 2 \\\\\n0 & 1 & | & 1\n\\end{bmatrix}\n\\]\n따라서 \\(x = 2\\), \\(y = 1\\)이라는 해를 얻을 수 있다.\n즉 가우스조던 소거법은 왼쪽을 항등행렬로 만들고, 그 오른쪽에 있는 값이 답이되는 소거법이다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "3-몰라"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/03.html#역행렬-구하기",
    "href": "posts/02_areas/선형대수/notes/03.html#역행렬-구하기",
    "title": "3-몰라",
    "section": "역행렬 구하기",
    "text": "역행렬 구하기\n역행렬을 구할 수 있다면 x의 값을 쉽게 구할 수 있다. (\\(x = A^{-1}b\\))\n가우스 조던 소거법을 이용해 역행렬을 구해보자.\n\\[\n\\begin{bmatrix}\na & b & | & 1 & 0 \\\\\nc & d & | & 0 & 1\n\\end{bmatrix}\n\\]\n\\[\n\\begin{bmatrix}\na & b & | & 1 & 0 \\\\\n0 & \\frac{ad-bc}{a} & | & -\\frac{c}{a} & 1\n\\end{bmatrix}\n\\]\n\\[\n\\begin{bmatrix}\na & b & | & 1 & 0 \\\\\n0 & 1 & | & -\\frac{-c}{ad-bc} & \\frac{a}{ad-bc}\n\\end{bmatrix}\n\\]\n\\[\n\\begin{bmatrix}\na & 0 & | & \\frac{ad}{ad-bc} & \\frac{-ab}{ad-bc} \\\\\n0 & 1 & | & -\\frac{-c}{ad-bc} & \\frac{a}{ad-bc}\n\\end{bmatrix}\n\\]\n\\[\n\\begin{bmatrix}\n1 & 0 & | & \\frac{d}{ad-bc} & \\frac{-b}{ad-bc} \\\\\n0 & 1 & | & -\\frac{-c}{ad-bc} & \\frac{a}{ad-bc}\n\\end{bmatrix}\n\\]\n\\[\n∴ A^{-1} = \\frac{1}{ad-bc}\n\\begin{bmatrix}\nd & -b \\\\\n-c & a\n\\end{bmatrix}\n\\]\n\ninvertible\n역행렬이 존재할 경우 invertible하다고 한다.\n\nnon singular matrix\ndet(A) ≠ 0: ad - bc(determinant) = 0인 경우 역행렬이 존재하지 않는다.\nA가 full rank이다\nN(A) = 0",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "3-몰라"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/03.html#determinant",
    "href": "posts/02_areas/선형대수/notes/03.html#determinant",
    "title": "3-몰라",
    "section": "determinant",
    "text": "determinant\n정사각행렬의 element로 scalar 값을 만드는 함\n\n3 x 3 행렬의 det\n\\[\nA=\n\\begin{bmatrix}\na & b & c\\\\\nd & e & f \\\\\ng & h & i\n\\end{bmatrix}\n\\]\n\\(det(A) = a(ei - fh) - b(di-fg)+c(dh-eg)\\)\nLaplace expansion or cofactor expansion\n\n\nproperties\n\ndet(A) = 0 이면 A is singular\nA가 rank-deficient 이면 det(A) = 0\ndiagonal or triangular matrix, det(A) = 대각요소의 곱\n항등행렬의 det=1\ndet(cA) = \\(c^ndet(A)\\) (A = nxn)\n\\(det(A^T) = det(A)\\)\ndet(AB) = det(A)det(B)\n\\(\\color{red}{det(A^{-1}) = \\frac{1}{det(A)}}\\)\n\\(\\color{red}{det(A) = λ_1λ_2,...,λ_n}\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "3-몰라"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/03.html#trace",
    "href": "posts/02_areas/선형대수/notes/03.html#trace",
    "title": "3-몰라",
    "section": "Trace",
    "text": "Trace\n정사각 행렬에 대해서만 정의되는 것, diagonal 전부 더함\n\\(tr(A) = \\sum_{i=1}^{n}a_{ii}\\)\n\ntr(A + B) = tr(A) + tr(B)\ntr(cA) = ctr(A)\n\\(tr(A^T) = tr(A)\\)\ntr(AB) = tr(BA)\n\\(tr(a^Tb) = tr(ba^T)\\)\ntr(ABCD) = tr(BCDA) = tr(CDAB) = tr(DABC) (cyclic property)\n\\(tr(A) = \\sum_{i=1}^{n}\\lambda_i\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "3-몰라"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/03.html#최소자승법",
    "href": "posts/02_areas/선형대수/notes/03.html#최소자승법",
    "title": "3-몰라",
    "section": "최소자승법",
    "text": "최소자승법",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "3-몰라"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/09.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/09.html#preprocessing",
    "title": "K Nearest Neighbors",
    "section": "preprocessing",
    "text": "preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndataset = pd.read_csv('_data/08.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "K Nearest Neighbors"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/09.html#modeling",
    "href": "posts/02_areas/machine_learning/notes/09.html#modeling",
    "title": "K Nearest Neighbors",
    "section": "Modeling",
    "text": "Modeling\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nclassifier = KNeighborsClassifier()\nclassifier.fit(x_train, y_train)\n\nKNeighborsClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  KNeighborsClassifier?Documentation for KNeighborsClassifieriFittedKNeighborsClassifier()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "K Nearest Neighbors"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/09.html#predict",
    "href": "posts/02_areas/machine_learning/notes/09.html#predict",
    "title": "K Nearest Neighbors",
    "section": "Predict",
    "text": "Predict\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ny_pred = classifier.predict(x_test)\nprint(confusion_matrix(y_test, y_pred))\naccuracy_score(y_test, y_pred)\n\n[[54  6]\n [ 3 37]]\n\n\n0.91",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "K Nearest Neighbors"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/02.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/02.html#preprocessing",
    "title": "Simple Linear Regression",
    "section": "preprocessing",
    "text": "preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndataset = pd.read_csv('_data/02-data.csv')\n\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Simple Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/02.html#train",
    "href": "posts/02_areas/machine_learning/notes/02.html#train",
    "title": "Simple Linear Regression",
    "section": "train",
    "text": "train\n\nfrom sklearn.linear_model import LinearRegression\n\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Simple Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/02.html#predict",
    "href": "posts/02_areas/machine_learning/notes/02.html#predict",
    "title": "Simple Linear Regression",
    "section": "predict",
    "text": "predict\n\ny_pred = regressor.predict(X_test)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Simple Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/02.html#visualize",
    "href": "posts/02_areas/machine_learning/notes/02.html#visualize",
    "title": "Simple Linear Regression",
    "section": "visualize",
    "text": "visualize\n\nplt.scatter(X_train, y_train, color='red')\nplt.plot(X_train, regressor.predict(X_train), color='blue')\nplt.title('Salary vs Experience (training set)')\nplt.xlabel('Years of Experience')\nplt.ylabel('Salary')\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.scatter(X_test, y_test, color='red')\nplt.plot(X_train, regressor.predict(X_train), color='blue')\nplt.title('Salary vs Experience (test set)')\nplt.xlabel('Years of Experience')\nplt.ylabel('Salary')\nplt.show()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Simple Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/02.html#evaluate",
    "href": "posts/02_areas/machine_learning/notes/02.html#evaluate",
    "title": "Simple Linear Regression",
    "section": "evaluate",
    "text": "evaluate\n\nfrom sklearn.metrics import r2_score\n\nr2_score(y_test, y_pred)\n\n0.9083252526929642",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Simple Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/08.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/08.html#preprocessing",
    "title": "Logistic Regression",
    "section": "preprocessing",
    "text": "preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndataset = pd.read_csv('_data/08.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Logistic Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/08.html#modeling",
    "href": "posts/02_areas/machine_learning/notes/08.html#modeling",
    "title": "Logistic Regression",
    "section": "Modeling",
    "text": "Modeling\n\nfrom sklearn.linear_model import LogisticRegression\n\nclassifier = LogisticRegression()\nclassifier.fit(x_train, y_train)\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LogisticRegression?Documentation for LogisticRegressioniFittedLogisticRegression()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Logistic Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/08.html#predict",
    "href": "posts/02_areas/machine_learning/notes/08.html#predict",
    "title": "Logistic Regression",
    "section": "Predict",
    "text": "Predict\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ny_pred = classifier.predict(x_test)\nprint(confusion_matrix(y_test, y_pred))\naccuracy_score(y_test, y_pred)\n\n[[55  7]\n [13 25]]\n\n\n0.8",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Logistic Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/13.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/13.html#preprocessing",
    "title": "Random Forest",
    "section": "preprocessing",
    "text": "preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndataset = pd.read_csv('_data/08.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Random Forest"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/13.html#modeling---linear",
    "href": "posts/02_areas/machine_learning/notes/13.html#modeling---linear",
    "title": "Random Forest",
    "section": "Modeling - linear",
    "text": "Modeling - linear\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier(n_estimators=10, criterion='entropy')\nclassifier.fit(x_train, y_train)\n\nRandomForestClassifier(criterion='entropy', n_estimators=10)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestClassifier?Documentation for RandomForestClassifieriFittedRandomForestClassifier(criterion='entropy', n_estimators=10)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Random Forest"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/13.html#predict",
    "href": "posts/02_areas/machine_learning/notes/13.html#predict",
    "title": "Random Forest",
    "section": "Predict",
    "text": "Predict\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ny_pred = classifier.predict(x_test)\nprint(confusion_matrix(y_test, y_pred))\naccuracy_score(y_test, y_pred)\n\n[[60  5]\n [ 7 28]]\n\n\n0.88",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Random Forest"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/13.html#predict-1",
    "href": "posts/02_areas/machine_learning/notes/13.html#predict-1",
    "title": "Random Forest",
    "section": "Predict",
    "text": "Predict\n\ny_pred = classifier.predict(x_test)\nprint(confusion_matrix(y_test, y_pred))\naccuracy_score(y_test, y_pred)\n\n[[60  5]\n [ 7 28]]\n\n\n0.88",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Random Forest"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/04.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/04.html#preprocessing",
    "title": "Polynorminal Linear Regression",
    "section": "preprocessing",
    "text": "preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndataset = pd.read_csv('_data/04.csv')\nx = dataset.iloc[:, 1:-1].values\ny = dataset.iloc[:, -1].values",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Polynorminal Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/04.html#linear-regression-model",
    "href": "posts/02_areas/machine_learning/notes/04.html#linear-regression-model",
    "title": "Polynorminal Linear Regression",
    "section": "Linear Regression Model",
    "text": "Linear Regression Model\n\nfrom sklearn.linear_model import LinearRegression\n\nregressor = LinearRegression()\nregressor.fit(x, y)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Polynorminal Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/04.html#polynorminal-linear-regression",
    "href": "posts/02_areas/machine_learning/notes/04.html#polynorminal-linear-regression",
    "title": "Polynorminal Linear Regression",
    "section": "Polynorminal Linear Regression",
    "text": "Polynorminal Linear Regression\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures(degree=4)\nx_poly = poly.fit_transform(x)\nregressor2 = LinearRegression()\nregressor2.fit(x_poly, y)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Polynorminal Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/04.html#visualize-linear-regression",
    "href": "posts/02_areas/machine_learning/notes/04.html#visualize-linear-regression",
    "title": "Polynorminal Linear Regression",
    "section": "Visualize Linear Regression",
    "text": "Visualize Linear Regression\n\nplt.scatter(x, y, color='red')\nplt.plot(x, regressor.predict(x), color='blue')\nplt.title('Linear Regression Model')\nplt.xlabel('Position Level')\nplt.ylabel('Salary')\nplt.show()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Polynorminal Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/04.html#visualize-poly-linear-regression",
    "href": "posts/02_areas/machine_learning/notes/04.html#visualize-poly-linear-regression",
    "title": "Polynorminal Linear Regression",
    "section": "Visualize Poly Linear Regression",
    "text": "Visualize Poly Linear Regression\n\nplt.scatter(x, y, color='red')\nplt.plot(x, regressor2.predict(x_poly), color='blue')\nplt.title('Poly Linear Regression Model')\nplt.xlabel('Position Level')\nplt.ylabel('Salary')\nplt.show()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Polynorminal Linear Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/10.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/10.html#preprocessing",
    "title": "Support Vector Machine",
    "section": "preprocessing",
    "text": "preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndataset = pd.read_csv('_data/08.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\n\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Support Vector Machine"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/10.html#modeling---linear",
    "href": "posts/02_areas/machine_learning/notes/10.html#modeling---linear",
    "title": "Support Vector Machine",
    "section": "Modeling - linear",
    "text": "Modeling - linear\n\nfrom sklearn.svm import SVC\n\nclassifier = SVC()\nclassifier.fit(x_train, y_train)\n\nSVC()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiFittedSVC()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Support Vector Machine"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/10.html#predict",
    "href": "posts/02_areas/machine_learning/notes/10.html#predict",
    "title": "Support Vector Machine",
    "section": "Predict",
    "text": "Predict\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ny_pred = classifier.predict(x_test)\nprint(confusion_matrix(y_test, y_pred))\naccuracy_score(y_test, y_pred)\n\n[[63  3]\n [ 2 32]]\n\n\n0.95",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Support Vector Machine"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/10.html#modeling---non-linear",
    "href": "posts/02_areas/machine_learning/notes/10.html#modeling---non-linear",
    "title": "Support Vector Machine",
    "section": "Modeling - non-linear",
    "text": "Modeling - non-linear\n\nclassifier = SVC(kernel='rbf')\nclassifier.fit(x_train, y_train)\n\nSVC()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiFittedSVC()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Support Vector Machine"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/10.html#predict-1",
    "href": "posts/02_areas/machine_learning/notes/10.html#predict-1",
    "title": "Support Vector Machine",
    "section": "Predict",
    "text": "Predict\n\ny_pred = classifier.predict(x_test)\nprint(confusion_matrix(y_test, y_pred))\naccuracy_score(y_test, y_pred)\n\n[[63  3]\n [ 2 32]]\n\n\n0.95",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Support Vector Machine"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/05.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/05.html#preprocessing",
    "title": "Support Vector Regression",
    "section": "preprocessing",
    "text": "preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndataset = pd.read_csv('_data/04.csv')\nx = dataset.iloc[:, 1:-1].values\ny = dataset.iloc[:, -1].values\ny = y.reshape(len(y), 1)\n\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc_x = StandardScaler()\nsc_y = StandardScaler()\n\nx = sc_x.fit_transform(x)\ny = sc_y.fit_transform(y)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Support Vector Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/05.html#train",
    "href": "posts/02_areas/machine_learning/notes/05.html#train",
    "title": "Support Vector Regression",
    "section": "Train",
    "text": "Train\n\nfrom sklearn.svm import SVR\n\nregressor = SVR(kernel='rbf')\nregressor.fit(x, y)\n\n/home/cryscham123/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning:\n\nA column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n\n\n\nSVR()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVR?Documentation for SVRiFittedSVR()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Support Vector Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/05.html#visualize",
    "href": "posts/02_areas/machine_learning/notes/05.html#visualize",
    "title": "Support Vector Regression",
    "section": "Visualize",
    "text": "Visualize\n\nplt.scatter(sc_x.inverse_transform(x), sc_y.inverse_transform(y), color='red')\nplt.plot(sc_x.inverse_transform(x), sc_y.inverse_transform(regressor.predict(x).reshape(-1, 1)))\nplt.show()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Support Vector Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/05.html#high-resolution",
    "href": "posts/02_areas/machine_learning/notes/05.html#high-resolution",
    "title": "Support Vector Regression",
    "section": "High resolution",
    "text": "High resolution\n\nx_grid = np.arange(min(sc_x.inverse_transform(x)), max(sc_x.inverse_transform(x)), 0.1)\nx_grid = x_grid.reshape((len(x_grid), 1))\nplt.scatter(sc_x.inverse_transform(x), sc_y.inverse_transform(y), color='red')\nplt.plot(x_grid, sc_y.inverse_transform(regressor.predict(sc_x.transform(x_grid)).reshape(-1, 1)))\nplt.show()\n\n/tmp/ipykernel_13943/1939094151.py:1: DeprecationWarning:\n\nConversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "Support Vector Regression"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/07.html#preprocessing",
    "href": "posts/02_areas/machine_learning/notes/07.html#preprocessing",
    "title": "random forest",
    "section": "Preprocessing",
    "text": "Preprocessing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndataset = pd.read_csv('_data/04.csv')\nx = dataset.iloc[:, 1:-1].values\ny = dataset.iloc[:, -1].values",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "random forest"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/07.html#modeling",
    "href": "posts/02_areas/machine_learning/notes/07.html#modeling",
    "title": "random forest",
    "section": "Modeling",
    "text": "Modeling\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nregressor = RandomForestRegressor(n_estimators=10, random_state=0)\n\n# 모델 학습\nregressor.fit(x, y)\n\nRandomForestRegressor(n_estimators=10, random_state=0)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestRegressor?Documentation for RandomForestRegressoriFittedRandomForestRegressor(n_estimators=10, random_state=0)",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "random forest"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/notes/07.html#visualization",
    "href": "posts/02_areas/machine_learning/notes/07.html#visualization",
    "title": "random forest",
    "section": "Visualization",
    "text": "Visualization\n\nx_grid = np.arange(min(x), max(x), 0.1)\nx_grid = x_grid.reshape((len(x_grid), 1))\nplt.scatter(x, y, color='red')\nplt.plot(x_grid, regressor.predict(x_grid), color='blue')\nplt.show()",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning",
      "Notes",
      "random forest"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/index.html",
    "href": "posts/02_areas/machine_learning/index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "machine learning 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/index.html#details",
    "href": "posts/02_areas/machine_learning/index.html#details",
    "title": "Machine Learning",
    "section": "",
    "text": "machine learning 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/index.html#tasks",
    "href": "posts/02_areas/machine_learning/index.html#tasks",
    "title": "Machine Learning",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/index.html#참고-자료",
    "href": "posts/02_areas/machine_learning/index.html#참고-자료",
    "title": "Machine Learning",
    "section": "참고 자료",
    "text": "참고 자료\n\n이 책\nudemy machine learning 강의",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning"
    ]
  },
  {
    "objectID": "posts/02_areas/machine_learning/index.html#related-posts",
    "href": "posts/02_areas/machine_learning/index.html#related-posts",
    "title": "Machine Learning",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Areas",
      "Machine Learning"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/09.html#데이터-변경-및-요약",
    "href": "posts/04_archives/adp_필기/notes/09.html#데이터-변경-및-요약",
    "title": "4 - 데이터 마트",
    "section": "데이터 변경 및 요약",
    "text": "데이터 변경 및 요약\n\n요약 변수: 전체적 특성을 대표하여 aggregate한 변수. 제활용성이 높다.\n파생 변수: 기존 데이터를 변환, 조합, 계산하여 새롭게 만든 변수. 주관이 개입될 수 있다.\n\n\n\n\n요약 변수 예시\n\n\n\n1. reshape 패키지 활용",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "4 - 데이터 마트"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/00.html#데이터와-정보",
    "href": "posts/04_archives/adp_필기/notes/00.html#데이터와-정보",
    "title": "1 - 데이터 이해",
    "section": "데이터와 정보",
    "text": "데이터와 정보\n\n1. 데이터\n\n객관적 사실을 나타내는 존재적 특성과, 추론 예측 전망 추정을 위한 근거가 되는 당위적 특성을 모두 포함하는 개념\n단위: 바이트(byte), 킬로바이트(KB), 메가바이트(MB), 기가바이트(GB), 테라바이트(TB), 페타바이트(PB), 엑사바이트(EB), 제타바이트(ZB), 요타바이트(YB)\n유형:\n\n정성적 데이터: 비정형 데이터, 주관적 내용, 통계분석이 어려움\n정량적 데이터: 정형 데이터, 객관적 내용, 통계분석이 용이함\n\n지식 경영의 핵심 이슈인 암묵지와 형식지를 연결하는 역할을 함\n\n\n\n\n\n\n\n\n정형 데이터: 표 형태로 정리된 데이터\n반정형 데이터: HTML, XML, JSON 등의 형태(스키마, 메타데이터)가 있고, 연산이 불가능한 데이터\n비정형 데이터: 형태가 없고, 연산이 불가능한 데이터\n\n\n\n\n\n\n\n\n\n\n\n암묵지:\n\n학습과 경험을 통해 개인에게 체화되어 잇지만 겉으로 드러나지 않는 지식\n개인에게 축적된 내면화된 지식 → 조직의 지식으로 공통화\n\n형식지:\n\n문서나 메뉴얼처럼 형상화된 지식\n언어, 기호, 숫자로 표출화된 지식 → 개인의 지식으로 연결화\n\n\n∴ 내면화 → 공통화 → 표출화 → 연결화 → 내면화\n\n\n\n\n\n2. 데이터와 정보의 관계\n\n데이터(data): 그 자체로는 의미가 중요하지 않은 객관적인 사실\nex) A마트는 100원, B마트는 200원에 휴지를 판다.\n정보(information): 데이터를 가공하여 의미를 부여한 결과물\nex) A마트가 100원에 판 휴지는 B마트보다 100원 싸다.\n지식(knowledge): 정보를 구조화하여 유의미한 정보를 분류하고 개인적인 경험을 결합시켜 고유의 지식으로 내재화된 것\nex) 가격이 더 저렴한 A마트에 가서 휴지를 사야겠다.\n지혜(wisdom): 지식의 축적과 아이디어가 결합된 창의적인 결과물\nex) A마트의 다른 물건도 B마트보다 저렴할 것이다.\n\n\n\n\nDIKW 피라미드",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "1 - 데이터 이해"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/00.html#데이터베이스-정의와-특징",
    "href": "posts/04_archives/adp_필기/notes/00.html#데이터베이스-정의와-특징",
    "title": "1 - 데이터 이해",
    "section": "데이터베이스 정의와 특징",
    "text": "데이터베이스 정의와 특징\n\n1. 데이터베이스의 정의\n기존에는 정형 데이터 관리의 의미로 사용되다가, 빅데이터의 출현으로 비정형 데이터까지 포함하는 개념으로 확장됨\n\n\n2. 데이터베이스의 일반적인 특징\n\n통합된 데이터: 동일한 내용의 데이터가 중복되어 있지 않다.\n저장된 데이터\n공용 데이터\n변화되는 데이터: 데이터베이스에는 항상 현재의 정확한 데이터를 유지한다.",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "1 - 데이터 이해"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/00.html#데이터베이스의-활용",
    "href": "posts/04_archives/adp_필기/notes/00.html#데이터베이스의-활용",
    "title": "1 - 데이터 이해",
    "section": "데이터베이스의 활용",
    "text": "데이터베이스의 활용\n\n1. 1980년대 기업 내부 데이터베이스\n\nOLTP(On-Line Transaction Processing)\n\n데이터베이스의 데이터를 실시간으로 갱신하는 프로세싱.\n구조가 복잡하고, 현재의 단기간 데이터.\n갱신이 동적이고, 엑세스 빈도가 높다.\n질의가 단순하고, 주기적이다.\n\nOLAP(On-Line Analytical Processing)\n\n데이터 조회, 분석 위주.\n구조가 단순하고, 과거의 장기간 요약 데이터.\n갱신이 정적이고, 엑세스 빈도가 보통이다.\n질의가 복잡하다.\n\n\n\n\n2. 2000년대 기업 내부 데이터베이스\n\nCRM(Customer Relationship Management): 고객 관리 시스템\nSCM(Supply Chain Management): 공급망 관리 시스템\n\n\n\n3. 각 분야별 내부 데이터베이스\n\n제조부문\n\nERP(Enterprise Resource Planning): 기업 내부 자료를 하나의 통합 시스템으로 재구축\nBI(Business Intelligence): 기업의 수많은 데이터를 정리, 분석해 의사결정에 활용하는 프로세스\nCRM\nRTE(Real-Time Enterprise): ERP, SCM, CRM 등의 부문별 전산화 시스템을 하나로 통합\n\n금융부문\n\nEAI(Enterprise Application Integration)\nEDW(Enterprise Data Warehouse): BPR, CRM, BSC 등의다양한 분석 시스템을 위한 원천\n\n유통부문\n\nKMS(Knowledge Management System)\nRFID(Radio Frequency Identification): 주파수를 이용해 ID를 식별\n\n\n\n\n4. 사회기반구조로서의 데이터베이스\n\nEDI(Electronic Data Interchange): 전자상거래를 위한 표준화된 데이터 포맷\nVAN(Value Added Network): EDI를 위한 통신망 (카드 결제 시, 가맹점과 카드사 사이에서 승인 요청 및 결과 전달을 중계함.)\nCALS(Commerce At Light Speed): 제품의 설계, 생산, 유통, 판매 등의 모든 과정을 통합한 경영정보시스템",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "1 - 데이터 이해"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/14.html#시각화의-정의",
    "href": "posts/04_archives/adp_필기/notes/14.html#시각화의-정의",
    "title": "5 - 시각화 디자인",
    "section": "시각화의 정의",
    "text": "시각화의 정의\n\n1. 데이터 시각화의 중요성\n데이터 시각화의 목적은 데이터 분석과 의사소통\n\n\n2. 시각 이해와 시각화\n\n\n데이터: 디자인의 대상이 될 수 없음\n정보\n\n데이터가 의미를 전달하기위한 형태를 가짐\n자기조직화 되지 않은 일반적인 의미를 가지고 있고, 생산자와 사용자의 관점에 따라 다르게 전달될 수 있다.\n\n지식: 다른 영역의 정보가 자기조직화된 형태\n지혜: 지식이 내면화되어 개인적 맥락에 포함된 형태. 명시적으로 상대에게 전달하기 어려움\n\n\n\n\n정보 인터랙션 디자인(사진좀 보이게 올려둬라 좀..)\n\n\n\n\n3. 시각화 분류와 구분\n\n\n데이터 시각화\n정보 시각화\n정보 디자인 \n\n데이터 시각화, 정보 시각화, 인포그래픽도 정보 디자인의 범위에 속한다고 볼 수 있다.\n대표적인 예시로 나폴레옹 행군 다이어그램, 나이팅게일 폴라 지역 다이어그램이 있다.\n\n인포그래픽(뉴스 그래픽): 중요한 정보를 한 장의 그래픽으로 표현한 것. 원 데이터는 취급 안함.\n\n정보형 메세지: 객관적인 정보를 전달하는데 목적을 둠. 대표적인 예시: 워싱턴 지하철 지도\n설득형 메세지: 대충 포스터 생각하면 됨",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "5 - 시각화 디자인"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/14.html#시각화-프로세스",
    "href": "posts/04_archives/adp_필기/notes/14.html#시각화-프로세스",
    "title": "5 - 시각화 디자인",
    "section": "시각화 프로세스",
    "text": "시각화 프로세스\n\n1. 정보 디자인 프로세스\n\n데이터 수집\n모든 것을 읽기\n내리티브 찾기\n문제의 정의\n계층 구조 만들기\n와이어프레임 그리기\n포맷 선택하기\n시각 접근 방법 결정하기\n정제와 테스트\n세상에 선보이기\n\n\n\n2. 빅데이터 시각화 프로세스\n\n\n\n시각화 프로세스\n\n\n\n\n\n방법론\n\n\n\n\n\n에드워드 터프티 시각 정보 디자인 7원칙",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "5 - 시각화 디자인"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/14.html#시각화-방법",
    "href": "posts/04_archives/adp_필기/notes/14.html#시각화-방법",
    "title": "5 - 시각화 디자인",
    "section": "시각화 방법",
    "text": "시각화 방법\n\n2. 정보 구조화\n\n데이터 수집 및 탐색\n데이터 분류: 확장자 맞게 분류\n데이터 배열: LATCH\n\nLocation\nAlphabet\nTime\nCategory\nHierarchy: 정보의 변화에 따라 데이터의 값이나 중요도 순서로 정렬\n\n데이터 재배열(관계 맺기):\n\n\n\n3. 정보 시각화\n\n\n\n\n좋은 그래프 디자인\n\n\n\n범례 만들지 말고, 직접 그려 넣은거\n테두리, 보조선 없는거\n굵은 글씨 대신 글자를 흐리게\n색깔은 최대한 적게 사용\n\n\n\n4. 정보 시각 표현\n\n자크 베르탱의 그래픽 7요소\n\n위치: 가장 중요한거는 좌측 상단에 배치\n크기\n모양\n색\n명도\n기울기\n질감\n\n타이포그래피\n\n산세리프: 돌기가 없음. 제목에 적합\n세리프: 돌기가 있음. 본문에 적합\n\n아이소타이프",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "5 - 시각화 디자인"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/01.html#빅데이터의-이해",
    "href": "posts/04_archives/adp_필기/notes/01.html#빅데이터의-이해",
    "title": "1 - 데이터의 가치와 미래",
    "section": "빅데이터의 이해",
    "text": "빅데이터의 이해\n\n1. 빅데이터의 정의\n\n\n좁은 범위\n\n데이터 자체의 특성에 초점을 맞춘 정의\n3V(다양성, 속도, 규모)를 강조\n\n중간 범위\n\n데이터 자체뿐 아니라 처리, 분석 방법도 포함하는 정의\n\n넓은 관점\n\n인재, 조직 변화까지 포함한 정의\n\n\n\n∴ 기존 방식으로는 얻을 수 없는 통찰 및 가치 창출\n\n\n2. 출현 배경과 변화\n\n산업계: 고객 데이터가 축적되며 새로운 가치 활용\n학계: 거대 데이터 활용 분야가 늘어나며 통계 도구들이 발전\n기술발전: 관련기술의 발전\n\n\n\n3. 빅데이터의 기능\n\n산업혁명의 석탄, 철: 산업 전반에 혁명적 변화를 가져옴\n21세기의 원유: 생산성을 향상시키고, 기존에 없던 새로운 범주의 산업을 만들어낼 것으로 전망\n렌즈: 데이터가 산업에 영향을 미침\n플랫폼\n\n\n\n4. 빅데이터가 만들어 내는 본질적인 변화\n\n사전처리 → 사후처리\n표본조사 → 전수조사\n질 → 양\n인과관계 → 상관관계",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "1 - 데이터의 가치와 미래"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/01.html#빅데이터의-가치와-영향",
    "href": "posts/04_archives/adp_필기/notes/01.html#빅데이터의-가치와-영향",
    "title": "1 - 데이터의 가치와 미래",
    "section": "빅데이터의 가치와 영향",
    "text": "빅데이터의 가치와 영향\n\n1. 빅데이터의 가치\n빅데이터는 아래와 같은 이유로 가치 선정이 어렵다.\n\n데이터 활용방식: 데이터를 언제 어디서 누가 사용할지 미리 예측하기 어려움\n새로운 가치 창출: 기존에 없던 가치를 창출하기 때문에 가치를 예측하기 어려움\n분석 기술 발전: 현재 가치가 없더라도, 추후 기술이 발전하면 가치가 생길 수 있음\n\n\n\n2. 빅데이터의 영향\n빅데이터는 다양한 주체(기업, 정부, 개인)에 영향을 미친다.",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "1 - 데이터의 가치와 미래"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/01.html#비즈니스-모델",
    "href": "posts/04_archives/adp_필기/notes/01.html#비즈니스-모델",
    "title": "1 - 데이터의 가치와 미래",
    "section": "비즈니스 모델",
    "text": "비즈니스 모델\n\n1. 빅데이터 활용 사례\n여러가지 활용 사례가 있다.\n\n\n2. 빅데이터 활용 기본 테크닉\n\n연관규칙학습: 범주형 데이터의 변인들간의 규칙을 발견. 비지도 학습 (ex. 장바구니 분석)\n유형(군집)분석: 데이터를 분류하거나 군집화. 비지도 학습 (not 분류분석)\n유전자 알고리즘: 최적해를 찾는 알고리즘\n기계학습: 훈련한 데이터로 예측\n회귀분석: 연속형 데이터의 독립변수와 종속변수의 관계를 수학적으로 모델링해서 예측\n감정분석: 비정형 데이터 분석\n소셜네트워크분석(사회관계망분석): 비정형 데이터 분석",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "1 - 데이터의 가치와 미래"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/01.html#위기-요인과-통제-방안",
    "href": "posts/04_archives/adp_필기/notes/01.html#위기-요인과-통제-방안",
    "title": "1 - 데이터의 가치와 미래",
    "section": "위기 요인과 통제 방안",
    "text": "위기 요인과 통제 방안\n\n1. 빅데이터 시대의 위기 요인과 통제 방안\n\n사생활 침해: 동의에서 책임으로\n책임 원칙 훼손: 결과 기반 책임 원칙 고수\n데이터 오용: 알고리즘 접근 허용, 알고리즈미스트",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "1 - 데이터의 가치와 미래"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/01.html#미래의-빅데이터",
    "href": "posts/04_archives/adp_필기/notes/01.html#미래의-빅데이터",
    "title": "1 - 데이터의 가치와 미래",
    "section": "미래의 빅데이터",
    "text": "미래의 빅데이터\n\n1. 빅데이터 활용의 3요소\n\n데이터: 모든것의 데이터화\n기술: 인공지능\n인력: 데이터 사이언티스트, 알고리즈미스트",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "1 - 데이터의 가치와 미래"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/04.html#분산-데이터-저장-기술",
    "href": "posts/04_archives/adp_필기/notes/04.html#분산-데이터-저장-기술",
    "title": "2 - 데이터 처리 기술",
    "section": "분산 데이터 저장 기술",
    "text": "분산 데이터 저장 기술\n\n1. 분산 파일 시스템\n\nGFS(Google File System): 구글의 분산 파일 시스템\n\nchunk: 64MB\n트리 구조가 아닌, 해시 테이블 구조로 관리\nPOSIX 인터페이스 지원하지 않음\n단일 마스터 노드가 메모리상에서 메타데이터 관리\n마스터 노드에 대한 로그를 기록하고, 마스터의 상태를 섀도우 마스터 노드에 복제\n하나의 파일에 대한 primary node를 정하고, 다른 노드에 복제본 분산 저장\n낮은 응답 지연시간보다 높은 처리율 중시\nMaster Node, Chunk Node, Client 구성\n\nHDFS(Hadoop Distributed File System): 아파치 하둡의 분산 파일 시스템\n\nGFS의 clone project\nPOSIX 인터페이스 지원하지 않음\nblock: 128MB\nNameNode가 메타데이터 관리\n낮은 응답 지연시간보다 높은 처리율 중시\nNameNode, DataNode, 보조 네임 노드, job tracker, task tracker 구성\n\nLustre: 고성능 컴퓨팅을 위한 분산 파일 시스템\n\nPOSIX 인터페이스 지원\nchunk가 아닌 striping 방식 데이터 저장\nClient Filesystem, Metadata Server, 객체 저장 서버로 구성\n\n\n\n\n2. 데이터베이스 클러스터\n\n\n\n\n\n\n\n무공유 디스크\n\n각 노드가 완전히 분리된 데이터를 가짐\nOracle RAC를 제외한 대부분의 클러스터가 채택\n노드 확장에 제한이 없음\n\n공유 디스크\n\nSAN과 같은 네트워크로 모든 노드가 디스크 공유\n노드 확장시 디스크 병목현상 고려 필요\n\n\n\n\n\n\nOrace RAC 데이터베이스 서버: 확장성보다는 고가용성이 중요한 서비스에 적합\nIBM DB2 ICE(integrated cluster environment)\n마이크로소프트 SQL Server: 전역 스키마가 없어서 모든 노드에 질의를 해야함. active-stanby 구성\nMySQL:\n\n클러스터에 참여하는 노드는 최대 255, 그 중 데이터 노드는 최대 48개까지 가능\n운영중에 노드를 추가 삭제 불가\n\n\n\n\n3. NoSQL\n\nGoogle BigTable:\n\n공유 디스크 방식\nRow Key 순으로 정렬 되어 있고, Row 내부적으로는 Column Key 순으로 정렬\nColumn Key, Value, Timestamp로 구성\nChubby를 이용해 마스터 노드 관리\n\nHBase\nAmazon SimpleDB\n\nschema가 없고, Domain(table), Item(record), Attribute(column), Value으로 구성\n\n마이크로소프트 SSDS: Container(table), Entity(record), Property(column)로 구성",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "2 - 데이터 처리 기술"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/04.html#분산-컴퓨팅-기술",
    "href": "posts/04_archives/adp_필기/notes/04.html#분산-컴퓨팅-기술",
    "title": "2 - 데이터 처리 기술",
    "section": "분산 컴퓨팅 기술",
    "text": "분산 컴퓨팅 기술\n\n1. MapReduce\n\n대용량 데이터를 분산 처리할 수 있는 모델\n보통 64MB를 기준으로 데이터 분할\n하나의 블록당 하나의 Map Task, 사용자가 지정한 갯수만큼의 Reduce Task 생성\nCount 작업에 적합하고, Sort 작업에는 적합하지 않음\n\n\nGoogle MapReduce\nHadoop MapReduce\n\n절차: 1. Split 1. Map 1. Combine 1. Partition 1. Shuffle 1. Sort 1. Reduce\n\n\n2. 병렬 쿼리 시스템\n\nGoogle Sawzall: MapReduce에 대한 이해가 없어도 쉽게 사용 가능\nApache Pig\nApache Hive\n\n\n\n3. SQL on Hadoop",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "2 - 데이터 처리 기술"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/04.html#클라우드-인프라-기술",
    "href": "posts/04_archives/adp_필기/notes/04.html#클라우드-인프라-기술",
    "title": "2 - 데이터 처리 기술",
    "section": "클라우드 인프라 기술",
    "text": "클라우드 인프라 기술\n\n2. CPU 가상화\n\n하이퍼바이저: 하드웨어 리소스를 가상화하여 여러 개의 가상 머신을 생성하는 소프트웨어\n\nbare-metal hypervisor: 하드웨어와 host 운영체제 사이에 hypervisor가 존재  \nhosted hypervisor: host 운영체제와 guest 운영체제 사이에 hypervisor가 존재\n\nContainer\n\n\n\n3. 메모리 가상화\n\nVMKernnel: hypervisor 내에 Show Page Table을 두고, 각 VM의 Guest OS의 Page Table을 관리\nMemory Ballooning: Guest OS의 메모리를 빼앗아서 다른 VM에 할당\nTransparent Page Sharing: 같은 내용의 메모리 페이지는 VM들이 공유\nMemory Overcommitment: VM에 할당된 메모리보다 더 많은 메모리를 할당할 수 있음\n\n\n\n4. I/O 가상화\n\n가상 이더넷: 가상 머신 간의 네트워크 통신을 위한 가상 네트워크. LAN 세그먼트를 가상화\n공유 이더넷 어댑터: 하나의 물리적 네트워크 어댑터를 여러 VM이 공유. 병목현상 발생 가능\n가상 디스크 어댑터",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "2 - 데이터 처리 기술"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/05.html#분석-과제-발굴",
    "href": "posts/04_archives/adp_필기/notes/05.html#분석-과제-발굴",
    "title": "3 - 데이터 분석 기획의 이해",
    "section": "분석 과제 발굴",
    "text": "분석 과제 발굴\n\n풀어야 할 다양한 문제를 데이터 분석 문제로 변환 후, 프로젝트를 수행할 수 있는 과제 정의서 형태로 도출\n\n\n\n\n도출을 위한 접근 방법\n\n\n최적의 의사결정은 두 접근 방식이 상호 보완 관계에 있을 때 가능하다.\n\n\n1. 하향식 접근법\n\n사물을 why 관점에서 보는 방식\n\n\n\n문제 탐색: 문제를 해결함으로써 발생하는 가치에 중점\n\n비즈니스 모델기반\n분석 기회 발굴의 범위 확장\n외부참조 모델 기반\n분석 유즈 케이스\n\n문제 정의: 식별된 비즈니스 문제를 데이터의 문제로 변환\n해결방안 탐색: 분석 역량과, 분석 기법 및 시스템 존재 여부를 고려한다.\n타당성 검토\n\n경제적 타당성: 비용대비 편익 분석 관점의 접근\n데이터 및 기술적 타당성\n\n\n\n\n2. 상향식 접근법\n\n사물을 what 관점에서 보는 방식\n\n\n비지도 학습\n지도 학습\n\n\n프로토타이핑 접근법",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "3 - 데이터 분석 기획의 이해"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/05.html#분석-기획-방향성-도출",
    "href": "posts/04_archives/adp_필기/notes/05.html#분석-기획-방향성-도출",
    "title": "3 - 데이터 분석 기획의 이해",
    "section": "분석 기획 방향성 도출",
    "text": "분석 기획 방향성 도출\n\n1. 분석기획의 특징\n\n과제를 발굴, 정의하고 의도했던 결과를 도출할 수 있도록 적절하게 관리할 수 있는 방안을 사전에 계획하는 일련의 작업 (말 그대로 기획)\n\n\n\n3. 목표 시점 별 분석 기획 방안\n\n\n\n4. 분석 기획시 고려사항\n\n가용 데이터\n적절한 활용방안과 유즈케이스\n장애요소들에 대한 사전계획 수립",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "3 - 데이터 분석 기획의 이해"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/05.html#분석-방법론",
    "href": "posts/04_archives/adp_필기/notes/05.html#분석-방법론",
    "title": "3 - 데이터 분석 기획의 이해",
    "section": "분석 방법론",
    "text": "분석 방법론\n\n방법론은 절차, 방법, 도구와 기법, 템플릿과 산출물로 구성된다.\n\n\n\n\n방법론 절차의 구성 요소\n\n\n\n폭포수 모델\n프로토타입 모델\n나선형 모델\n\n\n1. KDD 분석 방법론\n\n비즈니스 도메인에 대한 이해, 프로젝트 목표 설정\n데이터셋 선택\n데이터 전처리: 잡음, 이상치, 결측치 처리. 추가로 요구되는 데이터 셋이 필요한 경우, 데이터 선택 프로세스로 돌아감\n데이터 변환: 데이터 차원 축소, 학습용 데이터, 시험용 데이터 분리\n데이터 마이닝\n데이터 마이닝 결과 평가\n\n\n\n2. CRISP-DM 분석 방법론\n\n\n\nCRISP-DM 4레벨 구조\n\n\nGeneric Tasks 예시: 데이터 정제\nSpecialized Tass 예시: 범주형 데이터 정제, 연속형 데이터 정제\n\n\n\nCRISP-DM 6Phase\n\n\n\n업무 이해\n데이터 이해: 데이터셋 선택, 데이터 전처리\n데이터 준비: 데이터 변환\n모델링: 모델 평가\n평가: 모델 적용성 평가\n전개\n\n\n\n3. 빅데이터 분석 방법론\n\n\n\n빅데이터 분석 방법론의 5단계\n\n\n\n분석 기획\n\n비즈니스 이해 및 범위 설정\n프로젝트 정의 및 계획 수립 → SOW\n프로젝트 위험 계획 수립 → 회피, 전이, 완화, 수용\n\n데이터 준비\n\n필요 데이터 정의\n데이터 스토어 설계\n데이터 수집 및 정합성 점검\n\n데이터 분석\n\n분석 데이터 준비\n텍스트 분석\n탐색적 분석\n모델링 → 훈련용, 테스트용 데이터 분리\n모델 평가\n\n시스템 구현\n평가 및 전개",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "3 - 데이터 분석 기획의 이해"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/05.html#분석-프로젝트-관리-방안",
    "href": "posts/04_archives/adp_필기/notes/05.html#분석-프로젝트-관리-방안",
    "title": "3 - 데이터 분석 기획의 이해",
    "section": "분석 프로젝트 관리 방안",
    "text": "분석 프로젝트 관리 방안\n\n1. 분석과제 관리를 위한 5가지 주요 영역\n\nData Size\nData Complexity\nSpeed: 분석 모델의 성능 및 속도를 고려해야한다.\nAnalytic Complexity: 분석 모델의 정확도를 높이면서 해석이 가능하도록 최적 모델을 찾아야 한다.\nAccurancy & Precision: 정확도, 정밀도\n\n\n\n3. 분석 프로젝트 관리방안\n\n범위\n시간\n원가\n품질\n통합\n조달\n자원\n리스크\n의사소통\n이해관계자",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "3 - 데이터 분석 기획의 이해"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/03.html#etl",
    "href": "posts/04_archives/adp_필기/notes/03.html#etl",
    "title": "2 - 데이터 처리 프로세스",
    "section": "ETL",
    "text": "ETL\n\n1. ETL 개요\n\nETL(Extract, Transformation, Load): 데이터 이동 및 변환 절차\nbatch ETL, real-time ETL으로 나뉨\n\n\n\n\nETL 작업 단계\n\n\n\nInterface: 다양한 소스로부터 데이터 휙득을 위한 인터페이스(OLEDB, ODBC, FTP)\nStaging: 정기적으로 데이터 원천으로 부터 저장. 아직은 정규화 x\nProfiling: staging table의 데이터 특성을 식별하고, 품질 측정\nCleansing: profiling된 데이터를 보정\nIntegration: 데이터 충돌을 해소하고, 데이터를 통합. 아마 여기서 정규화가 이루어질듯(왜 책에 설명 똑바로 안해놓지)\nExport: 운영보고서 생성, 데이터웨어하우스 / 데이터마트에 적재하기 위한 최적화(denormalization) 진행\n\n\n\n2. ODS 구성\n\n통합된 데이터를 저정하는 중간 저장소\n실시간, 거의 실시간으로 데이터 적재\n\n\n\n3. 데이터 웨어하우스\n\nODS를 통해 정제 / 통합된 데이터를 분석 및 보고서 생성을 위해 저장\n\n특징\n\n주제중심성\n영속성/비휘발성\n통합성\n시계열성\n\n모델링 기법\n\n스타 스키마(조인 스키마)\n\n제 3정규형의 fact 테이블과 제 2정규형의 차원 테이블로 구성\n복잡성이 낮지만, 데이터 무결성이 떨어짐\n\n\n\n\n스노우플레이크 스키마\n\n스타 스키마의 차원 테이블을 제 3정규형으로 정규화한 상태\n데이터 무결성이 높지만, 복잡성이 높음\n\n\n\n\n\n\n\n\n\n제 1 정규형: 반복되는 record나 다치 attribute를 포함하지 않음 제 2 정규형: 부분 종속성(primary key의 일부가 다른 일부를 종속함)이 없음 제 3 정규형: 이행적 종속성(primary key가 아닌 attribute의 종속성)이 없음\n\n\n\n\n\n4. ODS vs DW",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "2 - 데이터 처리 프로세스"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/03.html#cdcchange-data-capture",
    "href": "posts/04_archives/adp_필기/notes/03.html#cdcchange-data-capture",
    "title": "2 - 데이터 처리 프로세스",
    "section": "CDC(change data capture)",
    "text": "CDC(change data capture)\n\n1. CDC 개념 및 특징\n\n데이터 변경을 감지하고, 변경된 데이터를 추출하는 기술\n하드웨어 계층부터 어플리케이션 계층까지 다양한 수준에서 적용 가능\n\n\n\n2. CDC 구현 기법\n\nTime Stamp on Rows\nVersion Numbers on Rows: 참조테이블을 같이 사용하는게 일반적이라고 한다.\nStatus on Rows: time stamp, version number 보완 용도로, 사람이 레코드 반영 여부를 직접 판단할 수 있게 적용할 수 있음\nTime/Version/Status on Rows\nTriggers on Tables: message queue로 변경 발생시 subscribe 된 대상에 publish하는 방식. 시스템 관리 복잡도가 높아짐\nEvent Programming: 어플리케이션에 데이터 변경 식별 기능을 추가\nLog Scanner on Database: 데이터 스키마 변경 불필요, 어플리케이션 영향 최소화, 지연시간 최소화\n\n\n\n3. CDC 구현 방식\n\nPush: 데이터 원천에서 변경 식별(agent)\nPull: 대상 시스템에서 원천을 주기적으로 모니터링",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "2 - 데이터 처리 프로세스"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/03.html#eai",
    "href": "posts/04_archives/adp_필기/notes/03.html#eai",
    "title": "2 - 데이터 처리 프로세스",
    "section": "EAI",
    "text": "EAI\n\n1. EAI의 개념 및 특징\n\n기업 내 혹은 기업 간 정보시스템을 연계하여 동기화.\nETL은 batch 처리 중심, EAI는 실시간 혹은 근접 실시간 처리 중심\n\n\n\n2. 데이터 연계 방식\n\n\nETL/CDC는 운영 데이터와 분석을 위한 데이터베이스가 구분되지만, EAI는 그냥 통합\n\n\n\n3. EAI 구성요소\n\nAdapter: 시스템 간 데이터 변환\nBroker: 데이터 전송\nBus: 데이터 전송 경로 설정\nTransformer: 데이터 형식 변환\n\n\n\n4. EAI 구현 유형\n\nMediation: Publish/Subscribe 방식\nFederaion: Request/Reply 방식\n\n\n\n5. EAI 활용 효과\n\n협력사, 파트너, 고객과의 상호 협력 프로세스 연계\n그룹 및 지주 회사 계열사들 간 상호 관련 데이터 동기화 등을 위한 데이터 표준화 기반 제공\n\n\n\n6. EAI vs ESB\n\n추가적인 자료",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "2 - 데이터 처리 프로세스"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/03.html#데이터-통합-및-연계-기법",
    "href": "posts/04_archives/adp_필기/notes/03.html#데이터-통합-및-연계-기법",
    "title": "2 - 데이터 처리 프로세스",
    "section": "데이터 통합 및 연계 기법",
    "text": "데이터 통합 및 연계 기법\n\n\n빅데이터는 시각화도 하고, NoSQL 같은 환경에서도 사용한다.",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "2 - 데이터 처리 프로세스"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_필기/notes/03.html#대용량의-비정형-데이터-처리-방법",
    "href": "posts/04_archives/adp_필기/notes/03.html#대용량의-비정형-데이터-처리-방법",
    "title": "2 - 데이터 처리 프로세스",
    "section": "대용량의 비정형 데이터 처리 방법",
    "text": "대용량의 비정형 데이터 처리 방법\n\n2. 대규모 분산 병렬 처리\n\n하둡:\n\nMapReduce와 HDFS를 기반으로 한 분산 병렬 처리 프레임워크\n비공유 분산 아키텍쳐\n선형적인 성능과 용량 확장\nMapReduce failover\n\n\n\nHadoop ecosystem\n\n\n\n3. 데이터 연동\n대규모 연산을 데이터베이스에서 처리하기 어렵기 때문에, 하둡으로 복사해와서 MapReduce 연산 후, 결과를 다시 데이터베이스에 기록하기 위해 스쿱 사용\n\nSqoop\n\nJDBC를 지원하는 RDBMS, Hbase와 Hadoop 간 데이터 전송(Import, Export)\nSQL 질의로 데이터 추출\nMapReduce 사용\n\n\n\n\n4. 데이터 질의 기술\n\nHive: SQL과 유사한 HiveQL 질의, batch 처리\nSQL on Hadoop: SQL 질의, 실시간 처리\n\napache Drill, Stinger, Shark, Tajo, Impala, HAWQ, Presto",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 필기 준비",
      "Notes",
      "2 - 데이터 처리 프로세스"
    ]
  },
  {
    "objectID": "posts/04_archives/vault/notes/0_overview.html#how-vault-encrypt-data",
    "href": "posts/04_archives/vault/notes/0_overview.html#how-vault-encrypt-data",
    "title": "Overview",
    "section": "how vault encrypt data",
    "text": "how vault encrypt data",
    "crumbs": [
      "PARA",
      "Archives",
      "vault",
      "Notes",
      "Overview"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/0_core_concept.html",
    "href": "posts/04_archives/k8s/notes/0_core_concept.html",
    "title": "k8s cluster architecture",
    "section": "",
    "text": "- master nodes: manage the worker nodes and the pods in the cluster - etcd: key-value store for all cluster data - kube-scheduler: schedules pods to worker nodes - kube-controller-manager: runs controller processes - replication controller: ensures that the correct number of pods are running - node controller: monitors the nodes - worker nodes: host the pods that are the components of the application - kubelet: communicates with the master node - kube-proxy: forwards requests to the correct pod\n\n\n  - initially, k8s was built on top of docker - gradually, k8s started supporting other container runtimes like containerd, cri-o, etc. and built a container runtime interface (CRI) to support multiple container runtimes - docker was not designed to be a container runtime, it was designed to be a container engine so it has a lot of features that are not needed by k8s and removed.\n\n\n\n\nkey-value store for all cluster data\nstores nodes, pods, configs, secrets, accounts, roles, bindings, etc.\n\n\n\n\n\n\n\nkube-api-server\n\n\n\n\n\n\n\n\n\n\n\n\nmust be installed on every node in the cluster manually ## kube-proxy\nkubeadm automatically installs kube-proxy on every node using daemonset\nwhen a service is created, kube-proxy creates a set of iptables rules to forward traffic to the correct pod",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "k8s cluster architecture"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/0_core_concept.html#docker-vs-containerd",
    "href": "posts/04_archives/k8s/notes/0_core_concept.html#docker-vs-containerd",
    "title": "k8s cluster architecture",
    "section": "",
    "text": "- initially, k8s was built on top of docker - gradually, k8s started supporting other container runtimes like containerd, cri-o, etc. and built a container runtime interface (CRI) to support multiple container runtimes - docker was not designed to be a container runtime, it was designed to be a container engine so it has a lot of features that are not needed by k8s and removed.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "k8s cluster architecture"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/0_core_concept.html#etcd",
    "href": "posts/04_archives/k8s/notes/0_core_concept.html#etcd",
    "title": "k8s cluster architecture",
    "section": "",
    "text": "key-value store for all cluster data\nstores nodes, pods, configs, secrets, accounts, roles, bindings, etc.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "k8s cluster architecture"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/0_core_concept.html#kube-api-server",
    "href": "posts/04_archives/k8s/notes/0_core_concept.html#kube-api-server",
    "title": "k8s cluster architecture",
    "section": "",
    "text": "kube-api-server",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "k8s cluster architecture"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/0_core_concept.html#kubelet",
    "href": "posts/04_archives/k8s/notes/0_core_concept.html#kubelet",
    "title": "k8s cluster architecture",
    "section": "",
    "text": "must be installed on every node in the cluster manually ## kube-proxy\nkubeadm automatically installs kube-proxy on every node using daemonset\nwhen a service is created, kube-proxy creates a set of iptables rules to forward traffic to the correct pod",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "k8s cluster architecture"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/2_logging_monitoring.html",
    "href": "posts/04_archives/k8s/notes/2_logging_monitoring.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "in-memmory solution.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "metrics server"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/2_logging_monitoring.html#metrics-server",
    "href": "posts/04_archives/k8s/notes/2_logging_monitoring.html#metrics-server",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "in-memmory solution.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "metrics server"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/2_logging_monitoring.html#cadvisor",
    "href": "posts/04_archives/k8s/notes/2_logging_monitoring.html#cadvisor",
    "title": "김형훈의 학습 블로그",
    "section": "cAdvisor",
    "text": "cAdvisor\n\ncontainer advisor\nsub-component of kubelet\ncollects, aggregates, processes, and exports information about running containers",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "metrics server"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/6_network.html",
    "href": "posts/04_archives/k8s/notes/6_network.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "k8s uses coreDNS to provide DNS service",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "core DNS"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/6_network.html#core-dns",
    "href": "posts/04_archives/k8s/notes/6_network.html#core-dns",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "k8s uses coreDNS to provide DNS service",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "core DNS"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/6_network.html#network-plugin",
    "href": "posts/04_archives/k8s/notes/6_network.html#network-plugin",
    "title": "김형훈의 학습 블로그",
    "section": "network plugin",
    "text": "network plugin\n\nbridge type network\n - all container runtime solutions use same bridge script - and you can use third party plugins like flannel, calico, weave, etc.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "core DNS"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/4_security.html",
    "href": "posts/04_archives/k8s/notes/4_security.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "k8s does not support user authentication by default (except service accounts)\n\n\n\n\nk8s uses TLS to secure communication between components \nuser can grouped by certificate’s Common Name or Organization field\nnode’s group name is system:nodes\n\n\n\n\n\n~/.kube/config file is used to store k8s cluster information\nkubectl uses this file to connect to the cluster\nclusters, users, context",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Authentication"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/4_security.html#authentication",
    "href": "posts/04_archives/k8s/notes/4_security.html#authentication",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "k8s does not support user authentication by default (except service accounts)\n\n\n\n\nk8s uses TLS to secure communication between components \nuser can grouped by certificate’s Common Name or Organization field\nnode’s group name is system:nodes\n\n\n\n\n\n~/.kube/config file is used to store k8s cluster information\nkubectl uses this file to connect to the cluster\nclusters, users, context",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Authentication"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/4_security.html#authorization",
    "href": "posts/04_archives/k8s/notes/4_security.html#authorization",
    "title": "김형훈의 학습 블로그",
    "section": "Authorization",
    "text": "Authorization\n\nAPI groups\n\nk8s API is divided into groups\ncore group is the default group\ngroup has its own set of resources and verbs \n\n\n\nRBAC\n\ncreate Role object (namespace scoped resources)\ncreate RoleBinding object\n\nor\n\ncreate ClusterRole object (cluster scoped resources)\ncreate ClusterRoleBinding object\n\n\n\nservice account\n\ncreate ServiceAccount object\nthen it create token\nthen create secret object with the token\nthen secret object is linked to the service account\nand the token is automatically mounted to the pod\n\n=&gt; but this is not secure, and scalable =&gt; TokenRequest API is used",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Authentication"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/4_security.html#image-security",
    "href": "posts/04_archives/k8s/notes/4_security.html#image-security",
    "title": "김형훈의 학습 블로그",
    "section": "image security",
    "text": "image security\nif you use private image registry, you need to create secret object 1. create docker-registry type secret 2. add imagePullSecrets field in the pod spec",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Authentication"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/index.html",
    "href": "posts/04_archives/k8s/index.html",
    "title": "k8s",
    "section": "",
    "text": "k8s 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/index.html#details",
    "href": "posts/04_archives/k8s/index.html#details",
    "title": "k8s",
    "section": "",
    "text": "k8s 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/index.html#tasks",
    "href": "posts/04_archives/k8s/index.html#tasks",
    "title": "k8s",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/index.html#참고-자료",
    "href": "posts/04_archives/k8s/index.html#참고-자료",
    "title": "k8s",
    "section": "참고 자료",
    "text": "참고 자료\n\nCKA Udemy 강의",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/index.html#related-posts",
    "href": "posts/04_archives/k8s/index.html#related-posts",
    "title": "k8s",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/03.html#데이터-전처리의-의미",
    "href": "posts/04_archives/adp_실기/notes/03.html#데이터-전처리의-의미",
    "title": "데이터 전처리",
    "section": "데이터 전처리의 의미",
    "text": "데이터 전처리의 의미\n\n데이터 클리닝\n데이터 통합\n데이터 변환\n데이터 축소\n불균형 데이터 처리\n데이터 분할",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "데이터 전처리"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/03.html#이상치-확인-및-정제",
    "href": "posts/04_archives/adp_실기/notes/03.html#이상치-확인-및-정제",
    "title": "데이터 전처리",
    "section": "이상치 확인 및 정제",
    "text": "이상치 확인 및 정제\n\n이상치 확인\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pandas.core.common import random_state\nfrom sklearn.datasets import load_wine\n\nwine_load = load_wine()\nwine = pd.DataFrame(wine_load.data, columns=wine_load.feature_names)\nwine['class'] = wine_load.target\nwine['class'] = wine['class'].map({0: 'class_0', 1: 'class_1', 2: 'class_2'})\n\nplt.boxplot(wine['color_intensity'], whis=1.5)\nplt.title('Boxplot of color_intensity')\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\ndef outliers_iqr(dt, col):\n    q1, q3 = np.percentile(dt[col], [25, 75])\n    iqr = q3 - q1\n    lower_bound = q1 - (iqr * 1.5)\n    upper_bound = q3 + (iqr * 1.5)\n    return dt[(dt[col] &lt; lower_bound) | (dt[col] &gt; upper_bound)]\n\noutliers = outliers_iqr(wine, 'color_intensity')\noutliers\n\n\n\n\n\n\n\n\nalcohol\nmalic_acid\nash\nalcalinity_of_ash\nmagnesium\ntotal_phenols\nflavanoids\nnonflavanoid_phenols\nproanthocyanins\ncolor_intensity\nhue\nod280/od315_of_diluted_wines\nproline\nclass\n\n\n\n\n151\n12.79\n2.67\n2.48\n22.0\n112.0\n1.48\n1.36\n0.24\n1.26\n10.80\n0.48\n1.47\n480.0\nclass_2\n\n\n158\n14.34\n1.68\n2.70\n25.0\n98.0\n2.80\n1.31\n0.53\n2.70\n13.00\n0.57\n1.96\n660.0\nclass_2\n\n\n159\n13.48\n1.67\n2.64\n22.5\n89.0\n2.60\n1.10\n0.52\n2.29\n11.75\n0.57\n1.78\n620.0\nclass_2\n\n\n166\n13.45\n3.70\n2.60\n23.0\n111.0\n1.70\n0.92\n0.43\n1.46\n10.68\n0.85\n1.56\n695.0\nclass_2\n\n\n\n\n\n\n\n\n\n이상치 정제\n\n이상치 제거\n\n\ndrop_outliers = wine.drop(index=outliers.index)\n\nprint(\"Original:\", wine.shape)\nprint(\"Drop outliers:\", drop_outliers.shape)\n\nOriginal: (178, 14)\nDrop outliers: (174, 14)\n\n\n\n이상치 대체\n\n이상치를 NULL로 만든 후, 결측치와 함께 대체\n\nwine.loc[outliers.index, 'color_intensity'] = np.NaN\n\nwine['color_intensity'].fillna(wine['color_intensity'].mean(), inplace=True)\nwine.loc[outliers.index, 'color_intensity']\n\n/tmp/ipykernel_14407/3568685677.py:3: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n\n\n151    4.908678\n158    4.908678\n159    4.908678\n166    4.908678\nName: color_intensity, dtype: float64",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "데이터 전처리"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/03.html#범주형-데이터-처리",
    "href": "posts/04_archives/adp_실기/notes/03.html#범주형-데이터-처리",
    "title": "데이터 전처리",
    "section": "범주형 데이터 처리",
    "text": "범주형 데이터 처리\n\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\niris = pd.DataFrame(iris.data, columns=iris.feature_names)\niris['Class'] = load_iris().target\niris['Class'] = iris['Class'].map({0: 'Setosa', \n                                   1:'Versicolour', \n                                   2: 'Virginica'})",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "데이터 전처리"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/03.html#데이터-분할",
    "href": "posts/04_archives/adp_실기/notes/03.html#데이터-분할",
    "title": "데이터 전처리",
    "section": "데이터 분할",
    "text": "데이터 분할\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(iris.drop(\n  columns='Class'), iris['Class'], test_size=0.2, random_state=1004)\nprint('X_train: ', X_train.shape, 'X_test: ', X_test.shape)\nprint('y_train: ', y_train.shape, 'y_test: ', y_test.shape)\n\nX_train:  (120, 4) X_test:  (30, 4)\ny_train:  (120,) y_test:  (30,)\n\n\n\nX_train.head(3)\n\n\n\n\n\n\n\n\nsepal length (cm)\nsepal width (cm)\npetal length (cm)\npetal width (cm)\n\n\n\n\n87\n6.3\n2.3\n4.4\n1.3\n\n\n67\n5.8\n2.7\n4.1\n1.0\n\n\n131\n7.9\n3.8\n6.4\n2.0\n\n\n\n\n\n\n\n\ny_train.head(3)\n\n87     Versicolour\n67     Versicolour\n131      Virginica\nName: Class, dtype: object\n\n\n\niris['Class'].value_counts()\n\nClass\nSetosa         50\nVersicolour    50\nVirginica      50\nName: count, dtype: int64\n\n\n\ny_train.value_counts()\n\nClass\nVersicolour    41\nSetosa         40\nVirginica      39\nName: count, dtype: int64",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "데이터 전처리"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/03.html#데이터-스케일링",
    "href": "posts/04_archives/adp_실기/notes/03.html#데이터-스케일링",
    "title": "데이터 전처리",
    "section": "데이터 스케일링",
    "text": "데이터 스케일링\n\nStandard Scaler\n\n평균이 0, 분산이 1이 되도록 변환\n이상치에 민감하다.\n회귀분석보다는 분류분석에 적합\n\n\nfrom sklearn.preprocessing import RobustScaler, StandardScaler\n\nStdScaler = StandardScaler()\n\nStdScaler.fit(X_train)\nX_train_sc = StdScaler.transform(X_train)\nX_test_sc = StdScaler.transform(X_test)\n\n\n\nMin-Max Scaler\n\n0 ~ 1 사이의 값으로 변환\n이상치에 민감하다.\n회귀분석에 적합\n\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nMinMaxScaler = MinMaxScaler()\n\nMinMaxScaler.fit(X_train)\nX_train_sc = MinMaxScaler.transform(X_train)\n\nX_test_sc = MinMaxScaler.transform(X_test)\n\n\n\nMax Abs Scaler\n\n-1 ~ 1 사이의 값으로 변환\n이상치에 민감하다.\n회귀분석에 적합\n\n\nfrom sklearn.preprocessing import MaxAbsScaler\n\nMaxAbsScaler = MaxAbsScaler()\n\nMaxAbsScaler.fit(X_train)\nX_train_sc = MaxAbsScaler.transform(X_train)\n\nX_test_sc = MaxAbsScaler.transform(X_test)\n\n\n\nRobust Scaler\n\n중앙값을 0으로 설정하고, IQR을 사용하여 잉상치 영향을 최소화함\n\n\nfrom sklearn.preprocessing import RobustScaler\n\nRobustScaler = RobustScaler()\n\nRobustScaler.fit(X_train)\nX_train_sc = RobustScaler.transform(X_train)\n\nX_test_sc = RobustScaler.transform(X_test)\n\n\n\n다시 완본으로 변경\n\nscaler.inverse_transform()\n\n\npd.DataFrame(X_train_sc).head(3)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\n0\n0.384615\n-1.4\n0.028369\n0.000000\n\n\n1\n0.000000\n-0.6\n-0.056738\n-0.200000\n\n\n2\n1.615385\n1.6\n0.595745\n0.466667\n\n\n\n\n\n\n\n\nX_original = RobustScaler.inverse_transform(X_train_sc)\n\npd.DataFrame(X_original).head(3)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\n0\n6.3\n2.3\n4.4\n1.3\n\n\n1\n5.8\n2.7\n4.1\n1.0\n\n\n2\n7.9\n3.8\n6.4\n2.0",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "데이터 전처리"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/03.html#차원-축소",
    "href": "posts/04_archives/adp_실기/notes/03.html#차원-축소",
    "title": "데이터 전처리",
    "section": "차원 축소",
    "text": "차원 축소\n\nfeatures = []\nx = iris.drop(columns='Class')\n\nx = StandardScaler().fit_transform(x)\n\npd.DataFrame(x).head(3)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n\n\n\n\n0\n-0.900681\n1.019004\n-1.340227\n-1.315444\n\n\n1\n-1.143017\n-0.131979\n-1.340227\n-1.315444\n\n\n2\n-1.385353\n0.328414\n-1.397064\n-1.315444\n\n\n\n\n\n\n\n\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=4)\npca_fit = pca.fit(x)\n\nprint(pca.singular_values_)\nprint(pca.explained_variance_ratio_.cumsum())\n\n[20.92306556 11.7091661   4.69185798  1.76273239]\n[0.72962445 0.95813207 0.99482129 1.        ]\n\n\n\nplt.title('Scree Plot')\nplt.plot(pca.explained_variance_ratio_, 'o-')\nplt.show()",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "데이터 전처리"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/03.html#데이터-불균형-문제-처리",
    "href": "posts/04_archives/adp_실기/notes/03.html#데이터-불균형-문제-처리",
    "title": "데이터 전처리",
    "section": "데이터 불균형 문제 처리",
    "text": "데이터 불균형 문제 처리",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "데이터 전처리"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/01.html",
    "href": "posts/04_archives/adp_실기/notes/01.html",
    "title": "pandas data 구조",
    "section": "",
    "text": "pandas: numpy를 라벨링한거",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "pandas data 구조"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/01.html#before",
    "href": "posts/04_archives/adp_실기/notes/01.html#before",
    "title": "pandas data 구조",
    "section": "Before",
    "text": "Before\n데이터를 호출하고, 데이터 내용과 요약 / 통계 정보를 확인해야함\n칼럼명이 칼럼 타입을 변경해야할 때도 있음\n\nPandas 사용 준비\n\n라이브러리 설치\n라이브러리 호출\n\n\nimport pandas as pd\n\npd.set_option('display.max_rows', 10)\n\n\n\nDataFrame 선언\n\nimport numpy as np\ndataset = np.array([['kor', 70], ['math', 80]])\n# declare df 1\ndf = pd.DataFrame(dataset, columns=['class', 'score'])\n# declare df 2\ndf = pd.DataFrame([['kor', 70], ['math', 80]], columns=['class', 'score'])\n# declare df 3\ndf = pd.DataFrame({'class': ['kor', 'math'], 'score': [70, 80]})\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n\n\n\n\n0\nkor\n70\n\n\n1\nmath\n80\n\n\n\n\n\n\n\n\n\nDataFrame 읽고 저장\n\n# filepath = '../book/data/data.csv'\n# data = pd.read_csv(filepath, na_values='NA', encoding='utf8')\n# data.to_csv('result.csv', header=True, index=True, encoding='utf8')\n\n\n\nDataFrame 출력\n\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\niris\n\n{'data': array([[5.1, 3.5, 1.4, 0.2],\n        [4.9, 3. , 1.4, 0.2],\n        [4.7, 3.2, 1.3, 0.2],\n        [4.6, 3.1, 1.5, 0.2],\n        [5. , 3.6, 1.4, 0.2],\n        [5.4, 3.9, 1.7, 0.4],\n        [4.6, 3.4, 1.4, 0.3],\n        [5. , 3.4, 1.5, 0.2],\n        [4.4, 2.9, 1.4, 0.2],\n        [4.9, 3.1, 1.5, 0.1],\n        [5.4, 3.7, 1.5, 0.2],\n        [4.8, 3.4, 1.6, 0.2],\n        [4.8, 3. , 1.4, 0.1],\n        [4.3, 3. , 1.1, 0.1],\n        [5.8, 4. , 1.2, 0.2],\n        [5.7, 4.4, 1.5, 0.4],\n        [5.4, 3.9, 1.3, 0.4],\n        [5.1, 3.5, 1.4, 0.3],\n        [5.7, 3.8, 1.7, 0.3],\n        [5.1, 3.8, 1.5, 0.3],\n        [5.4, 3.4, 1.7, 0.2],\n        [5.1, 3.7, 1.5, 0.4],\n        [4.6, 3.6, 1. , 0.2],\n        [5.1, 3.3, 1.7, 0.5],\n        [4.8, 3.4, 1.9, 0.2],\n        [5. , 3. , 1.6, 0.2],\n        [5. , 3.4, 1.6, 0.4],\n        [5.2, 3.5, 1.5, 0.2],\n        [5.2, 3.4, 1.4, 0.2],\n        [4.7, 3.2, 1.6, 0.2],\n        [4.8, 3.1, 1.6, 0.2],\n        [5.4, 3.4, 1.5, 0.4],\n        [5.2, 4.1, 1.5, 0.1],\n        [5.5, 4.2, 1.4, 0.2],\n        [4.9, 3.1, 1.5, 0.2],\n        [5. , 3.2, 1.2, 0.2],\n        [5.5, 3.5, 1.3, 0.2],\n        [4.9, 3.6, 1.4, 0.1],\n        [4.4, 3. , 1.3, 0.2],\n        [5.1, 3.4, 1.5, 0.2],\n        [5. , 3.5, 1.3, 0.3],\n        [4.5, 2.3, 1.3, 0.3],\n        [4.4, 3.2, 1.3, 0.2],\n        [5. , 3.5, 1.6, 0.6],\n        [5.1, 3.8, 1.9, 0.4],\n        [4.8, 3. , 1.4, 0.3],\n        [5.1, 3.8, 1.6, 0.2],\n        [4.6, 3.2, 1.4, 0.2],\n        [5.3, 3.7, 1.5, 0.2],\n        [5. , 3.3, 1.4, 0.2],\n        [7. , 3.2, 4.7, 1.4],\n        [6.4, 3.2, 4.5, 1.5],\n        [6.9, 3.1, 4.9, 1.5],\n        [5.5, 2.3, 4. , 1.3],\n        [6.5, 2.8, 4.6, 1.5],\n        [5.7, 2.8, 4.5, 1.3],\n        [6.3, 3.3, 4.7, 1.6],\n        [4.9, 2.4, 3.3, 1. ],\n        [6.6, 2.9, 4.6, 1.3],\n        [5.2, 2.7, 3.9, 1.4],\n        [5. , 2. , 3.5, 1. ],\n        [5.9, 3. , 4.2, 1.5],\n        [6. , 2.2, 4. , 1. ],\n        [6.1, 2.9, 4.7, 1.4],\n        [5.6, 2.9, 3.6, 1.3],\n        [6.7, 3.1, 4.4, 1.4],\n        [5.6, 3. , 4.5, 1.5],\n        [5.8, 2.7, 4.1, 1. ],\n        [6.2, 2.2, 4.5, 1.5],\n        [5.6, 2.5, 3.9, 1.1],\n        [5.9, 3.2, 4.8, 1.8],\n        [6.1, 2.8, 4. , 1.3],\n        [6.3, 2.5, 4.9, 1.5],\n        [6.1, 2.8, 4.7, 1.2],\n        [6.4, 2.9, 4.3, 1.3],\n        [6.6, 3. , 4.4, 1.4],\n        [6.8, 2.8, 4.8, 1.4],\n        [6.7, 3. , 5. , 1.7],\n        [6. , 2.9, 4.5, 1.5],\n        [5.7, 2.6, 3.5, 1. ],\n        [5.5, 2.4, 3.8, 1.1],\n        [5.5, 2.4, 3.7, 1. ],\n        [5.8, 2.7, 3.9, 1.2],\n        [6. , 2.7, 5.1, 1.6],\n        [5.4, 3. , 4.5, 1.5],\n        [6. , 3.4, 4.5, 1.6],\n        [6.7, 3.1, 4.7, 1.5],\n        [6.3, 2.3, 4.4, 1.3],\n        [5.6, 3. , 4.1, 1.3],\n        [5.5, 2.5, 4. , 1.3],\n        [5.5, 2.6, 4.4, 1.2],\n        [6.1, 3. , 4.6, 1.4],\n        [5.8, 2.6, 4. , 1.2],\n        [5. , 2.3, 3.3, 1. ],\n        [5.6, 2.7, 4.2, 1.3],\n        [5.7, 3. , 4.2, 1.2],\n        [5.7, 2.9, 4.2, 1.3],\n        [6.2, 2.9, 4.3, 1.3],\n        [5.1, 2.5, 3. , 1.1],\n        [5.7, 2.8, 4.1, 1.3],\n        [6.3, 3.3, 6. , 2.5],\n        [5.8, 2.7, 5.1, 1.9],\n        [7.1, 3. , 5.9, 2.1],\n        [6.3, 2.9, 5.6, 1.8],\n        [6.5, 3. , 5.8, 2.2],\n        [7.6, 3. , 6.6, 2.1],\n        [4.9, 2.5, 4.5, 1.7],\n        [7.3, 2.9, 6.3, 1.8],\n        [6.7, 2.5, 5.8, 1.8],\n        [7.2, 3.6, 6.1, 2.5],\n        [6.5, 3.2, 5.1, 2. ],\n        [6.4, 2.7, 5.3, 1.9],\n        [6.8, 3. , 5.5, 2.1],\n        [5.7, 2.5, 5. , 2. ],\n        [5.8, 2.8, 5.1, 2.4],\n        [6.4, 3.2, 5.3, 2.3],\n        [6.5, 3. , 5.5, 1.8],\n        [7.7, 3.8, 6.7, 2.2],\n        [7.7, 2.6, 6.9, 2.3],\n        [6. , 2.2, 5. , 1.5],\n        [6.9, 3.2, 5.7, 2.3],\n        [5.6, 2.8, 4.9, 2. ],\n        [7.7, 2.8, 6.7, 2. ],\n        [6.3, 2.7, 4.9, 1.8],\n        [6.7, 3.3, 5.7, 2.1],\n        [7.2, 3.2, 6. , 1.8],\n        [6.2, 2.8, 4.8, 1.8],\n        [6.1, 3. , 4.9, 1.8],\n        [6.4, 2.8, 5.6, 2.1],\n        [7.2, 3. , 5.8, 1.6],\n        [7.4, 2.8, 6.1, 1.9],\n        [7.9, 3.8, 6.4, 2. ],\n        [6.4, 2.8, 5.6, 2.2],\n        [6.3, 2.8, 5.1, 1.5],\n        [6.1, 2.6, 5.6, 1.4],\n        [7.7, 3. , 6.1, 2.3],\n        [6.3, 3.4, 5.6, 2.4],\n        [6.4, 3.1, 5.5, 1.8],\n        [6. , 3. , 4.8, 1.8],\n        [6.9, 3.1, 5.4, 2.1],\n        [6.7, 3.1, 5.6, 2.4],\n        [6.9, 3.1, 5.1, 2.3],\n        [5.8, 2.7, 5.1, 1.9],\n        [6.8, 3.2, 5.9, 2.3],\n        [6.7, 3.3, 5.7, 2.5],\n        [6.7, 3. , 5.2, 2.3],\n        [6.3, 2.5, 5. , 1.9],\n        [6.5, 3. , 5.2, 2. ],\n        [6.2, 3.4, 5.4, 2.3],\n        [5.9, 3. , 5.1, 1.8]]),\n 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n 'frame': None,\n 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='&lt;U10'),\n 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. dropdown:: References\\n\\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n    Mathematical Statistics\" (John Wiley, NY, 1950).\\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n    Structure and Classification Rule for Recognition in Partially Exposed\\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n    on Information Theory, May 1972, 431-433.\\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n    conceptual clustering system finds 3 classes in the data.\\n  - Many, many more ...\\n',\n 'feature_names': ['sepal length (cm)',\n  'sepal width (cm)',\n  'petal length (cm)',\n  'petal width (cm)'],\n 'filename': 'iris.csv',\n 'data_module': 'sklearn.datasets.data'}\n\n\n\niris = pd.DataFrame(iris.data, columns=iris.feature_names)\niris\n\n\n\n\n\n\n\n\nsepal length (cm)\nsepal width (cm)\npetal length (cm)\npetal width (cm)\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\n\n\n1\n4.9\n3.0\n1.4\n0.2\n\n\n2\n4.7\n3.2\n1.3\n0.2\n\n\n3\n4.6\n3.1\n1.5\n0.2\n\n\n4\n5.0\n3.6\n1.4\n0.2\n\n\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\n\n\n146\n6.3\n2.5\n5.0\n1.9\n\n\n147\n6.5\n3.0\n5.2\n2.0\n\n\n148\n6.2\n3.4\n5.4\n2.3\n\n\n149\n5.9\n3.0\n5.1\n1.8\n\n\n\n\n150 rows × 4 columns\n\n\n\n\niris.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 4 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   sepal length (cm)  150 non-null    float64\n 1   sepal width (cm)   150 non-null    float64\n 2   petal length (cm)  150 non-null    float64\n 3   petal width (cm)   150 non-null    float64\ndtypes: float64(4)\nmemory usage: 4.8 KB\n\n\n\niris.describe()\n\n\n\n\n\n\n\n\nsepal length (cm)\nsepal width (cm)\npetal length (cm)\npetal width (cm)\n\n\n\n\ncount\n150.000000\n150.000000\n150.000000\n150.000000\n\n\nmean\n5.843333\n3.057333\n3.758000\n1.199333\n\n\nstd\n0.828066\n0.435866\n1.765298\n0.762238\n\n\nmin\n4.300000\n2.000000\n1.000000\n0.100000\n\n\n25%\n5.100000\n2.800000\n1.600000\n0.300000\n\n\n50%\n5.800000\n3.000000\n4.350000\n1.300000\n\n\n75%\n6.400000\n3.300000\n5.100000\n1.800000\n\n\nmax\n7.900000\n4.400000\n6.900000\n2.500000\n\n\n\n\n\n\n\nsepal length와 petal width의 값의 차이가 크다.\n전처리 과정에서 변수 정규화 수행의 근거가 된다.\n\n\nindex / column 명 변경\n\ndf.index\n\nRangeIndex(start=0, stop=2, step=1)\n\n\n\nlist(df.index)\n\n[0, 1]\n\n\n\ndf.index = ['A', 'B']\ndf.index\n\nIndex(['A', 'B'], dtype='object')\n\n\n\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n\n\n\n\nA\nkor\n70\n\n\nB\nmath\n80\n\n\n\n\n\n\n\n\ndf.set_index('class', drop=True, append=False, inplace=True)\ndf\n\n\n\n\n\n\n\n\nscore\n\n\nclass\n\n\n\n\n\nkor\n70\n\n\nmath\n80\n\n\n\n\n\n\n\n\ndf.reset_index(drop=False, inplace=True)\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n\n\n\n\n0\nkor\n70\n\n\n1\nmath\n80\n\n\n\n\n\n\n\n\niris.columns\n\nIndex(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n       'petal width (cm)'],\n      dtype='object')\n\n\n\niris.columns = ['sepal length', 'sepal width', 'petal length', 'petal width']\niris\n\n\n\n\n\n\n\n\nsepal length\nsepal width\npetal length\npetal width\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\n\n\n1\n4.9\n3.0\n1.4\n0.2\n\n\n2\n4.7\n3.2\n1.3\n0.2\n\n\n3\n4.6\n3.1\n1.5\n0.2\n\n\n4\n5.0\n3.6\n1.4\n0.2\n\n\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\n\n\n146\n6.3\n2.5\n5.0\n1.9\n\n\n147\n6.5\n3.0\n5.2\n2.0\n\n\n148\n6.2\n3.4\n5.4\n2.3\n\n\n149\n5.9\n3.0\n5.1\n1.8\n\n\n\n\n150 rows × 4 columns\n\n\n\n\niris.columns = iris.columns.str.replace(' ', '_')\niris\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\n\n\n1\n4.9\n3.0\n1.4\n0.2\n\n\n2\n4.7\n3.2\n1.3\n0.2\n\n\n3\n4.6\n3.1\n1.5\n0.2\n\n\n4\n5.0\n3.6\n1.4\n0.2\n\n\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\n\n\n146\n6.3\n2.5\n5.0\n1.9\n\n\n147\n6.5\n3.0\n5.2\n2.0\n\n\n148\n6.2\n3.4\n5.4\n2.3\n\n\n149\n5.9\n3.0\n5.1\n1.8\n\n\n\n\n150 rows × 4 columns\n\n\n\n\n\n데이터 타입 변경\n사용 가능한 타입\n\nint\nfloat\nbool\ndatetime\ncategory\nobject\n\n\niris.dtypes\n\nsepal_length    float64\nsepal_width     float64\npetal_length    float64\npetal_width     float64\ndtype: object\n\n\n\niris['sepal_length'] = iris['sepal_length'].astype('int')\niris[['sepal_width', 'petal_length']] = \\\niris[['sepal_width', 'petal_length']].astype('int')\niris\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\n0\n5\n3\n1\n0.2\n\n\n1\n4\n3\n1\n0.2\n\n\n2\n4\n3\n1\n0.2\n\n\n3\n4\n3\n1\n0.2\n\n\n4\n5\n3\n1\n0.2\n\n\n...\n...\n...\n...\n...\n\n\n145\n6\n3\n5\n2.3\n\n\n146\n6\n2\n5\n1.9\n\n\n147\n6\n3\n5\n2.0\n\n\n148\n6\n3\n5\n2.3\n\n\n149\n5\n3\n5\n1.8\n\n\n\n\n150 rows × 4 columns",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "pandas data 구조"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/01.html#row-coumn-선택-추가-삭제",
    "href": "posts/04_archives/adp_실기/notes/01.html#row-coumn-선택-추가-삭제",
    "title": "pandas data 구조",
    "section": "row / coumn 선택 추가 삭제",
    "text": "row / coumn 선택 추가 삭제\n\nrow 선택\n\niris[0:4]\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\n0\n5\n3\n1\n0.2\n\n\n1\n4\n3\n1\n0.2\n\n\n2\n4\n3\n1\n0.2\n\n\n3\n4\n3\n1\n0.2\n\n\n\n\n\n\n\n\n\ncolumn 선택\nSeries 형식으로 출력\n\niris['sepal_length']\n\n0      5\n1      4\n2      4\n3      4\n4      5\n      ..\n145    6\n146    6\n147    6\n148    6\n149    5\nName: sepal_length, Length: 150, dtype: int64\n\n\nDataFrame 형식으로 출력\n\niris[['sepal_length', 'sepal_width']]\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\n\n\n\n\n0\n5\n3\n\n\n1\n4\n3\n\n\n2\n4\n3\n\n\n3\n4\n3\n\n\n4\n5\n3\n\n\n...\n...\n...\n\n\n145\n6\n3\n\n\n146\n6\n2\n\n\n147\n6\n3\n\n\n148\n6\n3\n\n\n149\n5\n3\n\n\n\n\n150 rows × 2 columns\n\n\n\n\n\ncolumn, row 선택\n\niris.loc[0:4, ['sepal_length', 'sepal_width']]\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\n\n\n\n\n0\n5\n3\n\n\n1\n4\n3\n\n\n2\n4\n3\n\n\n3\n4\n3\n\n\n4\n5\n3\n\n\n\n\n\n\n\n\niris.iloc[0:4, [1, 2]]\n\n\n\n\n\n\n\n\nsepal_width\npetal_length\n\n\n\n\n0\n3\n1\n\n\n1\n3\n1\n\n\n2\n3\n1\n\n\n3\n3\n1\n\n\n\n\n\n\n\n\n\nrow 추가\n\n# 방법 1: concat 사용\n# df = pd.concat([df, pd.DataFrame([{'class': 'eng', 'score': 90}])], ignore_index=True)\n\n# 방법 2: loc 사용 \ndf.loc[len(df)] = {'class': 'eng', 'score': 90}\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n\n\n\n\n0\nkor\n70\n\n\n1\nmath\n80\n\n\n2\neng\n90\n\n\n\n\n\n\n\n\n\ncolumn 추가\n\ndf['yo'] = df['score'] + 10\ndf\n\n\n\n\n\n\n\n\nclass\nscore\nyo\n\n\n\n\n0\nkor\n70\n80\n\n\n1\nmath\n80\n90\n\n\n2\neng\n90\n100\n\n\n\n\n\n\n\n\n\nrow 삭제\n\ndf.drop(2, inplace=True)\ndf\n\n\n\n\n\n\n\n\nclass\nscore\nyo\n\n\n\n\n0\nkor\n70\n80\n\n\n1\nmath\n80\n90\n\n\n\n\n\n\n\n\n\ncolumn 삭제\n\ndf.drop(columns=['yo'], inplace=True)\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n\n\n\n\n0\nkor\n70\n\n\n1\nmath\n80",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "pandas data 구조"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/01.html#조건-선택",
    "href": "posts/04_archives/adp_실기/notes/01.html#조건-선택",
    "title": "pandas data 구조",
    "section": "조건 선택",
    "text": "조건 선택\n\niris[(iris['sepal_length'] &gt; 5) & (iris['sepal_width'] &lt; 3)]\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\n54\n6\n2\n4\n1.5\n\n\n58\n6\n2\n4\n1.3\n\n\n62\n6\n2\n4\n1.0\n\n\n63\n6\n2\n4\n1.4\n\n\n68\n6\n2\n4\n1.5\n\n\n...\n...\n...\n...\n...\n\n\n130\n7\n2\n6\n1.9\n\n\n132\n6\n2\n5\n2.2\n\n\n133\n6\n2\n5\n1.5\n\n\n134\n6\n2\n5\n1.4\n\n\n146\n6\n2\n5\n1.9\n\n\n\n\n29 rows × 4 columns\n\n\n\n\ndf.loc[df['score'] &gt; 70, '합격'] = 'Pass'\ndf.loc[df['합격'] != 'Pass', '합격'] = 'Fail'\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n합격\n\n\n\n\n0\nkor\n70\nFail\n\n\n1\nmath\n80\nPass\n\n\n\n\n\n\n\n\nimport numpy as np\n\ncondition_list = [(df['score'] &gt;= 70), \n                  (df['score'] &lt; 70) & (df['score'] &gt;= 60),\n                  (df['score'] &lt; 60)]\ngrade_list = ['A', 'B', 'C']\ndf['grade'] = np.select(condition_list, grade_list, default='F')\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n합격\ngrade\n\n\n\n\n0\nkor\n70\nFail\nA\n\n\n1\nmath\n80\nPass\nA\n\n\n\n\n\n\n\n\n결측치 탐색\n\ndf.isna().sum()\n\nclass    0\nscore    0\n합격       0\ngrade    0\ndtype: int64\n\n\n\ndf.notna().sum(1) # 행 기준\n\n0    4\n1    4\ndtype: int64\n\n\n\n\n결측치 제거\n\n# dropna(axis=0, how='any' or 'all', thresh=None, subset=None, inplace=False)\ndf.dropna()\n\n\n\n\n\n\n\n\nclass\nscore\n합격\ngrade\n\n\n\n\n0\nkor\n70\nFail\nA\n\n\n1\nmath\n80\nPass\nA\n\n\n\n\n\n\n\n\n\n결측치 대체\n\n# fillna(value=None, method=None ('pad', 'ffill', 'backfill', 'bfill'), axis=None, inplace=False, limit=None)",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "pandas data 구조"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/14_machine_learning.html",
    "href": "posts/04_archives/aws_saa/notes/14_machine_learning.html",
    "title": "Amazon Rekognition",
    "section": "",
    "text": "Amazon Rekognition\n\nfind objects, people, text, scenes in image and video analysis ## content moderation\ndetect explicit and suggestive content\na2i for human review\n\n\n\nAmazon Transcribe\n: speech-to-text service\n\n\nAmazon Polly\n: text-to-speech service\n\n\nAmazon Translate\n: language translation service\n\n\nAmazon Comprehend\n: natural language processing service\n\n\nAmazon Lex\n: chatbot service\n\n\nAmazon SageMaker\n: machine learning service\n\n\nAmazon Forecast\n: time series forecasting service\n\n\nkendra\n: document search service\n\n\nAmazon Personalize\n: personalized recommendation service\n\n\nTextract\n: OCR service\n\n\n\n\n 맨 위로",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon Rekognition"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/02_ec2.html",
    "href": "posts/04_archives/aws_saa/notes/02_ec2.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "EC2 stands for Elastic Compute Cloud. It is a web service provided by Amazon Web Services (AWS) that allows users to rent virtual servers in the cloud.\nEC2 instances can be easily scaled up or down based on the user’s needs, providing flexibility and cost efficiency.\nThese instances can be used to run applications, host websites, process large amounts of data, and perform various other computing tasks.\nEC2 offers a wide range of instance types to cater to different workloads, and users have full control over the configuration and management of their instances.\n\n\n\nlaunch virtual servers\nmanage storage (EBS, EFS, S3)\nscale up or down based on demand (ASG)\ndistribute traffic across multiple instances (ELB)\n\n\n\n\n\nos\nCPU\nmemory\nstorage\nnetwork\nsecurity (IAM, security groups, key pairs)\nbootstrap scripts (user data)\n\n\n\n\n\ngeneral purpose (t2, m5)\ncompute optimized (c5)\nmemory optimized (r5)\nstorage optimized (i3)\naccelerated computing (p3, g4)\n\n\n\n\n\nact as a virtual firewall for your EC2 instances\ncontrol inbound and outbound traffic\ncan be associated with multiple instances\nlocked down to a region/VPC combination\ndoes live outside the EC2 - if traffic is blocked, the EC2 instance won’t see it (time out)\ncan reference other security groups\n\n\n\n\n\non-demand: pay for what you use\nreserved: capacity reservation for 1 or 3 years\n\n\nreserved\nconvertible reserved instances\ngood for steady-state usage application(db)\nreserve a specific instance attributes (instance type, region, tenancy, os)\nyou can buy and sell in marketplace\n\n\nspot: bid for unused capacity\nsavings plan: commit to a consistent amount of usage for a discount\nif beyond pay, converted to on-demand\nlocked to a specific instance family, aws region\nflexible: instance size, os, tenancy\ndedicated hosts: physical server dedicated for your use\ndedicated instances: instance running on a dedicated host\ncapacity reservation: reserve capacity for specific instance type in a specific AZ\n\n\n\n\n\ncluster: low latency, high throughput\npartition: multiple EC2 instances within a single AZ\nspread: EC2 instances on distinct hardware, maximum 7",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "what is EC2"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/02_ec2.html#what-is-ec2",
    "href": "posts/04_archives/aws_saa/notes/02_ec2.html#what-is-ec2",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "EC2 stands for Elastic Compute Cloud. It is a web service provided by Amazon Web Services (AWS) that allows users to rent virtual servers in the cloud.\nEC2 instances can be easily scaled up or down based on the user’s needs, providing flexibility and cost efficiency.\nThese instances can be used to run applications, host websites, process large amounts of data, and perform various other computing tasks.\nEC2 offers a wide range of instance types to cater to different workloads, and users have full control over the configuration and management of their instances.\n\n\n\nlaunch virtual servers\nmanage storage (EBS, EFS, S3)\nscale up or down based on demand (ASG)\ndistribute traffic across multiple instances (ELB)\n\n\n\n\n\nos\nCPU\nmemory\nstorage\nnetwork\nsecurity (IAM, security groups, key pairs)\nbootstrap scripts (user data)\n\n\n\n\n\ngeneral purpose (t2, m5)\ncompute optimized (c5)\nmemory optimized (r5)\nstorage optimized (i3)\naccelerated computing (p3, g4)\n\n\n\n\n\nact as a virtual firewall for your EC2 instances\ncontrol inbound and outbound traffic\ncan be associated with multiple instances\nlocked down to a region/VPC combination\ndoes live outside the EC2 - if traffic is blocked, the EC2 instance won’t see it (time out)\ncan reference other security groups\n\n\n\n\n\non-demand: pay for what you use\nreserved: capacity reservation for 1 or 3 years\n\n\nreserved\nconvertible reserved instances\ngood for steady-state usage application(db)\nreserve a specific instance attributes (instance type, region, tenancy, os)\nyou can buy and sell in marketplace\n\n\nspot: bid for unused capacity\nsavings plan: commit to a consistent amount of usage for a discount\nif beyond pay, converted to on-demand\nlocked to a specific instance family, aws region\nflexible: instance size, os, tenancy\ndedicated hosts: physical server dedicated for your use\ndedicated instances: instance running on a dedicated host\ncapacity reservation: reserve capacity for specific instance type in a specific AZ\n\n\n\n\n\ncluster: low latency, high throughput\npartition: multiple EC2 instances within a single AZ\nspread: EC2 instances on distinct hardware, maximum 7",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "what is EC2"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/07_S3.html",
    "href": "posts/04_archives/aws_saa/notes/07_S3.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "Simple Storage Service\nobject storage service\nunlimited storage\ndefined at region level\nmax object size: 5TB (larger objects than 5GB can be stored using multipart upload)\nkey: full path\nvalue: body\nversion ID: enabled at the bucket level\nmetadata\ntags\n\n\n\n\nuser-based\n\nIAM policies\n\nresource-based\n\nbucket policies: allows cross account\nbucket ACL(Access Control List)\nobject ACL\n\nblock public access\n\n\n\n\n\nCRR: Cross-Region Replication\nSRR: Same-Region Replication\nversioning must be enabled on both source and destination buckets\nreplication is asynchronous\nreplication is cross-account\n\n\n\n\ndelete marker is replicated\noptional setting\n\n\n\n\n\ncan replicate existing objects and failed replication\n\n\n\n\n\n\nS3 Standard: 99.99% availability, general purpose #### infrequent access : for data that is less frequently accessed but requires rapid access when needed\nS3 Standard-IA: 99.9% availability\nS3 One Zone-IA: 99.5% availability #### Glacier : lower cost, for archive / backup\nS3 Glacier instant retrieval: milliseconds retrieval, 90 days minimum storage\nS3 Glacier flexible retireval: minutes to hours retrieval, 90 days minimum storage\nS3 Glacier Deep Archive: 12 hours to 48 hours retrieval, 180 days minimum storage\nS3 Intelligent-Tiering: auto pricing, auto move between IA and Standard\n\n\n\n\n: automate moving objects between storage classes - transition action - expriation action\n\n\n\n\nS3 event notification: SNS, SQS, Lambda\n\n\n\n\n\n3,500 PUT/COPY/POST/DELETE and 5,500 GET/HEAD requests per second per prefix in a bucket\n\n\n\n\n\nCloudFront edge locations\nmultipart upload is compatible\n\n\n\n\n\n\n\nS3 byte-range fetches\n\n\n\n\n\n\nS3 select: SQL query on S3 objects\nGlacier select: SQL query on Glacier objects\n\n\n\n\n\nS3 Batch Operations: S3 operations on large number of objects use cases: encrypt unencrypted objects, copy objects, … \n\n\n\n\n\nmulti-account, multi-region analyze dashboard\n\n\n\n\n\nSSE\n\nSSE-S3: S3 managed keys, enabled by default, must set request header x-amz-server-side-encryption: AES256\nSSE-KMS: KMS managed, must set request header x-amz-server-side-encryption: aws:kms, request limits\nSSE-C: customer managed, must set request header x-amz-server-side-encryption-customer-algorithm: AES256, must provide encryption key\n\nCSE\n\nclient-side encryption\n\n\n\n\n\n\npermanently delete objects\nsuspend versioning on bucket\nto enable, must enable versioning on bucket and only the bucket owner(root account) can enable MFA\n\n\n\n\n\ncompliance and WORM (Write Once Read Many) model\nbucket level lock\n\n\n\n\n\ncompliance and WORM (Write Once Read Many) model\nblock object deletion for a specified retention period\nmust set versioning\ncompliance and governance mode\nlegal hold: protect object from deletion indefinitely",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS S3"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/07_S3.html#aws-s3",
    "href": "posts/04_archives/aws_saa/notes/07_S3.html#aws-s3",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "Simple Storage Service\nobject storage service\nunlimited storage\ndefined at region level\nmax object size: 5TB (larger objects than 5GB can be stored using multipart upload)\nkey: full path\nvalue: body\nversion ID: enabled at the bucket level\nmetadata\ntags\n\n\n\n\nuser-based\n\nIAM policies\n\nresource-based\n\nbucket policies: allows cross account\nbucket ACL(Access Control List)\nobject ACL\n\nblock public access\n\n\n\n\n\nCRR: Cross-Region Replication\nSRR: Same-Region Replication\nversioning must be enabled on both source and destination buckets\nreplication is asynchronous\nreplication is cross-account\n\n\n\n\ndelete marker is replicated\noptional setting\n\n\n\n\n\ncan replicate existing objects and failed replication\n\n\n\n\n\n\nS3 Standard: 99.99% availability, general purpose #### infrequent access : for data that is less frequently accessed but requires rapid access when needed\nS3 Standard-IA: 99.9% availability\nS3 One Zone-IA: 99.5% availability #### Glacier : lower cost, for archive / backup\nS3 Glacier instant retrieval: milliseconds retrieval, 90 days minimum storage\nS3 Glacier flexible retireval: minutes to hours retrieval, 90 days minimum storage\nS3 Glacier Deep Archive: 12 hours to 48 hours retrieval, 180 days minimum storage\nS3 Intelligent-Tiering: auto pricing, auto move between IA and Standard\n\n\n\n\n: automate moving objects between storage classes - transition action - expriation action\n\n\n\n\nS3 event notification: SNS, SQS, Lambda\n\n\n\n\n\n3,500 PUT/COPY/POST/DELETE and 5,500 GET/HEAD requests per second per prefix in a bucket\n\n\n\n\n\nCloudFront edge locations\nmultipart upload is compatible\n\n\n\n\n\n\n\nS3 byte-range fetches\n\n\n\n\n\n\nS3 select: SQL query on S3 objects\nGlacier select: SQL query on Glacier objects\n\n\n\n\n\nS3 Batch Operations: S3 operations on large number of objects use cases: encrypt unencrypted objects, copy objects, … \n\n\n\n\n\nmulti-account, multi-region analyze dashboard\n\n\n\n\n\nSSE\n\nSSE-S3: S3 managed keys, enabled by default, must set request header x-amz-server-side-encryption: AES256\nSSE-KMS: KMS managed, must set request header x-amz-server-side-encryption: aws:kms, request limits\nSSE-C: customer managed, must set request header x-amz-server-side-encryption-customer-algorithm: AES256, must provide encryption key\n\nCSE\n\nclient-side encryption\n\n\n\n\n\n\npermanently delete objects\nsuspend versioning on bucket\nto enable, must enable versioning on bucket and only the bucket owner(root account) can enable MFA\n\n\n\n\n\ncompliance and WORM (Write Once Read Many) model\nbucket level lock\n\n\n\n\n\ncompliance and WORM (Write Once Read Many) model\nblock object deletion for a specified retention period\nmust set versioning\ncompliance and governance mode\nlegal hold: protect object from deletion indefinitely",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS S3"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/13_data_analytics.html",
    "href": "posts/04_archives/aws_saa/notes/13_data_analytics.html",
    "title": "Amazon Redshift",
    "section": "",
    "text": "SQLqueries -S3as data source - supportsCSV,JSON,Parquet,ORCdata formats - 5$ per TB scanned ## Performance Improvement - usecolumnardata formats (less scan) =&gt;Parquet,ORCby usingAWS Glue- compress data =&gt;GZIP,Snappy,LZO-partition datasetsin S3 for easy querying on virtual columns (path) -Use larger files` (&gt; 128MB) to minimize overhead",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Performance Improvement"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/13_data_analytics.html#federated-query",
    "href": "posts/04_archives/aws_saa/notes/13_data_analytics.html#federated-query",
    "title": "Amazon Redshift",
    "section": "Federated Query",
    "text": "Federated Query\nallows you to query data in relational, non-relational, object, … in a single query on AWS or on-premises",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Performance Improvement"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/13_data_analytics.html#cluster",
    "href": "posts/04_archives/aws_saa/notes/13_data_analytics.html#cluster",
    "title": "Amazon Redshift",
    "section": "cluster",
    "text": "cluster\n\nleader node\ncompute node",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Performance Improvement"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/13_data_analytics.html#snapshots-and-dr",
    "href": "posts/04_archives/aws_saa/notes/13_data_analytics.html#snapshots-and-dr",
    "title": "Amazon Redshift",
    "section": "snapshots and DR",
    "text": "snapshots and DR\n\nMulti-AZ for some cluster\nsnapshots are point-in-time backups in S3\nchange is saved\nautomate snapshot, manual snapshote",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Performance Improvement"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/13_data_analytics.html#loading-data-into-redshift",
    "href": "posts/04_archives/aws_saa/notes/13_data_analytics.html#loading-data-into-redshift",
    "title": "Amazon Redshift",
    "section": "loading data into redshift",
    "text": "loading data into redshift\n\nAmazon Kinesis Data Firehose\nAmazon S3 copy\nEC2 instance JDBC driver",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Performance Improvement"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/13_data_analytics.html#redshift-spectrum",
    "href": "posts/04_archives/aws_saa/notes/13_data_analytics.html#redshift-spectrum",
    "title": "Amazon Redshift",
    "section": "Redshift Spectrum",
    "text": "Redshift Spectrum\n: query data directly in S3 without loading it into Redshift",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Performance Improvement"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/10_message_queue.html",
    "href": "posts/04_archives/aws_saa/notes/10_message_queue.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "Amazon Simple Queue Service (SQS) is a fully managed message queuing service that makes it easy to decouple and scale microservices, distributed systems, and serverless applications.\nunlimited throughput, no limit on the number of messages\nmessage retention period: default 4 days, maximum 14 days.\nlimit on message size 256kb\ncan have duplicate messages, out of order messages =&gt; need to handle in application or use FIFO queue\nSQS Access Policy\n\n\n\n\nthe amount of time that the message is invisible in the queue after a reader picks up the message.\ncan increase timeout by calling ChangeMessageVisibility API\n\n\n\n\n\nif no message in queue, the request will wait for a message to arrive for a certain amount of time.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS SQS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/10_message_queue.html#aws-sqs",
    "href": "posts/04_archives/aws_saa/notes/10_message_queue.html#aws-sqs",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "Amazon Simple Queue Service (SQS) is a fully managed message queuing service that makes it easy to decouple and scale microservices, distributed systems, and serverless applications.\nunlimited throughput, no limit on the number of messages\nmessage retention period: default 4 days, maximum 14 days.\nlimit on message size 256kb\ncan have duplicate messages, out of order messages =&gt; need to handle in application or use FIFO queue\nSQS Access Policy\n\n\n\n\nthe amount of time that the message is invisible in the queue after a reader picks up the message.\ncan increase timeout by calling ChangeMessageVisibility API\n\n\n\n\n\nif no message in queue, the request will wait for a message to arrive for a certain amount of time.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS SQS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/10_message_queue.html#aws-sns",
    "href": "posts/04_archives/aws_saa/notes/10_message_queue.html#aws-sns",
    "title": "김형훈의 학습 블로그",
    "section": "AWS SNS",
    "text": "AWS SNS\n\npublish/subscribe messaging service\nSNS FIFO (only SQS can subscribe)\nmessage filtering\n\n\nFanout\nSNS + multiple SQS",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS SQS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/10_message_queue.html#amazon-kinesis",
    "href": "posts/04_archives/aws_saa/notes/10_message_queue.html#amazon-kinesis",
    "title": "김형훈의 학습 블로그",
    "section": "Amazon Kinesis",
    "text": "Amazon Kinesis\n\nKinesis Data Streams\n\nreal-time data streaming service\ndata retention: default 24 hours, maximum 365 days\nonce data inserted, cannot be deleted\nprovisioned mode, on-demand mode\nVPC endpoint available \n\n\n\nKinensis Data Firehose\n\ndata transformation, compression, encryption\nbatch data delivery\nserverless  \n\n\n\nKinesis Data Analytics\n\n\nKinesis Video Streams",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS SQS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/11_serverless.html",
    "href": "posts/04_archives/aws_saa/notes/11_serverless.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "AWS Lambda is a serverless compute service that lets you run code without provisioning or managing servers.\nLambda runs your code only when needed and scales automatically, from a few requests per day to thousands per second.\nYou pay only for the compute time you consume - there is no charge when your code is not running. ### limitation (per region)\nmemory: 128MB - 10GB (more memory, need more vCPU)\nmax execution time: 15 minutes\nenvironment variables: 4KB\n/tmp directory storage: 512MB to 10GB\nconcurrent executions: 1000\ndeployment package: 50MB (zipped)\ndeployment package: 250MB (unzipped)\n\n\n\n\n\n\n\n\n\nLambda@Edge",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Lambda"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/11_serverless.html#aws-lambda",
    "href": "posts/04_archives/aws_saa/notes/11_serverless.html#aws-lambda",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "AWS Lambda is a serverless compute service that lets you run code without provisioning or managing servers.\nLambda runs your code only when needed and scales automatically, from a few requests per day to thousands per second.\nYou pay only for the compute time you consume - there is no charge when your code is not running. ### limitation (per region)\nmemory: 128MB - 10GB (more memory, need more vCPU)\nmax execution time: 15 minutes\nenvironment variables: 4KB\n/tmp directory storage: 512MB to 10GB\nconcurrent executions: 1000\ndeployment package: 50MB (zipped)\ndeployment package: 250MB (unzipped)\n\n\n\n\n\n\n\n\n\nLambda@Edge",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Lambda"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/11_serverless.html#dynamodb",
    "href": "posts/04_archives/aws_saa/notes/11_serverless.html#dynamodb",
    "title": "김형훈의 학습 블로그",
    "section": "DynamoDB",
    "text": "DynamoDB\n\nAmazon DynamoDB is a fully managed, serverless, key-value and document database that delivers single-digit millisecond performance at any scale.\nstandard table: high availability, durability, and performance\nIA table: infrequently accessed data\nmax item size: 400KB\nprovisioned mode, on-demand mode\n\n\nDynamoDB Accelerator (DAX)\n\nAmazon DynamoDB Accelerator (DAX) is a fully managed, highly available, in-memory cache for DynamoDB that delivers up to a 10x performance improvement - from milliseconds to microseconds - even at millions of requests per second.\nmicroseconds latency\nno need to modify application \n\n\n\nDynamoDB Streams\n\nDynamoDB Streams is an optional feature that captures data modification events in DynamoDB tables.\ncan trigger lambda function, SQS, Kinesis\n24 hours retention period\nlimit: 5 active streams per table\n\n\n\nGlobal Tables\n\nAmazon DynamoDB global tables provide a fully managed solution for deploying a multi-region, multi-master database, without having to build and maintain your own replication solution.\nautomatic replication\nmust enable DynamoDB Streams\n\n\n\nbackup and restore\n\nPoint-in-Time Recovery\n\nPoint-in-time recovery helps protect your DynamoDB tables from accidental write or delete operations.\nrestore to any point in time within 35 days\nthe recovery process creates a new table\n\non-demand backup\n\nrestore to any point\nthe recovery process creates a new table",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Lambda"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/11_serverless.html#api-gateway",
    "href": "posts/04_archives/aws_saa/notes/11_serverless.html#api-gateway",
    "title": "김형훈의 학습 블로그",
    "section": "API Gateway",
    "text": "API Gateway\n\nAmazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale.\nEdge-optimized API: global, use CloudFront\nRegional API: regional, use API Gateway\nPrivate API: VPC endpoint",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Lambda"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/11_serverless.html#step-functions",
    "href": "posts/04_archives/aws_saa/notes/11_serverless.html#step-functions",
    "title": "김형훈의 학습 블로그",
    "section": "Step Functions",
    "text": "Step Functions\n\nAWS Step Functions is a serverless function orchestrator that makes it easy to sequence AWS Lambda functions and multiple AWS services into business-critical applications.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Lambda"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/11_serverless.html#amazon-cognito",
    "href": "posts/04_archives/aws_saa/notes/11_serverless.html#amazon-cognito",
    "title": "김형훈의 학습 블로그",
    "section": "Amazon Cognito",
    "text": "Amazon Cognito\n\nAmazon Cognito lets you add user sign-up, sign-in, and access control to your web and mobile apps quickly and easily.\nUser Pools: user directory\nIdentity Pools: federated identity, temporary access AWS resources",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Lambda"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/03_ebs.html",
    "href": "posts/04_archives/aws_saa/notes/03_ebs.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "EBS is a network device designed to work with AWS EC2 instances.\nEBS volumes are placed in a specific AZ and are automatically replicated to protect you from component failure.\nEBS volumes attached only to one instance at a time.\nEBS volumes can be detached from one instance and attached to another.\nEBS volumes can be used as a boot volume.\nEBS volumes have a provisioned size and IOPS can be resized.\nEBS volumes can exist independently of an EC2 instance.\nmultiple EBS volumes can be attached to a single EC2 instance.\n\n\n\n\nBy default, the root EBS volume is deleted when the EC2 instance is terminated.\nAdditional EBS volumes are not deleted when the EC2 instance is terminated.\n\n\n\n\n\nEBS snapshots archive tier:\n75% cheaper than the general-purpose tier.\ntakes 24 to 72 hours to restore.\nrecycle bin:\nset up rule to retain deleted snapshots\ncan specify period\nFast Snapshot Restore(FSR):\nforce full initialization of the EBS volume to have no latency\ntakes money\n\n\n\n\nAmazon Machine Image - AMI is a template that contains a software configuration (OS, application server, and applications) required to launch an EC2 instance. - AMI is built for a specific region. - can be copied to other regions.\n\n\n\n\nbetter IO performance than EBS volumes\ndata is lost when the instance is stopped or terminated.\ncan’t be resized.\n\n\n\n\n\nGeneral Purpose SSD (gp2, gp3): can be used for boot volumes\n\ngenerally used for system boot volumes, virtual desktops, low-latency interactive apps, development, and test environments\ngp2: 1GiB - 16TiB, burst up to 3000 IOPS linked to volume size\ngp3: 1GiB - 16TiB, 3000 IOPS, 125MiB/s, burst up to 16000 IOPS, 1000MiB/s independently\n\nHigh Performance SSD (io1, io2): can be used for boot volumes\n\ncritical business applications that require sustained IOPS performance\nmore than 16000 IOPS\ngenerally used for databases\n4GiB - 16TiB\nMax PIOPS: 64000 for Nitro EC2, 32000 for other EC2\nCan increase PIOPS independently from volume size\nio2 have more durability and more IOPS per GiB\nio2 Block Express: 4GiB - 64TiB, 256000 IOPS\nsupport Multi-Attach\n\nbound in AZ\nup to 16 EC2 instances\nMust use a file system that is cluster-aware (GFS, OCFS2, NTFS)\n\n\nLow cost, designed for frequently accessed HDD (st1)\n\n125MiB - 16TiB\n500MiB/s - 500MiB/s\nused for big data, data warehouses, log processing\n\nLow cost, designed for less frequently accessed HDD (sc1)\n\n125MiB - 16TiB\n250MiB/s - 250MiB/s\nused for file servers, infrequently accessed workloads\n\n\n\n\n\n\nElastic File System\nscalable storage solution for EC2 instances\ncan be shared across multiple instances in multi-AZ\ncan be accessed by multiple instances simultaneously\nexpensive than EBS\ncan be used for `content management, web serving\nuse NFSv4.1 protocol\nuse security group to control access\ncompatible with Linux-based AMI\nPerformance Mode:\n\nGeneral Purpose: latency-sensitive use cases\nMax I/O: higher latency, higher throughput\n\nThroughput Mode:\n\nBursting: burstable throughput\nProvisioned: provisioned throughput\nElastic: elastic throughput\n\nstorage classes:\n\nStandard: frequently accessed\nInfrequent Access: infrequently accessed\nOne Zone: infrequently accessed, stored in a single AZ. 90% cheaper than Regional",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "what is ebs"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/03_ebs.html#what-is-ebs",
    "href": "posts/04_archives/aws_saa/notes/03_ebs.html#what-is-ebs",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "EBS is a network device designed to work with AWS EC2 instances.\nEBS volumes are placed in a specific AZ and are automatically replicated to protect you from component failure.\nEBS volumes attached only to one instance at a time.\nEBS volumes can be detached from one instance and attached to another.\nEBS volumes can be used as a boot volume.\nEBS volumes have a provisioned size and IOPS can be resized.\nEBS volumes can exist independently of an EC2 instance.\nmultiple EBS volumes can be attached to a single EC2 instance.\n\n\n\n\nBy default, the root EBS volume is deleted when the EC2 instance is terminated.\nAdditional EBS volumes are not deleted when the EC2 instance is terminated.\n\n\n\n\n\nEBS snapshots archive tier:\n75% cheaper than the general-purpose tier.\ntakes 24 to 72 hours to restore.\nrecycle bin:\nset up rule to retain deleted snapshots\ncan specify period\nFast Snapshot Restore(FSR):\nforce full initialization of the EBS volume to have no latency\ntakes money\n\n\n\n\nAmazon Machine Image - AMI is a template that contains a software configuration (OS, application server, and applications) required to launch an EC2 instance. - AMI is built for a specific region. - can be copied to other regions.\n\n\n\n\nbetter IO performance than EBS volumes\ndata is lost when the instance is stopped or terminated.\ncan’t be resized.\n\n\n\n\n\nGeneral Purpose SSD (gp2, gp3): can be used for boot volumes\n\ngenerally used for system boot volumes, virtual desktops, low-latency interactive apps, development, and test environments\ngp2: 1GiB - 16TiB, burst up to 3000 IOPS linked to volume size\ngp3: 1GiB - 16TiB, 3000 IOPS, 125MiB/s, burst up to 16000 IOPS, 1000MiB/s independently\n\nHigh Performance SSD (io1, io2): can be used for boot volumes\n\ncritical business applications that require sustained IOPS performance\nmore than 16000 IOPS\ngenerally used for databases\n4GiB - 16TiB\nMax PIOPS: 64000 for Nitro EC2, 32000 for other EC2\nCan increase PIOPS independently from volume size\nio2 have more durability and more IOPS per GiB\nio2 Block Express: 4GiB - 64TiB, 256000 IOPS\nsupport Multi-Attach\n\nbound in AZ\nup to 16 EC2 instances\nMust use a file system that is cluster-aware (GFS, OCFS2, NTFS)\n\n\nLow cost, designed for frequently accessed HDD (st1)\n\n125MiB - 16TiB\n500MiB/s - 500MiB/s\nused for big data, data warehouses, log processing\n\nLow cost, designed for less frequently accessed HDD (sc1)\n\n125MiB - 16TiB\n250MiB/s - 250MiB/s\nused for file servers, infrequently accessed workloads\n\n\n\n\n\n\nElastic File System\nscalable storage solution for EC2 instances\ncan be shared across multiple instances in multi-AZ\ncan be accessed by multiple instances simultaneously\nexpensive than EBS\ncan be used for `content management, web serving\nuse NFSv4.1 protocol\nuse security group to control access\ncompatible with Linux-based AMI\nPerformance Mode:\n\nGeneral Purpose: latency-sensitive use cases\nMax I/O: higher latency, higher throughput\n\nThroughput Mode:\n\nBursting: burstable throughput\nProvisioned: provisioned throughput\nElastic: elastic throughput\n\nstorage classes:\n\nStandard: frequently accessed\nInfrequent Access: infrequently accessed\nOne Zone: infrequently accessed, stored in a single AZ. 90% cheaper than Regional",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "what is ebs"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/06_route53.html",
    "href": "posts/04_archives/aws_saa/notes/06_route53.html",
    "title": "Route53",
    "section": "",
    "text": "Domain/subdomain\nRecord type (A, AAAA, CNAME, NS)\n\nA: IPv4\nAAAA: IPv6\nCNAME: Canonical name. cant be used for root domain\nNS: Name server (another DNS server)\nalias: Route53 specific. can be used for root domain. free. health check. no TTL, can’t be used for ec2 instance\n\nValue\nRouting policy\n\nSimple: one record with multiple values, choose randomly by client, no health check, if alias then specify only one\nWeighted: split traffic based on weight\nLatency based: split traffic based on latency\nFailover: primary and secondary\nGeolocation\nMultivalue answer: multiple values, health check, choose randomly by client\nGeo-proximity\n\nTTL\n\n\n\n\nEndpoint\nCalculated\nCloudWatch alarm",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Route53"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/06_route53.html#health-check",
    "href": "posts/04_archives/aws_saa/notes/06_route53.html#health-check",
    "title": "Route53",
    "section": "",
    "text": "Endpoint\nCalculated\nCloudWatch alarm",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Route53"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/19_DR.html",
    "href": "posts/04_archives/aws_saa/notes/19_DR.html",
    "title": "Disaster Recovery(DR)",
    "section": "",
    "text": "Disaster Recovery(DR)\n\nRPO: Recovery Point Objective\n\nthe maximum acceptable amount of data loss measured in time\n\nRTO: Recovery Time Objective\n\nthe maximum acceptable amount of time to recover the system  ## DR Strategies\n\nBackup and Restore: Simple but RPO and RTO are high\nPilot Light: Minimal version of the environment is always running\nWarm Standby: A scaled-down version of a fully functional environment is always running\nHot-site / Multi-Site Approach: Fully functional environment is always running\n\n\n\nDatabase Migration Service(DMS)\n\nmigrate data from one database to another\nsource is available during migration\nHomogeneous Migration: same database engine\nHeterogeneous Migration: different database engine. must use Schema Conversion Tool(SCT)\nContinuous Data Replication using CDC\n\n\n\n\n\n 맨 위로",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Disaster Recovery(DR)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/09_aws_storage.html",
    "href": "posts/04_archives/aws_saa/notes/09_aws_storage.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "AWS Snow Family is a collection of physical devices designed for use in edge locations, data centers, and in disconnected environments.\nData Migration: snowcone, snowball edge, snowmobile\nEdge Computing: snowcone, snowball edge  ### use process\n\n\nOrder: Order a Snow device from the AWS Management Console.\ninstall: Install the Snow client / AWS ops hub on your server\nTransfer: Transfer data to the Snow device using the Snow client.\nShip: Ship the Snow device back to AWS.\nLoad: Load the data into your S3 bucket.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Snow Family"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-snow-family",
    "href": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-snow-family",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "AWS Snow Family is a collection of physical devices designed for use in edge locations, data centers, and in disconnected environments.\nData Migration: snowcone, snowball edge, snowmobile\nEdge Computing: snowcone, snowball edge  ### use process\n\n\nOrder: Order a Snow device from the AWS Management Console.\ninstall: Install the Snow client / AWS ops hub on your server\nTransfer: Transfer data to the Snow device using the Snow client.\nShip: Ship the Snow device back to AWS.\nLoad: Load the data into your S3 bucket.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Snow Family"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-fsx",
    "href": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-fsx",
    "title": "김형훈의 학습 블로그",
    "section": "AWS FSx",
    "text": "AWS FSx\n\nAmazon FSx for Windows File Server: fully managed Windows file system\nAmazon FSx for Lustre: fully managed Lustre file system, seamlessly integrated with S3 (can read and write data directly to S3)\nAmazon FSx for NetApp ONTAP: fully managed NetApp ONTAP file system, point-in-time snapshots, data deduplication, and data compression\nAmazon FSx for OpenZFS: fully managed OpenZFS file system, point-in-time snapshots, data deduplication, and data compression\n\n\nFile System Deployment Options\n\nScratch File System: temporary storage for data processing. no replication.\nPersistent File System: long-term storage for data processing. replicate data across multiple Availability Zones.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Snow Family"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-storage-gateway",
    "href": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-storage-gateway",
    "title": "김형훈의 학습 블로그",
    "section": "AWS Storage Gateway",
    "text": "AWS Storage Gateway\n\nAWS Storage Gateway is a hybrid cloud storage service that gives you on-premises access to virtually unlimited cloud storage.\nS3 File Gateway: store and retrieve objects in Amazon S3 using file protocols (NFS, SMB), cache data locally, not glacier.\nFSx File Gateway: store and retrieve objects in Amazon FSx using file protocols (NFS, SMB) for window file server.\nVolume Gateway: store and retrieve objects in Amazon S3, EBS Snapshot using iSCSI protocol.\n\ncached volume: cache frequently accessed data locally.\nstored volume: entire dataset stored locally, asynchronously backed up to S3.\n\nTape Gateway: store and retrieve objects in Amazon S3 using virtual tape library (VTL) interface",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Snow Family"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-datasync",
    "href": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-datasync",
    "title": "김형훈의 학습 블로그",
    "section": "AWS DataSync",
    "text": "AWS DataSync\n\nAWS DataSync is a data transfer service that makes it easy for you to automate moving data between on-premises storage and Amazon S3, Amazon Elastic File System (Amazon EFS), or Amazon FSx for Windows File Server.\nFile permissions and metadata are preserved during transfer.\nif not aws to aws, need agent to transfer data.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Snow Family"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/index.html",
    "href": "posts/04_archives/aws_saa/index.html",
    "title": "AWS SAA 준비",
    "section": "",
    "text": "COMPLETED\n    \n    \n        시작일: 2024-04-15\n        종료일: 2024-05-22\n    \n    \n        \n            \n        \n        계산 중...\n    \n    \n    \n        자격증cloud",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/index.html#details",
    "href": "posts/04_archives/aws_saa/index.html#details",
    "title": "AWS SAA 준비",
    "section": "Details",
    "text": "Details\nAWS Solution Architect Associate 자격증을 취득하였습니다.\n자격증 링크",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/index.html#tasks",
    "href": "posts/04_archives/aws_saa/index.html#tasks",
    "title": "AWS SAA 준비",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/index.html#참고-자료",
    "href": "posts/04_archives/aws_saa/index.html#참고-자료",
    "title": "AWS SAA 준비",
    "section": "참고 자료",
    "text": "참고 자료\n\nAWS Udemy 강의",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/index.html#related-posts",
    "href": "posts/04_archives/aws_saa/index.html#related-posts",
    "title": "AWS SAA 준비",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#눈의-구조",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#눈의-구조",
    "title": "Sensor System (Visual)",
    "section": "눈의 구조",
    "text": "눈의 구조\n\n결막 (conjunctiva): 눈을 보호\n각막 (cornea): 빛을 굴절\n홍채(iris): 빛의 양을 조절\n동공 (pupil): 빛이 들어오는 곳\n수정체(lens): 빛을 집중하는 역할\n공막 (sclera): 눈을 보호\n유리체 (vitreous humor): 눈을 유지\n망막(retina): 빛을 감지\n망막의 세포\n\nNerve cell: 빛을 감지\nPhotoreceptor: 빛을 감지\n\n간상세포(cone): 세부적인 정보, 색상 인식, photopic conditions. fovea에 몰려있음. 짧은 파장의 색에 더 민감함\n막대세포(rod): 어두운 곳에서 활동, 주변 시야 빛을 받으면 rhodopsin이 분해됨, scotopic conditions. 긴 파장의 색에 더 민감함.\n\nChoroid: 영양 공급\n\n시신경(optic nerve): 망막에서 뇌로 정보 전달\n맹점(optic disk)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Sensor System (Visual)"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#light-adaption",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#light-adaption",
    "title": "Sensor System (Visual)",
    "section": "light adaption",
    "text": "light adaption\n\n눈이 어두운 곳에서 밝은 곳으로 이동할 때, 시간이 걸림\n명순응동안 rod sensitivity가 감소하고 cone sensitivity가 증가\n어두운 곳에서 밝은 곳으로 이동할 때, 눈이 눈부실 수 있음\n암순응동안 cone sensitivity가 감소하고 rod sensitivity가 증가",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Sensor System (Visual)"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#color-vision",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#color-vision",
    "title": "Sensor System (Visual)",
    "section": "color vision",
    "text": "color vision\n\ncone cell의 photo-pigment(RGB 64:32:2)로 색상을 인식\n망막 중앙에는 파란색이 없음\nsharpness는 brightness와 color difference에 영향을 받음\n사람은 7백만가지 색상을 인식할 수 있음",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Sensor System (Visual)"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#design-with-color",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#design-with-color",
    "title": "Sensor System (Visual)",
    "section": "design with color",
    "text": "design with color\n\nMono-chromatic: 단색\nAnalogous: 비슷한 색\nComplementary: 반대 색\n\n\nbefore design\n\n굳이 흑백을 안쓰고 color를 사용해야하는 이유가 있는지\ncolor가 텍스트나 object에 적합한지\ncolor가 이해나 관습에 도움이 되는지\n노안 / 색맹 고려",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Sensor System (Visual)"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#depth-perception",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#depth-perception",
    "title": "Sensor System (Visual)",
    "section": "depth perception",
    "text": "depth perception\n\ndepth judgment\n\nobject-centered cues\n\n\nlinear perspective: 두 평행선이 좁을 수록 더 멀리 있는 것으로 인식\ninterposition(occlusion): 물체가 다른 물체를 가리면 가려진 물체가 더 멀리 있는 것으로 인식\nheight in the plane: 물체가 높이 있을수록 더 멀리 있는 것으로 인식\nlight and shadow: 빛과 그림자로 물체의 거리를 인식\nrelative size: 물체가 작을수록 더 멀리 있는 것으로 인식\ntexture gradient: 물체가 멀어질수록 세부적인 텍스처가 사라짐\nbrightness: 물체가 밝을수록 더 가까이 있는 것으로 인식\naerial perspective: 물체가 먼발에서 가까워질수록 색이 흐려짐\nmotion parallax: 물체가 빠르게 움직일수록 더 가까이 있는 것으로 인식 fixation point\n\n\nobserver-centered cues\n\n\nbinocular disparity: 두 눈의 시각적 차이\nconvergence: 눈이 물체를 바라볼 때 발생하는 각도\naccommodation: 눈의 렌즈가 물체를 바라볼 때 발생하는 조절. 가까운 물체일수록 렌즈가 더 둥글어짐",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Sensor System (Visual)"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#display-purpose",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#display-purpose",
    "title": "Display",
    "section": "Display Purpose",
    "text": "Display Purpose\n\n사람의 인지와 시스템의 실제 정보 사이의 커뮤니케이션을 위한 중간 다리 역할.\n시스템이 무엇을 하는 중이고, 무엇을 해야 하고, 어떻게 작동하는지 오퍼레이터에게 전달하기 위한 목적(mental model을 만들기 위함)\n설계된 sensory input을 통해서 파악하게 해야함\n다른 sensory input과 구별이 되야함.\n사용자가 이해할 수 있어야함(Compatible)\n\nConceptual Compatibility\nex) 플로피 디스크 심볼은 저장 용도로 사용됨\nmovement compatibility(pictorial realism): 실제와 유사한 모양을 사용하면 이해하기 쉬움\nex) 엘리베이터가 위 아래로 움직이니까 스케일을 linear로 맞춤",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Display"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#display-rules",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#display-rules",
    "title": "Display",
    "section": "Display Rules",
    "text": "Display Rules\n\nFour Cardinal Rules\n\n꼭 필요한 정보만 제공해라\n필요한 수준의 정확도만 제공하라 (ex. 소숫점 3자리까지만. 굳이 다 보여주지 않아도 됨)\n가장 direct, simple, understandable, and usable하게 정보를 제공하라\nex) 지하철 디스플레이에서 열차가 언제 도착하는지 알려줘야 하는데 이상한걸 보여줘서 멘탈 워크로드가 높아진다.\n고장이나 작업 실패의 경우 명확히 어디서 문제가 발생했는지 바로 알아차리게 제공하라\n첫번째 원칙을 위반할 수도 있다(alarm flooding)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Display"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#types-of-displays",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#types-of-displays",
    "title": "Display",
    "section": "Types of Displays",
    "text": "Types of Displays\n\nAuditory\n\nDetectable\nDiscrmination\nMeaningful\nMain problem: hearing ability depends on environments / background noise (auditory spatial coding 인지하기 힘듦)\n\nTactual(Haptic)\n\nDetectable: 손처럼 민감한 부분은 가능하지만, 둔감한 부분은 어렵다\nDiscrimination: nomal job이랑 구분되어야 한다\nMeaningful: tactual display에서는 어려운 부분. convention이 없음\nMain problem: 잘 안쓰이고, 손 이외에는 사용하기 어렵다\n\nOlfactory Displays - smell\n\nDetectable\nDiscrimination\nMeaningful\nMain problem: 냄새에 대한 민감도가 사람마다 다르다. regenerate 하기가 어렵다. 후각이 금방 마비된다. 전쟁에서 후각을 이용한 의사전달을 시도하기도 함",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Display"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#visual-displays",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#visual-displays",
    "title": "Display",
    "section": "Visual Displays",
    "text": "Visual Displays\n\nAppropriate if:\n\nNoisy environment\n한 자리에 머무는 경우(traditional. 옛날엔 들고 다니기 어려웠음)\nmessage가 길거나 복잡한 경우, spatial coding이 필요한 경우\n\nGuiding principles for design:\n\n눈에 잘 띄어야함(배경과 전경의 차이가 구분되어야함)\nLegible, 쉽게 보고 읽을 수 있어야함(ex. 엠뷸런스의 글씨)\nUnderstandable\nmain problem: 시각이 overload됨. 정보가 너무 많음\n\n\n\nDynamic Information\n변화하는 정보를 보여주는 것에는 4가지 원칙이 있다.\n\nSituation awareness\n가까운 미래에 무슨 일이 일어날 지 예측할 수 있어야함\n상황 인식 3단계:\n\nPerception: 무엇이 일어나고 있는지 인지(check readings)\nComprehension: 그것이 무엇을 의미하는지 이해\nProjection: 미래에 무슨 일이 일어날지 예측\n\n\n\nQuantitative readings\n정확한 값을 보여주는 용도로 사용됨\n\n고정 스케일의 움직이는 초점 (generally best)\n움직이는 스케일의 고정 초점\ndigital display (변동성이 큰 경우 그냥 숫자만 보여주는것보다 스케일, 초점을 사용하는게 더 효과적임)\nDesign of Analog Scales\n\n일반적으로 fixed scale, moving pointer가 좋다\n숫자의 증가는, linear 스케일에 움직이는 포인터가 자연스럽다.\nex) 온도계, 엘리베이터\n같은 작업을 하는 여러개의 pointer, scale indicator를 섞어 쓰지 말아라.\ncontrol, display가 혼합된경우 control로 pointer로 움직여라\n작은 변화 감지가 중요한 경우는 moving pointer가 더 좋다\n범위가 너무 큰 경우는 moving scale이 더 좋다\n\n\n\n\nQualitative readings\n대략적인 값, 트렌드, 변화의 비율, 변화의 방향을 보여주는 용도로 주로 사용됨.\n\ncontinuous data converted to range\n의미를 강조하고 싶을 때 color를 보조 도구로써 보여주기도 함\nShape coding\nex) 교통 표지판 8각형은 stop을 의미\nZone coding\nex) 신호등의 위치가 고정되어 있음\n\nRedundancy gain: 시각 청각 촉각, 혹은 칼라코드, 위치코드 같이 여러가지 정보(multi-modal)를 제공하면 정확히 해석할 수 있다.\n\n\nCheck readings\n시스템의 상태를 확인할 수 있어야함\n\nqualitaative reading의 특별한 case\n정상인 상태는 명확히 보여줘야함\n정상적인 것은 align해서, 비정상적인 것은 삐뚤어지게 설계해서 pre-attentive processing을 유도하라\n시각 정보를 보완하기 위해 청각 시그널을 제공하라",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Display"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#signal-and-warning-lights",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#signal-and-warning-lights",
    "title": "Display",
    "section": "Signal and Warning Lights",
    "text": "Signal and Warning Lights\n실질적인, 잠재적인 위험 상황을 알리는 용도\n일반적으로 하나의 라이트만 사용함\n\nsteady-state light: 지속적인 싱태를 나타냄\nflashing light: 위급 상황 (flash 비율은 3-10 per seconds)\n배경에 비해 최소 두 배 이상 밝아야함\n유효 시야 30도 안쪽에 배치해야함",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Display"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/2_human_information_processing_model.html#인간-정보-처리-과정",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/2_human_information_processing_model.html#인간-정보-처리-과정",
    "title": "Human Information Processing Model",
    "section": "인간 정보 처리 과정",
    "text": "인간 정보 처리 과정\n\n\n1. 감각 처리 (Sensory Processing)\n\n주요 감각: 시각, 청각, 운동 감각(proprioception)\n운동 감각: 생리적 신호, 중력과 가속도에 따른 몸의 위치 감각\nSTSS (Short Term Sensory Store)\n\n각 감각기관별 정보 저장 공간\n주의 집중 불필요, 정보 그대로 저장\n빠르게 소멸 (예: 시각 - Iconic Memory 200-300ms, 청각 - Echoic Memory 2-8s)\n\n\n\n\n2. 지각 (Perception)\n\n정보 해석 과정\nTop-Down Processing: 과거 기억으로 정보 해석 (Long Term Memory 활용)\nBottom-Up Processing: 새로운/익숙하지 않은 정보 해석\nPreattentive Processing: 주의 집중 없이 자동적 정보 해석 (예: Stroop Effect)\n\n\n\n3. 주의 자원 (Attention Resources)\n\n전반적인 정보 처리 과정에 영향\nSearch Light Metaphor: 주의 집중의 비유적 설명\n주의 실패 유형:\n\nSelective Attention: 잘못된 곳에 집중\nFocused Attention: 주의 집중 부족\nDivided Attention: 다중 작업 시 주의 분산\nSustained Attention: 장시간 주의 유지 실패\n\n\n\n\n4. 장기 기억 (Long Term Memory)\n\n학습을 통한 정보 저장\n유형:\n\nDeclarative Memory (What): 사실적 지식 (Episodic, Semantic)\nProcedural Memory (How): 절차적 지식\n\n기억 실패: Encoding, Storage, Retrieval 단계에서 발생 가능\n\n\n\n5. 인지 (Cognition)\n\nWorking Memory:\n\n단기적 정보 처리 및 조작\n제한된 용량 (7±2 items)\nLong Term Memory와 Perception으로부터 정보 획득\n\n\n\n\n6. 반응 선택 (Response Selection)\n\n의사결정 이론:\n\nSignal Detection Theory\nExpected Value\nBayesian Decision Theory\nMulti-attribute Theory\n\nInformation Processing\n\nAttention and working memory\nHeuristics and biases: 인간은 합리적이지 않음\n\nNaturalistic Decision Making: Recognition-Primed Decision Model (직감)\n\n\n\n7. 반응 실행 (Response Execution)\n\n\n8. 시스템 환경 (System Environment)\n\nclosed-loop 형태의 피드백 제공\ndelay가 발생시 성능 저하",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Human Information Processing Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#귀의-구조",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#귀의-구조",
    "title": "Auditory Haptic",
    "section": "귀의 구조",
    "text": "귀의 구조",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#sound-waves",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#sound-waves",
    "title": "Auditory Haptic",
    "section": "Sound Waves",
    "text": "Sound Waves\n\n소리는 압력이 변하는 것\n소리는 vibrating object에 의해 발생한다\n연못에 돌을 던지면 생기는 wave와 비슷함\n어떤 분자든 움직이고 압력을 만들 수 있는건 전달 가능함\n물속에서도 소리가 전달됨. (밀도가 높아서 더 빨리 전달됨)\n고체(층간소음, 철로), gas\n진공에서는 매질이 없어서 소리가 안들림(우주 공간) &lt;-&gt; 빛은 매질이 없어도 이동됨\n파동이 전기신호로 바뀌어서 들림\n\n\n물리적 특성\n\n\namplitude: 진폭의 크기 -&gt; volume\nwavelength: 진폭의 넓이 -&gt; pitch, 1초 안에 몇 번 진동하는지(주파수 10Hz = 10번 진동)\n\n\n\n사람이 느끼는 perception\n\nPitch(소리의 높낮이)\n사람이 들을 수 있는 주파수는 20Hz ~ 15kHz\n어릴 때는 고주파를 잘 들음 (고주파에 고막이 반응을 못해서)\n사람은 고주파에 반응을 잘 못함\n절대 음감이랑 관련\nTimbre(음색)\n음악에서는 악기마다 다른 음색이 있음\n음색은 여러 주파수의 하모니(complex set of resonance공명)로 결정됨\nAmplitude and loudness\n소리의 물리적 강도가 2배 증가할 때 우리가 느끼는 소리의 크기(loudness)가 배로 느껴짐(찾아보니까 2배는 아니긴 함) 160db까지 들을 수 있음 130db부터는 고통스러움\nSpatialisation\n소리는 어느 방향에서 소리가 나도 들을 수 있음 (omnidirectional).\n시각은 볼 수 있는 방향만 볼 수 있음\n\n\n\nSound intensity (dB)\n\n데시벨(dB)은 기준점에서 로그 스케일만큼 증가. (선형적 x)\nthreshold: 주변의 소음에 비해 소리가 들리는 정도. 주파수에 따라 다른 특성을 가짐.\n\n\n\n85 dB에 장시간 노출되면 청력 손상\n\n신경의 손상: 장시간 센 자극에 hair cell이 손상됨\nconduction damage: 소리의 세기가 너무 커서 고막이나 뼈에서 손상이 생김",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#masking-effect",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#masking-effect",
    "title": "Auditory Haptic",
    "section": "Masking Effect",
    "text": "Masking Effect\n\n청각에서만 주로 나타남.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#equal-loudness-contour",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#equal-loudness-contour",
    "title": "Auditory Haptic",
    "section": "Equal Loudness Contour",
    "text": "Equal Loudness Contour\n\n곡선은 사람들이 소리가 같은 크기라고 느끼는 지점을 나타냄\n인간 청력의 threshold가 주파수마다 다르다.\n저주파수와 고주파수는 중간 주파수에 비해 같은 강도에서 상대적으로 작게 들립니다",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#locating-sounds",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#locating-sounds",
    "title": "Auditory Haptic",
    "section": "Locating Sounds",
    "text": "Locating Sounds\n왼쪽 귀와 오른쪽 귀에서 들리는 소리의 차이\n\ndifference in phase(위상): 소리의 파장이 오목한 phase, 볼록한 phase 차이\ndifference in loudness: 가까운게 더 크게 들림\ndifference in onset: 가까운게 더 빨리 도달함\n\n\n여기까지가 소리의 mechanical한 특성이고, 이후는 이 소리를 인간이 어떻게 perception하는지에 관한 내용",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#hearing-without-awareness",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#hearing-without-awareness",
    "title": "Auditory Haptic",
    "section": "Hearing Without Awareness",
    "text": "Hearing Without Awareness\n\nCocktail Party Effect: 주변 소음에서도 특정 소리를 들을 수 있음\nEx) 친구 이름을 듣고 반응하는 것, 한국인들이 한국말을 잘 듣는것\nDichotic Listening: 두 귀에 다른 소리를 들려주고 정보를 인식했는지 확인\nignored 귀에서 여전히 정보를 인식할 수 있다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#alarms",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#alarms",
    "title": "Auditory Haptic",
    "section": "Alarms",
    "text": "Alarms\n\nOverview\nomnidirectional한 특성때문에 visual alarm에 비해 자주 사용된다\nEx) 소방차 사이렌 소리\n\n주변 소음에 비해 충분히 db이 커야함 주변 소음과의 차이가 15dB minimal, 30dB required\n하지만 소리가 너무 크면 청각에 손상을 일으킬 수 있음\n안전상의 이유로 소리는 85 ~ 90dB 이하로 유지되어야 함\nmasking 위협때문에 여러 주파수를 혼합해서 냄\n다른 signal과 헷갈리지 않아야함\nEx) 병원의 환자실에 여러 장비가 있는데 장비마다 알람이 구분이 안되면 안됨.\nInformative and distinctive\n각각의 physical dimension(pitch(4), duration(4), amplitude(4))은 4개를 넘게 쓰지 마라\nEx) 컴퓨터 메인보드, 장비 고장 시 비프음 기준이 있음\nEx) 자동차\n\nstereotypic: 어디서 소리가 오는지\n\npitch\n\n\n\n\nNon-speech Alarm\n\nlanguage independent\n글로벌하게 가고 싶다면\nNSA가 유용하다는 증거\n클릭을할 때 딸깍 소리가 나면 실수가 덜 함\n비디오 게이머들은 소리가 없으면 게임을 못함\n일시적이고 부수적인 상태 정보 전달에 효과적\n예시) 게임에서:\n\nHP가 부족할 때 주기적인 경고음\n\n아이템 획득 시 짧은 효과음\n\n배경에서 지속적으로 재생되는 상태 알림음\n\nstereo sound로 방향을 알려줄 수 있음\n비쥬얼로는 3d 표현하기 어려움\n\n\n\nVoice Alarm\n\n자연스러운 방법으로 기기와 통신할 수 있음\nSymbolic alarm에 비해 더 많은 정보를 전달할 수 있음\nSymbolic alarm은 학습을 해야한다는 단점이 있음\nNon-Speech에 비한 한계\n\n소리가 섞이면 헷갈림\n\nmore susceptible to frequency-specific masking\n사람의 voice는 정해진 주파수가 있다.\n그 주파수에 소리가 섞이면 소리를 못들을 수 있음\n다국어 환경을 고려해야함\n\nSound Transmission Problem\n말하고자 하는 바가 전달이 잘 안될 수 있음\nEx) 파일럿 안내. 라디오에서 사용할 수 있는 대역폭이 제한되있음",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#voice-recognition",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#voice-recognition",
    "title": "Auditory Haptic",
    "section": "Voice Recognition",
    "text": "Voice Recognition\nSound Transmission Problem을 해결하기 위해 사용됨\n\nArticulation index: pure bottom-up(signal의 특성에 의존) approach\nsignal이 얼마나 명확하게 잘 들리는지 평가\n1.0: 주변소음에 상관없이 잘 들리는 상태\n0.0: 주변소음에 묻혀서 소리가 들리지 않는 상태\nSpeech intelligibility measure\npoor signal quality is compensated by top-down processing =&gt; 어떻게 top-down processing을 잘 할까?를 테스트 해 보았다.\n전달하는 정보의 양을 제한, 문장의 형태로 전달하는게 좋음\n긍정이나 부정이 잘 나타나는 단어를 사용(Ok는 애매함)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#tactile-perception",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#tactile-perception",
    "title": "Auditory Haptic",
    "section": "Tactile Perception",
    "text": "Tactile Perception\n\nTouch is complex\nOnly bi-directional communication channel: 접촉하거나 움직이거나 한 다음에 반응을 얻는 등, input과 output이 동시에 일어남\n환경에 대한 정보를 포괄해서 전달함\n온도, 표면의 거칠기, 등등\nfeedback을 제공함\n수용체가 피부 변형을 감지함\n민감도는 단위 면적당 촉점이 얼마나 분포되어 있는지에 따라 결정됨",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#tactile-information",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#tactile-information",
    "title": "Auditory Haptic",
    "section": "Tactile information",
    "text": "Tactile information\n\n운동 감각을 통해 받아들이는 것 (force feedback)\n\n\n\n큰 물체는 움직이기 어렵게 함 =&gt; 더 세밀하게 조종 가능\n\n게임에서 많이 사용됨\n\n\n촉감을 통해 받아들이는 것 (vibration feedback)\n\n\n\nusing vibration for information transfer\nsimilar physical characteristics to auditory signal\n\namplitude, frequency, duration, wave pattern\n\nused for navigation aid\n중요한 정보는 시각, 나머지 feedback은 촉각, 청각으로 받아들임.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/6-정규분포.html#정규-분포의-합",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/6-정규분포.html#정규-분포의-합",
    "title": "정규 분포",
    "section": "정규 분포의 합",
    "text": "정규 분포의 합\n두 분포의 합이 같은 분포가 되는 경우는 흔치 않다 (uniform distribution도 같지 않다)\n두 정규분포의 합은 정규분포가 된다\n\\(X + Y \\sim N(μ_1 + μ_2, σ_1^2 + σ_2^2)\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "정규 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/6-정규분포.html#chi-square-분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/6-정규분포.html#chi-square-분포",
    "title": "정규 분포",
    "section": "Chi-square 분포",
    "text": "Chi-square 분포\nα = ν/2, θ = 2인 감마분포\n\\(Z \\sim N(0,1)\\)일 때, \\(Z^2 \\sim χ^2(1)\\)\n\\(Z_i \\sim N(0,1)\\)일 때, \\(Z_1^2 + Z_2^2 + ...  + Z_n^2 \\sim χ^2(n)\\)\n\\(X_i\\)가 서로 독립이고, 자유도가 \\(ν_i\\)인 카이제곱분포를 따른다면, \\(X_1 + X_2 + ... + X_n \\sim x^2(ν_1 + ν_2 + ... + ν_n)\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "정규 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#통계학의-정의",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#통계학의-정의",
    "title": "확률과 통계의 정의",
    "section": "통계학의 정의",
    "text": "통계학의 정의\n\n불확실한 상황에서 데이터에 근거하여 과학적인 의사결정을 도출하기 위한 이론과 방법 체계\n모집단으로부터 수집된 데이터(sample)를 기반으로 모집단의 특성을 추론하는 것을 목표로 함\n\n\n\n모집단: 통계분석의 대상이 되는 모든 개체들의 집합\n표본: 모집단으로부터 일정한 규칙에 의해 추출한 부분집합",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#확률의-개념",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#확률의-개념",
    "title": "확률과 통계의 정의",
    "section": "확률의 개념",
    "text": "확률의 개념\n\n모집단에서 특정 사건(event)의 상대도수의 극한\n\n\nLaw of Large Numbers\n무수히 많은 시행이 반복되면 상대도수에 의해 계산되는 확률(통계적 확률)이 이론적 확률로 수렴한다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#sample-space-and-events",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#sample-space-and-events",
    "title": "확률과 통계의 정의",
    "section": "Sample Space and Events",
    "text": "Sample Space and Events\n\nExperiment(확률실험): 동일한 조건에서 독립적으로 반복할 수 있는 실험이나 관측\nSample space(표본공간): 모든 simple event의 집합\nEvent(사건): 실험에서 발생하는 결과 (부분 집합)\nSimple event(단순사건): 원소가 하나인 사건\n\n\n\n\nevent는 여러 원소를 가질 수 있다",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#확률의-정의",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#확률의-정의",
    "title": "확률과 통계의 정의",
    "section": "확률의 정의",
    "text": "확률의 정의\n\n고전적 확률: 모든 simple event가 동일한 확률을 가질 때 P(A)는 sample space가 n개의 원소로 이루어져 있을 때 k개의 원소를 가지는 event A의 확률\n통계적 확률: simple event가 동일한 확률을 가지지 않아도 된다. 표본의 수가 무한대로 갈 때, 표본의 확률이 수렴하는 값\n\n\n확률의 성질\n\n모든x에 대하여 P(x) &gt;= 0\nP(sample space) = 1\nA와 B가 배반사건이면 P(A or B) = P(A) + P(B)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#조건부-확률",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#조건부-확률",
    "title": "확률과 통계의 정의",
    "section": "조건부 확률",
    "text": "조건부 확률\n\nEvent B가 발생했을 때 Event A의 확률 \\[P(A|B) = \\frac{P(A∩B)}{P(B)}\\]\n결합확률 (joint probability): P(A∩B)\n주변확률 (marginal probability): P(A), P(B), …\n\n\nMultiplication Law\n\\[P(A∩B) = P(A|B)P(B)\\]",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#independent-events",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#independent-events",
    "title": "확률과 통계의 정의",
    "section": "Independent Events",
    "text": "Independent Events\n\n두 사건 A와 B가 독립일 때, P(A|B) = P(A), P(B|A) = P(B)\nsample space는 임의의 event와 독립이다.\n공집합은 임의의 event와 독립이다. (P(∅∩A) = P(∅) * P(A) = 0 * P(A) = 0 = P(∅))",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#베이즈-정리",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#베이즈-정리",
    "title": "확률과 통계의 정의",
    "section": "베이즈 정리",
    "text": "베이즈 정리\n\n\nsample space를 상호 배반인 {B1, B2, …, Bn}으로 분할 (partition)\n\\(P(A) = P(A∩B_1) + P(A∩B_2) + ... + P(A∩B_n)\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/3-확률변수의-기댓값.html#확률변수의-기댓값",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/3-확률변수의-기댓값.html#확률변수의-기댓값",
    "title": "확률변수의 기댓값",
    "section": "확률변수의 기댓값",
    "text": "확률변수의 기댓값\n\n\\(μ = E(x)\\)로 가정. (모집단)\ncovariance는 선형관계를 보여준다.\nx와 y는 독립이다 -&gt; cov(x, y) = 0",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수의 기댓값"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/3-확률변수의-기댓값.html#moment-generationg-functions",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/3-확률변수의-기댓값.html#moment-generationg-functions",
    "title": "확률변수의 기댓값",
    "section": "Moment Generationg Functions",
    "text": "Moment Generationg Functions\n\n평균과 분산만으로 확률분포를 설명하기에는 부족하다.\n\nmoment: \\(μ_k′ = E(X^k), k ∈ ℤ+\\)\nVar(x) = \\(μ_2′ - μ_1′^2\\)\nE(x) = \\(μ_1′\\)\n모든 k에 대해 검증 불가 =&gt; mgf(moment generating function)\nmgf: \\(M_X(t) = E(e^{tx})\\)\n\n\n\\(M_X(t) = 1 + tμ_1′ + \\frac{t^2}{2!}μ_2′ + \\frac{t^3}{3!}μ_3′ + ...\\)\n\\(M′(t) = μ_1′ + \\frac{2t}{2!}μ_2′ + \\frac{3t^2}{3!}μ_3′ + ...\\)\n\\(M′(0) = μ_1′\\)\n\\(M′′(0) = μ_2′\\)\n\\(M^{(k)}(0) = μ_k′\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수의 기댓값"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#좋은-추정량이-되기-위한-조건",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#좋은-추정량이-되기-위한-조건",
    "title": "표본의 분포",
    "section": "좋은 추정량이 되기 위한 조건",
    "text": "좋은 추정량이 되기 위한 조건\n\n불편성 (Unbiasedness) - 기본 조건\n추정량의 기대값이 추정하려는 모수와 같아야 함\n\\(E(\\hat{X}) = μ\\)\n\\(E(X_1) = μ\\)\n최소분산 (Minimum Variance)\n추정량의 분산이 가능한 작아야 함.\n표본의 갯수를 늘릴수록 분산이 줄어들어서 더 좋은 추정량이 됨\n\\(Var(\\hat{X}) = \\frac{σ^2}{n}\\)\n\\(Var(X_1) = \\sigma^2\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "표본의 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#표본평균의-분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#표본평균의-분포",
    "title": "표본의 분포",
    "section": "표본평균의 분포",
    "text": "표본평균의 분포",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "표본의 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#표본분산의-분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#표본분산의-분포",
    "title": "표본의 분포",
    "section": "표본분산의 분포",
    "text": "표본분산의 분포\n정규분포로 부터 추출된 표본의 \\(\\sum_{i=1}^{n} Z^2\\)은 자유도가 n인 카이제곱분포를 따름\n정규분포로 부터 추출된 표본의 \\(\\frac{(n-1)s^2}{\\sigma^2}\\)은 자유도가 n-1인 카이제곱분포를 따름",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "표본의 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#평균",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#평균",
    "title": "표본의 분포",
    "section": "평균",
    "text": "평균\n\\(\\frac{\\hat{X} - μ}{s/\\sqrt{n}}\\) t-분포를 따름\nT분포: 표준 정규분포 Z, 자유도가 n인 카이제곱분포가 서로 독립일 때 \\(T=\\frac{Z}{\\sqrt{Y/n}}\\)\nT분포는 정규분포와 비슷하지만, 표본의 크기가 작을 때 정규분포보다 두꺼운 꼬리를 가짐\nT분포가 값이 더 작고, 신뢰도가 감소함",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "표본의 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#분산",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#분산",
    "title": "표본의 분포",
    "section": "분산",
    "text": "분산\n확률변수 U와 V가 자유도가 n1, n2인 카이제곱분포를 따르고 서로 독립이면, \\(F=\\frac{U/n1}{V/n2}\\)는 F분포를 따름",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "표본의 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/04-2.html#ddl-data-definition-language",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/04-2.html#ddl-data-definition-language",
    "title": "SQL",
    "section": "DDL (Data Definition Language)",
    "text": "DDL (Data Definition Language)\n\nCREATE (database, tables, views, indexes)\nALTER: modify columns / constraints\nDROP (database, tables, views, indexes)\nTRUNCATE: delete table data while keeping structure.\nMS Access에서는 지원하지 않음 =&gt; DELETE FROM table\n\nCREATE TABLE student (\n    id INT NOT NULL,\n    CourseID INT NOT NULL,\n    Name VARCHAR(100) UNIQUE, # unique는 자동으로 index 생성\n    Age INT,\n    CONSTRAINT STUDENT_PK PRIMARY KEY (id),\n    CONSTRAINT \n    COURSE_FK FOREIGN KEY (CourseID) \n    REFERENCES Course(CourseID) \n    ON UPDATE CASACADE \n    ON DELETE NO ACTION\n);\nALTER TABLE student ADD COLUMN major VARCHAR(100);\nALTER TABLE student ADD CONSTRAINT STUDENT_FK FOREIGN KEY (CourseID) REFERENCES Course(CourseID) ON DELETE CASCADE;\nALTER TABLE student ADD CONSTRAINT AGE_CHECK CHECK (Age &gt; 0);\nALTER TABLE student DROP CONSTRAINT AGE_CHECK;\nDROP TABLE student;\nTRUNCATE TABLE student;\n\nCREATE VIEW [view name] AS SELECT * FROM student;\n\nDML (Data Manipulation Language)\nINSERT INTO student VALUES (1, 'Alice', 20);\nUPDATE student SET age = 21, Name = 'babo' WHERE id = 1;\nDELETE FROM student WHERE id = 1;\n\n\nDQL (Data Query Language)\nA query create temporarily a new table.\nthis allows a query to create a new relation and feed information to another query as a subquery\nSELECT * FROM student;\nSELECT name \nFROM student \nWHERE age &gt; 20\nORDER BY name DESC, age ASC;\nSELECT DISTINCT name FROM student;\nSELECT name, age FROM student WHERE Age &gt; (SELECT AVG(Age) FROM student);\n\n\nJOIN\n\ninner join(equijoin)\n\nexplicit join: FROM table1 INNER JOIN table2 ON table1.id = table2.id\n(MS Access에서는 INNER를 명시해야됨)\nimplicit join: FROM table1, table2 WHERE table1.id = table2.id\n\nouter join\n\nleft outer join: FROM table1 LEFT JOIN table2 ON table1.id = table2.id\nright outer join: FROM table1 RIGHT JOIN table2 ON table1.id = table2.id",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "SQL"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#entity",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#entity",
    "title": "The Relational Model",
    "section": "entity",
    "text": "entity\na formal name for a thing that is being tracked one theme or topic (just single table)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#relation",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#relation",
    "title": "The Relational Model",
    "section": "Relation",
    "text": "Relation\n\na two-dimensional table that has specific charateristics\nCell of the table hold single value\nAll entries in a column are of the same kind\nNo two rows in a table are identical",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#domain-cartesian-product",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#domain-cartesian-product",
    "title": "The Relational Model",
    "section": "domain & cartesian product",
    "text": "domain & cartesian product\n\ndomain: set of possible values for a column\ncartesian product: set of all possible combinations of rows from two tables",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#presenting-relation-structures",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#presenting-relation-structures",
    "title": "The Relational Model",
    "section": "Presenting Relation Structures",
    "text": "Presenting Relation Structures\nRELATION_NAME(PrimaryKey, ForeignKey, ColumnName, …)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#key",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#key",
    "title": "The Relational Model",
    "section": "key",
    "text": "key\n\nidentify a row\nUnique Key(Primary Key)\nNonUnique Key(Foreign Key)\nComposite Key: Primary key가 두개 이상. Surrogate Key로 대체되곤 함.\nCandidate Key: unique한 columns\nSurrogate Key: 자동으로 할당되는 일련번호\nIDENTITY (start, increment)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#referential-integrity-constraint",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#referential-integrity-constraint",
    "title": "The Relational Model",
    "section": "Referential Integrity Constraint",
    "text": "Referential Integrity Constraint\n\n모든 foriegn key는 존재하는 primary key와 매칭되야한다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#null-values",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#null-values",
    "title": "The Relational Model",
    "section": "Null values",
    "text": "Null values\n\nrequired, allow nulls 설정으로 null값을 허용할지 결정",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/04-1.html#normalization",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/04-1.html#normalization",
    "title": "Database Normalization",
    "section": "Normalization",
    "text": "Normalization\n\nprocess of organizing a database to reduce redundancy problem and improve data integrity",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Normalization"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/04-1.html#functional-dependency",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/04-1.html#functional-dependency",
    "title": "Database Normalization",
    "section": "Functional Dependency",
    "text": "Functional Dependency\n\n하나의 atrribute가 다른 attribute의 value를 결정하는지 여부를 판단\nwell formed인지 판별할 수 있는 기준\nA(Determinant) -&gt; B(dependent): A가 결정되면 B도 결정된다면 B는 A에 함수적 종속\nEvery determinant must be a Candidate Key",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Normalization"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/04-1.html#normalization-process",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/04-1.html#normalization-process",
    "title": "Database Normalization",
    "section": "Normalization Process",
    "text": "Normalization Process\n\nBCFNF: Boyce-Codd Normal Form =&gt; Each relation has only one theme\n\n\nIdentify all the Candidate Keys.\nIdentify all the Functional Dependencies.\nExamine the determinants of the functional dependencies\n\nplace the columns of the functional dependency in a new relation of their own\nmake the determinant of the functianl dependency the primary key of the new relation\nLeabe a copy of the determinant as a foreign key in the original relation\ncreate a referential integrity constraint between the original and new relation\n\nRepeat the process until every determinant of every relation is a candidate key",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Normalization"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/11.html#concurrency-control",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/11.html#concurrency-control",
    "title": "Database Administration",
    "section": "Concurrency control",
    "text": "Concurrency control\nEnsuring that one user’s work does not inappropriately influence another user’s work\n\nStrict concurrency control requires locking the database, 다른 사용자의 동시 사용 허가 x\nLower concurrency control allows more throughput\n\n\nTransactions\nUsers submit Transactions(LUWs)\n\nAtmomic Transaction: 데이터베이스에서 일련의 작업들이 모두 성공적으로 수행되거나, 그렇지 않을 경우 작업이 전혀 수행되지 않아 데이터베이스가 변경되지 않는 상태를 유지하는 트랜잭션\n→ Before committed, all LUWs must be successfully completed, or rollback\nConcurrent Transactions: 여러 트랜잭션이 동시에 실행되는 것\n\nLost update problem: 두 트랜잭션이 동시에 같은 데이터를 수정할 때, 하나의 트렌잭션이 다른 트랜잭션의 변경을 덮어쓰는 문제\nInconsistent read problem: 한 트랜잭션이 데이터를 읽는 도중 다른 트랜잭션이 데이터를 수정하는 문제\n\nDirty read: commit 되기 이전에 수정된 데이터를 읽는 것. 만약 rollback이 될 경우 문제가 발생.\nNonrepeatable read: 데이터를 두 번 읽었는데 commit된 transaction 때문에 값이 다른 경우\nPhantom read: 데이터를 두 번 읽었는데 commit된 transaction 때문에 새로운 row가 추가된 경우\n\nResource locking\n\nImplicit locks: DBMS가 자동으로 수행하는 lock\nExplicit locks\nLOCK TABLES table_name READ -- or WRITE\nUNLOCK TABLES\nExclusive locks: 다른 트랜잭션에서 읽기/쓰기 불가\nShared locks: 다른 트랜잭션에서 읽기 가능, 쓰기 불가\nrock granularity: row-level vs table-level vs database-level\n\n\nSerializable Transactions: 가장 강력한 격리 수준 보장\n\nTwo-pase locking(2PL): growing phase와 shrinking phase로 나뉨\n\nACID Transaction\n\nAtomic: 성공한 transaction만 저장되어야 한다\nConsistent: 현재의 transaction이 마무리 되기 전 까지 record를 저장할 수 없다\n→ 트랜잭션의 살향 결과로 데이터베이스 상태가 모순되지 않음\nIsolated\n\nread uncommitted: 다른 트랜잭션에서 commit되지 않은 데이터도 읽을 수 있음\nread committed: 다른 트랜잭션이 commit된 데이터만 읽을 수 있음\nrepeatable read: 한 트랜잭션에서 하나의 스냅션만 사용\nserializable: 가장 강력한 격리 수준 보장\n\nDurable: 트랜잭션이 성공적으로 완료되면, 그 결과는 영구적으로 저장되어야 한다\n\n\n\n\n\nDeadlock / deadly embrace\n두 개 이상의 트랜잭션이 서로 unlock을 무한히 기다리는 상태\n\n\nlock\n\noptimistic locking\n\nassumption: No conflict will occur\nif no conflict occurs, the transaction is committed else it is rolled back and repeated\n\npessimistic locking\n\nassumption: Conflict will occur\nlock the data before the transaction starts\n\n\n\n\nCursor\nA cursor is a pointer into a set of rows that are the result set from an SQL SELECT statement\nDECLARE cursor_name CURSOR FOR SELECT column_name FROM table_name",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Administration"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/11.html#backup-and-recovery",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/11.html#backup-and-recovery",
    "title": "Database Administration",
    "section": "Backup and recovery",
    "text": "Backup and recovery\n\nRecovery\n\nvia Reprocessing\nvia Rollback and Rollforward\n\nlog file transaction을 undo할 때, before-images가 존재해함. (rollback) transaction을 redo할 때, after-images가 존재해함.(rollforward)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Administration"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/11.html#security",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/11.html#security",
    "title": "Database Administration",
    "section": "Security",
    "text": "Security\nonly authenticated users perform authorized activities\n\nAuthentication: User ID와 password를 사용하여 사용자를 인증\nAuthorization: user groups(roles): dbcreator, public, … sql  GRANT SELECT, INSERT, UPDATE, DELETE ON table_name TO user_name",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Administration"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/11.html#database-performance",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/11.html#database-performance",
    "title": "Database Administration",
    "section": "Database Performance",
    "text": "Database Performance\n\nindex\ndisk mirroring: 데이터 복제 말씀하신 듯\nRAID\nSANs\nDistributed database: service cluster partitioned replicated\n\n\nDBA Responsibilities\n\nuser reported errors를 모아서 system이 잘 돌아갈 수 있게 해야함\ndatabase 설정을 잘 관리해야함\n문서화 잘 해야함\ncloud로 db 관리(service level agreement)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Administration"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/index.html",
    "href": "posts/04_archives/bs_2_2/index.html",
    "title": "2학년 2학기 학부 정리",
    "section": "",
    "text": "COMPLETED\n    \n    \n        시작일: 2024-09-02\n        종료일: 2024-12-20\n    \n    \n        \n            \n        \n        계산 중...\n    \n    \n    \n        산업공학 학부",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/index.html#details",
    "href": "posts/04_archives/bs_2_2/index.html#details",
    "title": "2학년 2학기 학부 정리",
    "section": "Details",
    "text": "Details\n산업정보시스템공학과 2학년 2학기 수강 과목들에 대한 개념 정리 노트입니다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/index.html#tasks",
    "href": "posts/04_archives/bs_2_2/index.html#tasks",
    "title": "2학년 2학기 학부 정리",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/index.html#related-posts",
    "href": "posts/04_archives/bs_2_2/index.html#related-posts",
    "title": "2학년 2학기 학부 정리",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/data_mining/00.html#수업-요약",
    "href": "posts/01_projects/bs_3_1/notes/data_mining/00.html#수업-요약",
    "title": "Numpy",
    "section": "수업 요약",
    "text": "수업 요약\n\nnumpy랑 pandas 비교, broadcast\nnumpy 다차원 pandas 2차원\npython list 보다 빠름\n차원을 rank, 크기를 shape\n\n\nimport numpy as np\n\nv1 = np.arange(1, 10, 2) ** 2\nprint(v1)\n\n[ 1  9 25 49 81]\n\n\n\nv2 = np.arange(3, 10, 1, dtype=float)\nprint(v2)\n\n[3. 4. 5. 6. 7. 8. 9.]\n\n\n\n수업으로 공부하지 말고 따로 올려준 자료로 공부해라\n\n\na = np.zeros((2,2))\nprint(a)\n\n[[0. 0.]\n [0. 0.]]\n\n\n\na = np.ones((2, 3))\nprint(a)\n\n[[1. 1. 1.]\n [1. 1. 1.]]\n\n\n\nlst1 = [[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9],\n        [9, 10, 11],\n        [12, 13, 14]]\na = np.array(lst1)\na[[1, 2]]\n\narray([[4, 5, 6],\n       [7, 8, 9]])\n\n\n\na = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\nb = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\na + b\n\narray([[ 2,  4,  6],\n       [ 8, 10, 12],\n       [14, 16, 18]])",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Data Mining",
      "Numpy"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/02.html",
    "href": "posts/01_projects/bs_3_1/notes/OR/02.html",
    "title": "Integer Programming",
    "section": "",
    "text": "all or nothing problem에서 사용\nex) knapsack problem → 아이템을 0.8개 넣을 수 없다",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Integer Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/02.html#requirements-on-selecting-variables",
    "href": "posts/01_projects/bs_3_1/notes/OR/02.html#requirements-on-selecting-variables",
    "title": "Integer Programming",
    "section": "Requirements on selecting variables",
    "text": "Requirements on selecting variables\n\nAt Least\nat least one of variables among items 1, 3, 4:\n\\(x_1 + x_3 + x_4 ≥ 1\\)\nAt Most\nat most two of variables among items 1, 3, 4:\n\\(x_1 + x_3 + x_4 ≤ 2\\)\nOr\nselect variable 1 or 2:\n\\(x_1 + x_2 ≥ 1\\)\nselect 2 otherwise item 3 and 4 together:\n\\(2x_2 + x_3 + x_4 ≥ 2\\)\nIf-else\nif variable 1 is selected, then variable 2 is also selected:\n\\(x_1 ≤ x_2\\)\nif variable 1 is selected, do not select item 3 and 4:\n\\(2(1 - x_1) ≥ x_3 + x_4\\)",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Integer Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/02.html#at-leastmost-some-constraints",
    "href": "posts/01_projects/bs_3_1/notes/OR/02.html#at-leastmost-some-constraints",
    "title": "Integer Programming",
    "section": "At least/most some constraints",
    "text": "At least/most some constraints\nconstraints를 유연하게 선택하는 방법\n\\(g_1(x) ≤ b_1\\)과 \\(g_2(x) ≥ b_2\\)를 둘 다 만족하는 경우를 표현하려면 union으로 표현할 수 있다.\n이는 linear program에 적합하지 않기 때문에 variable로 표현한다.\n\\[z = \\begin{cases}\n0 & \\text{if } g_1(x) ≤ b_1 \\\\\n1 & \\text{if } g_2(x) ≤ b_2\n\\end{cases}\\]\n이는 아래의 수식으로 표현할 수 있다\n\\[\\begin{align}\n&g_1(x) - b_1 ≤ M_1z \\\\\n&g_2(x) - b_2 ≤ M_2(1 - z)\n\\end{align}\\]\n이때\\(M_1\\)과 \\(M_2\\)는 충분히 큰 상수이다.",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Integer Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/02.html#일반적인-예시",
    "href": "posts/01_projects/bs_3_1/notes/OR/02.html#일반적인-예시",
    "title": "Integer Programming",
    "section": "일반적인 예시",
    "text": "일반적인 예시\nFacility location problem\n\nwhere to open convenience stores?\nwhere to build warehouses or distribution centers?\nwhere to build factories?\nwhere to build power stations, fire stations, or police stations?\n\n→ where to locate scarce resource?\ndemoand nodes potential locations\n\nset covering problem\nmaximum covering problem\nfixed charge location problem\n\n\nmachine scheduling problem\n\nproduction mode\n\nsingle machine serial production\nmultiple parallel machines\nflow shop scheduling: all jobs must follow the same sequence\njob shop scheduling: each job has its own sequence\n\n\n\njob splitting\n\npreemptive problem: 특정 작업을 중단하고 시급한 다른 작업을 수행한 후, 다시 돌아올 수 있음\nnon-preemptive problem\n\n\n\nperformance measurement\n\nMakespan: 모든 작업이 끝나는 시간\ntotal completion time\nnumber of delayed jobs\ntotal lateness: completion time이 due time보다 앞서는 경우 negative lateness\ntotal tardiness: completion time이 due time보다 뒤에 있는 경우에만 completion time - due time, 그 외 0",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Integer Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/01.html#terminology",
    "href": "posts/01_projects/bs_3_1/notes/OR/01.html#terminology",
    "title": "Linear Programming",
    "section": "Terminology",
    "text": "Terminology\n\nprocess of fomulating and solving linear programs\nmathematical program with some special properties\n\nobjective function\nconstraints (\\(b_1, b_2, ..., b_m\\))\ndecision variables (\\(x_1, x_2, ..., x_n, x_i ∈ ℝ\\))\n→ also expressed as a \\(x\\) that means vector of \\(n\\) variables\n\n\n\nconstraints\n\nSign constraints: single variable\n\nnonnegative: \\(x_i ≥ 0\\)\nnonpositive: \\(x_i ≤ 0\\)\nunrestricted in sign or free: no sign constraints\n\nFunctional constraints: other cases\nequality constraints: \\(a_1x_1 + a_2x_2 + ... + a_nx_n = b\\)\ninequality constraints: \\(a_1x_1 + a_2x_2 + ... + a_nx_n ≤ b\\)\nbinding constraints (or active constraints)\nno matter \\(g(x)\\) is equality or not, if \\(g(a) = b, a\\) is binding\nstrict constraints: \\(a_1x_1 + a_2x_2 + ... + a_nx_n &lt; b\\)\nweak constraints: \\(a_1x_1 + a_2x_2 + ... + a_nx_n ≤ b\\)\n→ practical mathematical program’s inequalities are all weak\n\n\n\nsolution\n\nfeasible solution: satisfies all constraints\n\nfeasible region: set of all feasible solutions\n\noptimal solution: maximizes or minimizes the objective function\nthere may be multiple or no optimal solutions",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Linear Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/01.html#three-types-of-lps",
    "href": "posts/01_projects/bs_3_1/notes/OR/01.html#three-types-of-lps",
    "title": "Linear Programming",
    "section": "Three types of LPs",
    "text": "Three types of LPs\n\nInfeasible\nUnbounded: unbounded feasible region does not imply an unbounded LP\nFinitely optimal\n\nUnique optimal solutions\nMultiple optimal solutions\n\n\n\nParameter: we know. \\(C_1, C_2, ...\\)\nVariables: do not know. \\(x_1, x_2, ...\\)",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Linear Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/03.html#nonlinear-programming-example",
    "href": "posts/01_projects/bs_3_1/notes/OR/03.html#nonlinear-programming-example",
    "title": "Nonlinear Programming",
    "section": "Nonlinear Programming Example",
    "text": "Nonlinear Programming Example\n\nPricing\nInventory\nPortfolio optimization (finance)\n→ Balance (margin vs price, ordering cost vs inventory cost, return vs risk, …)\n\nBecause trade off can only be modeled in a nonlinear way, the programs are by nature nonlinear\n\nAt least one of fumular is nonlinear, Nonlinear Program.\nBut some people says that NLP contents LP\n\n\nExample: Pricing a single good\n\nA retailer buys one product at a unit cost \\(c\\)\nIt chooses a unit retail price \\(p\\)\nThe demand is a function of \\(p\\): \\(D(p) = a - bp\\)\nFind profit-maximizing price\n\n\\[\\begin{aligned}\n\\underset{p}{max} \\quad  &(p-c)(a-bp) \\\\\ns.t. \\quad  &p ≥ 0 \\\\\n\\end{aligned}\\]\n\\[\n\\text{or}\n\\]\n\\[\\begin{aligned}\n\\underset{p\\ge0}{max} \\quad  &(p-c)(a-bp) \\\\\n\\end{aligned}\\]\n\\(p - c\\) is sales margin, \\(a-bp\\) is Demand (how many sales)\n\n\nExample: Folding a piece of paper\n\n\n\nExample: locating a hospital",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Nonlinear Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/03.html#eoq-model-economic-order-quantity",
    "href": "posts/01_projects/bs_3_1/notes/OR/03.html#eoq-model-economic-order-quantity",
    "title": "Nonlinear Programming",
    "section": "EOQ Model (Economic Order Quantity)",
    "text": "EOQ Model (Economic Order Quantity)\n \n\nParameters\n\n\\(D\\): annual demand\n\\(K\\): unit ordering cost\n\\(h\\): unit holding cost per year\n\\(p\\): unit purchasing cost\n\nDecision varaible\n\n\\(q\\): order quantity per order\n\nObjective: Minimizing annual total cost",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Nonlinear Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/03.html#portfolio-model",
    "href": "posts/01_projects/bs_3_1/notes/OR/03.html#portfolio-model",
    "title": "Nonlinear Programming",
    "section": "Portfolio Model",
    "text": "Portfolio Model",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Nonlinear Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/product/00.html",
    "href": "posts/01_projects/bs_3_1/notes/product/00.html",
    "title": "Intro",
    "section": "",
    "text": "시험시간: 21:00 - 22:00\n생산: 유, 무형의 제품을 만드는 것\n시스템: 투입물을 산출물로 만드는 것들의 집합\n관리: 목표를 달성하기 위한 체계적인 의사결정\n\n목표: 원가, 품질, 납품, 유연성 (trade-off)\n\n\n\n\n\n 맨 위로",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Product",
      "Intro"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/scholarships/2.html",
    "href": "posts/01_projects/bs_3_1/notes/scholarships/2.html",
    "title": "성적 장학금",
    "section": "",
    "text": "오~예~ (남은 등록금 300만원을 대출 받으며)\n\n\n\n 맨 위로",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Scholarships",
      "성적 장학금"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/index.html",
    "href": "posts/01_projects/bs_3_1/index.html",
    "title": "학부 3학년 1학기",
    "section": "",
    "text": "ON-GOING\n    \n    \n        시작일: 2024-12-21\n        종료일: 2025-06-20\n    \n    \n        \n            \n        \n        계산 중...\n    \n    \n    \n        산업공학 학부",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/index.html#details",
    "href": "posts/01_projects/bs_3_1/index.html#details",
    "title": "학부 3학년 1학기",
    "section": "Details",
    "text": "Details\n산업정보시스템공학과 3학년 1학기 개념 정리, 과제, 할 일 등을 총 정리한 노트 모음입니다.",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/index.html#tasks",
    "href": "posts/01_projects/bs_3_1/index.html#tasks",
    "title": "학부 3학년 1학기",
    "section": "Tasks",
    "text": "Tasks\n\n\n\n    \n    \n    \n            \n                \n                \n                    푸른등대 기부장학금 - 두나무UDC 신청 (~2025-01-20 18:00)\n                \n                신청 완료. 결과 4월 중순\n            \n            \n            \n                \n                \n                    2025 DB 드림리더 장학생 신청 (~2025-01-10)\n                \n                잘할 자신이 없다\n            \n            \n            \n                \n                \n                    경기도 학자금대출 이자 지원 신청 (~2025.02.14 18:00)\n                \n                신청 완료\n            \n            \n            \n                \n                    \n                    학과 근로 신청\n                \n                신청 완료\n            \n\n            \n            \n                \n                \n                    연재장학재단 지원금 신청 (~2025-02-06 15:00)\n                \n                1명만 뽑는 장학금에 학과장님 추천서 받기 망설여진다\n            \n            \n            \n                \n                    \n                    KMOOC 학점 인정 신청 (2025-03-10~)\n                \n                하나는 기간이 지나 버렸다. 종강 전에 하나만 더 듣자.\n            \n\n            \n            \n                \n                    \n                    봉사활동 계획서 작성 (2025-03-11~)\n                \n                \n            \n\n            \n            \n                \n                \n                    OR 과제 1 (~2025-03-16 23:59)\n                \n                제출 완료",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/index.html#필요한-자료",
    "href": "posts/01_projects/bs_3_1/index.html#필요한-자료",
    "title": "학부 3학년 1학기",
    "section": "필요한 자료",
    "text": "필요한 자료\n\n자기소개서 작성 1\n교육 이수 증빙자료\nPortfolio: 큰일 났다. 진짜 못만들었다.",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/index.html#참고-자료",
    "href": "posts/01_projects/bs_3_1/index.html#참고-자료",
    "title": "학부 3학년 1학기",
    "section": "참고 자료",
    "text": "참고 자료\n\nOR 강의",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/index.html#related-posts",
    "href": "posts/01_projects/bs_3_1/index.html#related-posts",
    "title": "학부 3학년 1학기",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/09.html",
    "href": "posts/02_areas/선형대수/notes/09.html",
    "title": "가감법으로 연립방정식을 풀기 위한 행렬",
    "section": "",
    "text": "맨 위로",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "가감법으로 연립방정식을 풀기 위한 행렬"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/structure/00.html",
    "href": "posts/01_projects/bs_3_1/notes/structure/00.html",
    "title": "자료구조와 알고리즘",
    "section": "",
    "text": "맨 위로",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Structure",
      "자료구조와 알고리즘"
    ]
  },
  {
    "objectID": "posts/00_inboxes/notes/02.html",
    "href": "posts/00_inboxes/notes/02.html",
    "title": "나의 단점에 관한 고찰",
    "section": "",
    "text": "나는 단점이 없다고 생각했다. 그래서 자기소개서 같은 곳에 장점, 단점을 적는 칸이 있으면 아래같이 유머 아닌 유머같은 답을 적곤 했다.\n\n\n\n장점\n단점이 없다.\n\n\n단점\n\n\n\n\n최근 드는 생각인데, 내 단점은 사람을 대할 때 꽤나 간사한 면이 있다는 것이다.\n사회적으로나, 능력적으로나, 누구든 나보다 잘나다고 생각되는 사람 앞에서 나는 수줍고 소심한 사람이 된다. 뭐.. 사실 이정도는 누구나 그런 면이 있을 수 있다 생각한다. 하지만 나보다 열등하다고 생각되는 사람 앞에서 나는 꽤 강압적이고 무례한 사람이 된다. 흔히 말하는 ’강약약강’이라는 말이 아마 나를 잘 설명해주는 것 같다.\n사실 어쩌면 이런 강압적인 모습이 나의 본성이 아닐까 하는 생각이 든다. 수줍고 소심한 모습은 아마 사회화된 또 다른 나의 모습이 아닐까. 왜냐하면 나는 나의 부모님에게서 수줍고 소심한 모습을 본 적이 없기 때문이다.\n그렇다면 나는 이 단점들을 극복해야 하나? 극복한다면 어떤 모습이 바람직한 나의 모습일까? 쓸모없는 사회화된 모습을 덜어야 할까? 아니면 추한 본성을 덜어야 할까? 사실 지금의 나도 살아가는데 그렇게 큰 불편함은 없긴 하다. 조금씩 밸런스를 맞춰가며 살아가야지.\n\n\n\n 맨 위로",
    "crumbs": [
      "PARA",
      "Inboxes",
      "Notes",
      "나의 단점에 관한 고찰"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/product/02.html#수업-요약",
    "href": "posts/01_projects/bs_3_1/notes/product/02.html#수업-요약",
    "title": "organization을 process 관점에서 바라보기",
    "section": "수업 요약",
    "text": "수업 요약\n\n시험 시간 9시-10시\n왜 공급을 할 수 있는 비즈니스 프로세스는 즉각적이지 않은가",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Product",
      "organization을 process 관점에서 바라보기"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/product/02.html#예시",
    "href": "posts/01_projects/bs_3_1/notes/product/02.html#예시",
    "title": "organization을 process 관점에서 바라보기",
    "section": "예시",
    "text": "예시\n\n방사선조영실 작업 간트 차트\n\n작업\n대기: 수요와 공급의 불일치, 작업들에 존재하는 불확실성으로 생기는 것\n흐름(flow): 작업이 진행되는 것을 tracking\n\n단위\n\n자원: 노동력, 설비\n\n\n\n프로세스 평가를 위한 3가지 요소\n\n흐름률: 처리 능력. 생산 능력\n\n흐름률이 오르면 생산 능력이 오른다.\n\n흐름시간\n\n흐름시간이 줄어들면 수요-공급 사이의 시간도 줄어든다.\n\n재고\n\n제일 다루기 간편함\n\n\n\n\n리틀의 법칙\n위의 세개와 수요 공급간의 관계가 있다.\n\nI = R * T (항상 성립)\n\nI: 평균 재고 (flow time 동안 들어온 input)\nR: 평균 흐름률\nT: 평균 흐름시간",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Product",
      "organization을 process 관점에서 바라보기"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/data_mining/01.html#masking",
    "href": "posts/01_projects/bs_3_1/notes/data_mining/01.html#masking",
    "title": "Numpy-2",
    "section": "Masking",
    "text": "Masking\n\nimport numpy as np\n\na = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nbool_indexing = (a % 2 == 0)\nprint(bool_indexing)\n\n[[False  True False]\n [ True False  True]\n [False  True False]]\n\n\n\nprint(a[bool_indexing])\n\n[2 4 6 8]\n\n\n\ndata = np.random.randn(4, 5)\nnp.around(data, 2) \n\narray([[-0.  ,  1.1 ,  0.01, -0.11, -0.52],\n       [-0.89,  0.52, -0.83, -0.96, -0.13],\n       [-1.07, -1.03, -1.04, -0.14, -0.18],\n       [-1.51, -2.27, -0.79, -1.82, -1.29]])\n\n\n\ndata = np.array([[ 1.87883804, -0.39056004, 1.18374625, -0.91699153, 0.23666417],\n[ 0.28408269, 1.14786861, -1.54178089, 0.12426074, 0.54734241],\n[-1.67396474, -1.88974809, -0.09876402, 1.05047587, 1.31776863],\n[-0.27404289, -0.73640766, -0.16014918,\n-1.03578294, 0.62956063]])\ndata[data[:, 0] &lt;0, 1:3] = 1.0\n\n\na[::-1]\n\narray([[7, 8, 9],\n       [4, 5, 6],\n       [1, 2, 3]])\n\n\n\na = np.array([[1, 2, 3], [4, 5, 6]])\nprint(a.reshape(3, 2))\n\n[[1 2]\n [3 4]\n [5 6]]\n\n\n\nprint(a.T)\n\n[[1 4]\n [2 5]\n [3 6]]\n\n\n\nimport matplotlib.pyplot as plt\n\nx1 = np.arange(0, 10, 0.1)\nx2 = np.sin(x1)\n\nplt.plot(x1, x2)\nplt.show()\n\n\n\n\n\n\n\n\n\ny1=np.sin(x1)\ny2=np.cos(x1)\nplt.plot(x1, y1, label='sin')\nplt.plot(x1, y2, linestyle='--', label='cos')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('sin and cos')\nplt.legend()\nplt.show()",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Data Mining",
      "Numpy-2"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/data_mining/02.html#series",
    "href": "posts/01_projects/bs_3_1/notes/data_mining/02.html#series",
    "title": "pandas",
    "section": "Series",
    "text": "Series\n\nindex, value로 이루어진 데이터 구조\n\n\nimport pandas as pd\n\ns = pd.Series(['1', 3, 5, 7, 9])\n\n\ndata = {\n  'yo': {\n      'hey': 300\n  },\n  'hey': [200, 500],\n  'haha': [100, 90]\n}\ndata = pd.Series(data)\ndata.name = 'what'\ndata.index.name = 'kiki'\ndata\n\nkiki\nyo      {'hey': 300}\nhey       [200, 500]\nhaha       [100, 90]\nName: what, dtype: object",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Data Mining",
      "pandas"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/statistics/01.html",
    "href": "posts/01_projects/bs_3_1/notes/statistics/01.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "맨 위로",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Statistics",
      "01"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/statistics/01.html#통계적-추론",
    "href": "posts/01_projects/bs_3_1/notes/statistics/01.html#통계적-추론",
    "title": "통계적 추정",
    "section": "통계적 추론",
    "text": "통계적 추론\n표본으로부터 모수를 추론하는 것:\n\n추정\n\n점추정\n구간추정\n\n가설 검정",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Statistics",
      "통계적 추정"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/statistics/01.html#추정",
    "href": "posts/01_projects/bs_3_1/notes/statistics/01.html#추정",
    "title": "통계적 추정",
    "section": "추정",
    "text": "추정\n추정량의 결정 기준:\n\n불편성\n\n\\(E(\\hat{\\theta}) = θ\\)\nbias = \\(E(\\hat{\\theta}) - \\theta\\)\n\n보통 sample size가 커질수록 bias는 0에 수렴\n\n\\(\\bar{X}, X_n\\)은 μ의 불편추정량이다.\n\n\n\n최소분산\n\n\\(Var(\\bar{X})\\)가 \\(Var(X_n)\\)보다 분산이 작아서 더 좋은 추정량\n\\(MSE(\\hat{\\theta}) = E[(\\hat{\\theta} - \\theta)^2] = Var(\\hat{\\theta}) + bias^2\\)\n\n큰 오차에 더 큰 페널티를 주기 위해 제곱\n\n\n\n\n대표적인 불편추정량\n\n모평균\n모비율\n모평균 차이\n모비율 차이",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Statistics",
      "통계적 추정"
    ]
  }
]