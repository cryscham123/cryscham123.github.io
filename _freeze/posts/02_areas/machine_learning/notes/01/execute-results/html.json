{
  "hash": "2ef98fda0d2bfd59bbe841de83af1b3e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"data preprocessing\"\ndate: 2025-02-26\ncategories: [\"machine learning\"]\n---\n\n\n\n\n![](/img/stat-thumb.jpg){.post-thumbnail}\n\n## Load Library and data\n\n::: {#5289072e .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndataset = pd.read_csv('_data/00-data.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n```\n:::\n\n\n::: {#d83b46d1 .cell execution_count=2}\n``` {.python .cell-code}\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\narray([['France', 44.0, 72000.0],\n       ['Spain', 27.0, 48000.0],\n       ['Germany', 30.0, 54000.0],\n       ['Spain', 38.0, 61000.0],\n       ['Germany', 40.0, nan],\n       ['France', 35.0, 58000.0],\n       ['Spain', nan, 52000.0],\n       ['France', 48.0, 79000.0],\n       ['Germany', 50.0, 83000.0],\n       ['France', 37.0, 67000.0]], dtype=object)\n```\n:::\n:::\n\n\n::: {#e6fe0b53 .cell execution_count=3}\n``` {.python .cell-code}\ny\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\narray(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n      dtype=object)\n```\n:::\n:::\n\n\n## Taking care of Missing data\n\n1. delete\n1. replace\n\n::: {#7c47cdc1 .cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(x[:, 1:3])\nx[:, 1:3] = imputer.transform(x[:, 1:3])\nprint(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[['France' 44.0 72000.0]\n ['Spain' 27.0 48000.0]\n ['Germany' 30.0 54000.0]\n ['Spain' 38.0 61000.0]\n ['Germany' 40.0 63777.77777777778]\n ['France' 35.0 58000.0]\n ['Spain' 38.77777777777778 52000.0]\n ['France' 48.0 79000.0]\n ['Germany' 50.0 83000.0]\n ['France' 37.0 67000.0]]\n```\n:::\n:::\n\n\n## Encoding Cagegorical data\n\n- 단순히 categorical 변수를 1, 2, 3으로 변형하면 순서가 고려된 것으로 간주될 수 있다.\n- 그래서 [0, 0, 1], [1, 0, 1] 이런 식으로 one hot encoding을 진행한다.\n\n::: {#658fbb8c .cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nx = np.array(ct.fit_transform(x))\nprint(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1.0 0.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [0.0 1.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [0.0 1.0 0.0 40.0 63777.77777777778]\n [1.0 0.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [1.0 0.0 0.0 48.0 79000.0]\n [0.0 1.0 0.0 50.0 83000.0]\n [1.0 0.0 0.0 37.0 67000.0]]\n```\n:::\n:::\n\n\n::: {#e7c95dad .cell execution_count=6}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ny = le.fit_transform(y)\nprint(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[0 1 0 0 1 1 0 1 0 1]\n```\n:::\n:::\n\n\n## Split dataset into training set and test set\n\n- feature scaling 이전에 진행되어야함. (test set은 모델이 모르는 정보가 되야하기 때문)\n\n::: {#281433b5 .cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n```\n:::\n\n\n## feature scaling\n\n::: {#980f6480 .cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\nX_test[:, 3:] = sc.transform(X_test[:, 3:])\n```\n:::\n\n\n::: {#3181ddde .cell execution_count=9}\n``` {.python .cell-code}\nprint(X_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[0.0 1.0 0.0 -1.2231822690784795 -1.074632541818236]\n [1.0 0.0 0.0 0.628120624661922 0.5410562913562817]\n [0.0 1.0 0.0 1.4215361505506654 1.5284216894073759]\n [0.0 1.0 0.0 0.09917694073609294 -0.19697441021726317]\n [1.0 0.0 0.0 -0.2975308222082788 0.09225383769669344]\n [0.0 0.0 1.0 -0.16529490122682156 -0.4463091066948125]\n [0.0 0.0 1.0 -1.6198900320228513 -1.6131954862097422]\n [1.0 0.0 0.0 1.157064308587751 1.1693797264797055]]\n```\n:::\n:::\n\n\n::: {#7d521e71 .cell execution_count=10}\n``` {.python .cell-code}\nprint(X_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[0.0 0.0 1.0 -0.06244474046346582 -1.2541535232820715]\n [1.0 0.0 0.0 -0.5620026641711934 -0.7155905788905655]]\n```\n:::\n:::\n\n\n",
    "supporting": [
      "01_files"
    ],
    "filters": [],
    "includes": {}
  }
}