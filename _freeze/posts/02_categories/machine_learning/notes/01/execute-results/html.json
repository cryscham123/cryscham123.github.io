{
  "hash": "2ef98fda0d2bfd59bbe841de83af1b3e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"data preprocessing\"\ndate: 2025-02-26\ncategories: [\"machine learning\"]\n---\n\n\n\n\n![](/img/stat-thumb.jpg){.post-thumbnail}\n\n## Load Library and data\n\n::: {#104ab7e7 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndataset = pd.read_csv('_data/00-data.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n```\n:::\n\n\n::: {#8d3c7774 .cell execution_count=2}\n``` {.python .cell-code}\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\narray([['France', 44.0, 72000.0],\n       ['Spain', 27.0, 48000.0],\n       ['Germany', 30.0, 54000.0],\n       ['Spain', 38.0, 61000.0],\n       ['Germany', 40.0, nan],\n       ['France', 35.0, 58000.0],\n       ['Spain', nan, 52000.0],\n       ['France', 48.0, 79000.0],\n       ['Germany', 50.0, 83000.0],\n       ['France', 37.0, 67000.0]], dtype=object)\n```\n:::\n:::\n\n\n::: {#856d7301 .cell execution_count=3}\n``` {.python .cell-code}\ny\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\narray(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n      dtype=object)\n```\n:::\n:::\n\n\n## Taking care of Missing data\n\n1. delete\n1. replace\n\n::: {#07fc0de1 .cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(x[:, 1:3])\nx[:, 1:3] = imputer.transform(x[:, 1:3])\nprint(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[['France' 44.0 72000.0]\n ['Spain' 27.0 48000.0]\n ['Germany' 30.0 54000.0]\n ['Spain' 38.0 61000.0]\n ['Germany' 40.0 63777.77777777778]\n ['France' 35.0 58000.0]\n ['Spain' 38.77777777777778 52000.0]\n ['France' 48.0 79000.0]\n ['Germany' 50.0 83000.0]\n ['France' 37.0 67000.0]]\n```\n:::\n:::\n\n\n## Encoding Cagegorical data\n\n- 단순히 categorical 변수를 1, 2, 3으로 변형하면 순서가 고려된 것으로 간주될 수 있다.\n- 그래서 [0, 0, 1], [1, 0, 1] 이런 식으로 one hot encoding을 진행한다.\n\n::: {#a125cf20 .cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nx = np.array(ct.fit_transform(x))\nprint(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1.0 0.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [0.0 1.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [0.0 1.0 0.0 40.0 63777.77777777778]\n [1.0 0.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [1.0 0.0 0.0 48.0 79000.0]\n [0.0 1.0 0.0 50.0 83000.0]\n [1.0 0.0 0.0 37.0 67000.0]]\n```\n:::\n:::\n\n\n::: {#7989ba93 .cell execution_count=6}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ny = le.fit_transform(y)\nprint(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[0 1 0 0 1 1 0 1 0 1]\n```\n:::\n:::\n\n\n## Split dataset into training set and test set\n\n- feature scaling 이전에 진행되어야함. (test set은 모델이 모르는 정보가 되야하기 때문)\n\n::: {#0181a42f .cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n```\n:::\n\n\n## feature scaling\n\n::: {#6901f8c6 .cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\nX_test[:, 3:] = sc.transform(X_test[:, 3:])\n```\n:::\n\n\n::: {#18e0b9a3 .cell execution_count=9}\n``` {.python .cell-code}\nprint(X_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[0.0 1.0 0.0 1.589843519888049 1.6688118414569673]\n [0.0 1.0 0.0 0.11473097566202425 -0.017053551664523183]\n [0.0 0.0 1.0 -1.8029153318318079 -1.4008274581573077]\n [0.0 0.0 1.0 -0.06556055752115642 -1.0500115382013906]\n [1.0 0.0 0.0 -0.32780278760578313 0.26554816163329864]\n [0.0 0.0 1.0 -0.18029153318318067 -0.260675718300577]\n [1.0 0.0 0.0 1.294821011042844 1.31799592150105]\n [1.0 0.0 0.0 -0.622825296450988 -0.5237876582675148]]\n```\n:::\n:::\n\n\n::: {#506c6910 .cell execution_count=10}\n``` {.python .cell-code}\nprint(X_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[0.0 1.0 0.0 -1.3603815685640004 -0.874603578223432]\n [1.0 0.0 0.0 0.7047759933524341 0.704068061578195]]\n```\n:::\n:::\n\n\n",
    "supporting": [
      "01_files"
    ],
    "filters": [],
    "includes": {}
  }
}