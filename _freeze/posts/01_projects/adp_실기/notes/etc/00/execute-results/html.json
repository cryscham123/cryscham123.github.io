{
  "hash": "e512fcd77858497b6a1c69d9bcd129db",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"다차원 척도법 (Multidimensional Scaling)\"\ndate: 2025-07-13\ncategories: [\"확률 통계\"]\n---\n\n\n\n\n![](/img/stat-thumb.jpg){.post-thumbnail}\n\n## 다차원 척도법(MDS)이란?\n\n다차원 척도법(Multidimensional Scaling, MDS)은 고차원 데이터를 저차원 공간에 시각화하는 차원 축소 기법입니다. 객체들 간의 거리나 유사도를 보존하면서 2차원 또는 3차원 공간에 데이터를 투영합니다.\n\n## 필요한 라이브러리 설치 및 임포트\n\n::: {#966db7de .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import MDS\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.datasets import make_classification\nfrom scipy.spatial.distance import pdist, squareform\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams['font.family'] = 'Noto Sans KR'\n```\n:::\n\n\n## 샘플 데이터 생성\n\n다양한 케이스를 위한 샘플 데이터를 생성합니다.\n\n::: {#9591b6dd .cell execution_count=2}\n``` {.python .cell-code}\n# 1. 연속변수만 포함하는 데이터\nnp.random.seed(42)\ncontinuous_data = make_classification(\n    n_samples=100, \n    n_features=5, \n    n_classes=3, \n    n_redundant=0, \n    n_informative=5,\n    random_state=42\n)[0]\n\ncontinuous_df = pd.DataFrame(\n    continuous_data, \n    columns=[f'feature_{i+1}' for i in range(5)]\n)\n\nprint(\"연속변수 데이터셋 shape:\", continuous_df.shape)\nprint(continuous_df.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n연속변수 데이터셋 shape: (100, 5)\n   feature_1  feature_2  feature_3  feature_4  feature_5\n0   0.051936  -1.797511  -1.855638  -1.396449  -1.196204\n1   0.403789   0.921306   3.200886   1.984403   0.106783\n2   0.300321  -0.930015   0.162936  -0.576956   2.232421\n3  -0.199444  -0.496488  -1.928236   0.929103  -1.480070\n4   1.144153  -1.221289  -0.581620  -0.475414   1.675759\n```\n:::\n:::\n\n\n::: {#6e8588ab .cell execution_count=3}\n``` {.python .cell-code}\n# 2. 명목변수를 포함하는 혼합 데이터\nnp.random.seed(42)\n\n# 연속변수\nage = np.random.normal(35, 10, 100)\nincome = np.random.normal(50000, 15000, 100)\nexperience = np.random.normal(5, 3, 100)\n\n# 명목변수\neducation = np.random.choice(['고등학교', '대학교', '대학원'], 100)\ndepartment = np.random.choice(['영업', '마케팅', '개발', 'HR'], 100)\nlocation = np.random.choice(['서울', '부산', '대구', '광주'], 100)\n\nmixed_df = pd.DataFrame({\n    'age': age,\n    'income': income,\n    'experience': experience,\n    'education': education,\n    'department': department,\n    'location': location\n})\n\nprint(\"\\n혼합 데이터셋 shape:\", mixed_df.shape)\nprint(mixed_df.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n혼합 데이터셋 shape: (100, 6)\n         age        income  experience education department location\n0  39.967142  28769.438869    6.073362      고등학교         개발       서울\n1  33.617357  43690.320159    6.682354       대학교        마케팅       서울\n2  41.476885  44859.282252    8.249154      고등학교        마케팅       광주\n3  50.230299  37965.840962    8.161406      고등학교         개발       서울\n4  32.658466  47580.714325    0.866992       대학원         개발       광주\n```\n:::\n:::\n\n\n::: {#861d4607 .cell execution_count=4}\n``` {.python .cell-code}\n# 3. 거리 행렬 데이터 (도시간 거리 예시)\ncities = ['서울', '부산', '대구', '인천', '광주', '대전', '울산']\n# 실제 도시간 거리 (km)\ndistance_matrix = np.array([\n    [0, 325, 237, 28, 267, 140, 340],      # 서울\n    [325, 0, 88, 353, 158, 185, 45],       # 부산\n    [237, 88, 0, 265, 215, 97, 85],        # 대구\n    [28, 353, 265, 0, 295, 168, 368],      # 인천\n    [267, 158, 215, 295, 0, 168, 200],     # 광주\n    [140, 185, 97, 168, 168, 0, 230],      # 대전\n    [340, 45, 85, 368, 200, 230, 0]       # 울산\n])\n\ndistance_df = pd.DataFrame(distance_matrix, \n                          index=cities, \n                          columns=cities)\n\nprint(\"\\n도시간 거리 행렬:\")\nprint(distance_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n도시간 거리 행렬:\n     서울   부산   대구   인천   광주   대전   울산\n서울    0  325  237   28  267  140  340\n부산  325    0   88  353  158  185   45\n대구  237   88    0  265  215   97   85\n인천   28  353  265    0  295  168  368\n광주  267  158  215  295    0  168  200\n대전  140  185   97  168  168    0  230\n울산  340   45   85  368  200  230    0\n```\n:::\n:::\n\n\n## 1. 연속변수만 포함하는 기본 MDS 분석\n\n연속변수로만 구성된 데이터에 MDS를 적용하는 예시입니다.\n\n::: {#5bfe7e0b .cell execution_count=5}\n``` {.python .cell-code}\n# 데이터 표준화\nscaler = StandardScaler()\ncontinuous_scaled = scaler.fit_transform(continuous_df)\n\n# 기본 MDS 적용 (2차원)\nmds = MDS(n_components=2, random_state=42)\nmds_result = mds.fit_transform(continuous_scaled)\n\n# 결과를 DataFrame으로 변환\nmds_df = pd.DataFrame(mds_result, columns=['MDS1', 'MDS2'])\n\nprint(\"MDS 결과:\")\nprint(mds_df.head())\nprint(f\"\\nStress 값: {mds.stress_:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMDS 결과:\n       MDS1      MDS2\n0  0.329495 -1.755421\n1  0.049463  3.238964\n2 -0.946161  0.369966\n3  0.357709 -0.007320\n4 -0.769899 -0.435848\n\nStress 값: 3208.7256\n```\n:::\n:::\n\n\n::: {#b7201053 .cell execution_count=6}\n``` {.python .cell-code}\n# 시각화\nplt.figure(figsize=(10, 8))\nplt.scatter(mds_df['MDS1'], mds_df['MDS2'], alpha=0.7, s=50)\nplt.xlabel('MDS Dimension 1')\nplt.ylabel('MDS Dimension 2')\nplt.title('MDS 결과 - 연속변수 데이터')\nplt.grid(True, alpha=0.3)\n\n# 각 점에 인덱스 번호 표시\nfor i, (x, y) in enumerate(zip(mds_df['MDS1'], mds_df['MDS2'])):\n    if i % 10 == 0:  # 10개마다 번호 표시\n        plt.annotate(str(i), (x, y), xytext=(5, 5), \n                    textcoords='offset points', fontsize=8)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-7-output-1.png){width=950 height=757}\n:::\n:::\n\n\n::: {#29231f8d .cell execution_count=7}\n``` {.python .cell-code}\n# 클래스별로 색상을 다르게 하여 시각화 (원본 클래스 정보 사용)\n_, y_true = make_classification(\n    n_samples=100, \n    n_features=5, \n    n_classes=3, \n    n_redundant=0, \n    n_informative=5,\n    random_state=42\n)\n\nplt.figure(figsize=(10, 8))\ncolors = ['red', 'blue', 'green']\nfor i in range(3):\n    mask = y_true == i\n    plt.scatter(mds_df.loc[mask, 'MDS1'], \n                mds_df.loc[mask, 'MDS2'], \n                c=colors[i], label=f'Class {i}', alpha=0.7, s=50)\n\nplt.xlabel('MDS Dimension 1')\nplt.ylabel('MDS Dimension 2')\nplt.title('MDS 결과 - 클래스별 색상 구분')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-8-output-1.png){width=950 height=757}\n:::\n:::\n\n\n::: {#884ed1d6 .cell execution_count=8}\n``` {.python .cell-code}\n# 거리 보존 정도 확인\nfrom sklearn.metrics import pairwise_distances\n\n# 원본 데이터의 거리 행렬\noriginal_distances = pairwise_distances(continuous_scaled)\n# MDS 결과의 거리 행렬\nmds_distances = pairwise_distances(mds_result)\n\n# 거리 상관계수 계산\ndistance_correlation = np.corrcoef(\n    original_distances.flatten(), \n    mds_distances.flatten()\n)[0, 1]\n\nprint(f\"원본 거리와 MDS 거리의 상관계수: {distance_correlation:.4f}\")\n\n# Shepard diagram 그리기\nplt.figure(figsize=(8, 6))\nplt.scatter(original_distances.flatten(), \n            mds_distances.flatten(), \n            alpha=0.3, s=1)\nplt.xlabel('Original Distances')\nplt.ylabel('MDS Distances')\nplt.title('Shepard Diagram - 거리 보존 정도')\nplt.plot([0, original_distances.max()], \n         [0, original_distances.max()], \n         'r--', alpha=0.8)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n원본 거리와 MDS 거리의 상관계수: 0.8435\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-9-output-2.png){width=758 height=566}\n:::\n:::\n\n\n## 2. 명목변수를 포함하는 혼합 데이터 MDS 분석\n\n명목변수와 연속변수가 혼합된 데이터에 MDS를 적용하는 예시입니다.\n\n::: {#83cef539 .cell execution_count=9}\n``` {.python .cell-code}\n# 혼합 데이터 전처리\ndef preprocess_mixed_data(df):\n    \"\"\"혼합 데이터를 MDS에 적합하도록 전처리\"\"\"\n    processed_df = df.copy()\n    \n    # 연속변수 표준화\n    continuous_cols = ['age', 'income', 'experience']\n    scaler = StandardScaler()\n    processed_df[continuous_cols] = scaler.fit_transform(processed_df[continuous_cols])\n    \n    # 명목변수 원핫 인코딩\n    categorical_cols = ['education', 'department', 'location']\n    for col in categorical_cols:\n        dummies = pd.get_dummies(processed_df[col], prefix=col)\n        processed_df = pd.concat([processed_df, dummies], axis=1)\n        processed_df.drop(col, axis=1, inplace=True)\n    \n    return processed_df\n\n# 데이터 전처리\nmixed_processed = preprocess_mixed_data(mixed_df)\nprint(\"전처리된 혼합 데이터 shape:\", mixed_processed.shape)\nprint(\"\\n컬럼 목록:\")\nprint(mixed_processed.columns.tolist())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n전처리된 혼합 데이터 shape: (100, 14)\n\n컬럼 목록:\n['age', 'income', 'experience', 'education_고등학교', 'education_대학교', 'education_대학원', 'department_HR', 'department_개발', 'department_마케팅', 'department_영업', 'location_광주', 'location_대구', 'location_부산', 'location_서울']\n```\n:::\n:::\n\n\n::: {#da459f19 .cell execution_count=10}\n``` {.python .cell-code}\n# 혼합 데이터에 MDS 적용\nmds_mixed = MDS(n_components=2, random_state=42)\nmds_mixed_result = mds_mixed.fit_transform(mixed_processed)\n\n# 결과를 DataFrame으로 변환\nmds_mixed_df = pd.DataFrame(mds_mixed_result, columns=['MDS1', 'MDS2'])\n\nprint(\"혼합 데이터 MDS 결과:\")\nprint(mds_mixed_df.head())\nprint(f\"\\nStress 값: {mds_mixed.stress_:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n혼합 데이터 MDS 결과:\n       MDS1      MDS2\n0  1.112396 -1.853207\n1  0.199845 -1.172801\n2 -0.073573 -1.903613\n3 -0.293398 -2.665801\n4  1.287388  1.284487\n\nStress 값: 3843.1912\n```\n:::\n:::\n\n\n::: {#d47091a4 .cell execution_count=11}\n``` {.python .cell-code}\n# 부서별로 색상을 다르게 하여 시각화\nplt.figure(figsize=(12, 8))\ndepartments = mixed_df['department'].unique()\ncolors = ['red', 'blue', 'green', 'orange']\n\nfor i, dept in enumerate(departments):\n    mask = mixed_df['department'] == dept\n    plt.scatter(mds_mixed_df.loc[mask, 'MDS1'], \n                mds_mixed_df.loc[mask, 'MDS2'], \n                c=colors[i], label=dept, alpha=0.7, s=60)\n\nplt.xlabel('MDS Dimension 1')\nplt.ylabel('MDS Dimension 2')\nplt.title('MDS 결과 - 부서별 색상 구분 (혼합 데이터)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-12-output-1.png){width=1142 height=758}\n:::\n:::\n\n\n::: {#671aa270 .cell execution_count=12}\n``` {.python .cell-code}\n# 학력별로 마커를 다르게 하여 시각화\nplt.figure(figsize=(12, 8))\neducations = mixed_df['education'].unique()\nmarkers = ['o', 's', '^']\n\nfor i, edu in enumerate(educations):\n    mask = mixed_df['education'] == edu\n    plt.scatter(mds_mixed_df.loc[mask, 'MDS1'], \n                mds_mixed_df.loc[mask, 'MDS2'], \n                marker=markers[i], label=edu, alpha=0.7, s=60)\n\nplt.xlabel('MDS Dimension 1')\nplt.ylabel('MDS Dimension 2')\nplt.title('MDS 결과 - 학력별 마커 구분 (혼합 데이터)')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-13-output-1.png){width=1142 height=758}\n:::\n:::\n\n\n::: {#9dfc1b8d .cell execution_count=13}\n``` {.python .cell-code}\n# 부서와 학력을 함께 시각화\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n\n# 부서별 시각화\ndepartments = mixed_df['department'].unique()\ncolors = ['red', 'blue', 'green', 'orange']\n\nfor i, dept in enumerate(departments):\n    mask = mixed_df['department'] == dept\n    ax1.scatter(mds_mixed_df.loc[mask, 'MDS1'], \n                mds_mixed_df.loc[mask, 'MDS2'], \n                c=colors[i], label=dept, alpha=0.7, s=60)\n\nax1.set_xlabel('MDS Dimension 1')\nax1.set_ylabel('MDS Dimension 2')\nax1.set_title('부서별 구분')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# 학력별 시각화\neducations = mixed_df['education'].unique()\ncolors2 = ['purple', 'brown', 'pink']\n\nfor i, edu in enumerate(educations):\n    mask = mixed_df['education'] == edu\n    ax2.scatter(mds_mixed_df.loc[mask, 'MDS1'], \n                mds_mixed_df.loc[mask, 'MDS2'], \n                c=colors2[i], label=edu, alpha=0.7, s=60)\n\nax2.set_xlabel('MDS Dimension 1')\nax2.set_ylabel('MDS Dimension 2')\nax2.set_title('학력별 구분')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-14-output-1.png){width=1910 height=757}\n:::\n:::\n\n\n::: {#ea33eefa .cell execution_count=14}\n``` {.python .cell-code}\n# Gower 거리를 사용한 혼합 데이터 MDS\ndef gower_distance(X):\n    \"\"\"Gower 거리 계산 (연속변수와 명목변수 혼합용)\"\"\"\n    n_samples, n_features = X.shape\n    distances = np.zeros((n_samples, n_samples))\n    \n    # 각 피처가 연속변수인지 이진변수인지 판단\n    is_continuous = []\n    for j in range(n_features):\n        unique_vals = np.unique(X[:, j])\n        is_continuous.append(len(unique_vals) > 2)\n    \n    for i in range(n_samples):\n        for j in range(i+1, n_samples):\n            distance = 0\n            for k in range(n_features):\n                if is_continuous[k]:\n                    # 연속변수: 절대차이를 범위로 나눔\n                    range_k = np.max(X[:, k]) - np.min(X[:, k])\n                    if range_k > 0:\n                        distance += abs(X[i, k] - X[j, k]) / range_k\n                else:\n                    # 명목변수: 같으면 0, 다르면 1\n                    distance += 0 if X[i, k] == X[j, k] else 1\n            \n            distances[i, j] = distances[j, i] = distance / n_features\n    \n    return distances\n\n# 원본 혼합 데이터로 Gower 거리 계산\nmixed_array = mixed_processed.values\ngower_dist = gower_distance(mixed_array)\n\n# Gower 거리 기반 MDS\nmds_gower = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\nmds_gower_result = mds_gower.fit_transform(gower_dist)\n\n# 결과 시각화\nplt.figure(figsize=(10, 8))\ndepartments = mixed_df['department'].unique()\ncolors = ['red', 'blue', 'green', 'orange']\n\nfor i, dept in enumerate(departments):\n    mask = mixed_df['department'] == dept\n    plt.scatter(mds_gower_result[mask, 0], \n                mds_gower_result[mask, 1], \n                c=colors[i], label=dept, alpha=0.7, s=60)\n\nplt.xlabel('MDS Dimension 1')\nplt.ylabel('MDS Dimension 2')\nplt.title('Gower 거리 기반 MDS 결과')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(f\"Gower 거리 기반 MDS Stress 값: {mds_gower.stress_:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-15-output-1.png){width=950 height=757}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nGower 거리 기반 MDS Stress 값: 70.5540\n```\n:::\n:::\n\n\n## 3. 거리 행렬 기반 MDS 분석\n\n미리 계산된 거리 행렬을 사용하여 MDS를 적용하는 예시입니다.\n\n::: {#04c87ba6 .cell execution_count=15}\n``` {.python .cell-code}\n# 도시간 거리 행렬로 MDS 수행\nmds_distance = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\ncity_mds_result = mds_distance.fit_transform(distance_matrix)\n\n# 결과를 DataFrame으로 변환\ncity_mds_df = pd.DataFrame(city_mds_result, \n                          columns=['MDS1', 'MDS2'], \n                          index=cities)\n\nprint(\"도시 MDS 결과:\")\nprint(city_mds_df)\nprint(f\"\\nStress 값: {mds_distance.stress_:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n도시 MDS 결과:\n          MDS1        MDS2\n서울  -85.433007 -154.346568\n부산   59.327174  130.031955\n대구  -27.112189   81.647524\n인천  -99.393194 -179.287057\n광주  145.126739  -10.586077\n대전  -24.860674  -32.769460\n울산   32.345151  165.309682\n\nStress 값: 2023.2616\n```\n:::\n:::\n\n\n::: {#101f3de1 .cell execution_count=16}\n``` {.python .cell-code}\n# 도시 위치 시각화\nplt.figure(figsize=(12, 10))\ncolors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink']\n\nfor i, city in enumerate(cities):\n    plt.scatter(city_mds_df.loc[city, 'MDS1'], \n                city_mds_df.loc[city, 'MDS2'], \n                c=colors[i], s=200, alpha=0.7, \n                label=city, edgecolors='black', linewidth=1)\n    \n    # 도시 이름 표시\n    plt.annotate(city, \n                (city_mds_df.loc[city, 'MDS1'], city_mds_df.loc[city, 'MDS2']),\n                xytext=(10, 10), textcoords='offset points', \n                fontsize=12, fontweight='bold')\n\nplt.xlabel('MDS Dimension 1')\nplt.ylabel('MDS Dimension 2')\nplt.title('도시간 거리 기반 MDS 결과')\nplt.grid(True, alpha=0.3)\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-17-output-1.png){width=1144 height=949}\n:::\n:::\n\n\n::: {#4fcc4885 .cell execution_count=17}\n``` {.python .cell-code}\n# 실제 거리와 MDS 거리 비교\nmds_city_distances = pairwise_distances(city_mds_result)\n\n# 거리 상관계수 계산\ncity_distance_correlation = np.corrcoef(\n    distance_matrix.flatten(), \n    mds_city_distances.flatten()\n)[0, 1]\n\nprint(f\"실제 거리와 MDS 거리의 상관계수: {city_distance_correlation:.4f}\")\n\n# Shepard diagram for city distances\nplt.figure(figsize=(8, 6))\nplt.scatter(distance_matrix.flatten(), \n            mds_city_distances.flatten(), \n            alpha=0.6, s=30)\nplt.xlabel('Original Distances (km)')\nplt.ylabel('MDS Distances')\nplt.title('Shepard Diagram - 도시간 거리 보존 정도')\nplt.plot([0, distance_matrix.max()], \n         [0, distance_matrix.max()], \n         'r--', alpha=0.8)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n실제 거리와 MDS 거리의 상관계수: 0.9970\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-18-output-2.png){width=758 height=566}\n:::\n:::\n\n\n::: {#6a960d30 .cell execution_count=18}\n``` {.python .cell-code}\n# 3차원 MDS 수행\nmds_3d = MDS(n_components=3, dissimilarity='precomputed', random_state=42)\ncity_mds_3d_result = mds_3d.fit_transform(distance_matrix)\n\n# 3D 시각화\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(12, 10))\nax = fig.add_subplot(111, projection='3d')\n\ncolors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink']\n\nfor i, city in enumerate(cities):\n    ax.scatter(city_mds_3d_result[i, 0], \n               city_mds_3d_result[i, 1], \n               city_mds_3d_result[i, 2],\n               c=colors[i], s=200, alpha=0.7, \n               label=city, edgecolors='black', linewidth=1)\n    \n    # 도시 이름 표시\n    ax.text(city_mds_3d_result[i, 0], \n            city_mds_3d_result[i, 1], \n            city_mds_3d_result[i, 2], \n            city, fontsize=10, fontweight='bold')\n\nax.set_xlabel('MDS Dimension 1')\nax.set_ylabel('MDS Dimension 2')\nax.set_zlabel('MDS Dimension 3')\nax.set_title('3차원 MDS 결과 - 도시간 거리')\nax.legend(bbox_to_anchor=(1.1, 1), loc='upper left')\nplt.tight_layout()\nplt.show()\n\nprint(f\"3차원 MDS Stress 값: {mds_3d.stress_:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-19-output-1.png){width=1100 height=950}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n3차원 MDS Stress 값: 1974.2860\n```\n:::\n:::\n\n\n::: {#2ba3c891 .cell execution_count=19}\n``` {.python .cell-code}\n# 차원별 Stress 값 비교\ndimensions = range(1, 6)\nstress_values = []\n\nfor dim in dimensions:\n    mds_temp = MDS(n_components=dim, dissimilarity='precomputed', random_state=42)\n    mds_temp.fit(distance_matrix)\n    stress_values.append(mds_temp.stress_)\n\n# Stress plot (Scree plot)\nplt.figure(figsize=(10, 6))\nplt.plot(dimensions, stress_values, 'bo-', linewidth=2, markersize=8)\nplt.xlabel('차원 수')\nplt.ylabel('Stress 값')\nplt.title('차원 수에 따른 Stress 값 변화')\nplt.grid(True, alpha=0.3)\nplt.xticks(dimensions)\n\n# 각 점에 stress 값 표시\nfor i, stress in enumerate(stress_values):\n    plt.annotate(f'{stress:.3f}', \n                (dimensions[i], stress), \n                xytext=(0, 10), textcoords='offset points', \n                ha='center', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"차원별 Stress 값:\")\nfor dim, stress in zip(dimensions, stress_values):\n    print(f\"{dim}차원: {stress:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-20-output-1.png){width=950 height=565}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n차원별 Stress 값:\n1차원: 340937.8571\n2차원: 2023.2616\n3차원: 1974.2860\n4차원: 1980.2935\n5차원: 1982.6011\n```\n:::\n:::\n\n\n## 4. 다양한 MDS 변형 기법\n\n다양한 MDS 알고리즘을 비교해보는 예시입니다.\n\n::: {#f361ef61 .cell execution_count=20}\n``` {.python .cell-code}\n# 다양한 MDS 알고리즘 비교\nfrom sklearn.manifold import MDS\n\n# 연속 데이터를 사용하여 다양한 MDS 알고리즘 비교\nalgorithms = {\n    'Classical MDS': MDS(metric=True, random_state=42),\n    'Non-metric MDS': MDS(metric=False, random_state=42),\n    'MDS with different init': MDS(metric=True, n_init=10, random_state=42)\n}\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\nfor idx, (name, mds_algo) in enumerate(algorithms.items()):\n    # MDS 수행\n    result = mds_algo.fit_transform(continuous_scaled)\n    \n    # 클래스별 색상으로 시각화\n    colors = ['red', 'blue', 'green']\n    for i in range(3):\n        mask = y_true == i\n        axes[idx].scatter(result[mask, 0], result[mask, 1], \n                         c=colors[i], label=f'Class {i}', alpha=0.7, s=30)\n    \n    axes[idx].set_xlabel('MDS Dimension 1')\n    axes[idx].set_ylabel('MDS Dimension 2')\n    axes[idx].set_title(f'{name}\\nStress: {mds_algo.stress_:.4f}')\n    axes[idx].legend()\n    axes[idx].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-21-output-1.png){width=1718 height=564}\n:::\n:::\n\n\n::: {#4b1821d5 .cell execution_count=21}\n``` {.python .cell-code}\n# 거리 메트릭 비교\nfrom sklearn.metrics.pairwise import euclidean_distances, manhattan_distances, cosine_distances\n\n# 다양한 거리 메트릭으로 MDS 수행\ndistance_metrics = {\n    'Euclidean': euclidean_distances(continuous_scaled),\n    'Manhattan': manhattan_distances(continuous_scaled),\n    'Cosine': cosine_distances(continuous_scaled)\n}\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\nfor idx, (metric_name, dist_matrix) in enumerate(distance_metrics.items()):\n    # 거리 행렬을 사용한 MDS\n    mds_metric = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n    result = mds_metric.fit_transform(dist_matrix)\n    \n    # 클래스별 색상으로 시각화\n    colors = ['red', 'blue', 'green']\n    for i in range(3):\n        mask = y_true == i\n        axes[idx].scatter(result[mask, 0], result[mask, 1], \n                         c=colors[i], label=f'Class {i}', alpha=0.7, s=30)\n    \n    axes[idx].set_xlabel('MDS Dimension 1')\n    axes[idx].set_ylabel('MDS Dimension 2')\n    axes[idx].set_title(f'{metric_name} Distance MDS\\nStress: {mds_metric.stress_:.4f}')\n    axes[idx].legend()\n    axes[idx].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-22-output-1.png){width=1718 height=564}\n:::\n:::\n\n\n## 5. MDS 결과 해석 및 평가\n\nMDS 결과를 해석하고 평가하는 방법들을 소개합니다.\n\n::: {#eac0116c .cell execution_count=22}\n``` {.python .cell-code}\n# Stress 값 해석 기준\ndef interpret_stress(stress_value):\n    \"\"\"Stress 값을 해석하는 함수\"\"\"\n    if stress_value < 0.05:\n        return \"매우 좋음 (Excellent)\"\n    elif stress_value < 0.1:\n        return \"좋음 (Good)\"\n    elif stress_value < 0.2:\n        return \"보통 (Fair)\"\n    else:\n        return \"나쁨 (Poor)\"\n\n# 각 MDS 결과의 Stress 값 해석\nprint(\"=== MDS 결과 평가 ===\")\nprint(f\"연속변수 MDS Stress: {mds.stress_:.4f} - {interpret_stress(mds.stress_)}\")\nprint(f\"혼합데이터 MDS Stress: {mds_mixed.stress_:.4f} - {interpret_stress(mds_mixed.stress_)}\")\nprint(f\"Gower 거리 MDS Stress: {mds_gower.stress_:.4f} - {interpret_stress(mds_gower.stress_)}\")\nprint(f\"도시 거리 MDS Stress: {mds_distance.stress_:.4f} - {interpret_stress(mds_distance.stress_)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n=== MDS 결과 평가 ===\n연속변수 MDS Stress: 3208.7256 - 나쁨 (Poor)\n혼합데이터 MDS Stress: 3843.1912 - 나쁨 (Poor)\nGower 거리 MDS Stress: 70.5540 - 나쁨 (Poor)\n도시 거리 MDS Stress: 2023.2616 - 나쁨 (Poor)\n```\n:::\n:::\n\n\n::: {#9180be12 .cell execution_count=23}\n``` {.python .cell-code}\n# 차원 축소 효과 비교\ndef calculate_explained_variance_ratio(original_data, mds_result):\n    \"\"\"MDS로 설명되는 분산 비율 계산\"\"\"\n    original_var = np.var(original_data, axis=0).sum()\n    mds_var = np.var(mds_result, axis=0).sum()\n    return mds_var / original_var\n\n# 연속변수 데이터의 분산 설명 비율\nexplained_ratio = calculate_explained_variance_ratio(continuous_scaled, mds_result)\nprint(f\"\\n연속변수 MDS 분산 설명 비율: {explained_ratio:.4f} ({explained_ratio*100:.2f}%)\")\n\n# 원본 데이터 차원과 MDS 결과 비교\nprint(f\"원본 데이터 차원: {continuous_scaled.shape[1]}차원\")\nprint(f\"MDS 결과 차원: {mds_result.shape[1]}차원\")\nprint(f\"차원 축소율: {(1 - mds_result.shape[1]/continuous_scaled.shape[1])*100:.1f}%\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n연속변수 MDS 분산 설명 비율: 0.9358 (93.58%)\n원본 데이터 차원: 5차원\nMDS 결과 차원: 2차원\n차원 축소율: 60.0%\n```\n:::\n:::\n\n\n::: {#11367870 .cell execution_count=24}\n``` {.python .cell-code}\n# MDS vs PCA 비교\nfrom sklearn.decomposition import PCA\n\n# PCA 수행\npca = PCA(n_components=2, random_state=42)\npca_result = pca.fit_transform(continuous_scaled)\n\n# 비교 시각화\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# MDS 결과\ncolors = ['red', 'blue', 'green']\nfor i in range(3):\n    mask = y_true == i\n    ax1.scatter(mds_result[mask, 0], mds_result[mask, 1], \n                c=colors[i], label=f'Class {i}', alpha=0.7, s=30)\n\nax1.set_xlabel('MDS Dimension 1')\nax1.set_ylabel('MDS Dimension 2')\nax1.set_title(f'MDS 결과\\nStress: {mds.stress_:.4f}')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# PCA 결과\nfor i in range(3):\n    mask = y_true == i\n    ax2.scatter(pca_result[mask, 0], pca_result[mask, 1], \n                c=colors[i], label=f'Class {i}', alpha=0.7, s=30)\n\nax2.set_xlabel('PC1')\nax2.set_ylabel('PC2')\nax2.set_title(f'PCA 결과\\n설명분산비율: {pca.explained_variance_ratio_.sum():.4f}')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"PCA 설명 분산 비율: {pca.explained_variance_ratio_.sum():.4f} ({pca.explained_variance_ratio_.sum()*100:.2f}%)\")\nprint(f\"각 주성분별 설명 분산 비율: PC1={pca.explained_variance_ratio_[0]:.4f}, PC2={pca.explained_variance_ratio_[1]:.4f}\")\n```\n\n::: {.cell-output .cell-output-display}\n![](00_files/figure-html/cell-25-output-1.png){width=1526 height=564}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nPCA 설명 분산 비율: 0.5028 (50.28%)\n각 주성분별 설명 분산 비율: PC1=0.2727, PC2=0.2301\n```\n:::\n:::\n\n\n## 결론\n\n다차원 척도법(MDS)은 다양한 유형의 데이터에 적용할 수 있는 강력한 차원 축소 기법입니다:\n\n### 주요 특징:\n1. **거리 보존**: 원본 데이터의 거리 관계를 저차원에서 최대한 보존\n2. **유연성**: 연속변수, 명목변수, 거리 행렬 등 다양한 데이터 타입 지원\n3. **직관적 해석**: 2D/3D 시각화를 통한 직관적인 데이터 이해\n\n### 적용 사례:\n1. **연속변수**: 표준화 후 직접 적용\n2. **혼합 데이터**: 원핫 인코딩 또는 Gower 거리 사용\n3. **거리 행렬**: 미리 계산된 거리 정보 활용\n\n### 평가 지표:\n- **Stress 값**: 낮을수록 좋음 (< 0.1이 권장)\n- **거리 상관계수**: 원본과 MDS 거리의 상관관계\n- **Shepard diagram**: 거리 보존 정도 시각화\n\n",
    "supporting": [
      "00_files"
    ],
    "filters": [],
    "includes": {}
  }
}