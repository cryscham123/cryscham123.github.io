{
  "hash": "a3e7365f8318821985f39810546c71c4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"분류 - 산탄데르 고객 만족 예측\"\ndate: 2025-07-27\ncategories: [\"머신 러닝\"]\n---\n\n\n\n\n![](/img/stat-thumb.jpg){.post-thumbnail}\n\n## Preprocessing\n\n::: {#d5947441 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\n\nplt.rcParams['font.family'] = 'Noto Sans KR'\nwarnings.filterwarnings('ignore')\n\ndf = pd.read_csv('_data/santander/train.csv', encoding='latin-1')\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 76020 entries, 0 to 76019\nColumns: 371 entries, ID to TARGET\ndtypes: float64(111), int64(260)\nmemory usage: 215.2 MB\n```\n:::\n:::\n\n\n::: {#64745c05 .cell execution_count=2}\n``` {.python .cell-code}\ndf.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>var3</th>\n      <th>var15</th>\n      <th>imp_ent_var16_ult1</th>\n      <th>imp_op_var39_comer_ult1</th>\n      <th>imp_op_var39_comer_ult3</th>\n      <th>imp_op_var40_comer_ult1</th>\n      <th>imp_op_var40_comer_ult3</th>\n      <th>imp_op_var40_efect_ult1</th>\n      <th>imp_op_var40_efect_ult3</th>\n      <th>...</th>\n      <th>saldo_medio_var33_hace2</th>\n      <th>saldo_medio_var33_hace3</th>\n      <th>saldo_medio_var33_ult1</th>\n      <th>saldo_medio_var33_ult3</th>\n      <th>saldo_medio_var44_hace2</th>\n      <th>saldo_medio_var44_hace3</th>\n      <th>saldo_medio_var44_ult1</th>\n      <th>saldo_medio_var44_ult3</th>\n      <th>var38</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>...</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>7.602000e+04</td>\n      <td>76020.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>75964.050723</td>\n      <td>-1523.199277</td>\n      <td>33.212865</td>\n      <td>86.208265</td>\n      <td>72.363067</td>\n      <td>119.529632</td>\n      <td>3.559130</td>\n      <td>6.472698</td>\n      <td>0.412946</td>\n      <td>0.567352</td>\n      <td>...</td>\n      <td>7.935824</td>\n      <td>1.365146</td>\n      <td>12.215580</td>\n      <td>8.784074</td>\n      <td>31.505324</td>\n      <td>1.858575</td>\n      <td>76.026165</td>\n      <td>56.614351</td>\n      <td>1.172358e+05</td>\n      <td>0.039569</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>43781.947379</td>\n      <td>39033.462364</td>\n      <td>12.956486</td>\n      <td>1614.757313</td>\n      <td>339.315831</td>\n      <td>546.266294</td>\n      <td>93.155749</td>\n      <td>153.737066</td>\n      <td>30.604864</td>\n      <td>36.513513</td>\n      <td>...</td>\n      <td>455.887218</td>\n      <td>113.959637</td>\n      <td>783.207399</td>\n      <td>538.439211</td>\n      <td>2013.125393</td>\n      <td>147.786584</td>\n      <td>4040.337842</td>\n      <td>2852.579397</td>\n      <td>1.826646e+05</td>\n      <td>0.194945</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>-999999.000000</td>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.163750e+03</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>38104.750000</td>\n      <td>2.000000</td>\n      <td>23.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.787061e+04</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>76043.000000</td>\n      <td>2.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.064092e+05</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>113748.750000</td>\n      <td>2.000000</td>\n      <td>40.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.187563e+05</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>151838.000000</td>\n      <td>238.000000</td>\n      <td>105.000000</td>\n      <td>210000.000000</td>\n      <td>12888.030000</td>\n      <td>21024.810000</td>\n      <td>8237.820000</td>\n      <td>11073.570000</td>\n      <td>6600.000000</td>\n      <td>6600.000000</td>\n      <td>...</td>\n      <td>50003.880000</td>\n      <td>20385.720000</td>\n      <td>138831.630000</td>\n      <td>91778.730000</td>\n      <td>438329.220000</td>\n      <td>24650.010000</td>\n      <td>681462.900000</td>\n      <td>397884.300000</td>\n      <td>2.203474e+07</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 371 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#e314ea19 .cell execution_count=3}\n``` {.python .cell-code}\ndf['var3'].replace(-999999, 2, inplace=True)\ndf.drop('ID', axis=1, inplace=True)\n\nX_features = df.iloc[:, :-1]\nlabels = df.iloc[:, -1]\n```\n:::\n\n\n::: {#f9cec085 .cell execution_count=4}\n``` {.python .cell-code}\ntest_df = pd.read_csv('_data/santander/test.csv', encoding='latin-1')\ntest_df['var3'].replace(-999999, 2, inplace=True)\ntest_df.drop('ID', axis=1, inplace=True)\n```\n:::\n\n\n::: {#05d26bff .cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_features, labels, test_size=0.2)\n```\n:::\n\n\n- train, test의 label의 비율이 동일한게 좋은걸까\n\n## XGBoost\n\n::: {#8340b7d0 .cell execution_count=6}\n``` {.python .cell-code}\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3)\n```\n:::\n\n\n::: {#43b1a238 .cell execution_count=7}\n``` {.python .cell-code}\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\nevals = [(X_tr, y_tr), (X_val, y_val)]\nxgb_clf = XGBClassifier(n_estimators=400, \n                    learning_rate=0.05, \n                    early_stopping_rounds=100,\n                    eval_metric=['auc'])\nxgb_clf.fit(X_tr, y_tr, eval_set=evals, verbose=False)\nxgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\nprint(f'{xgb_roc_score:.3f}')\n```\n:::\n\n\n### 베이지안 최적화\n\n::: {#ffd62d7c .cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\ndef objective_func(search_space):\n    xgb_clf = XGBClassifier(n_estimators=100, \n                            early_stopping_rounds=30,\n                            eval_metric='auc',\n                            max_depth=int(search_space['max_depth']),\n                            min_child_weight=int(search_space['min_child_weight']),\n                            colsample_bytree=search_space['colsample_bytree'],\n                            learning_rate=search_space['learning_rate'])\n    roc_auc_list = []\n    kf = KFold(n_splits=3)\n    for tr_index, val_index in kf.split(X_train):\n        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n        X_val, y_val =  X_train.iloc[val_index], y_train.iloc[val_index]\n\n        xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])\n        roc_auc_list.append(score)\n\n    return -1 * np.mean(roc_auc_list)\n```\n:::\n\n\n::: {#c5c43e8f .cell execution_count=9}\n``` {.python .cell-code}\nfrom hyperopt import hp, fmin, tpe, Trials\n\nxgb_search_space = {\n  'max_depth': hp.quniform('max_depth', 5, 15, 1),\n  'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n  'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95),\n  'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n}\n\ntrials = Trials()\nbest = fmin(fn=objective_func,\n            space=xgb_search_space,\n            algo=tpe.suggest,\n            max_evals=50,\n            trials=trials)\nprint(best)\n```\n:::\n\n\n### 재 학습\n\n::: {#84dbf898 .cell execution_count=10}\n``` {.python .cell-code}\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\nevals = [(X_tr, y_tr), (X_val, y_val)]\nxgb_clf = XGBClassifier(n_estimators=500, \n                    learning_rate=round(best['learning_rate'], 5),\n                    max_depth=int(best['max_depth']),\n                    min_child_weight=int(best['min_child_weight']),\n                    colsample_bytree=round(best['colsample_bytree'], 5),\n                    early_stopping_rounds=100,\n                    eval_metric=['auc'])\nxgb_clf.fit(X_tr, y_tr, eval_set=evals, verbose=False)\nxgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\nprint(f'{xgb_roc_score:.3f}')\n```\n:::\n\n\n### plot importance\n\n::: {#7efd1ad9 .cell execution_count=11}\n``` {.python .cell-code}\nfrom xgboost import plot_importance\n\nplot_importance(xgb_clf, max_num_features=20, height=0.4)\n```\n:::\n\n\n## LightGBM\n\n::: {#58532da1 .cell execution_count=12}\n``` {.python .cell-code}\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier\n\nlgbm_clf = LGBMClassifier(n_estimators=500, early_stopping_rounds=100, eval_metric='auc')\n\neval_set = [(X_tr, y_tr), (X_val, y_val)]\nlgbm_clf.fit(X_tr, y_tr, eval_set=eval_set)\n\nlgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\nprint(f'{lgbm_roc_score:.3f}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Info] Number of positive: 1653, number of negative: 40918\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007850 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13447\n[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 251\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038829 -> initscore=-3.208978\n[LightGBM] [Info] Start training from score -3.208978\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.117279\tvalid_1's binary_logloss: 0.137813\n[LightGBM] [Warning] Unknown parameter: eval_metric\n0.834\n```\n:::\n:::\n\n\n### 베이지안 최적화\n\n::: {#d3b3256c .cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn.model_selection import KFold\n\ndef objective_func(search_space):\n    lgbm_clf = LGBMClassifier(n_estimators=100, \n                            early_stopping_rounds=30,\n                            eval_metric='auc',\n                            num_leaves=int(search_space['num_leaves']),\n                            max_depth=int(search_space['max_depth']),\n                            min_child_samples=int(search_space['min_child_samples']),\n                            subsample=search_space['subsample'],\n                            learning_rate=search_space['learning_rate'])\n    roc_auc_list = []\n    kf = KFold(n_splits=3)\n    for tr_index, val_index in kf.split(X_train):\n        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n        X_val, y_val =  X_train.iloc[val_index], y_train.iloc[val_index]\n\n        lgbm_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1])\n        roc_auc_list.append(score)\n\n    return -1 * np.mean(roc_auc_list)\n```\n:::\n\n\n::: {#b6d8769a .cell execution_count=14}\n``` {.python .cell-code}\nfrom hyperopt import hp, fmin, tpe, Trials\n\nlgbm_search_space = {\n  'num_leaves': hp.quniform('num_leaves', 32, 64, 1),\n  'max_depth': hp.quniform('max_depth', 100, 160, 1),\n  'min_child_samples': hp.quniform('min_child_samples', 60, 100, 1),\n  'subsample': hp.uniform('subsample', 0.7, 1),\n  'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n}\n\ntrials = Trials()\nbest = fmin(fn=objective_func,\n            space=lgbm_search_space,\n            algo=tpe.suggest,\n            max_evals=50,\n            trials=trials)\nprint(best)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009804 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Total Bins 12809\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Start training from score -3.168309\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \rTraining until validation scores don't improve for 30 rounds\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \rEarly stopping, best iteration is:\n[36]\ttraining's binary_logloss: 0.121676\tvalid_1's binary_logloss: 0.127049\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011714 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Total Bins 12874\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Start training from score -3.194075\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \rTraining until validation scores don't improve for 30 rounds\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \rEarly stopping, best iteration is:\n[44]\ttraining's binary_logloss: 0.115084\tvalid_1's binary_logloss: 0.135595\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007309 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Total Bins 12874\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Start training from score -3.233233\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \rTraining until validation scores don't improve for 30 rounds\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \rEarly stopping, best iteration is:\n[50]\ttraining's binary_logloss: 0.110571\tvalid_1's binary_logloss: 0.140209\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006776 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Total Bins 12809\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.168309\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \rEarly stopping, best iteration is:\n[68]\ttraining's binary_logloss: 0.119949\tvalid_1's binary_logloss: 0.127337\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:02<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008185 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Total Bins 12874\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.194075\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[74]\ttraining's binary_logloss: 0.114945\tvalid_1's binary_logloss: 0.135003\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005666 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Total Bins 12865\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.233233\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  2%|▏         | 1/50 [00:03<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[75]\ttraining's binary_logloss: 0.111732\tvalid_1's binary_logloss: 0.140191\n\r  2%|▏         | 1/50 [00:04<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<01:41,  2.08s/trial, best loss: -0.8354243542379886]\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006637 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12907\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.168309\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[21]\ttraining's binary_logloss: 0.121998\tvalid_1's binary_logloss: 0.127349\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:04<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006521 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12970\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.194075\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[26]\ttraining's binary_logloss: 0.115056\tvalid_1's binary_logloss: 0.136143\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008614 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 13049\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.233233\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.110308\tvalid_1's binary_logloss: 0.140967\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<01:41,  2.12s/trial, best loss: -0.8361046999787884]\r  6%|▌         | 3/50 [00:05<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006389 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12809\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.168309\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.119702\tvalid_1's binary_logloss: 0.127682\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005965 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12874\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.194075\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[21]\ttraining's binary_logloss: 0.11491\tvalid_1's binary_logloss: 0.13632\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:06<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006447 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12865\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.233233\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[19]\ttraining's binary_logloss: 0.113764\tvalid_1's binary_logloss: 0.141398\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:07<01:31,  1.95s/trial, best loss: -0.8361046999787884]\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006690 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12809\n\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.168309\n\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  8%|▊         | 4/50 [00:07<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[71]\ttraining's binary_logloss: 0.114179\tvalid_1's binary_logloss: 0.127237\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006128 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12874\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.194075\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  8%|▊         | 4/50 [00:08<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[57]\ttraining's binary_logloss: 0.113751\tvalid_1's binary_logloss: 0.136174\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007084 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12865\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.233233\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[58]\ttraining's binary_logloss: 0.11113\tvalid_1's binary_logloss: 0.140897\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:09<01:24,  1.83s/trial, best loss: -0.8361046999787884]\r 10%|█         | 5/50 [00:09<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:09<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:09<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006562 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12809\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.168309\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[23]\ttraining's binary_logloss: 0.120721\tvalid_1's binary_logloss: 0.127623\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005976 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12874\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.194075\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[21]\ttraining's binary_logloss: 0.117914\tvalid_1's binary_logloss: 0.135692\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:10<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006221 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12865\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.233233\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.117142\tvalid_1's binary_logloss: 0.141073\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:11<01:28,  1.98s/trial, best loss: -0.8361046999787884]\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005795 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12809\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.168309\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[23]\ttraining's binary_logloss: 0.122492\tvalid_1's binary_logloss: 0.127389\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:11<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005857 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12882\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.194075\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.119931\tvalid_1's binary_logloss: 0.13599\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007378 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12883\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.233233\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[21]\ttraining's binary_logloss: 0.116742\tvalid_1's binary_logloss: 0.14122\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:12<01:20,  1.83s/trial, best loss: -0.8361046999787884]\r 14%|█▍        | 7/50 [00:12<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:12<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:12<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:12<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 14%|█▍        | 7/50 [00:12<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006486 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12809\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.168309\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[37]\ttraining's binary_logloss: 0.118076\tvalid_1's binary_logloss: 0.12711\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008708 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12874\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.194075\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 14%|█▍        | 7/50 [00:13<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[27]\ttraining's binary_logloss: 0.118244\tvalid_1's binary_logloss: 0.135768\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007417 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12865\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.233233\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[34]\ttraining's binary_logloss: 0.11261\tvalid_1's binary_logloss: 0.140798\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:14<01:12,  1.69s/trial, best loss: -0.8361046999787884]\r 16%|█▌        | 8/50 [00:14<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:14<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:14<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:14<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 16%|█▌        | 8/50 [00:14<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007634 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 16%|█▌        | 8/50 [00:14<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12907\n\r 16%|█▌        | 8/50 [00:14<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 16%|█▌        | 8/50 [00:14<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:14<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:14<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.168309\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[93]\ttraining's binary_logloss: 0.113871\tvalid_1's binary_logloss: 0.127108\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007168 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12934\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.194075\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 16%|█▌        | 8/50 [00:15<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[75]\ttraining's binary_logloss: 0.113106\tvalid_1's binary_logloss: 0.135792\n\r 16%|█▌        | 8/50 [00:16<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:16<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:16<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:16<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:16<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 16%|█▌        | 8/50 [00:16<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008788 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 16%|█▌        | 8/50 [00:16<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12989\n\r 16%|█▌        | 8/50 [00:16<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 16%|█▌        | 8/50 [00:16<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:16<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:16<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 16%|█▌        | 8/50 [00:17<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.233233\n\r 16%|█▌        | 8/50 [00:17<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 16%|█▌        | 8/50 [00:17<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[82]\ttraining's binary_logloss: 0.109277\tvalid_1's binary_logloss: 0.140921\n\r 16%|█▌        | 8/50 [00:17<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:17<01:14,  1.76s/trial, best loss: -0.8361046999787884]\r 18%|█▊        | 9/50 [00:17<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:17<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:17<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:17<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 18%|█▊        | 9/50 [00:17<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007124 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 18%|█▊        | 9/50 [00:17<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12809\n\r 18%|█▊        | 9/50 [00:17<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 18%|█▊        | 9/50 [00:17<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.168309\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[57]\ttraining's binary_logloss: 0.120677\tvalid_1's binary_logloss: 0.127111\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009349 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12874\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.194075\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 18%|█▊        | 9/50 [00:18<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[50]\ttraining's binary_logloss: 0.118347\tvalid_1's binary_logloss: 0.135488\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013450 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Total Bins 12865\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.233233\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 18%|█▊        | 9/50 [00:19<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \rEarly stopping, best iteration is:\n[54]\ttraining's binary_logloss: 0.114424\tvalid_1's binary_logloss: 0.140196\n\r 18%|█▊        | 9/50 [00:20<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:20<01:27,  2.14s/trial, best loss: -0.8361046999787884]\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006974 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12907\n\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 20%|██        | 10/50 [00:20<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[78]\ttraining's binary_logloss: 0.111459\tvalid_1's binary_logloss: 0.12715\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006741 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[58]\ttraining's binary_logloss: 0.112371\tvalid_1's binary_logloss: 0.13579\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:21<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:22<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:22<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:22<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 20%|██        | 10/50 [00:22<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007176 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 20%|██        | 10/50 [00:22<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 13017\n\r 20%|██        | 10/50 [00:22<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 20%|██        | 10/50 [00:22<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:22<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:22<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 20%|██        | 10/50 [00:25<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 20%|██        | 10/50 [00:25<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 20%|██        | 10/50 [00:25<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[76]\ttraining's binary_logloss: 0.105423\tvalid_1's binary_logloss: 0.141018\n\r 20%|██        | 10/50 [00:25<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:25<01:30,  2.26s/trial, best loss: -0.8361046999787884]\r 22%|██▏       | 11/50 [00:25<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006851 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[19]\ttraining's binary_logloss: 0.123258\tvalid_1's binary_logloss: 0.127671\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008232 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 22%|██▏       | 11/50 [00:26<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[19]\ttraining's binary_logloss: 0.118847\tvalid_1's binary_logloss: 0.135735\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006765 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.115967\tvalid_1's binary_logloss: 0.140884\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:27<02:09,  3.33s/trial, best loss: -0.8361046999787884]\r 24%|██▍       | 12/50 [00:27<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:27<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:27<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007459 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[17]\ttraining's binary_logloss: 0.118279\tvalid_1's binary_logloss: 0.128419\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010830 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12882\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 24%|██▍       | 12/50 [00:28<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[16]\ttraining's binary_logloss: 0.114963\tvalid_1's binary_logloss: 0.136964\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008271 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12935\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.111041\tvalid_1's binary_logloss: 0.141811\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:29<01:49,  2.88s/trial, best loss: -0.8361046999787884]\r 26%|██▌       | 13/50 [00:29<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:29<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:29<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:29<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006716 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12911\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.117911\tvalid_1's binary_logloss: 0.127609\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007818 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12970\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 26%|██▌       | 13/50 [00:30<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[26]\ttraining's binary_logloss: 0.112846\tvalid_1's binary_logloss: 0.135945\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007760 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 13049\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[21]\ttraining's binary_logloss: 0.11335\tvalid_1's binary_logloss: 0.141758\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:31<01:36,  2.60s/trial, best loss: -0.8361046999787884]\r 28%|██▊       | 14/50 [00:31<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011169 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[15]\ttraining's binary_logloss: 0.123793\tvalid_1's binary_logloss: 0.127794\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006417 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 28%|██▊       | 14/50 [00:32<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[17]\ttraining's binary_logloss: 0.117509\tvalid_1's binary_logloss: 0.136341\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012417 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[14]\ttraining's binary_logloss: 0.118131\tvalid_1's binary_logloss: 0.141827\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:33<01:29,  2.48s/trial, best loss: -0.8361046999787884]\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006221 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 30%|███       | 15/50 [00:33<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.116669\tvalid_1's binary_logloss: 0.127316\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008685 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 30%|███       | 15/50 [00:34<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.112195\tvalid_1's binary_logloss: 0.13634\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008114 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.110627\tvalid_1's binary_logloss: 0.141491\n\r 30%|███       | 15/50 [00:35<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:36<01:18,  2.23s/trial, best loss: -0.8361046999787884]\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006910 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[44]\ttraining's binary_logloss: 0.11468\tvalid_1's binary_logloss: 0.127009\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:36<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008679 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.116699\tvalid_1's binary_logloss: 0.136132\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009082 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[37]\ttraining's binary_logloss: 0.110851\tvalid_1's binary_logloss: 0.140914\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.28s/trial, best loss: -0.8361046999787884]\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009004 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 34%|███▍      | 17/50 [00:38<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.133099\tvalid_1's binary_logloss: 0.130118\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010889 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 34%|███▍      | 17/50 [00:39<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.128591\tvalid_1's binary_logloss: 0.138373\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006967 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 34%|███▍      | 17/50 [00:40<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.125837\tvalid_1's binary_logloss: 0.144181\n\r 34%|███▍      | 17/50 [00:41<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:41<01:17,  2.35s/trial, best loss: -0.8361046999787884]\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007196 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 36%|███▌      | 18/50 [00:41<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[35]\ttraining's binary_logloss: 0.117838\tvalid_1's binary_logloss: 0.127509\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009471 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12882\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[34]\ttraining's binary_logloss: 0.114266\tvalid_1's binary_logloss: 0.136132\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:42<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007509 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12935\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[44]\ttraining's binary_logloss: 0.107097\tvalid_1's binary_logloss: 0.141644\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:43<01:18,  2.47s/trial, best loss: -0.8361046999787884]\r 38%|███▊      | 19/50 [00:43<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:43<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:43<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006872 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12911\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[32]\ttraining's binary_logloss: 0.120651\tvalid_1's binary_logloss: 0.12748\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007690 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12970\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 38%|███▊      | 19/50 [00:44<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.117806\tvalid_1's binary_logloss: 0.135748\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007569 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 13049\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \rEarly stopping, best iteration is:\n[39]\ttraining's binary_logloss: 0.111183\tvalid_1's binary_logloss: 0.140593\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:45<01:17,  2.49s/trial, best loss: -0.8361046999787884]\r 40%|████      | 20/50 [00:45<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:45<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:45<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:46<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 40%|████      | 20/50 [00:46<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010567 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 40%|████      | 20/50 [00:46<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 40%|████      | 20/50 [00:46<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 40%|████      | 20/50 [00:46<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:46<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:46<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 40%|████      | 20/50 [00:46<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 40%|████      | 20/50 [00:46<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 40%|████      | 20/50 [00:46<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.127621\tvalid_1's binary_logloss: 0.127975\n\r 40%|████      | 20/50 [00:46<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:46<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028233 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.123117\tvalid_1's binary_logloss: 0.136484\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:47<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007220 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.120407\tvalid_1's binary_logloss: 0.141888\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:48<01:10,  2.36s/trial, best loss: -0.8361046999787884]\r 42%|████▏     | 21/50 [00:48<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:48<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:48<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008396 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[94]\ttraining's binary_logloss: 0.120321\tvalid_1's binary_logloss: 0.12706\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007023 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[95]\ttraining's binary_logloss: 0.116042\tvalid_1's binary_logloss: 0.135298\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007237 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.112382\tvalid_1's binary_logloss: 0.140103\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.53s/trial, best loss: -0.8361046999787884]\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007562 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 44%|████▍     | 22/50 [00:51<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.120691\tvalid_1's binary_logloss: 0.127296\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009653 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 44%|████▍     | 22/50 [00:52<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[99]\ttraining's binary_logloss: 0.116561\tvalid_1's binary_logloss: 0.135521\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007650 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 44%|████▍     | 22/50 [00:53<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.113883\tvalid_1's binary_logloss: 0.140482\n\r 44%|████▍     | 22/50 [00:54<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:54<01:11,  2.56s/trial, best loss: -0.8361206531552328]\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009103 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 46%|████▌     | 23/50 [00:54<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.12506\tvalid_1's binary_logloss: 0.127517\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007298 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 46%|████▌     | 23/50 [00:55<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.120784\tvalid_1's binary_logloss: 0.135909\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006853 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 46%|████▌     | 23/50 [00:56<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.11795\tvalid_1's binary_logloss: 0.141026\n\r 46%|████▌     | 23/50 [00:57<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:57<01:11,  2.65s/trial, best loss: -0.8361206531552328]\r 48%|████▊     | 24/50 [00:57<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:57<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [00:57<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:57<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 48%|████▊     | 24/50 [00:57<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006418 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 48%|████▊     | 24/50 [00:57<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 48%|████▊     | 24/50 [00:57<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 48%|████▊     | 24/50 [00:57<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:57<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [00:57<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 48%|████▊     | 24/50 [01:00<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 48%|████▊     | 24/50 [01:00<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 48%|████▊     | 24/50 [01:00<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[49]\ttraining's binary_logloss: 0.120728\tvalid_1's binary_logloss: 0.12726\n\r 48%|████▊     | 24/50 [01:00<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:00<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:00<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:00<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007255 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[51]\ttraining's binary_logloss: 0.116085\tvalid_1's binary_logloss: 0.13534\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006430 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 48%|████▊     | 24/50 [01:01<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[60]\ttraining's binary_logloss: 0.11095\tvalid_1's binary_logloss: 0.140369\n\r 48%|████▊     | 24/50 [01:02<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:02<01:10,  2.71s/trial, best loss: -0.8361206531552328]\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007186 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 50%|█████     | 25/50 [01:02<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[97]\ttraining's binary_logloss: 0.118162\tvalid_1's binary_logloss: 0.127362\n\r 50%|█████     | 25/50 [01:03<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:03<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006679 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[93]\ttraining's binary_logloss: 0.114804\tvalid_1's binary_logloss: 0.135408\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:04<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:05<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 50%|█████     | 25/50 [01:05<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007134 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 50%|█████     | 25/50 [01:05<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 50%|█████     | 25/50 [01:05<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 50%|█████     | 25/50 [01:05<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:05<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:05<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 50%|█████     | 25/50 [01:05<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 50%|█████     | 25/50 [01:05<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 50%|█████     | 25/50 [01:05<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[98]\ttraining's binary_logloss: 0.111333\tvalid_1's binary_logloss: 0.140214\n\r 50%|█████     | 25/50 [01:05<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:05<01:28,  3.53s/trial, best loss: -0.8361206531552328]\r 52%|█████▏    | 26/50 [01:05<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006927 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[35]\ttraining's binary_logloss: 0.11927\tvalid_1's binary_logloss: 0.127628\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007967 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:06<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[33]\ttraining's binary_logloss: 0.11608\tvalid_1's binary_logloss: 0.136215\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007403 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 52%|█████▏    | 26/50 [01:07<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[37]\ttraining's binary_logloss: 0.111732\tvalid_1's binary_logloss: 0.141059\n\r 52%|█████▏    | 26/50 [01:08<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:08<01:23,  3.49s/trial, best loss: -0.8361206531552328]\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011520 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 54%|█████▍    | 27/50 [01:08<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[65]\ttraining's binary_logloss: 0.11962\tvalid_1's binary_logloss: 0.127063\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007475 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 54%|█████▍    | 27/50 [01:09<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[72]\ttraining's binary_logloss: 0.114002\tvalid_1's binary_logloss: 0.135602\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008925 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 54%|█████▍    | 27/50 [01:10<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[71]\ttraining's binary_logloss: 0.111386\tvalid_1's binary_logloss: 0.140329\n\r 54%|█████▍    | 27/50 [01:11<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:11<01:11,  3.11s/trial, best loss: -0.8361206531552328]\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006519 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[26]\ttraining's binary_logloss: 0.123961\tvalid_1's binary_logloss: 0.127545\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010127 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 56%|█████▌    | 28/50 [01:11<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[32]\ttraining's binary_logloss: 0.117126\tvalid_1's binary_logloss: 0.13534\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007890 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 56%|█████▌    | 28/50 [01:12<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[41]\ttraining's binary_logloss: 0.111145\tvalid_1's binary_logloss: 0.140511\n\r 56%|█████▌    | 28/50 [01:13<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:13<01:06,  3.03s/trial, best loss: -0.8361206531552328]\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010351 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 58%|█████▊    | 29/50 [01:13<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.135256\tvalid_1's binary_logloss: 0.131344\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007594 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.130846\tvalid_1's binary_logloss: 0.139185\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:14<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006775 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.127867\tvalid_1's binary_logloss: 0.14514\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:15<00:57,  2.75s/trial, best loss: -0.8361206531552328]\r 60%|██████    | 30/50 [01:15<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:15<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:15<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:15<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 60%|██████    | 30/50 [01:15<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006594 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 60%|██████    | 30/50 [01:15<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 60%|██████    | 30/50 [01:15<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 60%|██████    | 30/50 [01:15<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:15<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:15<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.127239\tvalid_1's binary_logloss: 0.127384\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006879 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 60%|██████    | 30/50 [01:16<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.12288\tvalid_1's binary_logloss: 0.135571\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007380 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.120284\tvalid_1's binary_logloss: 0.140863\n\r 60%|██████    | 30/50 [01:17<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:18<00:54,  2.70s/trial, best loss: -0.8361206531552328]\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008255 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 62%|██████▏   | 31/50 [01:18<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[76]\ttraining's binary_logloss: 0.119732\tvalid_1's binary_logloss: 0.127276\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007609 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[70]\ttraining's binary_logloss: 0.116807\tvalid_1's binary_logloss: 0.135585\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:19<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008248 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[80]\ttraining's binary_logloss: 0.112368\tvalid_1's binary_logloss: 0.14032\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:20<00:49,  2.59s/trial, best loss: -0.8361206531552328]\r 64%|██████▍   | 32/50 [01:20<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:20<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:20<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007186 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[50]\ttraining's binary_logloss: 0.120657\tvalid_1's binary_logloss: 0.126949\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006888 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 64%|██████▍   | 32/50 [01:21<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[42]\ttraining's binary_logloss: 0.118801\tvalid_1's binary_logloss: 0.135645\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006469 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[51]\ttraining's binary_logloss: 0.113559\tvalid_1's binary_logloss: 0.140513\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:22<00:47,  2.66s/trial, best loss: -0.8361206531552328]\r 66%|██████▌   | 33/50 [01:22<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012104 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[36]\ttraining's binary_logloss: 0.121629\tvalid_1's binary_logloss: 0.127166\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008693 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 66%|██████▌   | 33/50 [01:23<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[34]\ttraining's binary_logloss: 0.117903\tvalid_1's binary_logloss: 0.13587\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011244 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[34]\ttraining's binary_logloss: 0.115553\tvalid_1's binary_logloss: 0.140845\n\r 66%|██████▌   | 33/50 [01:24<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:25<00:42,  2.48s/trial, best loss: -0.8361206531552328]\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007149 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[16]\ttraining's binary_logloss: 0.118882\tvalid_1's binary_logloss: 0.128522\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008471 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 68%|██████▊   | 34/50 [01:25<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[11]\ttraining's binary_logloss: 0.12009\tvalid_1's binary_logloss: 0.136809\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012520 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 68%|██████▊   | 34/50 [01:26<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[14]\ttraining's binary_logloss: 0.114296\tvalid_1's binary_logloss: 0.141912\n\r 68%|██████▊   | 34/50 [01:27<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:27<00:37,  2.36s/trial, best loss: -0.8361206531552328]\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009374 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12870\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[67]\ttraining's binary_logloss: 0.117834\tvalid_1's binary_logloss: 0.127248\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:27<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008813 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12934\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[55]\ttraining's binary_logloss: 0.116506\tvalid_1's binary_logloss: 0.135743\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008382 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12939\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 70%|███████   | 35/50 [01:28<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:29<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:29<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 70%|███████   | 35/50 [01:29<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 70%|███████   | 35/50 [01:29<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 70%|███████   | 35/50 [01:29<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[62]\ttraining's binary_logloss: 0.112207\tvalid_1's binary_logloss: 0.140686\n\r 70%|███████   | 35/50 [01:29<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:29<00:33,  2.26s/trial, best loss: -0.8361206531552328]\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008790 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 72%|███████▏  | 36/50 [01:29<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[72]\ttraining's binary_logloss: 0.116081\tvalid_1's binary_logloss: 0.12713\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008642 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 72%|███████▏  | 36/50 [01:30<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[49]\ttraining's binary_logloss: 0.117446\tvalid_1's binary_logloss: 0.135845\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006554 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 72%|███████▏  | 36/50 [01:31<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \rEarly stopping, best iteration is:\n[54]\ttraining's binary_logloss: 0.113495\tvalid_1's binary_logloss: 0.140635\n\r 72%|███████▏  | 36/50 [01:32<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:32<00:32,  2.33s/trial, best loss: -0.8361206531552328]\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008911 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 74%|███████▍  | 37/50 [01:32<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[97]\ttraining's binary_logloss: 0.11803\tvalid_1's binary_logloss: 0.126746\n\r 74%|███████▍  | 37/50 [01:35<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:35<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008127 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[85]\ttraining's binary_logloss: 0.115626\tvalid_1's binary_logloss: 0.135332\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:36<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:37<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 74%|███████▍  | 37/50 [01:37<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013095 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 74%|███████▍  | 37/50 [01:37<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 74%|███████▍  | 37/50 [01:37<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 74%|███████▍  | 37/50 [01:37<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:37<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:37<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 74%|███████▍  | 37/50 [01:37<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 74%|███████▍  | 37/50 [01:37<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 74%|███████▍  | 37/50 [01:37<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[89]\ttraining's binary_logloss: 0.112365\tvalid_1's binary_logloss: 0.140135\n\r 74%|███████▍  | 37/50 [01:37<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:37<00:31,  2.40s/trial, best loss: -0.8361206531552328]\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007640 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12870\n\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 76%|███████▌  | 38/50 [01:37<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[98]\ttraining's binary_logloss: 0.123399\tvalid_1's binary_logloss: 0.126912\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12934\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 76%|███████▌  | 38/50 [01:38<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.119208\tvalid_1's binary_logloss: 0.135189\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011345 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12939\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 76%|███████▌  | 38/50 [01:39<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.116397\tvalid_1's binary_logloss: 0.140343\n\r 76%|███████▌  | 38/50 [01:40<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:40<00:40,  3.35s/trial, best loss: -0.8368093643173017]\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006904 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12870\n\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 78%|███████▊  | 39/50 [01:40<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.13496\tvalid_1's binary_logloss: 0.13089\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006719 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12934\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.130487\tvalid_1's binary_logloss: 0.138913\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:41<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:42<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 78%|███████▊  | 39/50 [01:42<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009924 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 78%|███████▊  | 39/50 [01:42<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12939\n\r 78%|███████▊  | 39/50 [01:42<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 78%|███████▊  | 39/50 [01:42<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:42<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:42<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 78%|███████▊  | 39/50 [01:42<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 78%|███████▊  | 39/50 [01:42<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 78%|███████▊  | 39/50 [01:42<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.12765\tvalid_1's binary_logloss: 0.144942\n\r 78%|███████▊  | 39/50 [01:42<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:42<00:34,  3.12s/trial, best loss: -0.8368093643173017]\r 80%|████████  | 40/50 [01:42<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:42<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:42<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008446 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12907\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[91]\ttraining's binary_logloss: 0.119162\tvalid_1's binary_logloss: 0.126781\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010092 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 80%|████████  | 40/50 [01:43<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[76]\ttraining's binary_logloss: 0.117526\tvalid_1's binary_logloss: 0.135504\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018761 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 13017\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 80%|████████  | 40/50 [01:44<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[84]\ttraining's binary_logloss: 0.113084\tvalid_1's binary_logloss: 0.140427\n\r 80%|████████  | 40/50 [01:45<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:45<00:29,  2.92s/trial, best loss: -0.8368093643173017]\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007948 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12870\n\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 82%|████████▏ | 41/50 [01:45<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.124667\tvalid_1's binary_logloss: 0.127059\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006578 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12934\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 82%|████████▏ | 41/50 [01:46<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.120428\tvalid_1's binary_logloss: 0.135621\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006144 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12935\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.117733\tvalid_1's binary_logloss: 0.140661\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:47<00:25,  2.86s/trial, best loss: -0.8368093643173017]\r 84%|████████▍ | 42/50 [01:47<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008411 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.120438\tvalid_1's binary_logloss: 0.127484\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006109 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 84%|████████▍ | 42/50 [01:48<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.118015\tvalid_1's binary_logloss: 0.13605\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006744 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.115064\tvalid_1's binary_logloss: 0.14127\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:49<00:22,  2.76s/trial, best loss: -0.8368093643173017]\r 86%|████████▌ | 43/50 [01:49<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008998 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12907\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[16]\ttraining's binary_logloss: 0.117532\tvalid_1's binary_logloss: 0.128445\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009310 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12970\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 86%|████████▌ | 43/50 [01:50<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[13]\ttraining's binary_logloss: 0.116506\tvalid_1's binary_logloss: 0.136088\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007065 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 13049\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.10854\tvalid_1's binary_logloss: 0.14215\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.51s/trial, best loss: -0.8368093643173017]\r 88%|████████▊ | 44/50 [01:51<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009960 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12907\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[31]\ttraining's binary_logloss: 0.120736\tvalid_1's binary_logloss: 0.127726\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007563 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12934\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 88%|████████▊ | 44/50 [01:52<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.117682\tvalid_1's binary_logloss: 0.135689\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010431 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12989\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[35]\ttraining's binary_logloss: 0.112434\tvalid_1's binary_logloss: 0.141034\n\r 88%|████████▊ | 44/50 [01:53<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.37s/trial, best loss: -0.8368093643173017]\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007370 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12907\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.114951\tvalid_1's binary_logloss: 0.127139\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:54<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007464 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12970\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.114337\tvalid_1's binary_logloss: 0.136683\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007329 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 13017\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 90%|█████████ | 45/50 [01:55<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[22]\ttraining's binary_logloss: 0.110257\tvalid_1's binary_logloss: 0.141881\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.29s/trial, best loss: -0.8368093643173017]\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011444 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[45]\ttraining's binary_logloss: 0.120473\tvalid_1's binary_logloss: 0.127224\n\r 92%|█████████▏| 46/50 [01:56<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007092 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[47]\ttraining's binary_logloss: 0.115765\tvalid_1's binary_logloss: 0.135738\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 92%|█████████▏| 46/50 [01:57<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006695 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12865\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[43]\ttraining's binary_logloss: 0.114087\tvalid_1's binary_logloss: 0.140748\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.26s/trial, best loss: -0.8368093643173017]\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007464 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12870\n\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 94%|█████████▍| 47/50 [01:58<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[50]\ttraining's binary_logloss: 0.117042\tvalid_1's binary_logloss: 0.127461\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006729 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12934\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 94%|█████████▍| 47/50 [01:59<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[58]\ttraining's binary_logloss: 0.110513\tvalid_1's binary_logloss: 0.135839\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011866 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12989\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[61]\ttraining's binary_logloss: 0.107023\tvalid_1's binary_logloss: 0.140678\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.26s/trial, best loss: -0.8368093643173017]\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008940 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12818\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[50]\ttraining's binary_logloss: 0.116856\tvalid_1's binary_logloss: 0.127122\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009554 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12934\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[36]\ttraining's binary_logloss: 0.117447\tvalid_1's binary_logloss: 0.13599\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006844 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12935\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[48]\ttraining's binary_logloss: 0.110674\tvalid_1's binary_logloss: 0.140834\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.44s/trial, best loss: -0.8368093643173017]\r 98%|█████████▊| 49/50 [02:03<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1637, number of negative: 38907\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007160 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12809\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -> initscore=-3.168309\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.168309\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.117901\tvalid_1's binary_logloss: 0.128002\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1597, number of negative: 38947\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008421 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -> initscore=-3.194075\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.194075\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.11285\tvalid_1's binary_logloss: 0.135927\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1538, number of negative: 39006\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007163 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Total Bins 12874\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -> initscore=-3.233233\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.233233\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 98%|█████████▊| 49/50 [02:05<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.110102\tvalid_1's binary_logloss: 0.141424\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.50s/trial, best loss: -0.8368093643173017]\r100%|██████████| 50/50 [02:06<00:00,  2.48s/trial, best loss: -0.8368093643173017]\r100%|██████████| 50/50 [02:06<00:00,  2.53s/trial, best loss: -0.8368093643173017]\n{'learning_rate': 0.043324531254078945, 'max_depth': 133.0, 'min_child_samples': 85.0, 'num_leaves': 36.0, 'subsample': 0.7305792288105732}\n```\n:::\n:::\n\n\n### 재학습\n\n::: {#05fb8493 .cell execution_count=15}\n``` {.python .cell-code}\nlgbm_clf = LGBMClassifier(n_estimators=500, \n                          num_leaves=int(best['num_leaves']),\n                          max_depth=int(best['max_depth']),\n                          min_child_samples=int(best['min_child_samples']),\n                          subsample=round(best['subsample'], 5),\n                          learning_rate=round(best['learning_rate'], 5),\n                          early_stopping_rounds=100, \n                          eval_metric='auc')\n\neval_set = [(X_tr, y_tr), (X_val, y_val)]\nlgbm_clf.fit(X_tr, y_tr, eval_set=eval_set)\n\nlgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\nprint(f'{lgbm_roc_score:.3f}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Info] Number of positive: 1653, number of negative: 40918\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009941 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 12969\n[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 192\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038829 -> initscore=-3.208978\n[LightGBM] [Info] Start training from score -3.208978\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[62]\ttraining's binary_logloss: 0.119449\tvalid_1's binary_logloss: 0.137449\n[LightGBM] [Warning] Unknown parameter: eval_metric\n0.838\n```\n:::\n:::\n\n\n## 제출\n\n::: {#7af1ef06 .cell execution_count=16}\n``` {.python .cell-code}\ntarget = lgbm_clf.predict(test_df)\n\nsubmit = pd.read_csv('_data/santander/sample_submission.csv', encoding='latin-1')\nsubmit['TARGET'] = target\nsubmit.to_csv('_data/santander/submission.csv', encoding='latin-1', index=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[LightGBM] [Warning] Unknown parameter: eval_metric\n```\n:::\n:::\n\n\n",
    "supporting": [
      "03_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}