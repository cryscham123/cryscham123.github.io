{
  "hash": "5b8d931772d7287a71a48408e4458f23",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"new\"\ndate: 2025-05-23\ncategories: [\"data mining\"]\n---\n\n\n\n\n![](/img/human-thumb.jpg){.post-thumbnail}\n\n::: {#e0ce1a21 .cell execution_count=1}\n``` {.python .cell-code}\nimport tabulate\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, roc_curve, auc, classification_report\nfrom sklearn.preprocessing import LabelEncoder\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tabulate import tabulate\nimport random\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nrandom.seed(1234)\n\nX_train_df = pd.read_csv(\"_data/train_data.csv\")\nX_test_df = pd.read_csv(\"_data/test_data.csv\")\n\ny_train_raw = X_train_df['y']\nweights_train = X_train_df['weights'].values\nX_train = X_train_df.drop(columns=['y', 'weights'])\n\ny_test_raw = X_test_df['y']\nweights_test = X_test_df['weights'].values\nX_test = X_test_df.drop(columns=['y', 'weights'])\n\nlabel_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train_raw)\ny_test = label_encoder.transform(y_test_raw)\nclass_names = label_encoder.classes_\nunique_encoded_classes = np.unique(y_train)\n\nprint(f\"학습 데이터 형태: X_train {X_train.shape}, y_train {y_train.shape}\")\nprint(f\"테스트 데이터 형태: X_test {X_test.shape}, y_test {y_test.shape}\")\nprint(f\"클래스 종류 (원래 이름): {class_names}\")\nprint(f\"인코딩된 y_train의 고유값: {unique_encoded_classes}\")\nprint(f\"label_encoder로부터 얻은 클래스 개수: {len(label_encoder.classes_)}\")\n\n\n# --- 가중 혼동 행렬 및 성능 지표 계산 함수 ---\ndef calculate_weighted_performance(y_true, y_pred, weights, encoded_class_labels_for_cm, original_class_names_for_display, model_name=\"모델\"):\n    num_classes_for_cm = len(encoded_class_labels_for_cm)\n    # 혼동행렬의 실제 차원은 y_true와 y_pred에 나타나는 최대 인덱스 + 1이 되어야 함.\n    # label_encoder.classes_의 길이를 사용하는 것이 더 안전.\n    max_label_val = 0\n    if len(y_true) > 0 : max_label_val = max(max_label_val, np.max(y_true))\n    if len(y_pred) > 0 : max_label_val = max(max_label_val, np.max(y_pred))\n    # num_distinct_classes_in_data = max_label_val + 1\n    # 혼동행렬은 전체 클래스 개수를 기준으로 생성 (label_encoder.classes_ 사용)\n    num_total_classes = len(original_class_names_for_display)\n    weighted_cm = np.zeros((num_total_classes, num_total_classes))\n\n\n    for true_label_idx, pred_label_idx, weight in zip(y_true, y_pred, weights):\n        # y_pred에 혹시라도 학습 과정에서 보지 못한 레이블이 나올 경우 대비 및 인덱스 범위 확인\n        if true_label_idx < num_total_classes and pred_label_idx < num_total_classes:\n             weighted_cm[true_label_idx, pred_label_idx] += weight\n\n    print(f\"\\n=== {model_name} 가중 혼동 행렬 ===\")\n    cm_df = pd.DataFrame(weighted_cm,\n                         index=[f\"Actual: {name}\" for name in original_class_names_for_display],\n                         columns=[f\"Predicted: {name}\" for name in original_class_names_for_display])\n    print(cm_df.round(2))\n\n    total_weighted_sum = np.sum(weighted_cm)\n    weighted_accuracy = np.sum(np.diag(weighted_cm)) / total_weighted_sum if total_weighted_sum > 0 else 0\n\n    num_display_classes = len(original_class_names_for_display)\n    weighted_precision = np.zeros(num_display_classes)\n    weighted_recall = np.zeros(num_display_classes)\n    weighted_f1 = np.zeros(num_display_classes)\n\n    for i in range(num_display_classes): # 혼동행렬의 인덱스 i를 사용\n        TP = weighted_cm[i, i]\n        FP = np.sum(weighted_cm[:, i]) - TP\n        FN = np.sum(weighted_cm[i, :]) - TP\n        weighted_precision[i] = TP / (TP + FP) if (TP + FP) > 0 else 0\n        weighted_recall[i] = TP / (TP + FN) if (TP + FN) > 0 else 0\n        weighted_f1[i] = 2 * (weighted_precision[i] * weighted_recall[i]) / (weighted_precision[i] + weighted_recall[i]) if (weighted_precision[i] + weighted_recall[i]) > 0 else 0\n\n    print(f\"\\n=== {model_name} 가중 성능 지표 ===\")\n    print(f\"가중 정확도: {weighted_accuracy:.4f}\")\n    print(f\"\\n{model_name} 범주별 가중 정밀도:\")\n    for i, label in enumerate(original_class_names_for_display): print(f\"  {label}: {weighted_precision[i]:.4f}\")\n    print(f\"\\n{model_name} 범주별 가중 재현율:\")\n    for i, label in enumerate(original_class_names_for_display): print(f\"  {label}: {weighted_recall[i]:.4f}\")\n    print(f\"\\n{model_name} 범주별 가중 F1-score:\")\n    for i, label in enumerate(original_class_names_for_display): print(f\"  {label}: {weighted_f1[i]:.4f}\")\n\n    return weighted_accuracy, weighted_precision, weighted_recall, weighted_f1, weighted_cm\n\n# --- 1. 무작위 분류기 (Baseline) ---\nprint(\"\\n--- 1. 무작위 분류기 (Baseline) ---\")\n_unique_train_labels, counts = np.unique(y_train, return_counts=True)\nclass_proportions_dict = dict(zip(_unique_train_labels, counts / len(y_train)))\nprob_values = [class_proportions_dict.get(cls_idx, 0) for cls_idx in _unique_train_labels]\n\n# np.random.choice의 p 합계가 1인지 확인 (작은 오차는 무시)\nif not np.isclose(sum(prob_values), 1.0):\n    print(f\"경고: 무작위 분류기의 확률 합계가 1이 아닙니다: {sum(prob_values)}\")\n    # 확률 정규화 (만약을 위해)\n    if sum(prob_values) > 0:\n        prob_values = np.array(prob_values) / sum(prob_values)\n    else: # 모든 클래스의 비율이 0인 극단적인 경우 (예: y_train이 비어있음)\n          # 이 경우 _unique_train_labels도 비어있을 것이므로, 아래 choice에서 오류 발생 가능\n          # -> 이 부분은 y_train이 비어있지 않음을 가정함.\n        print(\"오류: y_train에 클래스 정보가 없어 무작위 분류기 확률을 설정할 수 없습니다.\")\n\n\nif len(_unique_train_labels) > 0 and len(prob_values) == len(_unique_train_labels): # 예측할 클래스와 확률 배열 길이가 맞는지 확인\n    random_predictions_indices = np.random.choice(\n        _unique_train_labels,\n        size=len(y_test),\n        replace=True,\n        p=prob_values\n    )\n    acc_random, _, _, _, _ = calculate_weighted_performance(\n        y_test, random_predictions_indices, weights_test,\n        label_encoder.classes_, # 혼동행렬의 차원은 전체 클래스 개수 기준\n        class_names,            # 출력용 클래스 이름\n        \"무작위 분류기\"\n    )\nelse:\n    print(\"오류: 무작위 분류기를 위한 클래스 또는 확률 정보가 부족합니다.\")\n    acc_random = 0\n\n\n# --- 2. 랜덤 포레스트 모델 (기본) ---\nprint(\"\\n--- 2. 랜덤 포레스트 모델 (기본) ---\")\nrf_model = RandomForestClassifier(n_estimators=500, max_features='sqrt', random_state=1234)\nrf_model.fit(X_train, y_train, sample_weight=weights_train)\n\nimportances_rf = rf_model.feature_importances_\nfeature_names_list = X_train.columns.tolist()\nsorted_indices_rf = np.argsort(importances_rf)[::-1]\nprint(\"\\n랜덤 포레스트 변수 중요도 (상위 10개):\")\nfor i in range(min(10, len(feature_names_list))): print(f\"{feature_names_list[sorted_indices_rf[i]]}: {importances_rf[sorted_indices_rf[i]]:.4f}\")\nif len(feature_names_list) > 0 and len(importances_rf) > 0 : # 변수가 있을 때만 그래프 그림\n    plt.figure(figsize=(10, min(6, 0.5 * min(10, len(feature_names_list)))))\n    plt.title(\"랜덤 포레스트 변수 중요도 (상위 10개)\")\n    plt.bar(range(min(10, len(feature_names_list))), importances_rf[sorted_indices_rf][:min(10, len(feature_names_list))], align=\"center\")\n    plt.xticks(range(min(10, len(feature_names_list))), np.array(feature_names_list)[sorted_indices_rf][:min(10, len(feature_names_list))], rotation=90)\n    plt.tight_layout()\n    plt.show()\n\ny_pred_rf = rf_model.predict(X_test)\nacc_rf, _, _, _, _ = calculate_weighted_performance(\n    y_test, y_pred_rf, weights_test, label_encoder.classes_, class_names, \"랜덤 포레스트(기본)\"\n)\n\ny_pred_prob_rf = rf_model.predict_proba(X_test)\nprint(\"\\n비가중 ROC 곡선 (참고용 - 랜덤 포레스트 기본):\")\n# 클래스가 하나만 있는 경우 ROC 곡선 그리기 어려움\nif len(class_names) > 1:\n    plt.figure(figsize=(7 * min(2, len(class_names)), 6 * int(np.ceil(len(class_names)/2)) ))\n    auc_values_rf_unweighted = []\n    for i in range(len(class_names)):\n        fpr, tpr, _ = roc_curve(y_test, y_pred_prob_rf[:, i], pos_label=i)\n        roc_auc = auc(fpr, tpr)\n        auc_values_rf_unweighted.append(roc_auc)\n        plt.subplot(int(np.ceil(len(class_names)/2)), min(2, len(class_names)), i + 1)\n        plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n        plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n        plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n        plt.title(f'ROC for {class_names[i]} (Unweighted)'); plt.legend(loc=\"lower right\")\n    plt.tight_layout()\n    plt.show()\n    print(\"\\n각 클래스별 비가중 AUC (랜덤 포레스트 기본):\")\n    for i, label_name in enumerate(class_names): print(f\"  {label_name}: {auc_values_rf_unweighted[i]:.4f}\")\nelse:\n    print(\"클래스가 하나만 있어 ROC 곡선을 그릴 수 없습니다.\")\n    auc_values_rf_unweighted = [np.nan] * len(class_names)\n\n\n# --- 3. 튜닝된 랜덤 포레스트 모델 (GridSearchCV) ---\nprint(\"\\n--- 3. 튜닝된 랜덤 포레스트 모델 ---\")\nparam_grid_rf = {'max_features': [int(np.sqrt(X_train.shape[1]))] if X_train.shape[1] > 1 else [1]}\nfit_params_rf_tuned = {'sample_weight': weights_train}\nrf_tuned_search = GridSearchCV(\n    estimator=RandomForestClassifier(n_estimators=500, random_state=1234),\n    param_grid=param_grid_rf, scoring='accuracy', cv=5, verbose=1\n)\nrf_tuned_search.fit(X_train, y_train, **fit_params_rf_tuned)\nprint(\"\\n최적 파라미터 (튜닝된 랜덤 포레스트):\", rf_tuned_search.best_params_)\nrf_tuned_model = rf_tuned_search.best_estimator_\nimportances_rf_tuned = rf_tuned_model.feature_importances_\nsorted_indices_rf_tuned = np.argsort(importances_rf_tuned)[::-1]\nprint(\"\\n튜닝된 랜덤 포레스트 변수 중요도 (상위 10개):\")\ntop_vars_tuned_rf = []\nfor i in range(min(10, len(feature_names_list))):\n    var_name = feature_names_list[sorted_indices_rf_tuned[i]]\n    top_vars_tuned_rf.append(var_name)\n    print(f\"{var_name}: {importances_rf_tuned[sorted_indices_rf_tuned[i]]:.4f}\")\ny_pred_rf_tuned = rf_tuned_model.predict(X_test)\nacc_rf_tuned, pre_rf_tuned, rec_rf_tuned, f1_rf_tuned, _ = calculate_weighted_performance(\n    y_test, y_pred_rf_tuned, weights_test, label_encoder.classes_, class_names, \"랜덤 포레스트(튜닝)\"\n)\n\n# --- 4. XGBoost 모델 ---\nprint(\"\\n--- 4. XGBoost 모델 ---\")\nacc_xgb, pre_xgb_list, rec_xgb_list, f1_xgb_list = 0, [0]*len(class_names), [0]*len(class_names), [0]*len(class_names)\n\nif y_train.shape[0] == 0:\n    print(\"오류: XGBoost에 전달될 y_train이 비어있습니다! XGBoost 학습을 건너뜁니다.\")\nelse:\n    num_classes_for_xgboost = len(label_encoder.classes_)\n    print(f\"XGBoost에 설정될 num_class: {num_classes_for_xgboost}\")\n    # 데이터에 실제로 존재하는 클래스 수 확인 (y_train_raw 기준)\n    actual_num_distinct_classes_in_data = X_train_df['y'].nunique()\n\n    if num_classes_for_xgboost < 2 or actual_num_distinct_classes_in_data < 2 : # LabelEncoder가 인식한 클래스 또는 실제 데이터의 클래스가 2개 미만이면\n        print(f\"오류: XGBoost multi:softprob 목적 함수는 최소 2개의 클래스가 필요하지만, LabelEncoder 클래스 수: {num_classes_for_xgboost}개, 실제 데이터 클래스 수: {actual_num_distinct_classes_in_data}개가 감지되었습니다. XGBoost 학습을 건너뜁니다.\")\n    else:\n        xgb_model = xgb.XGBClassifier(\n            objective=\"multi:softprob\", eval_metric=\"mlogloss\", num_class=num_classes_for_xgboost,\n            learning_rate=0.3, max_depth=6, min_child_weight=1, subsample=0.8, colsample_bytree=0.8,\n            n_estimators=100, random_state=1234, use_label_encoder=False\n        )\n        print(\"\\nXGBoost 모델 학습 중...\")\n        try:\n            xgb_model.fit(X_train, y_train, sample_weight=weights_train, verbose=False)\n            print(\"XGBoost 모델 학습 완료.\")\n            importances_xgb = xgb_model.feature_importances_\n            sorted_indices_xgb = np.argsort(importances_xgb)[::-1]\n            print(\"\\nXGBoost 변수 중요도 (상위 10개):\")\n            if len(importances_xgb) > 0 and len(feature_names_list) > 0:\n                for i in range(min(10, len(feature_names_list))): print(f\"{feature_names_list[sorted_indices_xgb[i]]}: {importances_xgb[sorted_indices_xgb[i]]:.4f}\")\n                plt.figure(figsize=(10, min(6, 0.5 * min(10, len(feature_names_list)))))\n                plt.title(\"XGBoost 변수 중요도 (상위 10개)\")\n                plt.bar(range(min(10, len(feature_names_list))), importances_xgb[sorted_indices_xgb][:min(10, len(feature_names_list))], align=\"center\")\n                plt.xticks(range(min(10, len(feature_names_list))), np.array(feature_names_list)[sorted_indices_xgb][:min(10, len(feature_names_list))], rotation=90)\n                plt.tight_layout()\n                plt.show()\n            else: print(\"\\nXGBoost 변수 중요도를 계산할 수 없거나 특성 이름이 없습니다.\")\n            print(\"\\nXGBoost 모델로 테스트 세트 예측 중...\")\n            y_pred_xgb = xgb_model.predict(X_test)\n            print(\"예측 완료.\")\n            acc_xgb, pre_xgb_list, rec_xgb_list, f1_xgb_list, _ = calculate_weighted_performance(\n                y_test, y_pred_xgb, weights_test, label_encoder.classes_, class_names, \"XGBoost\"\n            )\n        except Exception as e:\n            print(f\"XGBoost 모델 학습 또는 평가 중 오류 발생: {e}\")\n\n# --- 5. 다항 로지스틱 회귀 모델 ---\nprint(\"\\n--- 5. 다항 로지스틱 회귀 모델 ---\")\nlogistic_model = LogisticRegression(\n    multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=1234\n)\nprint(\"\\n다항 로지스틱 회귀 모델 학습 중...\")\nlogistic_model.fit(X_train, y_train, sample_weight=weights_train)\nprint(\"다항 로지스틱 회귀 모델 학습 완료.\")\nprint(\"\\n다항 로지스틱 회귀 모델로 테스트 세트 예측 중...\")\ny_pred_logistic = logistic_model.predict(X_test)\nprint(\"예측 완료.\")\nacc_logistic, pre_logistic, rec_logistic, f1_logistic, _ = calculate_weighted_performance(\n    y_test, y_pred_logistic, weights_test, label_encoder.classes_, class_names, \"다항 로지스틱 회귀\"\n)\n\n# --- 6. 최종 모델 비교 및 결과 요약 ---\nprint(\"\\n--- 6. 최종 모델 비교 및 결과 요약 ---\")\nfinal_metrics_data = {\n    'Metric': ['가중 정확도 (%)'],\n    'RandomForest_Tuned': [round(acc_rf_tuned * 100, 2)],\n    'XGBoost': [round(acc_xgb * 100, 2) if acc_xgb is not None and acc_xgb !=0 else 'N/A'],\n    'LogisticRegression': [round(acc_logistic * 100, 2)],\n    'RandomForest_Basic': [round(acc_rf * 100, 2)],\n    'Random_Classifier': [round(acc_random * 100, 2) if acc_random != 0 else 'N/A'] # 무작위 분류기도 오류 가능성 고려\n}\nfinal_metrics_df = pd.DataFrame(final_metrics_data)\nprint(\"\\n=== 최종 모델 가중 정확도 비교 ===\")\nprint(tabulate(final_metrics_df, headers='keys', tablefmt='pipe', showindex=False))\n\nprint(\"\\n=== 튜닝된 랜덤 포레스트 모델 범주별 가중 성능 지표 ===\")\nclass_metrics_tuned_data = {\n    'Class': class_names,\n    'Weighted_Precision': [round(p, 4) for p in pre_rf_tuned],\n    'Weighted_Recall': [round(r, 4) for r in rec_rf_tuned],\n    'Weighted_F1': [round(f, 4) for f in f1_rf_tuned]\n}\nclass_metrics_tuned_df = pd.DataFrame(class_metrics_tuned_data)\nprint(tabulate(class_metrics_tuned_df, headers='keys', tablefmt='pipe', showindex=False))\n\nprint(\"\\n=== 튜닝된 랜덤 포레스트 모델 변수 중요도 (상위 10개) ===\")\nif len(feature_names_list) > 0 and len(importances_rf_tuned) > 0:\n    importance_df_tuned_data = {\n        'Variable': np.array(feature_names_list)[sorted_indices_rf_tuned][:min(10, len(feature_names_list))],\n        'Importance': importances_rf_tuned[sorted_indices_rf_tuned][:min(10, len(feature_names_list))]\n    }\n    importance_df_tuned_display = pd.DataFrame(importance_df_tuned_data)\n    importance_df_tuned_display['Importance'] = importance_df_tuned_display['Importance'].round(4)\n    print(tabulate(importance_df_tuned_display, headers='keys', tablefmt='pipe', showindex=False))\nelse:\n    print(\"튜닝된 랜덤 포레스트 모델의 변수 중요도를 표시할 수 없습니다 (특성 또는 중요도 정보 부족).\")\n\n\nprint(\"\\n분석 완료.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n학습 데이터 형태: X_train (1705, 50), y_train (1705,)\n테스트 데이터 형태: X_test (732, 50), y_test (732,)\n클래스 종류 (원래 이름): ['active' 'passive']\n인코딩된 y_train의 고유값: [0 1]\nlabel_encoder로부터 얻은 클래스 개수: 2\n\n--- 1. 무작위 분류기 (Baseline) ---\n\n=== 무작위 분류기 가중 혼동 행렬 ===\n                 Predicted: active  Predicted: passive\nActual: active            45943.38            44785.01\nActual: passive           47424.96            35545.02\n\n=== 무작위 분류기 가중 성능 지표 ===\n가중 정확도: 0.4691\n\n무작위 분류기 범주별 가중 정밀도:\n  active: 0.4921\n  passive: 0.4425\n\n무작위 분류기 범주별 가중 재현율:\n  active: 0.5064\n  passive: 0.4284\n\n무작위 분류기 범주별 가중 F1-score:\n  active: 0.4991\n  passive: 0.4353\n\n--- 2. 랜덤 포레스트 모델 (기본) ---\n\n랜덤 포레스트 변수 중요도 (상위 10개):\nparent_stress_w4: 0.0256\nself_confidence_w4: 0.0247\ndesire_stress_w1: 0.0240\nparent_monitoring_w3: 0.0236\nparent_monitoring_w4: 0.0234\nparent_stress_w2: 0.0227\nparent_monitoring_w5: 0.0225\nhigher_school_dependence_w5: 0.0220\nparent_attachment_w3: 0.0220\nself_confidence_w1: 0.0219\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](17_files/figure-html/cell-2-output-2.png){width=950 height=468}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n=== 랜덤 포레스트(기본) 가중 혼동 행렬 ===\n                 Predicted: active  Predicted: passive\nActual: active            70656.71            20071.67\nActual: passive           48834.34            34135.63\n\n=== 랜덤 포레스트(기본) 가중 성능 지표 ===\n가중 정확도: 0.6033\n\n랜덤 포레스트(기본) 범주별 가중 정밀도:\n  active: 0.5913\n  passive: 0.6297\n\n랜덤 포레스트(기본) 범주별 가중 재현율:\n  active: 0.7788\n  passive: 0.4114\n\n랜덤 포레스트(기본) 범주별 가중 F1-score:\n  active: 0.6722\n  passive: 0.4977\n\n비가중 ROC 곡선 (참고용 - 랜덤 포레스트 기본):\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](17_files/figure-html/cell-2-output-4.png){width=1334 height=566}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n각 클래스별 비가중 AUC (랜덤 포레스트 기본):\n  active: 0.6498\n  passive: 0.6498\n\n--- 3. 튜닝된 랜덤 포레스트 모델 ---\nFitting 5 folds for each of 1 candidates, totalling 5 fits\n\n최적 파라미터 (튜닝된 랜덤 포레스트): {'max_features': 7}\n\n튜닝된 랜덤 포레스트 변수 중요도 (상위 10개):\nparent_stress_w4: 0.0256\nself_confidence_w4: 0.0247\ndesire_stress_w1: 0.0240\nparent_monitoring_w3: 0.0236\nparent_monitoring_w4: 0.0234\nparent_stress_w2: 0.0227\nparent_monitoring_w5: 0.0225\nhigher_school_dependence_w5: 0.0220\nparent_attachment_w3: 0.0220\nself_confidence_w1: 0.0219\n\n=== 랜덤 포레스트(튜닝) 가중 혼동 행렬 ===\n                 Predicted: active  Predicted: passive\nActual: active            70656.71            20071.67\nActual: passive           48834.34            34135.63\n\n=== 랜덤 포레스트(튜닝) 가중 성능 지표 ===\n가중 정확도: 0.6033\n\n랜덤 포레스트(튜닝) 범주별 가중 정밀도:\n  active: 0.5913\n  passive: 0.6297\n\n랜덤 포레스트(튜닝) 범주별 가중 재현율:\n  active: 0.7788\n  passive: 0.4114\n\n랜덤 포레스트(튜닝) 범주별 가중 F1-score:\n  active: 0.6722\n  passive: 0.4977\n\n--- 4. XGBoost 모델 ---\nXGBoost에 설정될 num_class: 2\n\nXGBoost 모델 학습 중...\nXGBoost 모델 학습 완료.\n\nXGBoost 변수 중요도 (상위 10개):\nneg_esteem_w5: 0.0265\ndesire_stress_w4: 0.0264\ndeviant_esteem_w3: 0.0262\nparent_monitoring_w3: 0.0260\nparent_attachment_w3: 0.0255\nparent_monitoring_w2: 0.0249\nhigher_school_dependence_w3: 0.0246\nparent_stress_w3: 0.0245\nparent_monitoring_w4: 0.0242\nhigher_school_dependence_w4: 0.0240\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](17_files/figure-html/cell-2-output-6.png){width=950 height=468}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nXGBoost 모델로 테스트 세트 예측 중...\n예측 완료.\nXGBoost 모델 학습 또는 평가 중 오류 발생: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n\n--- 5. 다항 로지스틱 회귀 모델 ---\n\n다항 로지스틱 회귀 모델 학습 중...\n다항 로지스틱 회귀 모델 학습 완료.\n\n다항 로지스틱 회귀 모델로 테스트 세트 예측 중...\n예측 완료.\n\n=== 다항 로지스틱 회귀 가중 혼동 행렬 ===\n                 Predicted: active  Predicted: passive\nActual: active            58358.98            32369.40\nActual: passive           39585.54            43384.44\n\n=== 다항 로지스틱 회귀 가중 성능 지표 ===\n가중 정확도: 0.5857\n\n다항 로지스틱 회귀 범주별 가중 정밀도:\n  active: 0.5958\n  passive: 0.5727\n\n다항 로지스틱 회귀 범주별 가중 재현율:\n  active: 0.6432\n  passive: 0.5229\n\n다항 로지스틱 회귀 범주별 가중 F1-score:\n  active: 0.6186\n  passive: 0.5467\n\n--- 6. 최종 모델 비교 및 결과 요약 ---\n\n=== 최종 모델 가중 정확도 비교 ===\n| Metric          |   RandomForest_Tuned | XGBoost   |   LogisticRegression |   RandomForest_Basic |   Random_Classifier |\n|:----------------|---------------------:|:----------|---------------------:|---------------------:|--------------------:|\n| 가중 정확도 (%) |                60.33 | N/A       |                58.57 |                60.33 |               46.91 |\n\n=== 튜닝된 랜덤 포레스트 모델 범주별 가중 성능 지표 ===\n| Class   |   Weighted_Precision |   Weighted_Recall |   Weighted_F1 |\n|:--------|---------------------:|------------------:|--------------:|\n| active  |               0.5913 |            0.7788 |        0.6722 |\n| passive |               0.6297 |            0.4114 |        0.4977 |\n\n=== 튜닝된 랜덤 포레스트 모델 변수 중요도 (상위 10개) ===\n| Variable                    |   Importance |\n|:----------------------------|-------------:|\n| parent_stress_w4            |       0.0256 |\n| self_confidence_w4          |       0.0247 |\n| desire_stress_w1            |       0.024  |\n| parent_monitoring_w3        |       0.0236 |\n| parent_monitoring_w4        |       0.0234 |\n| parent_stress_w2            |       0.0227 |\n| parent_monitoring_w5        |       0.0225 |\n| higher_school_dependence_w5 |       0.022  |\n| parent_attachment_w3        |       0.022  |\n| self_confidence_w1          |       0.0219 |\n\n분석 완료.\n```\n:::\n:::\n\n\n",
    "supporting": [
      "17_files"
    ],
    "filters": [],
    "includes": {}
  }
}