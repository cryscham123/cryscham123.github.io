{
  "hash": "3e75976e27f3ce1cfc23a8785a0f085b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"그냥\"\ndate: 2025-03-10\ncategories: [\"학부 개념 정리\"]\n---\n\n\n\n\n![](/img/human-thumb.jpg){.post-thumbnail}\n\n::: {#bdb90287 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, LSTM, Dense, concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nimport random\nimport datetime\n\n# --- 1. 카페인 함량 정보 (예시) ---\nCAFFEINE_CONTENT = {\n    \"아메리카노\": 100, # mg\n    \"카페 라떼\": 120,\n    \"에스프레소\": 60,\n    \"봉지 커피\": 50,\n    \"녹차 (티백)\": 30,\n    \"홍차 (티백)\": 40,\n    \"콜라 (250ml)\": 25,\n    \"에너지 드링크 (250ml)\": 80,\n    \"다크 초콜릿 (50g)\": 40,\n    \"밀크 초콜릿 (50g)\": 10,\n}\n\n# mg을 음식으로 변환하는 간단한 함수 (이전 코드와 동일)\ndef mg_to_food(mg):\n    recommendations = []\n    remaining_mg = mg\n    if mg <= 0:\n        return [\"추가 섭취 가능한 카페인이 거의 없습니다.\"]\n\n    sorted_foods = sorted(CAFFEINE_CONTENT.items(), key=lambda item: item[1], reverse=True)\n\n    for food, caffeine_per_serving in sorted_foods:\n        if caffeine_per_serving > 0:\n            num_servings = remaining_mg // caffeine_per_serving\n            if num_servings >= 1:\n                recommendations.append(f\"{int(num_servings)}잔의 {food}\" if '커피' in food or '차' in food else f\"{int(num_servings)}개의 {food.replace(' (50g)', '').replace(' (250ml)', '')}\")\n                remaining_mg -= num_servings * caffeine_per_serving # 사용한 만큼 차감\n\n    if not recommendations and mg > 0:\n         return [f\"{int(mg)}mg의 카페인\"]\n\n    return recommendations\n\n\n# --- 2. 더미 데이터 생성 함수 (Stateful LSTM용: 시간별 데이터 중요) ---\n\ndef generate_hourly_dummy_data(num_days, seed=42):\n    \"\"\"\n    Stateful LSTM 모델 학습을 위한 더미 데이터를 생성합니다.\n    - 각 시간별 카페인 섭취량\n    - 일별 수면 데이터 (총 수면 시간, 시작/종료 시간)\n    - 일별 수면 질 (예측 타겟)\n    - 전날 수면 질 (입력 변수)\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n\n    hourly_caffeine = np.zeros((num_days, 24, 1)) # (날짜 수, 시간 수, 특징 수=1: 카페인 mg)\n    daily_static = np.zeros((num_days, 3)) # (날짜 수, 정적 특징 수=3: 총 수면 시간, 수면 시작 시간(0-24h), 수면 종료 시간(0-24h))\n    prev_day_sq = np.zeros((num_days, 1)) # (날짜 수, 특징 수=1: 전날 수면 질)\n    sleep_quality = np.zeros((num_days, 1)) # (날짜 수, 예측 타겟=1: 해당 날짜 밤 수면 질)\n\n    last_sq = 7.0 # 첫날 전날 수면 질 (디폴트 값)\n\n    for day in range(num_days):\n        # --- 카페인 데이터 생성 ---\n        caffeine_today = np.zeros(24)\n        # 오전 (7-10시), 오후 (13-17시), 저녁 (19-21시) 랜덤 섭취\n        for _ in range(random.randint(1, 4)): # 하루 1~4번 섭취\n            hour = random.choices(\n                list(range(7, 11)) + list(range(13, 18)) + list(range(19, 22)),\n                weights=[0.4]*4 + [0.3]*5 + [0.3]*3, # 오전 확률 높게\n                k=1\n            )[0]\n            caffeine_today[hour] += random.randint(50, 150) # 50-150 mg\n\n        # 늦은 시간 섭취 (21-23시): 수면 영향이 큽니다.\n        if random.random() < 0.15: # 15% 확률로 늦게 마심\n             late_hour = random.randint(21, 23)\n             caffeine_today[late_hour] += random.randint(100, 250) # 늦게는 좀 더 고용량일 수 있음\n\n        hourly_caffeine[day, :, 0] = caffeine_today\n\n        # --- 수면 데이터 생성 ---\n        # 수면 시작/종료 시간 (대략 23시 - 다음날 7시 사이 변동)\n        base_sleep_start = 23.0 # 밤 11시\n        start_hour = base_sleep_start + random.uniform(-1.5, 2.5) # 밤 9시 30분 ~ 다음날 1시 30분 사이\n        start_hour = max(21.0, start_hour) # 너무 이르지는 않게\n\n        base_sleep_duration = 7.5 # 7.5시간\n        total_sleep_hours = base_sleep_duration + random.uniform(-1.0, 1.5) # 6.5시간 ~ 9시간\n        total_sleep_hours = max(5.0, min(10.0, total_sleep_hours)) # 5-10시간 클리핑\n\n        end_hour = start_hour + total_sleep_hours\n\n        # 24시간 형식으로 변환 (모델 입력용)\n        sleep_start_24h = start_hour % 24\n        sleep_end_24h = end_hour % 24 # 자정을 넘으면 0-23 사이 값\n\n        # --- 수면 질 계산 (더미 로직) ---\n        # 수면 질 = 기본 점수 + 총 수면 시간 영향 + 늦은 카페인 영향 + 전날 수면 질 영향 + 노이즈\n        # Stateful LSTM은 24시간 시퀀스를 처리하므로, 늦은 카페인 영향은 LSTM이 학습할 것으로 가정하고\n        # 여기 더미 SQ 계산에서는 좀 더 간략하게 반영 (실제 학습은 데이터 패턴으로)\n        base_score = 7.0\n        duration_effect = max(-2, min(2, (total_sleep_hours - 7.5) * 1.0)) # 7.5시간 기준, 길면 긍정적\n\n        # 늦은 카페인 영향 계산 (Stateful LSTM 학습을 모방하여 계산에 사용)\n        # 이번 날 밤 8시부터 취침 시간까지의 카페인 합산 (더미)\n        late_caff_impact = 0\n        # 여기서는 간단하게 오늘 18시 이후 섭취량 합산\n        late_caff_impact = np.sum(caffeine_today[18:])\n\n\n        late_caffeine_effect = - (late_caff_impact / 300.0) * 2.0 # 늦은 카페인 합산량에 반비례하며 영향 큼\n\n        prev_sq_effect = (last_sq - 7.0) * 0.5 # 전날 7점 기준, 높으면 긍정, 낮으면 부정 영향\n\n        noise = random.uniform(-1.5, 1.5) # 랜덤 노이즈\n\n        sq = base_score + duration_effect + late_caffeine_effect + prev_sq_effect + noise\n\n        # 0-10 점수 범위로 클리핑\n        sq = max(0.0, min(10.0, sq))\n\n        # --- 데이터 저장 ---\n        daily_static[day, 0] = total_sleep_hours\n        daily_static[day, 1] = sleep_start_24h\n        daily_static[day, 2] = sleep_end_24h\n        prev_day_sq[day, 0] = last_sq # 이번 날의 '전날 수면 질' 변수 값\n\n        sleep_quality[day, 0] = sq # 이번 날의 '수면 질' (다음 날 예측의 타겟)\n\n        last_sq = sq # 다음 날을 위해 이번 날 수면 질 저장\n\n\n    # 학습/예측에 사용하기 위한 최종 입력 형태 결합\n    # LSTM 입력: (날짜 수, 시간 수, 시간 특징) -> (N, 24, 1) 형태 그대로\n    # 정적 입력: (날짜 수, 정적 특징) -> (N, 3 + 1) 형태로 daily_static과 prev_day_sq 결합\n    combined_static_input = np.concatenate([daily_static, prev_day_sq], axis=-1)\n\n\n    # 타겟 출력: (날짜 수, 타겟 특징) -> (N, 1) 형태 그대로\n    return hourly_caffeine, combined_static_input, sleep_quality\n\n\n# --- 3. Stateful LSTM 모델 정의 함수 (Input 레이어에 batch_shape 사용) ---\n# 오류가 발생한 부분을 수정했습니다.\n\ndef build_stateful_model(batch_size, time_steps, input_features_per_hour, static_features_per_day, lstm_units=64, dense_units=32):\n    \"\"\"\n    Stateful LSTM 모델을 빌드합니다.\n    Stateful 모델은 배치 간 상태를 유지하여 긴 시계열 데이터를 처리합니다.\n    Input 레이어에 batch_shape를 사용하여 배치 크기를 고정합니다.\n    \"\"\"\n    print(f\"모델 빌드 설정: Batch Size={batch_size}, Time Steps={time_steps}, LSTM Units={lstm_units}\")\n\n    # 시퀀스 입력 (시간별 카페인 기록)\n    # Input 레이어에 batch_shape를 사용하여 배치 크기, 시간 스텝, 특징 수를 모두 지정합니다.\n    # 이게 Stateful LSTM의 입력 형태를 정의하는 또 다른 방법입니다.\n    sequence_input = Input(batch_shape=(batch_size, time_steps, input_features_per_hour), name='hourly_caffeine_input')\n    print(f\"시퀀스 Input 레이어 형태 (batch_shape 사용): {sequence_input.shape}\")\n\n\n    # Stateful LSTM 레이어\n    # Input 레이어에서 이미 batch_shape가 정의되었으므로, LSTM 레이어에서는 batch_input_shape를 다시 지정하지 않습니다.\n    # stateful=True: 이전 배치/타임스텝의 상태를 다음 배치/타임스텝으로 전달합니다.\n    # return_sequences=False: LSTM 레이어는 입력 시퀀스 전체를 처리한 후, 마지막 타임스텝의 은닉 상태(혹은 출력)만을 다음 레이어로 전달합니다.\n    lstm_layer = LSTM(\n        lstm_units,\n        stateful=True,\n        return_sequences=False,\n        name='stateful_lstm',\n        # 여기서 batch_input_shape를 지정하지 않습니다. Input 레이어가 정의했기 때문입니다.\n        # batch_input_shape=(batch_size, time_steps, input_features_per_hour) # 이 줄을 삭제합니다.\n    )(sequence_input) # Input 레이어의 출력을 받습니다.\n    print(f\"LSTM 출력 형태 (return_sequences=False): {lstm_layer.shape}\")\n\n\n    # 일별 고정 입력 (총 수면 시간, 시작/종료 시간, 전날 수면 질)\n    # 이 입력은 시간 순서와 관련 없으며, 하루 단위로 LSTM의 최종 요약과 함께 사용됩니다.\n    static_input = Input(shape=(static_features_per_day,), name='daily_static_input')\n    print(f\"정적 입력 형태: {static_input.shape}\")\n\n\n    # LSTM의 마지막 출력(시간 시퀀스 요약)과 일별 고정 입력을 결합\n    # concatenate 레이어는 두 입력 텐서를 마지막 축(axis=-1)을 기준으로 합칩니다.\n    # LSTM 출력 형태: (Batch Size, LSTM_UNITS)\n    # Static 입력 형태: (Batch Size, STATIC_FEATURES_PER_DAY)\n    # 결합 후 형태: (Batch Size, LSTM_UNITS + STATIC_FEATURES_PER_DAY)\n    combined_features = concatenate([lstm_layer, static_input], name='concatenate_features')\n    print(f\"결합 특징 형태: {combined_features.shape}\")\n\n\n    # 결합된 특징을 바탕으로 수면 질을 예측하는 밀집 레이어\n    # Dense 레이어는 결합된 특징들 간의 복잡한 비선형 관계를 학습합니다.\n    dense_layer_1 = Dense(dense_units, activation='relu', name='dense_1')(combined_features)\n    # 필요하다면 여기에 Dense 레이어를 더 추가할 수 있습니다. 예: Dense(dense_units // 2, activation='relu', name='dense_2')\n\n    # 최종 출력 레이어 (수면 질 지수 회귀)\n    # 뉴런 1개, 활성화 함수 'linear' (또는 생략)는 회귀 문제의 표준 설정입니다.\n    output_layer = Dense(1, activation='linear', name='sleep_quality_output')(dense_layer_1)\n    print(f\"출력 형태: {output_layer.shape}\")\n\n\n    # 모델 정의\n    # Functional API 모델은 Model 클래스를 사용하여 정의합니다.\n    model = Model(inputs=[sequence_input, static_input], outputs=output_layer)\n\n    # 모델 컴파일\n    # optimizer: 모델 학습 방식을 결정합니다 (Adam이 일반적).\n    # loss: 모델이 최소화할 오차 함수입니다 (회귀에는 MSE가 일반적).\n    # metrics: 학습 중 성능 모니터링 지표입니다 (MAE는 오차의 평균 크기).\n    model.compile(optimizer=Adam(), loss='mse', metrics=['mae'])\n\n    return model\n\n\n# --- 4. 데이터 생성 및 모델 학습 ---\n\n# 설정\nNUM_DAYS_DATA = 90 # 학습 데이터 날짜 수 (많을수록 좋습니다)\nBATCH_SIZE = 1 # Stateful LSTM 예시이므로 배치 사이즈 1로 고정\nSTATEFUL_TIME_STEPS = 24 # 한 번에 LSTM에 입력할 시간 스텝 수 (하루 단위 처리)\n\n# 더미 데이터 생성 (한 사용자의 90일 데이터)\nprint(\"더미 데이터 생성 중 (Stateful LSTM용)...\")\n# hourly_data_all: (N, 24, 1)\n# static_data_all: (N, 4) -> [총 수면 시간, 시작, 종료, 전날 SQ]\n# quality_data_all: (N, 1) -> [수면 질]\nhourly_data_all, static_data_all, quality_data_all = generate_hourly_dummy_data(NUM_DAYS_DATA)\nprint(f\"더미 데이터 생성 완료: {NUM_DAYS_DATA}일치\")\nprint(f\"시간별 데이터 shape: {hourly_data_all.shape}\") # (N, 24, 1)\nprint(f\"일별 정적 데이터 shape: {static_data_all.shape}\") # (N, 4)\nprint(f\"수면 질 데이터 shape: {quality_data_all.shape}\") # (N, 1)\n\n# 학습/검증 데이터 분리 (예: 80% 학습, 20% 검증)\ntrain_split = int(NUM_DAYS_DATA * 0.8)\nhourly_train, hourly_val = hourly_data_all[:train_split], hourly_data_all[train_split:]\nstatic_train, static_val = static_data_all[:train_split], static_data_all[train_split:]\nquality_train, quality_val = quality_data_all[:train_split], quality_data_all[train_split:]\n\nprint(f\"학습 데이터 {train_split}일, 검증 데이터 {NUM_DAYS_DATA-train_split}일\")\n\n\n# 모델 빌드\n# 배치 사이즈는 데이터 생성/학습/예측 시 모두 동일해야 합니다.\n# build_stateful_model 함수가 이제 Input 레이어에서 batch_shape를 사용합니다.\nmodel = build_stateful_model(\n    batch_size=BATCH_SIZE, # 배치 사이즈 1\n    time_steps=STATEFUL_TIME_STEPS, # 24시간 단위\n    input_features_per_hour=hourly_data_all.shape[-1], # 1 (카페인 mg)\n    static_features_per_day=static_data_all.shape[-1] # 4 (수면 시간, 시작, 종료, 전날 SQ)\n)\n\n# 모델 구조 요약 출력\nmodel.summary()\n\n\n# Stateful LSTM 레이어 인스턴스 가져오기\n# Functional API에서는 모델 객체가 아닌 레이어 인스턴스에 대해 reset_states() 호출\nlstm_layer_instance = model.get_layer('stateful_lstm')\n\n\n# 학습\nNUM_EPOCHS = 150 # 학습 에폭 수 (더미 데이터에 대해 좀 더 학습)\n\nprint(\"\\n모델 학습 시작 (Stateful LSTM)...\")\n# Stateful 모델 학습 시 핵심: shuffle=False 와 reset_states()\nfor epoch in range(NUM_EPOCHS):\n    # print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\") # 에폭마다 출력 시 너무 길 수 있음\n\n    # --- 학습 데이터에 대한 학습 ---\n    # Stateful 모델의 상태 초기화 (각 에폭 시작 시)\n    # 같은 사용자의 연속된 데이터로 학습할 때는 에폭 시작 시점에만 초기화합니다.\n    # 여러 사용자를 순서대로 학습시킬 때는 사용자 데이터가 바뀔 때마다 초기화해야 합니다.\n    # 모델 객체 대신 레이어 인스턴스에 reset_states() 호출\n    lstm_layer_instance.reset_states()\n    # 데이터를 날짜 순서대로 (Stateful_TIME_STEPS=24 단위로) 모델에 입력\n    # fit 함수에 shuffle=False를 사용하여 데이터 순서를 유지합니다.\n    # 배치 사이즈가 1이므로 각 배치는 하루(24시간) 데이터와 그날의 정적 데이터, 수면 질 타겟이 됩니다.\n    history = model.fit(\n        [hourly_train, static_train], quality_train,\n        batch_size=BATCH_SIZE, # 여기서 지정하는 batch_size는 모델 build 시 batch_shape의 첫번째 값과 같아야 합니다.\n        epochs=1, # 에폭당 1회만 fit 호출 (상태 초기화는 에폭 시작 시만 하므로)\n        shuffle=False, # 순서 유지 중요!\n        verbose=0 # 학습 과정 출력 숨김\n    )\n\n    # --- 검증 데이터에 대한 평가 ---\n    # 검증 시에도 Stateful 모델 상태 초기화 필요\n    # 검증 데이터는 학습에 사용되지 않으므로 상태를 유지할 필요가 없습니다.\n    # 모델 객체 대신 레이어 인스턴스에 reset_states() 호출\n    lstm_layer_instance.reset_states()\n    # 검증 데이터도 학습 데이터와 동일한 배치 사이즈로 평가해야 합니다.\n    loss, mae = model.evaluate([hourly_val, static_val], quality_val, batch_size=BATCH_SIZE, verbose=0)\n\n\n    # 에폭별 결과 출력\n    if (epoch + 1) % 10 == 0 or epoch == 0: # 10 에폭마다 또는 첫 에폭에 출력\n         print(f\"Epoch {epoch+1} - train_loss: {history.history['loss'][0]:.4f}, train_mae: {history.history['mae'][0]:.4f} - val_loss: {loss:.4f}, val_mae: {mae:.4f}\")\n\n\nprint(\"모델 학습 완료!\")\n\n\n# --- 5. 예측 함수 ---\n# 학습된 모델과 입력 데이터를 바탕으로 수면 질을 예측합니다.\n# 예측 시에도 배치 사이즈와 time_steps는 학습 시와 동일해야 합니다.\n# Stateful 모델 예측 시에는 이전 예측이나 시뮬레이션 상태와 연결될 수 있습니다.\n# 완전히 새로운 예측 시작 시에는 model.reset_states() 호출 필요.\n\ndef predict_stateful_sq(model, lstm_layer_instance, hourly_input_batch, static_input_batch):\n     \"\"\"\n     Stateful 모델을 사용하여 수면 질 예측.\n     Stateful LSTM 레이어 인스턴스를 함께 전달해야 합니다.\n     입력 형태:\n     hourly_input_batch: (Batch Size=1, Time Steps=24, Features=1)\n     static_input_batch: (Batch Size=1, Static Features=4)\n     \"\"\"\n     # 예측 전에 reset_states()가 이미 적절한 시점(새로운 예측 시나리오 시작 등)에 호출되었다고 가정합니다.\n     predicted_quality = model.predict([hourly_input_batch, static_input_batch], verbose=0)[0, 0]\n     return predicted_quality\n\n\n# --- 6. 시뮬레이션 및 추천 로직 (개념 설명 + 간단 예시) ---\n\n# 모델이 학습되었다고 가정하고, 이 모델을 사용하여 시뮬레이션을 수행합니다.\n# 목표: 현재까지 섭취한 카페인 + 추가 섭취량을 고려했을 때 예상 수면 질이 7점 이상이 되도록 하는 추가 섭취량/시간을 찾기.\n\n# 시뮬레이션은 다음과 같은 단계로 이루어집니다:\n# 1. 현재 사용자의 '어제' 수면 질, '오늘' 시간별 카페인 기록 (현재 시간까지), '오늘' 목표 수면 시간 정보를 준비합니다.\n# 2. 이 정보를 바탕으로 **현재 상태의 예상 수면 질**을 모델로 예측합니다.\n#    - '어제' 수면 질은 정적 입력으로 사용됩니다.\n#    - '오늘' 시간별 카페인 기록은 현재 시간까지를 포함하여 시간별 시퀀스로 준비합니다. (나머지 시간은 0으로 채우거나 예상 패턴으로 채울 수 있습니다.)\n#    - 목표 수면 시간 정보는 정적 입력으로 사용됩니다.\n#    - 이 데이터를 모델에 넣어 예측합니다. 이때 예측 시점까지의 LSTM 상태가 계산됩니다.\n# 3. 예측된 수면 질이 목표(7점)보다 낮다면, 추가 섭취는 어렵습니다.\n# 4. 예측된 수면 질이 목표(7점) 이상이라면, **'추가 섭취' 시나리오를 가정하고 모델로 다시 예측**해 봅니다.\n#    - 예: \"지금부터 취침 전까지 특정 시간(예: 저녁 8시)에 커피 한 잔(100mg)을 더 마신다면?\"\n#    - 이 시나리오를 위해, 원래 '오늘' 시간별 카페인 기록에 해당 시간, 해당 양을 추가합니다.\n#    - **중요:** Stateful LSTM의 상태를 유지해야 하므로, 원래 예측 시 사용했던 시퀀스 처리를 중단한 시점(예: 현재 시간)부터 새로운 시나리오(추가 카페인 포함)의 시퀀스를 이어받아 모델에 입력해야 합니다. 이 부분을 정확히 구현하려면 모델 상태를 저장하고 복원하는 등의 복잡한 로직이 필요합니다. **예시 코드에서는 이 복잡성을 피하기 위해, 시뮬레이션 예측마다 모델 상태를 초기화하고 (독립적인 시나리오로 간주) 해당 시나리오의 '하루 전체' 데이터를 입력하는 방식**으로 간략화했습니다. 실제 앱에서는 상태 관리가 필요합니다.\n# 5. 시뮬레이션 결과 예측된 수면 질이 여전히 목표(7점) 이상인지 확인합니다.\n# 6. 4-5 단계를 반복하며 (다른 시간, 다른 양으로 시뮬레이션), 목표 수면 질을 유지하는 **최대 추가 가능량** 또는 **가장 늦은 시간**을 찾습니다. (이 탐색 과정은 복잡한 알고리즘이 될 수 있습니다)\n# 7. 찾은 추가 가능량(mg)을 `mg_to_food` 함수를 사용하여 음식 형태로 변환하여 추천합니다.\n\n# --- 시뮬레이션 개념 예시 (코드 구현은 단순화) ---\n\n# 시뮬레이션을 위한 임의의 '오늘' 상태 데이터 생성\n# 실제 앱에서는 사용자의 당일 기록에서 가져옵니다.\nprint(\"\\n--- 시뮬레이션 개념 예시 (Stateful LSTM 기반) ---\")\n\n# 예시 상태 1: 평소 수면 괜찮고, 오전에만 커피 한 잔 마셨고, 저녁 8시 (20시) 현재\nsim_prev_sq = 7.5 # 전날 수면 질\nsim_hourly_today_current = np.zeros(24)\nsim_hourly_today_current[8] = 120 # 아침 8시 카페 라떼 120mg 섭취\nsim_target_sleep_start = 23.5 # 밤 11시 30분 목표 수면 시작 (23.5시)\nsim_target_sleep_duration = 8.0 # 8시간 목표 수면\n\n# 현재 시점 (예: 저녁 8시)\ncurrent_clock_hour = 20 # 현재 시점은 저녁 8시라고 가정\n\n# --- 현재 상태 예측 ---\n# 현재 시점까지의 데이터로 LSTM 상태를 계산하고, 이 상태를 바탕으로 예측해야 하지만,\n# 예시 코드의 단순화를 위해 '오늘 하루 전체 데이터 (현재 시간까지 입력 + 이후 시간 0)'를 입력하여 예측합니다.\n# 실제 Stateful 구현에서는 현재 시간까지의 데이터를 순차 처리하여 얻은 '마지막 상태'를 활용합니다.\n\n# 현재 상태의 하루 전체 입력 데이터 (현재 시간 이후는 0)\nsim_current_hourly_full_day = np.zeros(24)\nsim_current_hourly_full_day[:current_clock_hour+1] = sim_hourly_today_current[:current_clock_hour+1] # 현재 시간까지의 데이터 복사\n\n# 입력 데이터 형태로 변환\nsim_current_hourly_input_batch = sim_current_hourly_full_day.reshape(1, 24, 1) # (Batch=1, Time=24, Features=1)\nsim_current_static_input_batch = np.array([[sim_target_sleep_duration, sim_target_sleep_start, (sim_target_sleep_start + sim_target_sleep_duration)%24, sim_prev_sq]]).reshape(1, 4) # (Batch=1, Static Features=4)\n\n\n# 예측 시작 전 상태 초기화 (독립적인 예측 시나리오 시작)\n# 모델 객체 대신 레이어 인스턴스에 reset_states() 호출\nlstm_layer_instance.reset_states()\npredicted_sq_current = predict_stateful_sq(model, lstm_layer_instance, sim_current_hourly_input_batch, sim_current_static_input_batch)\nprint(f\"1. 현재 상태 ({current_clock_hour}시 기준) 예상 수면 질: {predicted_sq_current:.2f} (목표: 7.0)\")\n\nif predicted_sq_current >= 7.0:\n    print(\"   -> 현재 상태로 목표 수면 질 달성 가능성이 높습니다. 추가 섭취량 탐색 시작.\")\n\n    # --- 시뮬레이션 1: 저녁 9시 (21시)에 아메리카노 1잔 (100mg) 추가 시뮬레이션 ---\n    sim_hourly_scenario_1 = np.copy(sim_hourly_today_current) # 현재 상태 복사\n    add_time_1 = 21 # 저녁 9시\n    add_amount_1 = CAFFEINE_CONTENT[\"아메리카노\"]\n    if add_time_1 >= current_clock_hour and add_time_1 < 24: # 현재 시점 이후이고 24시 이전인 경우만 시뮬레이션에 의미\n         sim_hourly_scenario_1[add_time_1] += add_amount_1\n         print(f\"   -> 시나리오: {add_time_1}시 아메리카노 1잔({add_amount_1}mg) 추가 가정\")\n\n         # 시뮬레이션 데이터 (하루 전체) 형태로 변환\n         sim_hourly_input_batch_1 = sim_hourly_scenario_1.reshape(1, 24, 1)\n\n         # 예측 시작 전 상태 초기화 (이 시뮬레이션 예측은 독립적으로 수행한다고 가정)\n         # 모델 객체 대신 레이어 인스턴스에 reset_states() 호출\n         lstm_layer_instance.reset_states()\n         predicted_sq_scenario_1 = predict_stateful_sq(model, lstm_layer_instance, sim_hourly_input_batch_1, sim_current_static_input_batch)\n\n         print(f\"   -> {add_time_1}시 {add_amount_1}mg 추가 시 예상 수면 질: {predicted_sq_scenario_1:.2f}\")\n\n         if predicted_sq_scenario_1 >= 7.0:\n             print(\"      -> 이 시나리오에서도 목표 수면 질 달성 가능해 보입니다.\")\n             # 실제 앱에서는 더 늦은 시간, 더 많은 양 등 다양한 시나리오 시뮬레이션 후 최적값 추천\n             print(\"      (더 많은 양이나 더 늦은 시간에 대한 시뮬레이션 추가 필요)\")\n             # 예: print(f\"      추천: {add_time_1}시까지 아메리카노 1잔 더 가능 ({add_amount_1}mg)\")\n         else:\n             print(\"      -> 이 시나리오에서는 목표 수면 질 달성이 어려울 수 있습니다.\")\n             # 실제 앱에서는 더 적은 양, 더 이른 시간 시뮬레이션 고려 또는 포기 추천\n\n    else:\n        print(f\"   -> 시나리오 시간({add_time_1}시)이 현재 시간({current_clock_hour}시) 이전 또는 유효하지 않습니다. 시뮬레이션 건너뜁니다.\")\n\n\n    # --- 시뮬레이션 3: 저녁 10시 (22시)에 다크 초콜릿 (40mg) 추가 시뮬레이션 ---\n    sim_hourly_scenario_2 = np.copy(sim_hourly_today_current) # 현재 상태 복사\n    add_time_2 = 22 # 저녁 10시\n    add_amount_2 = CAFFEINE_CONTENT[\"다크 초콜릿 (50g)\"]\n    if add_time_2 >= current_clock_hour and add_time_2 < 24: # 현재 시점 이후이고 24시 이전인 경우만 시뮬레이션에 의미\n         sim_hourly_scenario_2[add_time_2] += add_amount_2\n         print(f\"   -> 시나리오: {add_time_2}시에 다크 초콜릿({add_amount_2}mg) 추가 가정\")\n\n         sim_hourly_input_batch_2 = sim_hourly_scenario_2.reshape(1, 24, 1)\n\n         # 예측 시작 전 상태 초기화 (이 시뮬레이션 예측은 독립적으로 수행한다고 가정)\n         # 모델 객체 대신 레이어 인스턴스에 reset_states() 호출\n         lstm_layer_instance.reset_states()\n         predicted_sq_scenario_2 = predict_stateful_sq(model, lstm_layer_instance, sim_hourly_input_batch_2, sim_current_static_input_batch)\n\n         print(f\"   -> {add_time_2}시 {add_amount_2}mg 추가 시 예상 수면 질: {predicted_sq_scenario_2:.2f}\")\n         if predicted_sq_scenario_2 >= 7.0:\n             print(\"      -> 이 시나리오에서도 목표 수면 질 달성 가능해 보입니다.\")\n             # print(f\"      추천: {add_time_2}시까지 다크 초콜릿 1개 더 가능 ({add_amount_2}mg)\")\n\n         else:\n             print(\"      -> 이 시나리오에서는 목표 수면 질 달성이 어려울 수 있습니다.\")\n\n    else:\n         print(f\"   -> 시나리오 시간({add_time_2}시)이 현재 시간({current_clock_hour}시) 이전 또는 유효하지 않습니다. 시뮬레이션 건너뜁니다.\")\n\n\nelse: # predicted_sq_current < 7.0\n    print(\"-> 현재 상태로 예측 수면 질이 목표치보다 낮습니다. 추가 섭취는 권장되지 않습니다.\")\n    # 목표 수면 질 향상을 위한 다른 조언 제공\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n2025-04-26 11:12:16.127362: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2025-04-26 11:12:16.128433: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-26 11:12:16.132203: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-04-26 11:12:16.142926: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745633536.159036   21307 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745633536.163036   21307 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1745633536.176455   21307 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1745633536.176469   21307 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1745633536.176470   21307 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1745633536.176471   21307 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n2025-04-26 11:12:16.181084: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n더미 데이터 생성 중 (Stateful LSTM용)...\n더미 데이터 생성 완료: 90일치\n시간별 데이터 shape: (90, 24, 1)\n일별 정적 데이터 shape: (90, 4)\n수면 질 데이터 shape: (90, 1)\n학습 데이터 72일, 검증 데이터 18일\n모델 빌드 설정: Batch Size=1, Time Steps=24, LSTM Units=64\n시퀀스 Input 레이어 형태 (batch_shape 사용): (1, 24, 1)\nLSTM 출력 형태 (return_sequences=False): (1, 64)\n정적 입력 형태: (None, 4)\n결합 특징 형태: (1, 68)\n출력 형태: (1, 1)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nE0000 00:00:1745633538.401105   21307 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\nW0000 00:00:1745633538.401425   21307 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\nSkipping registering GPU devices...\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ hourly_caffeine_in… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ stateful_lstm       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │ hourly_caffeine_… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ daily_static_input  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_featur… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ stateful_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ daily_static_inp… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,208</span> │ concatenate_feat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ sleep_quality_outp… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,137</span> (74.75 KB)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,137</span> (74.75 KB)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n모델 학습 시작 (Stateful LSTM)...\nEpoch 1 - train_loss: 6.0002, train_mae: 1.9321 - val_loss: 0.8933, val_mae: 0.6900\nEpoch 10 - train_loss: 1.1769, train_mae: 0.9124 - val_loss: 0.8116, val_mae: 0.7317\nEpoch 20 - train_loss: 0.9070, train_mae: 0.7992 - val_loss: 0.9120, val_mae: 0.6965\nEpoch 30 - train_loss: 0.6313, train_mae: 0.6595 - val_loss: 1.1633, val_mae: 0.7338\nEpoch 40 - train_loss: 0.3966, train_mae: 0.5157 - val_loss: 1.2654, val_mae: 0.8142\nEpoch 50 - train_loss: 0.2575, train_mae: 0.3942 - val_loss: 1.5371, val_mae: 0.9266\nEpoch 60 - train_loss: 0.1193, train_mae: 0.2521 - val_loss: 1.3843, val_mae: 0.9202\nEpoch 70 - train_loss: 0.0733, train_mae: 0.1962 - val_loss: 1.5075, val_mae: 0.9371\nEpoch 80 - train_loss: 0.8513, train_mae: 0.7972 - val_loss: 1.0788, val_mae: 0.8391\nEpoch 90 - train_loss: 0.1946, train_mae: 0.3230 - val_loss: 1.1167, val_mae: 0.8084\nEpoch 100 - train_loss: 0.0387, train_mae: 0.1369 - val_loss: 1.0716, val_mae: 0.8062\nEpoch 110 - train_loss: 0.0341, train_mae: 0.1492 - val_loss: 0.9770, val_mae: 0.7002\nEpoch 120 - train_loss: 0.2039, train_mae: 0.3454 - val_loss: 1.4918, val_mae: 0.9455\nEpoch 130 - train_loss: 0.0785, train_mae: 0.2110 - val_loss: 1.7959, val_mae: 1.0370\nEpoch 140 - train_loss: 0.0698, train_mae: 0.1787 - val_loss: 1.7157, val_mae: 1.0045\nEpoch 150 - train_loss: 0.0360, train_mae: 0.1397 - val_loss: 1.8896, val_mae: 1.0594\n모델 학습 완료!\n\n--- 시뮬레이션 개념 예시 (Stateful LSTM 기반) ---\n1. 현재 상태 (20시 기준) 예상 수면 질: 8.49 (목표: 7.0)\n   -> 현재 상태로 목표 수면 질 달성 가능성이 높습니다. 추가 섭취량 탐색 시작.\n   -> 시나리오: 21시 아메리카노 1잔(100mg) 추가 가정\n   -> 21시 100mg 추가 시 예상 수면 질: 7.01\n      -> 이 시나리오에서도 목표 수면 질 달성 가능해 보입니다.\n      (더 많은 양이나 더 늦은 시간에 대한 시뮬레이션 추가 필요)\n   -> 시나리오: 22시에 다크 초콜릿(40mg) 추가 가정\n   -> 22시 40mg 추가 시 예상 수면 질: 8.28\n      -> 이 시나리오에서도 목표 수면 질 달성 가능해 보입니다.\n```\n:::\n:::\n\n\n",
    "supporting": [
      "02_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}