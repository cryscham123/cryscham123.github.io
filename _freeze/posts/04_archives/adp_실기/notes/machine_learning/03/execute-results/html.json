{
  "hash": "a3e7365f8318821985f39810546c71c4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"분류 - 산탄데르 고객 만족 예측\"\ndate: 2025-07-27\ncategories: [\"머신 러닝\"]\n---\n\n\n\n\n![](/img/stat-thumb.jpg){.post-thumbnail}\n\n## Preprocessing\n\n::: {#7fedd07a .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\n\nplt.rcParams['font.family'] = 'Noto Sans KR'\nwarnings.filterwarnings('ignore')\n\ndf = pd.read_csv('_data/santander/train.csv', encoding='latin-1')\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 76020 entries, 0 to 76019\nColumns: 371 entries, ID to TARGET\ndtypes: float64(111), int64(260)\nmemory usage: 215.2 MB\n```\n:::\n:::\n\n\n::: {#ce66c231 .cell execution_count=2}\n``` {.python .cell-code}\ndf.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>var3</th>\n      <th>var15</th>\n      <th>imp_ent_var16_ult1</th>\n      <th>imp_op_var39_comer_ult1</th>\n      <th>imp_op_var39_comer_ult3</th>\n      <th>imp_op_var40_comer_ult1</th>\n      <th>imp_op_var40_comer_ult3</th>\n      <th>imp_op_var40_efect_ult1</th>\n      <th>imp_op_var40_efect_ult3</th>\n      <th>...</th>\n      <th>saldo_medio_var33_hace2</th>\n      <th>saldo_medio_var33_hace3</th>\n      <th>saldo_medio_var33_ult1</th>\n      <th>saldo_medio_var33_ult3</th>\n      <th>saldo_medio_var44_hace2</th>\n      <th>saldo_medio_var44_hace3</th>\n      <th>saldo_medio_var44_ult1</th>\n      <th>saldo_medio_var44_ult3</th>\n      <th>var38</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>...</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>7.602000e+04</td>\n      <td>76020.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>75964.050723</td>\n      <td>-1523.199277</td>\n      <td>33.212865</td>\n      <td>86.208265</td>\n      <td>72.363067</td>\n      <td>119.529632</td>\n      <td>3.559130</td>\n      <td>6.472698</td>\n      <td>0.412946</td>\n      <td>0.567352</td>\n      <td>...</td>\n      <td>7.935824</td>\n      <td>1.365146</td>\n      <td>12.215580</td>\n      <td>8.784074</td>\n      <td>31.505324</td>\n      <td>1.858575</td>\n      <td>76.026165</td>\n      <td>56.614351</td>\n      <td>1.172358e+05</td>\n      <td>0.039569</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>43781.947379</td>\n      <td>39033.462364</td>\n      <td>12.956486</td>\n      <td>1614.757313</td>\n      <td>339.315831</td>\n      <td>546.266294</td>\n      <td>93.155749</td>\n      <td>153.737066</td>\n      <td>30.604864</td>\n      <td>36.513513</td>\n      <td>...</td>\n      <td>455.887218</td>\n      <td>113.959637</td>\n      <td>783.207399</td>\n      <td>538.439211</td>\n      <td>2013.125393</td>\n      <td>147.786584</td>\n      <td>4040.337842</td>\n      <td>2852.579397</td>\n      <td>1.826646e+05</td>\n      <td>0.194945</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>-999999.000000</td>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.163750e+03</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>38104.750000</td>\n      <td>2.000000</td>\n      <td>23.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.787061e+04</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>76043.000000</td>\n      <td>2.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.064092e+05</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>113748.750000</td>\n      <td>2.000000</td>\n      <td>40.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.187563e+05</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>151838.000000</td>\n      <td>238.000000</td>\n      <td>105.000000</td>\n      <td>210000.000000</td>\n      <td>12888.030000</td>\n      <td>21024.810000</td>\n      <td>8237.820000</td>\n      <td>11073.570000</td>\n      <td>6600.000000</td>\n      <td>6600.000000</td>\n      <td>...</td>\n      <td>50003.880000</td>\n      <td>20385.720000</td>\n      <td>138831.630000</td>\n      <td>91778.730000</td>\n      <td>438329.220000</td>\n      <td>24650.010000</td>\n      <td>681462.900000</td>\n      <td>397884.300000</td>\n      <td>2.203474e+07</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 371 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#dd1f03da .cell execution_count=3}\n``` {.python .cell-code}\ndf['var3'].replace(-999999, 2, inplace=True)\ndf.drop('ID', axis=1, inplace=True)\n\nX_features = df.iloc[:, :-1]\nlabels = df.iloc[:, -1]\n```\n:::\n\n\n::: {#618c0e4e .cell execution_count=4}\n``` {.python .cell-code}\ntest_df = pd.read_csv('_data/santander/test.csv', encoding='latin-1')\ntest_df['var3'].replace(-999999, 2, inplace=True)\ntest_df.drop('ID', axis=1, inplace=True)\n```\n:::\n\n\n::: {#637bf5d6 .cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_features, labels, test_size=0.2)\n```\n:::\n\n\n- train, test의 label의 비율이 동일한게 좋은걸까\n\n## XGBoost\n\n::: {#6f409853 .cell execution_count=6}\n``` {.python .cell-code}\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3)\n```\n:::\n\n\n::: {#1ba15f60 .cell execution_count=7}\n``` {.python .cell-code}\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\nevals = [(X_tr, y_tr), (X_val, y_val)]\nxgb_clf = XGBClassifier(n_estimators=400, \n                    learning_rate=0.05, \n                    early_stopping_rounds=100,\n                    eval_metric=['auc'])\nxgb_clf.fit(X_tr, y_tr, eval_set=evals, verbose=False)\nxgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\nprint(f'{xgb_roc_score:.3f}')\n```\n:::\n\n\n### 베이지안 최적화\n\n::: {#1b31b6f9 .cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\ndef objective_func(search_space):\n    xgb_clf = XGBClassifier(n_estimators=100, \n                            early_stopping_rounds=30,\n                            eval_metric='auc',\n                            max_depth=int(search_space['max_depth']),\n                            min_child_weight=int(search_space['min_child_weight']),\n                            colsample_bytree=search_space['colsample_bytree'],\n                            learning_rate=search_space['learning_rate'])\n    roc_auc_list = []\n    kf = KFold(n_splits=3)\n    for tr_index, val_index in kf.split(X_train):\n        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n        X_val, y_val =  X_train.iloc[val_index], y_train.iloc[val_index]\n\n        xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])\n        roc_auc_list.append(score)\n\n    return -1 * np.mean(roc_auc_list)\n```\n:::\n\n\n::: {#f38f3cc3 .cell execution_count=9}\n``` {.python .cell-code}\nfrom hyperopt import hp, fmin, tpe, Trials\n\nxgb_search_space = {\n  'max_depth': hp.quniform('max_depth', 5, 15, 1),\n  'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n  'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95),\n  'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n}\n\ntrials = Trials()\nbest = fmin(fn=objective_func,\n            space=xgb_search_space,\n            algo=tpe.suggest,\n            max_evals=50,\n            trials=trials)\nprint(best)\n```\n:::\n\n\n### 재 학습\n\n::: {#dfcb6ac0 .cell execution_count=10}\n``` {.python .cell-code}\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\nevals = [(X_tr, y_tr), (X_val, y_val)]\nxgb_clf = XGBClassifier(n_estimators=500, \n                    learning_rate=round(best['learning_rate'], 5),\n                    max_depth=int(best['max_depth']),\n                    min_child_weight=int(best['min_child_weight']),\n                    colsample_bytree=round(best['colsample_bytree'], 5),\n                    early_stopping_rounds=100,\n                    eval_metric=['auc'])\nxgb_clf.fit(X_tr, y_tr, eval_set=evals, verbose=False)\nxgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\nprint(f'{xgb_roc_score:.3f}')\n```\n:::\n\n\n### plot importance\n\n::: {#aaf3503d .cell execution_count=11}\n``` {.python .cell-code}\nfrom xgboost import plot_importance\n\nplot_importance(xgb_clf, max_num_features=20, height=0.4)\n```\n:::\n\n\n## LightGBM\n\n::: {#f767eb16 .cell execution_count=12}\n``` {.python .cell-code}\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier\n\nlgbm_clf = LGBMClassifier(n_estimators=500, early_stopping_rounds=100, eval_metric='auc')\n\neval_set = [(X_tr, y_tr), (X_val, y_val)]\nlgbm_clf.fit(X_tr, y_tr, eval_set=eval_set)\n\nlgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\nprint(f'{lgbm_roc_score:.3f}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Info] Number of positive: 1680, number of negative: 40891\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007185 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13313\n[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 246\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039463 -> initscore=-3.192116\n[LightGBM] [Info] Start training from score -3.192116\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[38]\ttraining's binary_logloss: 0.115227\tvalid_1's binary_logloss: 0.136678\n[LightGBM] [Warning] Unknown parameter: eval_metric\n0.835\n```\n:::\n:::\n\n\n### 베이지안 최적화\n\n::: {#2b2c2571 .cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn.model_selection import KFold\n\ndef objective_func(search_space):\n    lgbm_clf = LGBMClassifier(n_estimators=100, \n                            early_stopping_rounds=30,\n                            eval_metric='auc',\n                            num_leaves=int(search_space['num_leaves']),\n                            max_depth=int(search_space['max_depth']),\n                            min_child_samples=int(search_space['min_child_samples']),\n                            subsample=search_space['subsample'],\n                            learning_rate=search_space['learning_rate'])\n    roc_auc_list = []\n    kf = KFold(n_splits=3)\n    for tr_index, val_index in kf.split(X_train):\n        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n        X_val, y_val =  X_train.iloc[val_index], y_train.iloc[val_index]\n\n        lgbm_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1])\n        roc_auc_list.append(score)\n\n    return -1 * np.mean(roc_auc_list)\n```\n:::\n\n\n::: {#8063226d .cell execution_count=14}\n``` {.python .cell-code}\nfrom hyperopt import hp, fmin, tpe, Trials\n\nlgbm_search_space = {\n  'num_leaves': hp.quniform('num_leaves', 32, 64, 1),\n  'max_depth': hp.quniform('max_depth', 100, 160, 1),\n  'min_child_samples': hp.quniform('min_child_samples', 60, 100, 1),\n  'subsample': hp.uniform('subsample', 0.7, 1),\n  'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n}\n\ntrials = Trials()\nbest = fmin(fn=objective_func,\n            space=lgbm_search_space,\n            algo=tpe.suggest,\n            max_evals=50,\n            trials=trials)\nprint(best)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009724 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Total Bins 12869\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Start training from score -3.184987\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \rTraining until validation scores don't improve for 30 rounds\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \rDid not meet early stopping. Best iteration is:\n[71]\ttraining's binary_logloss: 0.112255\tvalid_1's binary_logloss: 0.135706\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008359 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Total Bins 12947\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Start training from score -3.196685\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \rTraining until validation scores don't improve for 30 rounds\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \rDid not meet early stopping. Best iteration is:\n[76]\ttraining's binary_logloss: 0.110659\tvalid_1's binary_logloss: 0.138201\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007536 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Total Bins 12908\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Start training from score -3.181760\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \rTraining until validation scores don't improve for 30 rounds\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \rEarly stopping, best iteration is:\n[61]\ttraining's binary_logloss: 0.115291\tvalid_1's binary_logloss: 0.135127\n\r  0%|          | 0/50 [00:03<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:03<?, ?trial/s, best loss=?]\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006936 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Total Bins 12812\n\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.184987\n\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  2%|▏         | 1/50 [00:03<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \rEarly stopping, best iteration is:\n[23]\ttraining's binary_logloss: 0.116064\tvalid_1's binary_logloss: 0.136172\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008904 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Total Bins 12943\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.196685\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \rEarly stopping, best iteration is:\n[16]\ttraining's binary_logloss: 0.120339\tvalid_1's binary_logloss: 0.138716\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012688 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Total Bins 12908\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.181760\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \rEarly stopping, best iteration is:\n[16]\ttraining's binary_logloss: 0.122183\tvalid_1's binary_logloss: 0.135018\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:05<02:51,  3.51s/trial, best loss: -0.8321249357878048]\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011380 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Total Bins 12804\n\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.184987\n\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  4%|▍         | 2/50 [00:05<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.116716\tvalid_1's binary_logloss: 0.136274\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008522 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Total Bins 12847\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.196685\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  4%|▍         | 2/50 [00:06<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.115805\tvalid_1's binary_logloss: 0.137993\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010308 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Total Bins 12817\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.181760\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  4%|▍         | 2/50 [00:07<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.116979\tvalid_1's binary_logloss: 0.135074\n\r  4%|▍         | 2/50 [00:08<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:08<02:07,  2.65s/trial, best loss: -0.8321249357878048]\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009715 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Total Bins 12944\n\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.184987\n\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  6%|▌         | 3/50 [00:08<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.11434\tvalid_1's binary_logloss: 0.136843\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007691 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Total Bins 12993\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.196685\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.113403\tvalid_1's binary_logloss: 0.13851\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:09<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:10<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r  6%|▌         | 3/50 [00:10<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008144 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  6%|▌         | 3/50 [00:10<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Total Bins 12917\n\r  6%|▌         | 3/50 [00:10<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r  6%|▌         | 3/50 [00:10<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:10<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:10<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r  6%|▌         | 3/50 [00:10<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.181760\n\r  6%|▌         | 3/50 [00:10<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  6%|▌         | 3/50 [00:10<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \rEarly stopping, best iteration is:\n[13]\ttraining's binary_logloss: 0.11959\tvalid_1's binary_logloss: 0.135042\n\r  6%|▌         | 3/50 [00:10<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:10<02:12,  2.83s/trial, best loss: -0.8321249357878048]\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007364 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Total Bins 12804\n\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.184987\n\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  8%|▊         | 4/50 [00:10<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \rEarly stopping, best iteration is:\n[50]\ttraining's binary_logloss: 0.114951\tvalid_1's binary_logloss: 0.135266\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009043 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Total Bins 12838\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.196685\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  8%|▊         | 4/50 [00:11<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \rEarly stopping, best iteration is:\n[49]\ttraining's binary_logloss: 0.114376\tvalid_1's binary_logloss: 0.138019\n\r  8%|▊         | 4/50 [00:12<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:12<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:12<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:12<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:13<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r  8%|▊         | 4/50 [00:13<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006748 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  8%|▊         | 4/50 [00:13<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Total Bins 12817\n\r  8%|▊         | 4/50 [00:13<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  8%|▊         | 4/50 [00:13<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:13<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:13<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r  8%|▊         | 4/50 [00:13<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.181760\n\r  8%|▊         | 4/50 [00:13<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  8%|▊         | 4/50 [00:13<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \rEarly stopping, best iteration is:\n[51]\ttraining's binary_logloss: 0.114762\tvalid_1's binary_logloss: 0.135074\n\r  8%|▊         | 4/50 [00:13<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:13<01:53,  2.46s/trial, best loss: -0.8321249357878048]\r 10%|█         | 5/50 [00:13<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:13<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:13<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:13<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 10%|█         | 5/50 [00:13<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007293 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 10%|█         | 5/50 [00:13<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Total Bins 12812\n\r 10%|█         | 5/50 [00:13<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r 10%|█         | 5/50 [00:13<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:13<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:13<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.184987\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.11413\tvalid_1's binary_logloss: 0.13591\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008305 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Total Bins 12943\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.196685\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 10%|█         | 5/50 [00:14<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \rEarly stopping, best iteration is:\n[17]\ttraining's binary_logloss: 0.120592\tvalid_1's binary_logloss: 0.138248\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009350 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Total Bins 12879\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.181760\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \rEarly stopping, best iteration is:\n[26]\ttraining's binary_logloss: 0.116027\tvalid_1's binary_logloss: 0.134638\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:15<02:02,  2.73s/trial, best loss: -0.8321345573094822]\r 12%|█▏        | 6/50 [00:15<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:15<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:15<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007637 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Total Bins 12900\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.184987\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \rEarly stopping, best iteration is:\n[33]\ttraining's binary_logloss: 0.113658\tvalid_1's binary_logloss: 0.13587\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010190 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Total Bins 12993\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.196685\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 12%|█▏        | 6/50 [00:16<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \rEarly stopping, best iteration is:\n[31]\ttraining's binary_logloss: 0.113983\tvalid_1's binary_logloss: 0.138398\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009348 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Total Bins 12917\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.181760\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 12%|█▏        | 6/50 [00:17<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.116757\tvalid_1's binary_logloss: 0.135006\n\r 12%|█▏        | 6/50 [00:18<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:18<01:49,  2.49s/trial, best loss: -0.8321862965498973]\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014190 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Total Bins 12804\n\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.184987\n\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 14%|█▍        | 7/50 [00:18<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[95]\ttraining's binary_logloss: 0.115034\tvalid_1's binary_logloss: 0.135206\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007240 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Total Bins 12847\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.196685\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 14%|█▍        | 7/50 [00:19<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[95]\ttraining's binary_logloss: 0.114229\tvalid_1's binary_logloss: 0.137941\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008922 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Total Bins 12817\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.181760\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 14%|█▍        | 7/50 [00:20<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[97]\ttraining's binary_logloss: 0.11512\tvalid_1's binary_logloss: 0.134343\n\r 14%|█▍        | 7/50 [00:21<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:21<01:49,  2.55s/trial, best loss: -0.8321862965498973]\r 16%|█▌        | 8/50 [00:21<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:21<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:21<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:21<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 16%|█▌        | 8/50 [00:21<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009362 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 16%|█▌        | 8/50 [00:21<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Total Bins 12804\n\r 16%|█▌        | 8/50 [00:21<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 16%|█▌        | 8/50 [00:21<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:21<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:21<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 16%|█▌        | 8/50 [00:21<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.184987\n\r 16%|█▌        | 8/50 [00:22<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 16%|█▌        | 8/50 [00:22<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[80]\ttraining's binary_logloss: 0.116244\tvalid_1's binary_logloss: 0.135104\n\r 16%|█▌        | 8/50 [00:22<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019852 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Total Bins 12838\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.196685\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 16%|█▌        | 8/50 [00:23<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[76]\ttraining's binary_logloss: 0.116122\tvalid_1's binary_logloss: 0.137831\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008059 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Total Bins 12817\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.181760\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 16%|█▌        | 8/50 [00:24<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[72]\ttraining's binary_logloss: 0.11803\tvalid_1's binary_logloss: 0.134506\n\r 16%|█▌        | 8/50 [00:25<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:25<01:56,  2.77s/trial, best loss: -0.8334837969495431]\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007825 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Total Bins 12804\n\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.184987\n\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 18%|█▊        | 9/50 [00:25<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \rEarly stopping, best iteration is:\n[19]\ttraining's binary_logloss: 0.119694\tvalid_1's binary_logloss: 0.135681\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007929 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Total Bins 12838\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.196685\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \rEarly stopping, best iteration is:\n[16]\ttraining's binary_logloss: 0.120319\tvalid_1's binary_logloss: 0.138538\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009337 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Total Bins 12817\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:26<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 18%|█▊        | 9/50 [00:27<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.181760\n\r 18%|█▊        | 9/50 [00:27<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 18%|█▊        | 9/50 [00:27<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \rEarly stopping, best iteration is:\n[17]\ttraining's binary_logloss: 0.120802\tvalid_1's binary_logloss: 0.13482\n\r 18%|█▊        | 9/50 [00:27<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:27<02:07,  3.11s/trial, best loss: -0.8335214645673078]\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008130 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \rEarly stopping, best iteration is:\n[51]\ttraining's binary_logloss: 0.119408\tvalid_1's binary_logloss: 0.134911\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:27<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009044 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \rEarly stopping, best iteration is:\n[49]\ttraining's binary_logloss: 0.119133\tvalid_1's binary_logloss: 0.137546\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007803 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 20%|██        | 10/50 [00:28<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:29<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:29<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 20%|██        | 10/50 [00:29<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 20%|██        | 10/50 [00:29<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 20%|██        | 10/50 [00:29<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \rEarly stopping, best iteration is:\n[47]\ttraining's binary_logloss: 0.120688\tvalid_1's binary_logloss: 0.134302\n\r 20%|██        | 10/50 [00:29<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:29<01:47,  2.69s/trial, best loss: -0.8335214645673078]\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011880 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 22%|██▏       | 11/50 [00:29<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.115117\tvalid_1's binary_logloss: 0.136209\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011556 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 22%|██▏       | 11/50 [00:30<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[27]\ttraining's binary_logloss: 0.115512\tvalid_1's binary_logloss: 0.138156\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008892 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 22%|██▏       | 11/50 [00:31<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.117743\tvalid_1's binary_logloss: 0.134897\n\r 22%|██▏       | 11/50 [00:32<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:32<01:39,  2.54s/trial, best loss: -0.8345904314135609]\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008049 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.118268\tvalid_1's binary_logloss: 0.135684\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 24%|██▍       | 12/50 [00:32<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006989 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12847\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[22]\ttraining's binary_logloss: 0.118735\tvalid_1's binary_logloss: 0.137976\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006796 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[24]\ttraining's binary_logloss: 0.119628\tvalid_1's binary_logloss: 0.134916\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:33<01:38,  2.59s/trial, best loss: -0.8345904314135609]\r 26%|██▌       | 13/50 [00:33<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010210 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[40]\ttraining's binary_logloss: 0.114319\tvalid_1's binary_logloss: 0.135995\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:34<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007309 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[39]\ttraining's binary_logloss: 0.113925\tvalid_1's binary_logloss: 0.137893\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009469 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 26%|██▌       | 13/50 [00:35<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[33]\ttraining's binary_logloss: 0.117803\tvalid_1's binary_logloss: 0.135217\n\r 26%|██▌       | 13/50 [00:36<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:36<01:27,  2.36s/trial, best loss: -0.8345904314135609]\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007370 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 28%|██▊       | 14/50 [00:36<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[99]\ttraining's binary_logloss: 0.117141\tvalid_1's binary_logloss: 0.135196\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013043 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 28%|██▊       | 14/50 [00:37<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[97]\ttraining's binary_logloss: 0.116927\tvalid_1's binary_logloss: 0.137695\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010449 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 28%|██▊       | 14/50 [00:38<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.117458\tvalid_1's binary_logloss: 0.134804\n\r 28%|██▊       | 14/50 [00:39<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:39<01:26,  2.40s/trial, best loss: -0.8345904314135609]\r 30%|███       | 15/50 [00:39<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:39<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:39<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:40<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 30%|███       | 15/50 [00:40<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009063 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 30%|███       | 15/50 [00:40<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12821\n\r 30%|███       | 15/50 [00:40<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 30%|███       | 15/50 [00:40<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:40<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:40<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 30%|███       | 15/50 [00:40<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 30%|███       | 15/50 [00:40<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 30%|███       | 15/50 [00:40<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.11267\tvalid_1's binary_logloss: 0.136106\n\r 30%|███       | 15/50 [00:40<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:40<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009274 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[22]\ttraining's binary_logloss: 0.115948\tvalid_1's binary_logloss: 0.13866\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:41<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011803 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12908\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[23]\ttraining's binary_logloss: 0.116131\tvalid_1's binary_logloss: 0.135187\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:42<01:33,  2.67s/trial, best loss: -0.8345904314135609]\r 32%|███▏      | 16/50 [00:42<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:42<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:42<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:42<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 32%|███▏      | 16/50 [00:42<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008073 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 32%|███▏      | 16/50 [00:42<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12900\n\r 32%|███▏      | 16/50 [00:42<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 32%|███▏      | 16/50 [00:42<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:42<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:42<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 32%|███▏      | 16/50 [00:43<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 32%|███▏      | 16/50 [00:43<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 32%|███▏      | 16/50 [00:43<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[84]\ttraining's binary_logloss: 0.11371\tvalid_1's binary_logloss: 0.135137\n\r 32%|███▏      | 16/50 [00:43<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:43<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:43<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:43<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:43<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 32%|███▏      | 16/50 [00:43<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007565 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 32%|███▏      | 16/50 [00:43<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12993\n\r 32%|███▏      | 16/50 [00:43<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 32%|███▏      | 16/50 [00:43<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[67]\ttraining's binary_logloss: 0.116405\tvalid_1's binary_logloss: 0.138124\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008722 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12917\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 32%|███▏      | 16/50 [00:44<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:45<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:45<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 32%|███▏      | 16/50 [00:45<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 32%|███▏      | 16/50 [00:45<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 32%|███▏      | 16/50 [00:45<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[84]\ttraining's binary_logloss: 0.114059\tvalid_1's binary_logloss: 0.134317\n\r 32%|███▏      | 16/50 [00:45<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:45<01:33,  2.76s/trial, best loss: -0.8345904314135609]\r 34%|███▍      | 17/50 [00:45<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:45<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:45<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:45<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 34%|███▍      | 17/50 [00:45<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009001 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 34%|███▍      | 17/50 [00:45<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 34%|███▍      | 17/50 [00:45<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 34%|███▍      | 17/50 [00:45<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:45<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:45<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[60]\ttraining's binary_logloss: 0.116861\tvalid_1's binary_logloss: 0.134877\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008590 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 34%|███▍      | 17/50 [00:46<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[58]\ttraining's binary_logloss: 0.11687\tvalid_1's binary_logloss: 0.13752\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006636 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \rEarly stopping, best iteration is:\n[67]\ttraining's binary_logloss: 0.115782\tvalid_1's binary_logloss: 0.134209\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:47<01:32,  2.82s/trial, best loss: -0.8345904314135609]\r 36%|███▌      | 18/50 [00:47<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007175 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12944\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.117901\tvalid_1's binary_logloss: 0.135627\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008634 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12993\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 36%|███▌      | 18/50 [00:48<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[24]\ttraining's binary_logloss: 0.114214\tvalid_1's binary_logloss: 0.138485\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008114 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12917\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[19]\ttraining's binary_logloss: 0.118579\tvalid_1's binary_logloss: 0.135136\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:49<01:25,  2.66s/trial, best loss: -0.8346199818249235]\r 38%|███▊      | 19/50 [00:49<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:49<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:49<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007573 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12869\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[64]\ttraining's binary_logloss: 0.112009\tvalid_1's binary_logloss: 0.13523\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:50<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007871 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12947\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[61]\ttraining's binary_logloss: 0.112082\tvalid_1's binary_logloss: 0.13837\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:51<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:52<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 38%|███▊      | 19/50 [00:52<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008356 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 38%|███▊      | 19/50 [00:52<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12908\n\r 38%|███▊      | 19/50 [00:52<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 38%|███▊      | 19/50 [00:52<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:52<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:52<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 38%|███▊      | 19/50 [00:52<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 38%|███▊      | 19/50 [00:52<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 38%|███▊      | 19/50 [00:52<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[60]\ttraining's binary_logloss: 0.113244\tvalid_1's binary_logloss: 0.134797\n\r 38%|███▊      | 19/50 [00:52<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:52<01:14,  2.42s/trial, best loss: -0.8346199818249235]\r 40%|████      | 20/50 [00:52<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:52<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:52<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:52<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 40%|████      | 20/50 [00:52<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007853 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.13445\tvalid_1's binary_logloss: 0.139692\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008540 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 40%|████      | 20/50 [00:53<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.133592\tvalid_1's binary_logloss: 0.142113\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010222 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 40%|████      | 20/50 [00:54<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.135205\tvalid_1's binary_logloss: 0.138742\n\r 40%|████      | 20/50 [00:55<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:55<01:17,  2.58s/trial, best loss: -0.8346199818249235]\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008607 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[52]\ttraining's binary_logloss: 0.118045\tvalid_1's binary_logloss: 0.134995\n\r 42%|████▏     | 21/50 [00:55<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009509 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12913\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[49]\ttraining's binary_logloss: 0.118325\tvalid_1's binary_logloss: 0.137852\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:56<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:57<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 42%|████▏     | 21/50 [00:57<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 42%|████▏     | 21/50 [00:57<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12879\n\r 42%|████▏     | 21/50 [00:57<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 42%|████▏     | 21/50 [00:57<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:57<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:57<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 42%|████▏     | 21/50 [00:57<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 42%|████▏     | 21/50 [00:57<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 42%|████▏     | 21/50 [00:57<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[54]\ttraining's binary_logloss: 0.118203\tvalid_1's binary_logloss: 0.134179\n\r 42%|████▏     | 21/50 [00:57<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:57<01:13,  2.55s/trial, best loss: -0.8346199818249235]\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009051 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 44%|████▍     | 22/50 [00:57<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[19]\ttraining's binary_logloss: 0.118534\tvalid_1's binary_logloss: 0.136106\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007194 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12913\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[15]\ttraining's binary_logloss: 0.120171\tvalid_1's binary_logloss: 0.137868\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007805 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12879\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 44%|████▍     | 22/50 [00:58<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.118138\tvalid_1's binary_logloss: 0.13535\n\r 44%|████▍     | 22/50 [00:59<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:59<01:09,  2.47s/trial, best loss: -0.8346199818249235]\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008298 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.123442\tvalid_1's binary_logloss: 0.135652\n\r 46%|████▌     | 23/50 [00:59<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007983 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.122527\tvalid_1's binary_logloss: 0.138185\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:00<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:01<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [01:01<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:01<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 46%|████▌     | 23/50 [01:01<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012976 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 46%|████▌     | 23/50 [01:01<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 46%|████▌     | 23/50 [01:01<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 46%|████▌     | 23/50 [01:01<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:01<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [01:01<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 46%|████▌     | 23/50 [01:01<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 46%|████▌     | 23/50 [01:01<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 46%|████▌     | 23/50 [01:01<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.123812\tvalid_1's binary_logloss: 0.13482\n\r 46%|████▌     | 23/50 [01:02<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:02<01:00,  2.23s/trial, best loss: -0.8346199818249235]\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007683 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 48%|████▊     | 24/50 [01:02<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[55]\ttraining's binary_logloss: 0.118913\tvalid_1's binary_logloss: 0.134591\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007060 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 48%|████▊     | 24/50 [01:03<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[51]\ttraining's binary_logloss: 0.119109\tvalid_1's binary_logloss: 0.137532\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007158 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \rEarly stopping, best iteration is:\n[53]\ttraining's binary_logloss: 0.119682\tvalid_1's binary_logloss: 0.134044\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:04<01:06,  2.56s/trial, best loss: -0.8346199818249235]\r 50%|█████     | 25/50 [01:04<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:04<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:04<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006965 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[41]\ttraining's binary_logloss: 0.116789\tvalid_1's binary_logloss: 0.135098\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009464 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 50%|█████     | 25/50 [01:05<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[39]\ttraining's binary_logloss: 0.116539\tvalid_1's binary_logloss: 0.138054\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006983 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[39]\ttraining's binary_logloss: 0.117685\tvalid_1's binary_logloss: 0.134656\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:06<01:01,  2.47s/trial, best loss: -0.8353293081416346]\r 52%|█████▏    | 26/50 [01:06<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008118 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.131216\tvalid_1's binary_logloss: 0.139484\n\r 52%|█████▏    | 26/50 [01:07<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017901 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12903\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 52%|█████▏    | 26/50 [01:08<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.130191\tvalid_1's binary_logloss: 0.141574\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007720 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12879\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 52%|█████▏    | 26/50 [01:09<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.131799\tvalid_1's binary_logloss: 0.138351\n\r 52%|█████▏    | 26/50 [01:10<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:10<00:57,  2.38s/trial, best loss: -0.8353293081416346]\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007748 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[60]\ttraining's binary_logloss: 0.119196\tvalid_1's binary_logloss: 0.134697\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:10<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007410 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[60]\ttraining's binary_logloss: 0.118245\tvalid_1's binary_logloss: 0.137653\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008656 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 54%|█████▍    | 27/50 [01:11<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[58]\ttraining's binary_logloss: 0.11982\tvalid_1's binary_logloss: 0.134115\n\r 54%|█████▍    | 27/50 [01:12<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:12<01:00,  2.64s/trial, best loss: -0.8353293081416346]\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008201 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 56%|█████▌    | 28/50 [01:12<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[55]\ttraining's binary_logloss: 0.118255\tvalid_1's binary_logloss: 0.13523\n\r 56%|█████▌    | 28/50 [01:13<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:13<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:13<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:13<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:13<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 56%|█████▌    | 28/50 [01:13<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008806 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 56%|█████▌    | 28/50 [01:13<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 56%|█████▌    | 28/50 [01:13<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 56%|█████▌    | 28/50 [01:13<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:13<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:13<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 56%|█████▌    | 28/50 [01:14<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 56%|█████▌    | 28/50 [01:14<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 56%|█████▌    | 28/50 [01:14<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[58]\ttraining's binary_logloss: 0.116637\tvalid_1's binary_logloss: 0.137971\n\r 56%|█████▌    | 28/50 [01:14<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:14<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011744 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[57]\ttraining's binary_logloss: 0.118083\tvalid_1's binary_logloss: 0.134172\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:15<00:55,  2.51s/trial, best loss: -0.8353293081416346]\r 58%|█████▊    | 29/50 [01:15<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009021 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[69]\ttraining's binary_logloss: 0.118755\tvalid_1's binary_logloss: 0.134976\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:16<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:17<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 58%|█████▊    | 29/50 [01:17<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013066 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 58%|█████▊    | 29/50 [01:17<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12913\n\r 58%|█████▊    | 29/50 [01:17<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 58%|█████▊    | 29/50 [01:17<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:17<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:17<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 58%|█████▊    | 29/50 [01:17<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 58%|█████▊    | 29/50 [01:17<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 58%|█████▊    | 29/50 [01:17<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[66]\ttraining's binary_logloss: 0.118516\tvalid_1's binary_logloss: 0.13759\n\r 58%|█████▊    | 29/50 [01:17<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:17<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011270 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12879\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[69]\ttraining's binary_logloss: 0.119213\tvalid_1's binary_logloss: 0.134123\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:18<00:58,  2.81s/trial, best loss: -0.8353293081416346]\r 60%|██████    | 30/50 [01:18<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007448 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.124451\tvalid_1's binary_logloss: 0.135306\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:19<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008631 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.123486\tvalid_1's binary_logloss: 0.137957\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007884 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12879\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:20<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 60%|██████    | 30/50 [01:21<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 60%|██████    | 30/50 [01:21<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 60%|██████    | 30/50 [01:21<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.124936\tvalid_1's binary_logloss: 0.13456\n\r 60%|██████    | 30/50 [01:21<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:21<00:57,  2.88s/trial, best loss: -0.8353293081416346]\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013677 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12896\n\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 62%|██████▏   | 31/50 [01:21<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.123182\tvalid_1's binary_logloss: 0.13554\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010535 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12947\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 62%|██████▏   | 31/50 [01:22<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.12218\tvalid_1's binary_logloss: 0.138117\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007774 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12908\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 62%|██████▏   | 31/50 [01:23<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.123535\tvalid_1's binary_logloss: 0.134833\n\r 62%|██████▏   | 31/50 [01:24<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:24<00:53,  2.80s/trial, best loss: -0.8353293081416346]\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016300 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.119038\tvalid_1's binary_logloss: 0.134688\n\r 64%|██████▍   | 32/50 [01:24<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008723 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.118066\tvalid_1's binary_logloss: 0.137695\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012208 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12879\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:25<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 64%|██████▍   | 32/50 [01:26<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 64%|██████▍   | 32/50 [01:26<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 64%|██████▍   | 32/50 [01:26<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.120385\tvalid_1's binary_logloss: 0.134541\n\r 64%|██████▍   | 32/50 [01:26<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:26<00:49,  2.77s/trial, best loss: -0.8353293081416346]\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007626 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 66%|██████▌   | 33/50 [01:26<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[42]\ttraining's binary_logloss: 0.113008\tvalid_1's binary_logloss: 0.135691\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012098 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12903\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[31]\ttraining's binary_logloss: 0.117041\tvalid_1's binary_logloss: 0.138101\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:27<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009215 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12879\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[42]\ttraining's binary_logloss: 0.113562\tvalid_1's binary_logloss: 0.134568\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:28<00:43,  2.56s/trial, best loss: -0.8353293081416346]\r 68%|██████▊   | 34/50 [01:28<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:28<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:28<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008779 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.121864\tvalid_1's binary_logloss: 0.135488\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007069 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12903\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 68%|██████▊   | 34/50 [01:29<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.120934\tvalid_1's binary_logloss: 0.138049\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012046 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12879\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 68%|██████▊   | 34/50 [01:30<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.122219\tvalid_1's binary_logloss: 0.134581\n\r 68%|██████▊   | 34/50 [01:31<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:31<00:40,  2.53s/trial, best loss: -0.8353293081416346]\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007576 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12812\n\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 70%|███████   | 35/50 [01:31<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.129099\tvalid_1's binary_logloss: 0.137718\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007789 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 70%|███████   | 35/50 [01:32<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.128316\tvalid_1's binary_logloss: 0.140125\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010383 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12879\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 70%|███████   | 35/50 [01:33<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.129766\tvalid_1's binary_logloss: 0.136703\n\r 70%|███████   | 35/50 [01:34<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:34<00:38,  2.60s/trial, best loss: -0.8353293081416346]\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009033 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 72%|███████▏  | 36/50 [01:34<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.120857\tvalid_1's binary_logloss: 0.135392\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007741 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12903\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[31]\ttraining's binary_logloss: 0.118985\tvalid_1's binary_logloss: 0.137371\n\r 72%|███████▏  | 36/50 [01:35<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010013 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.120758\tvalid_1's binary_logloss: 0.134185\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:36<00:37,  2.71s/trial, best loss: -0.8353293081416346]\r 74%|███████▍  | 37/50 [01:36<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:36<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:36<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:36<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 74%|███████▍  | 37/50 [01:36<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008582 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 74%|███████▍  | 37/50 [01:36<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 74%|███████▍  | 37/50 [01:36<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 74%|███████▍  | 37/50 [01:36<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:37<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:37<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 74%|███████▍  | 37/50 [01:37<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 74%|███████▍  | 37/50 [01:37<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 74%|███████▍  | 37/50 [01:37<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.122004\tvalid_1's binary_logloss: 0.134892\n\r 74%|███████▍  | 37/50 [01:37<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:37<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:37<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:37<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:37<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 74%|███████▍  | 37/50 [01:37<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007974 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.120947\tvalid_1's binary_logloss: 0.137433\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008872 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 74%|███████▍  | 37/50 [01:38<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.122411\tvalid_1's binary_logloss: 0.134261\n\r 74%|███████▍  | 37/50 [01:39<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:39<00:33,  2.54s/trial, best loss: -0.8353293081416346]\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512] \r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014886 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Total Bins 12804\n\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.184987\n\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 76%|███████▌  | 38/50 [01:39<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \rEarly stopping, best iteration is:\n[15]\ttraining's binary_logloss: 0.120015\tvalid_1's binary_logloss: 0.136651\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012741 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Total Bins 12838\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.196685\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \rEarly stopping, best iteration is:\n[15]\ttraining's binary_logloss: 0.118939\tvalid_1's binary_logloss: 0.138894\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 76%|███████▌  | 38/50 [01:40<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010061 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 76%|███████▌  | 38/50 [01:41<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Total Bins 12817\n\r 76%|███████▌  | 38/50 [01:41<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 76%|███████▌  | 38/50 [01:41<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:41<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:41<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 76%|███████▌  | 38/50 [01:41<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.181760\n\r 76%|███████▌  | 38/50 [01:41<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 76%|███████▌  | 38/50 [01:41<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \rEarly stopping, best iteration is:\n[12]\ttraining's binary_logloss: 0.122953\tvalid_1's binary_logloss: 0.134958\n\r 76%|███████▌  | 38/50 [01:41<00:31,  2.62s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:41<00:31,  2.62s/trial, best loss: -0.835331797276512]\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008189 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Total Bins 12804\n\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.184987\n\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 78%|███████▊  | 39/50 [01:41<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[88]\ttraining's binary_logloss: 0.117929\tvalid_1's binary_logloss: 0.135205\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008863 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Total Bins 12838\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.196685\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 78%|███████▊  | 39/50 [01:42<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[81]\ttraining's binary_logloss: 0.11844\tvalid_1's binary_logloss: 0.137484\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009540 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Total Bins 12817\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.181760\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 78%|███████▊  | 39/50 [01:43<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[85]\ttraining's binary_logloss: 0.118939\tvalid_1's binary_logloss: 0.134806\n\r 78%|███████▊  | 39/50 [01:44<00:26,  2.39s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:44<00:26,  2.39s/trial, best loss: -0.835331797276512]\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007878 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Total Bins 12804\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.184987\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \rEarly stopping, best iteration is:\n[50]\ttraining's binary_logloss: 0.119598\tvalid_1's binary_logloss: 0.134559\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:44<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013151 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Total Bins 12838\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.196685\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \rEarly stopping, best iteration is:\n[51]\ttraining's binary_logloss: 0.118541\tvalid_1's binary_logloss: 0.137523\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:45<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:46<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 80%|████████  | 40/50 [01:46<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011190 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 80%|████████  | 40/50 [01:46<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Total Bins 12817\n\r 80%|████████  | 40/50 [01:46<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 80%|████████  | 40/50 [01:46<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:46<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:46<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 80%|████████  | 40/50 [01:46<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.181760\n\r 80%|████████  | 40/50 [01:46<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 80%|████████  | 40/50 [01:46<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \rEarly stopping, best iteration is:\n[48]\ttraining's binary_logloss: 0.120332\tvalid_1's binary_logloss: 0.134165\n\r 80%|████████  | 40/50 [01:46<00:25,  2.54s/trial, best loss: -0.835331797276512]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:46<00:25,  2.54s/trial, best loss: -0.835331797276512]\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006984 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[33]\ttraining's binary_logloss: 0.119524\tvalid_1's binary_logloss: 0.135441\n\r 82%|████████▏ | 41/50 [01:47<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008826 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.120257\tvalid_1's binary_logloss: 0.137469\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007049 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 82%|████████▏ | 41/50 [01:48<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.121158\tvalid_1's binary_logloss: 0.134384\n\r 82%|████████▏ | 41/50 [01:49<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:49<00:24,  2.72s/trial, best loss: -0.8357102168343064]\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008870 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 84%|████████▍ | 42/50 [01:49<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.117395\tvalid_1's binary_logloss: 0.136137\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012995 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[33]\ttraining's binary_logloss: 0.115053\tvalid_1's binary_logloss: 0.138202\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:50<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008256 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[40]\ttraining's binary_logloss: 0.112815\tvalid_1's binary_logloss: 0.134646\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:51<00:19,  2.47s/trial, best loss: -0.8357102168343064]\r 86%|████████▌ | 43/50 [01:51<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:51<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006767 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[43]\ttraining's binary_logloss: 0.116209\tvalid_1's binary_logloss: 0.135515\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007724 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 86%|████████▌ | 43/50 [01:52<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[41]\ttraining's binary_logloss: 0.116373\tvalid_1's binary_logloss: 0.13768\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015228 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 86%|████████▌ | 43/50 [01:53<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[38]\ttraining's binary_logloss: 0.118563\tvalid_1's binary_logloss: 0.13498\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.49s/trial, best loss: -0.8357102168343064]\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008542 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.120117\tvalid_1's binary_logloss: 0.134789\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:54<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008040 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.119394\tvalid_1's binary_logloss: 0.137658\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009460 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 88%|████████▊ | 44/50 [01:55<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[37]\ttraining's binary_logloss: 0.114421\tvalid_1's binary_logloss: 0.134479\n\r 88%|████████▊ | 44/50 [01:56<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:56<00:14,  2.47s/trial, best loss: -0.8357102168343064]\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010005 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.115234\tvalid_1's binary_logloss: 0.135872\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:56<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008841 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[27]\ttraining's binary_logloss: 0.115194\tvalid_1's binary_logloss: 0.138408\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010236 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:57<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 90%|█████████ | 45/50 [01:58<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 90%|█████████ | 45/50 [01:58<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 90%|█████████ | 45/50 [01:58<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[26]\ttraining's binary_logloss: 0.116992\tvalid_1's binary_logloss: 0.135531\n\r 90%|█████████ | 45/50 [01:58<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:58<00:11,  2.31s/trial, best loss: -0.8357102168343064]\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007834 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 92%|█████████▏| 46/50 [01:58<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.115923\tvalid_1's binary_logloss: 0.13639\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009212 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[17]\ttraining's binary_logloss: 0.117019\tvalid_1's binary_logloss: 0.138229\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:59<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:00<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 92%|█████████▏| 46/50 [02:00<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010055 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 92%|█████████▏| 46/50 [02:00<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 92%|█████████▏| 46/50 [02:00<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 92%|█████████▏| 46/50 [02:00<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:00<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [02:00<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 92%|█████████▏| 46/50 [02:00<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 92%|█████████▏| 46/50 [02:00<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 92%|█████████▏| 46/50 [02:00<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.117591\tvalid_1's binary_logloss: 0.135204\n\r 92%|█████████▏| 46/50 [02:00<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:00<00:09,  2.32s/trial, best loss: -0.8357102168343064]\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009290 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 94%|█████████▍| 47/50 [02:00<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[27]\ttraining's binary_logloss: 0.117985\tvalid_1's binary_logloss: 0.135367\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010413 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.117671\tvalid_1's binary_logloss: 0.137665\n\r 94%|█████████▍| 47/50 [02:01<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008027 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[23]\ttraining's binary_logloss: 0.120142\tvalid_1's binary_logloss: 0.135155\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:02<00:06,  2.22s/trial, best loss: -0.8357102168343064]\r 96%|█████████▌| 48/50 [02:02<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014548 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \rEarly stopping, best iteration is:\n[69]\ttraining's binary_logloss: 0.117534\tvalid_1's binary_logloss: 0.134864\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:03<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007901 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[82]\ttraining's binary_logloss: 0.114016\tvalid_1's binary_logloss: 0.137702\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:04<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012228 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[75]\ttraining's binary_logloss: 0.116413\tvalid_1's binary_logloss: 0.134882\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:05<00:04,  2.25s/trial, best loss: -0.8357102168343064]\r 98%|█████████▊| 49/50 [02:05<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1611, number of negative: 38933\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013063 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12804\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039735 -> initscore=-3.184987\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.184987\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[99]\ttraining's binary_logloss: 0.115727\tvalid_1's binary_logloss: 0.135247\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:06<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1593, number of negative: 38951\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008711 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12847\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.196685\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.11494\tvalid_1's binary_logloss: 0.137861\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:07<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1616, number of negative: 38928\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007797 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Total Bins 12817\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039858 -> initscore=-3.181760\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.181760\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[99]\ttraining's binary_logloss: 0.116161\tvalid_1's binary_logloss: 0.134483\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:08<00:02,  2.49s/trial, best loss: -0.8357102168343064]\r100%|██████████| 50/50 [02:08<00:00,  2.67s/trial, best loss: -0.8357102168343064]\r100%|██████████| 50/50 [02:08<00:00,  2.58s/trial, best loss: -0.8357102168343064]\n{'learning_rate': 0.07078424888661622, 'max_depth': 143.0, 'min_child_samples': 93.0, 'num_leaves': 33.0, 'subsample': 0.9935662058378432}\n```\n:::\n:::\n\n\n### 재학습\n\n::: {#8f3a2e85 .cell execution_count=15}\n``` {.python .cell-code}\nlgbm_clf = LGBMClassifier(n_estimators=500, \n                          num_leaves=int(best['num_leaves']),\n                          max_depth=int(best['max_depth']),\n                          min_child_samples=int(best['min_child_samples']),\n                          subsample=round(best['subsample'], 5),\n                          learning_rate=round(best['learning_rate'], 5),\n                          early_stopping_rounds=100, \n                          eval_metric='auc')\n\neval_set = [(X_tr, y_tr), (X_val, y_val)]\nlgbm_clf.fit(X_tr, y_tr, eval_set=eval_set)\n\nlgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\nprint(f'{lgbm_roc_score:.3f}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Info] Number of positive: 1680, number of negative: 40891\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010648 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 12882\n[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 192\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039463 -> initscore=-3.192116\n[LightGBM] [Info] Start training from score -3.192116\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[43]\ttraining's binary_logloss: 0.120912\tvalid_1's binary_logloss: 0.136896\n[LightGBM] [Warning] Unknown parameter: eval_metric\n0.835\n```\n:::\n:::\n\n\n## 제출\n\n::: {#07194e50 .cell execution_count=16}\n``` {.python .cell-code}\ntarget = lgbm_clf.predict(test_df)\n\nsubmit = pd.read_csv('_data/santander/sample_submission.csv', encoding='latin-1')\nsubmit['TARGET'] = target\nsubmit.to_csv('_data/santander/submission.csv', encoding='latin-1', index=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[LightGBM] [Warning] Unknown parameter: eval_metric\n```\n:::\n:::\n\n\n",
    "supporting": [
      "03_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}