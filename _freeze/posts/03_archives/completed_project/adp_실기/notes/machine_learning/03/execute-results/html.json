{
  "hash": "a3e7365f8318821985f39810546c71c4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"분류 - 산탄데르 고객 만족 예측\"\ndate: 2025-07-27\ncategories: [\"머신 러닝\"]\n---\n\n\n\n\n![](/img/stat-thumb.jpg){.post-thumbnail}\n\n## Preprocessing\n\n::: {#30c7f328 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\n\nplt.rcParams['font.family'] = 'Noto Sans KR'\nwarnings.filterwarnings('ignore')\n\ndf = pd.read_csv('_data/santander/train.csv', encoding='latin-1')\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 76020 entries, 0 to 76019\nColumns: 371 entries, ID to TARGET\ndtypes: float64(111), int64(260)\nmemory usage: 215.2 MB\n```\n:::\n:::\n\n\n::: {#2847c582 .cell execution_count=2}\n``` {.python .cell-code}\ndf.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>var3</th>\n      <th>var15</th>\n      <th>imp_ent_var16_ult1</th>\n      <th>imp_op_var39_comer_ult1</th>\n      <th>imp_op_var39_comer_ult3</th>\n      <th>imp_op_var40_comer_ult1</th>\n      <th>imp_op_var40_comer_ult3</th>\n      <th>imp_op_var40_efect_ult1</th>\n      <th>imp_op_var40_efect_ult3</th>\n      <th>...</th>\n      <th>saldo_medio_var33_hace2</th>\n      <th>saldo_medio_var33_hace3</th>\n      <th>saldo_medio_var33_ult1</th>\n      <th>saldo_medio_var33_ult3</th>\n      <th>saldo_medio_var44_hace2</th>\n      <th>saldo_medio_var44_hace3</th>\n      <th>saldo_medio_var44_ult1</th>\n      <th>saldo_medio_var44_ult3</th>\n      <th>var38</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>...</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>7.602000e+04</td>\n      <td>76020.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>75964.050723</td>\n      <td>-1523.199277</td>\n      <td>33.212865</td>\n      <td>86.208265</td>\n      <td>72.363067</td>\n      <td>119.529632</td>\n      <td>3.559130</td>\n      <td>6.472698</td>\n      <td>0.412946</td>\n      <td>0.567352</td>\n      <td>...</td>\n      <td>7.935824</td>\n      <td>1.365146</td>\n      <td>12.215580</td>\n      <td>8.784074</td>\n      <td>31.505324</td>\n      <td>1.858575</td>\n      <td>76.026165</td>\n      <td>56.614351</td>\n      <td>1.172358e+05</td>\n      <td>0.039569</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>43781.947379</td>\n      <td>39033.462364</td>\n      <td>12.956486</td>\n      <td>1614.757313</td>\n      <td>339.315831</td>\n      <td>546.266294</td>\n      <td>93.155749</td>\n      <td>153.737066</td>\n      <td>30.604864</td>\n      <td>36.513513</td>\n      <td>...</td>\n      <td>455.887218</td>\n      <td>113.959637</td>\n      <td>783.207399</td>\n      <td>538.439211</td>\n      <td>2013.125393</td>\n      <td>147.786584</td>\n      <td>4040.337842</td>\n      <td>2852.579397</td>\n      <td>1.826646e+05</td>\n      <td>0.194945</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>-999999.000000</td>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.163750e+03</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>38104.750000</td>\n      <td>2.000000</td>\n      <td>23.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.787061e+04</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>76043.000000</td>\n      <td>2.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.064092e+05</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>113748.750000</td>\n      <td>2.000000</td>\n      <td>40.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.187563e+05</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>151838.000000</td>\n      <td>238.000000</td>\n      <td>105.000000</td>\n      <td>210000.000000</td>\n      <td>12888.030000</td>\n      <td>21024.810000</td>\n      <td>8237.820000</td>\n      <td>11073.570000</td>\n      <td>6600.000000</td>\n      <td>6600.000000</td>\n      <td>...</td>\n      <td>50003.880000</td>\n      <td>20385.720000</td>\n      <td>138831.630000</td>\n      <td>91778.730000</td>\n      <td>438329.220000</td>\n      <td>24650.010000</td>\n      <td>681462.900000</td>\n      <td>397884.300000</td>\n      <td>2.203474e+07</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 371 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#86d1cfd8 .cell execution_count=3}\n``` {.python .cell-code}\ndf['var3'].replace(-999999, 2, inplace=True)\ndf.drop('ID', axis=1, inplace=True)\n\nX_features = df.iloc[:, :-1]\nlabels = df.iloc[:, -1]\n```\n:::\n\n\n::: {#1b6dbbee .cell execution_count=4}\n``` {.python .cell-code}\ntest_df = pd.read_csv('_data/santander/test.csv', encoding='latin-1')\ntest_df['var3'].replace(-999999, 2, inplace=True)\ntest_df.drop('ID', axis=1, inplace=True)\n```\n:::\n\n\n::: {#d4714bf3 .cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_features, labels, test_size=0.2)\n```\n:::\n\n\n- train, test의 label의 비율이 동일한게 좋은걸까\n\n## XGBoost\n\n::: {#b5e6ed7d .cell execution_count=6}\n``` {.python .cell-code}\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3)\n```\n:::\n\n\n::: {#78fd7b83 .cell execution_count=7}\n``` {.python .cell-code}\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\nevals = [(X_tr, y_tr), (X_val, y_val)]\nxgb_clf = XGBClassifier(n_estimators=400, \n                    learning_rate=0.05, \n                    early_stopping_rounds=100,\n                    eval_metric=['auc'])\nxgb_clf.fit(X_tr, y_tr, eval_set=evals, verbose=False)\nxgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\nprint(f'{xgb_roc_score:.3f}')\n```\n:::\n\n\n### 베이지안 최적화\n\n::: {#27c21265 .cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\ndef objective_func(search_space):\n    xgb_clf = XGBClassifier(n_estimators=100, \n                            early_stopping_rounds=30,\n                            eval_metric='auc',\n                            max_depth=int(search_space['max_depth']),\n                            min_child_weight=int(search_space['min_child_weight']),\n                            colsample_bytree=search_space['colsample_bytree'],\n                            learning_rate=search_space['learning_rate'])\n    roc_auc_list = []\n    kf = KFold(n_splits=3)\n    for tr_index, val_index in kf.split(X_train):\n        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n        X_val, y_val =  X_train.iloc[val_index], y_train.iloc[val_index]\n\n        xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])\n        roc_auc_list.append(score)\n\n    return -1 * np.mean(roc_auc_list)\n```\n:::\n\n\n::: {#73547293 .cell execution_count=9}\n``` {.python .cell-code}\nfrom hyperopt import hp, fmin, tpe, Trials\n\nxgb_search_space = {\n  'max_depth': hp.quniform('max_depth', 5, 15, 1),\n  'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n  'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95),\n  'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n}\n\ntrials = Trials()\nbest = fmin(fn=objective_func,\n            space=xgb_search_space,\n            algo=tpe.suggest,\n            max_evals=50,\n            trials=trials)\nprint(best)\n```\n:::\n\n\n### 재 학습\n\n::: {#77a10666 .cell execution_count=10}\n``` {.python .cell-code}\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\nevals = [(X_tr, y_tr), (X_val, y_val)]\nxgb_clf = XGBClassifier(n_estimators=500, \n                    learning_rate=round(best['learning_rate'], 5),\n                    max_depth=int(best['max_depth']),\n                    min_child_weight=int(best['min_child_weight']),\n                    colsample_bytree=round(best['colsample_bytree'], 5),\n                    early_stopping_rounds=100,\n                    eval_metric=['auc'])\nxgb_clf.fit(X_tr, y_tr, eval_set=evals, verbose=False)\nxgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\nprint(f'{xgb_roc_score:.3f}')\n```\n:::\n\n\n### plot importance\n\n::: {#ac38b14f .cell execution_count=11}\n``` {.python .cell-code}\nfrom xgboost import plot_importance\n\nplot_importance(xgb_clf, max_num_features=20, height=0.4)\n```\n:::\n\n\n## LightGBM\n\n::: {#0ccfd20a .cell execution_count=12}\n``` {.python .cell-code}\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier\n\nlgbm_clf = LGBMClassifier(n_estimators=500, early_stopping_rounds=100, eval_metric='auc')\n\neval_set = [(X_tr, y_tr), (X_val, y_val)]\nlgbm_clf.fit(X_tr, y_tr, eval_set=eval_set)\n\nlgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\nprint(f'{lgbm_roc_score:.3f}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Info] Number of positive: 1694, number of negative: 40877\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010137 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13592\n[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 248\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039792 -> initscore=-3.183475\n[LightGBM] [Info] Start training from score -3.183475\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[33]\ttraining's binary_logloss: 0.117693\tvalid_1's binary_logloss: 0.137269\n[LightGBM] [Warning] Unknown parameter: eval_metric\n0.836\n```\n:::\n:::\n\n\n### 베이지안 최적화\n\n::: {#a629edb1 .cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn.model_selection import KFold\n\ndef objective_func(search_space):\n    lgbm_clf = LGBMClassifier(n_estimators=100, \n                            early_stopping_rounds=30,\n                            eval_metric='auc',\n                            num_leaves=int(search_space['num_leaves']),\n                            max_depth=int(search_space['max_depth']),\n                            min_child_samples=int(search_space['min_child_samples']),\n                            subsample=search_space['subsample'],\n                            learning_rate=search_space['learning_rate'])\n    roc_auc_list = []\n    kf = KFold(n_splits=3)\n    for tr_index, val_index in kf.split(X_train):\n        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n        X_val, y_val =  X_train.iloc[val_index], y_train.iloc[val_index]\n\n        lgbm_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1])\n        roc_auc_list.append(score)\n\n    return -1 * np.mean(roc_auc_list)\n```\n:::\n\n\n::: {#eed26a4e .cell execution_count=14}\n``` {.python .cell-code}\nfrom hyperopt import hp, fmin, tpe, Trials\n\nlgbm_search_space = {\n  'num_leaves': hp.quniform('num_leaves', 32, 64, 1),\n  'max_depth': hp.quniform('max_depth', 100, 160, 1),\n  'min_child_samples': hp.quniform('min_child_samples', 60, 100, 1),\n  'subsample': hp.uniform('subsample', 0.7, 1),\n  'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n}\n\ntrials = Trials()\nbest = fmin(fn=objective_func,\n            space=lgbm_search_space,\n            algo=tpe.suggest,\n            max_evals=50,\n            trials=trials)\nprint(best)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007286 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Total Bins 12947\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Start training from score -3.161962\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \rTraining until validation scores don't improve for 30 rounds\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.119239\tvalid_1's binary_logloss: 0.131547\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009173 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Total Bins 13055\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Start training from score -3.210495\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \rTraining until validation scores don't improve for 30 rounds\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.11513\tvalid_1's binary_logloss: 0.139265\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008461 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Total Bins 12996\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Start training from score -3.179828\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \rTraining until validation scores don't improve for 30 rounds\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.116828\tvalid_1's binary_logloss: 0.136952\n\r  0%|          | 0/50 [00:03<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:03<?, ?trial/s, best loss=?]\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008509 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Total Bins 12835\n\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.161962\n\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  2%|▏         | 1/50 [00:03<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.134361\tvalid_1's binary_logloss: 0.134539\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008662 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Total Bins 12988\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.210495\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  2%|▏         | 1/50 [00:04<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.129831\tvalid_1's binary_logloss: 0.142347\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008359 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Total Bins 12898\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.179828\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  2%|▏         | 1/50 [00:05<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.131634\tvalid_1's binary_logloss: 0.139054\n\r  2%|▏         | 1/50 [00:06<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:06<02:57,  3.63s/trial, best loss: -0.8341540202815528]\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008437 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Total Bins 12902\n\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.161962\n\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  4%|▍         | 2/50 [00:06<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[88]\ttraining's binary_logloss: 0.113936\tvalid_1's binary_logloss: 0.131766\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008792 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Total Bins 12988\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.210495\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  4%|▍         | 2/50 [00:07<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[71]\ttraining's binary_logloss: 0.11326\tvalid_1's binary_logloss: 0.139317\n\r  4%|▍         | 2/50 [00:08<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:08<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:09<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:09<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:09<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r  4%|▍         | 2/50 [00:09<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009763 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  4%|▍         | 2/50 [00:09<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Total Bins 12898\n\r  4%|▍         | 2/50 [00:09<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  4%|▍         | 2/50 [00:09<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:09<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:09<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r  4%|▍         | 2/50 [00:09<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.179828\n\r  4%|▍         | 2/50 [00:09<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  4%|▍         | 2/50 [00:09<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[77]\ttraining's binary_logloss: 0.113657\tvalid_1's binary_logloss: 0.136864\n\r  4%|▍         | 2/50 [00:10<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:10<02:30,  3.13s/trial, best loss: -0.8341540202815528]\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009179 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Total Bins 12835\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.161962\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \rEarly stopping, best iteration is:\n[39]\ttraining's binary_logloss: 0.12109\tvalid_1's binary_logloss: 0.131246\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:10<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008369 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Total Bins 12988\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.210495\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \rEarly stopping, best iteration is:\n[39]\ttraining's binary_logloss: 0.116743\tvalid_1's binary_logloss: 0.139211\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008111 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Total Bins 12898\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.179828\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  6%|▌         | 3/50 [00:11<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \rEarly stopping, best iteration is:\n[35]\ttraining's binary_logloss: 0.120149\tvalid_1's binary_logloss: 0.136702\n\r  6%|▌         | 3/50 [00:12<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:12<02:38,  3.38s/trial, best loss: -0.8341540202815528]\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008782 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Total Bins 12947\n\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.161962\n\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  8%|▊         | 4/50 [00:12<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.111064\tvalid_1's binary_logloss: 0.131895\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010004 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Total Bins 13055\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.210495\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  8%|▊         | 4/50 [00:13<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \rEarly stopping, best iteration is:\n[27]\ttraining's binary_logloss: 0.108994\tvalid_1's binary_logloss: 0.139854\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009049 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Total Bins 12996\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.179828\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.116146\tvalid_1's binary_logloss: 0.13756\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:14<02:16,  2.96s/trial, best loss: -0.8346097688713522]\r 10%|█         | 5/50 [00:14<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008251 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Total Bins 12947\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.161962\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.120067\tvalid_1's binary_logloss: 0.131511\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007845 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Total Bins 13055\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.210495\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 10%|█         | 5/50 [00:15<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \rEarly stopping, best iteration is:\n[31]\ttraining's binary_logloss: 0.112434\tvalid_1's binary_logloss: 0.139423\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009165 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Total Bins 12996\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.179828\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.115651\tvalid_1's binary_logloss: 0.136891\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:16<02:06,  2.80s/trial, best loss: -0.8346097688713522]\r 12%|█▏        | 6/50 [00:16<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:17<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:17<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:17<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 12%|█▏        | 6/50 [00:17<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010475 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 12%|█▏        | 6/50 [00:17<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Total Bins 12902\n\r 12%|█▏        | 6/50 [00:17<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 12%|█▏        | 6/50 [00:17<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:17<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:17<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 12%|█▏        | 6/50 [00:17<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.161962\n\r 12%|█▏        | 6/50 [00:17<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 12%|█▏        | 6/50 [00:17<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.128605\tvalid_1's binary_logloss: 0.133093\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008203 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Total Bins 12988\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.210495\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 12%|█▏        | 6/50 [00:18<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.124147\tvalid_1's binary_logloss: 0.141061\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007711 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Total Bins 12898\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.179828\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 12%|█▏        | 6/50 [00:19<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.125878\tvalid_1's binary_logloss: 0.13813\n\r 12%|█▏        | 6/50 [00:20<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:20<01:52,  2.55s/trial, best loss: -0.8346097688713522]\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008418 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Total Bins 12947\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.161962\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \rDid not meet early stopping. Best iteration is:\n[73]\ttraining's binary_logloss: 0.119266\tvalid_1's binary_logloss: 0.131216\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:20<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007783 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Total Bins 12998\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.210495\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \rEarly stopping, best iteration is:\n[63]\ttraining's binary_logloss: 0.116719\tvalid_1's binary_logloss: 0.139009\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:21<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:22<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 14%|█▍        | 7/50 [00:22<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008308 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 14%|█▍        | 7/50 [00:22<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Total Bins 12968\n\r 14%|█▍        | 7/50 [00:22<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 14%|█▍        | 7/50 [00:22<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:22<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:22<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 14%|█▍        | 7/50 [00:22<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.179828\n\r 14%|█▍        | 7/50 [00:22<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 14%|█▍        | 7/50 [00:22<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \rEarly stopping, best iteration is:\n[56]\ttraining's binary_logloss: 0.120087\tvalid_1's binary_logloss: 0.136444\n\r 14%|█▍        | 7/50 [00:22<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:22<01:58,  2.76s/trial, best loss: -0.8346097688713522]\r 16%|█▌        | 8/50 [00:22<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:22<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:22<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:22<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 16%|█▌        | 8/50 [00:22<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009077 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 16%|█▌        | 8/50 [00:22<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Total Bins 12835\n\r 16%|█▌        | 8/50 [00:22<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 16%|█▌        | 8/50 [00:22<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:22<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:22<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.161962\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \rEarly stopping, best iteration is:\n[57]\ttraining's binary_logloss: 0.120993\tvalid_1's binary_logloss: 0.131385\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007612 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Total Bins 12988\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.210495\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 16%|█▌        | 8/50 [00:23<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \rEarly stopping, best iteration is:\n[62]\ttraining's binary_logloss: 0.115325\tvalid_1's binary_logloss: 0.13881\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007536 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Total Bins 12898\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.179828\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \rEarly stopping, best iteration is:\n[50]\ttraining's binary_logloss: 0.120231\tvalid_1's binary_logloss: 0.136346\n\r 16%|█▌        | 8/50 [00:24<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:25<01:51,  2.65s/trial, best loss: -0.8354478683012264]\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008124 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Total Bins 12835\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.161962\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \rEarly stopping, best iteration is:\n[23]\ttraining's binary_logloss: 0.116031\tvalid_1's binary_logloss: 0.132494\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:25<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007737 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Total Bins 12988\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.210495\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \rEarly stopping, best iteration is:\n[22]\ttraining's binary_logloss: 0.112419\tvalid_1's binary_logloss: 0.140329\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007861 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Total Bins 12898\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.179828\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 18%|█▊        | 9/50 [00:26<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.115687\tvalid_1's binary_logloss: 0.137694\n\r 18%|█▊        | 9/50 [00:27<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:27<01:46,  2.59s/trial, best loss: -0.8354478683012264]\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007751 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12835\n\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 20%|██        | 10/50 [00:27<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[45]\ttraining's binary_logloss: 0.117033\tvalid_1's binary_logloss: 0.131893\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007925 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.11876\tvalid_1's binary_logloss: 0.139543\n\r 20%|██        | 10/50 [00:28<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008278 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[38]\ttraining's binary_logloss: 0.117423\tvalid_1's binary_logloss: 0.136738\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:29<01:40,  2.52s/trial, best loss: -0.8354478683012264]\r 22%|██▏       | 11/50 [00:29<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:29<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:29<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008637 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12902\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[78]\ttraining's binary_logloss: 0.115732\tvalid_1's binary_logloss: 0.13138\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007739 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 22%|██▏       | 11/50 [00:30<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[74]\ttraining's binary_logloss: 0.112624\tvalid_1's binary_logloss: 0.139339\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008653 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 22%|██▏       | 11/50 [00:31<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[74]\ttraining's binary_logloss: 0.114351\tvalid_1's binary_logloss: 0.136737\n\r 22%|██▏       | 11/50 [00:32<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:32<01:37,  2.49s/trial, best loss: -0.8354478683012264]\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010321 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12947\n\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 24%|██▍       | 12/50 [00:32<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[46]\ttraining's binary_logloss: 0.11276\tvalid_1's binary_logloss: 0.13165\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009865 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 13055\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 24%|██▍       | 12/50 [00:33<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 24%|██▍       | 12/50 [00:34<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[40]\ttraining's binary_logloss: 0.111011\tvalid_1's binary_logloss: 0.139831\n\r 24%|██▍       | 12/50 [00:34<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:34<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:34<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:34<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:34<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 24%|██▍       | 12/50 [00:34<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008053 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 24%|██▍       | 12/50 [00:34<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12996\n\r 24%|██▍       | 12/50 [00:34<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 24%|██▍       | 12/50 [00:34<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:35<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:35<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 24%|██▍       | 12/50 [00:35<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 24%|██▍       | 12/50 [00:35<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 24%|██▍       | 12/50 [00:35<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[43]\ttraining's binary_logloss: 0.111276\tvalid_1's binary_logloss: 0.137335\n\r 24%|██▍       | 12/50 [00:35<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:35<01:35,  2.51s/trial, best loss: -0.8354478683012264]\r 26%|██▌       | 13/50 [00:35<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:35<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:35<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:35<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 26%|██▌       | 13/50 [00:35<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008260 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 26%|██▌       | 13/50 [00:35<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12844\n\r 26%|██▌       | 13/50 [00:35<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 26%|██▌       | 13/50 [00:35<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:35<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:35<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 26%|██▌       | 13/50 [00:36<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 26%|██▌       | 13/50 [00:36<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 26%|██▌       | 13/50 [00:36<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.12681\tvalid_1's binary_logloss: 0.13222\n\r 26%|██▌       | 13/50 [00:36<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:36<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:36<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:36<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008850 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.122208\tvalid_1's binary_logloss: 0.139981\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:37<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:38<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 26%|██▌       | 13/50 [00:38<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009314 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 26%|██▌       | 13/50 [00:38<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 26%|██▌       | 13/50 [00:38<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 26%|██▌       | 13/50 [00:38<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:38<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:38<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 26%|██▌       | 13/50 [00:38<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 26%|██▌       | 13/50 [00:38<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 26%|██▌       | 13/50 [00:38<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.124131\tvalid_1's binary_logloss: 0.137316\n\r 26%|██▌       | 13/50 [00:39<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:39<01:41,  2.74s/trial, best loss: -0.8354478683012264]\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010560 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 28%|██▊       | 14/50 [00:39<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[19]\ttraining's binary_logloss: 0.119948\tvalid_1's binary_logloss: 0.132615\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009233 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[17]\ttraining's binary_logloss: 0.116812\tvalid_1's binary_logloss: 0.140251\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:40<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009001 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12958\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[19]\ttraining's binary_logloss: 0.117331\tvalid_1's binary_logloss: 0.137237\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:41<01:49,  3.04s/trial, best loss: -0.8354478683012264]\r 30%|███       | 15/50 [00:41<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:41<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:41<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010186 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[17]\ttraining's binary_logloss: 0.120445\tvalid_1's binary_logloss: 0.132691\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 30%|███       | 15/50 [00:42<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010950 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[16]\ttraining's binary_logloss: 0.117054\tvalid_1's binary_logloss: 0.139941\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008302 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12906\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 30%|███       | 15/50 [00:43<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.115401\tvalid_1's binary_logloss: 0.137413\n\r 30%|███       | 15/50 [00:44<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:44<01:38,  2.83s/trial, best loss: -0.8354478683012264]\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009370 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12835\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.11605\tvalid_1's binary_logloss: 0.133209\n\r 32%|███▏      | 16/50 [00:44<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008886 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[15]\ttraining's binary_logloss: 0.114923\tvalid_1's binary_logloss: 0.140959\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:45<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:46<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 32%|███▏      | 16/50 [00:46<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008924 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 32%|███▏      | 16/50 [00:46<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 32%|███▏      | 16/50 [00:46<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 32%|███▏      | 16/50 [00:46<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:46<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:46<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 32%|███▏      | 16/50 [00:46<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 32%|███▏      | 16/50 [00:46<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 32%|███▏      | 16/50 [00:46<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[14]\ttraining's binary_logloss: 0.117846\tvalid_1's binary_logloss: 0.13746\n\r 32%|███▏      | 16/50 [00:46<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:46<01:32,  2.72s/trial, best loss: -0.8354478683012264]\r 34%|███▍      | 17/50 [00:46<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:46<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:46<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:46<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 34%|███▍      | 17/50 [00:46<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009462 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 34%|███▍      | 17/50 [00:46<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12835\n\r 34%|███▍      | 17/50 [00:46<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 34%|███▍      | 17/50 [00:46<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:46<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:46<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[49]\ttraining's binary_logloss: 0.11538\tvalid_1's binary_logloss: 0.131723\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010342 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 34%|███▍      | 17/50 [00:47<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[31]\ttraining's binary_logloss: 0.117853\tvalid_1's binary_logloss: 0.139219\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007465 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.120676\tvalid_1's binary_logloss: 0.136931\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:48<01:26,  2.63s/trial, best loss: -0.8354478683012264]\r 36%|███▌      | 18/50 [00:48<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007036 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12835\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.119523\tvalid_1's binary_logloss: 0.131926\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008304 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 36%|███▌      | 18/50 [00:49<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[27]\ttraining's binary_logloss: 0.115902\tvalid_1's binary_logloss: 0.139583\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010535 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[24]\ttraining's binary_logloss: 0.11906\tvalid_1's binary_logloss: 0.137256\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:50<01:20,  2.53s/trial, best loss: -0.8354478683012264]\r 38%|███▊      | 19/50 [00:50<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014995 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12835\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.117616\tvalid_1's binary_logloss: 0.132237\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 38%|███▊      | 19/50 [00:51<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007897 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[23]\ttraining's binary_logloss: 0.115822\tvalid_1's binary_logloss: 0.140243\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020219 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 38%|███▊      | 19/50 [00:52<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.116668\tvalid_1's binary_logloss: 0.137218\n\r 38%|███▊      | 19/50 [00:53<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:53<01:13,  2.38s/trial, best loss: -0.8354478683012264]\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009889 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 13057\n\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 211\n\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 40%|████      | 20/50 [00:53<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[71]\ttraining's binary_logloss: 0.118472\tvalid_1's binary_logloss: 0.130909\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008639 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 13161\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 40%|████      | 20/50 [00:54<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[60]\ttraining's binary_logloss: 0.116535\tvalid_1's binary_logloss: 0.138826\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009875 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Total Bins 13044\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \rEarly stopping, best iteration is:\n[58]\ttraining's binary_logloss: 0.118597\tvalid_1's binary_logloss: 0.136638\n\r 40%|████      | 20/50 [00:55<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:56<01:12,  2.41s/trial, best loss: -0.8354478683012264]\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008395 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Total Bins 13057\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 211\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[96]\ttraining's binary_logloss: 0.116806\tvalid_1's binary_logloss: 0.131693\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:56<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008654 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Total Bins 13161\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[75]\ttraining's binary_logloss: 0.116396\tvalid_1's binary_logloss: 0.138474\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:57<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009684 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Total Bins 13044\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \rEarly stopping, best iteration is:\n[65]\ttraining's binary_logloss: 0.119662\tvalid_1's binary_logloss: 0.136275\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:58<01:11,  2.46s/trial, best loss: -0.8361261980967356]\r 44%|████▍     | 22/50 [00:58<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009310 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Total Bins 13057\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 211\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \rEarly stopping, best iteration is:\n[63]\ttraining's binary_logloss: 0.117775\tvalid_1's binary_logloss: 0.131201\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:59<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009518 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Total Bins 13161\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \rEarly stopping, best iteration is:\n[55]\ttraining's binary_logloss: 0.11576\tvalid_1's binary_logloss: 0.138797\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [01:00<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [01:01<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 44%|████▍     | 22/50 [01:01<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009738 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 44%|████▍     | 22/50 [01:01<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Total Bins 13044\n\r 44%|████▍     | 22/50 [01:01<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 44%|████▍     | 22/50 [01:01<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [01:01<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [01:01<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 44%|████▍     | 22/50 [01:01<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 44%|████▍     | 22/50 [01:01<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 44%|████▍     | 22/50 [01:01<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \rEarly stopping, best iteration is:\n[48]\ttraining's binary_logloss: 0.119114\tvalid_1's binary_logloss: 0.136592\n\r 44%|████▍     | 22/50 [01:01<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [01:01<01:12,  2.58s/trial, best loss: -0.8361261980967356]\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009989 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Total Bins 12993\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.121674\tvalid_1's binary_logloss: 0.131107\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [01:01<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009480 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Total Bins 13086\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.11765\tvalid_1's binary_logloss: 0.138596\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [01:02<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:03<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 46%|████▌     | 23/50 [01:03<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009169 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 46%|████▌     | 23/50 [01:03<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Total Bins 12996\n\r 46%|████▌     | 23/50 [01:03<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 46%|████▌     | 23/50 [01:03<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:03<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [01:03<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 46%|████▌     | 23/50 [01:03<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 46%|████▌     | 23/50 [01:03<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 46%|████▌     | 23/50 [01:03<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[95]\ttraining's binary_logloss: 0.119781\tvalid_1's binary_logloss: 0.136145\n\r 46%|████▌     | 23/50 [01:03<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [01:03<01:11,  2.65s/trial, best loss: -0.8361261980967356]\r 48%|████▊     | 24/50 [01:03<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:03<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:03<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008895 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Total Bins 12993\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.123945\tvalid_1's binary_logloss: 0.131312\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:04<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009337 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Total Bins 13086\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.119785\tvalid_1's binary_logloss: 0.138758\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:05<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:06<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 48%|████▊     | 24/50 [01:06<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009450 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 48%|████▊     | 24/50 [01:06<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Total Bins 12996\n\r 48%|████▊     | 24/50 [01:06<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 48%|████▊     | 24/50 [01:06<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:06<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [01:06<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 48%|████▊     | 24/50 [01:06<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 48%|████▊     | 24/50 [01:06<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 48%|████▊     | 24/50 [01:06<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.121345\tvalid_1's binary_logloss: 0.136253\n\r 48%|████▊     | 24/50 [01:06<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [01:06<01:04,  2.46s/trial, best loss: -0.8362934408440913]\r 50%|█████     | 25/50 [01:06<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:06<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:06<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:07<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 50%|█████     | 25/50 [01:07<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010296 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 50%|█████     | 25/50 [01:07<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12993\n\r 50%|█████     | 25/50 [01:07<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 50%|█████     | 25/50 [01:07<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:07<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:07<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 50%|█████     | 25/50 [01:07<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 50%|█████     | 25/50 [01:07<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 50%|█████     | 25/50 [01:07<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[99]\ttraining's binary_logloss: 0.115076\tvalid_1's binary_logloss: 0.131544\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011525 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13086\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 50%|█████     | 25/50 [01:08<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[99]\ttraining's binary_logloss: 0.110704\tvalid_1's binary_logloss: 0.139171\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009677 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12996\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 50%|█████     | 25/50 [01:09<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[74]\ttraining's binary_logloss: 0.117386\tvalid_1's binary_logloss: 0.137077\n\r 50%|█████     | 25/50 [01:10<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:10<01:06,  2.65s/trial, best loss: -0.8365225708987197]\r 52%|█████▏    | 26/50 [01:10<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:10<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:10<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009136 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12993\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[40]\ttraining's binary_logloss: 0.118745\tvalid_1's binary_logloss: 0.13174\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009702 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13086\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 52%|█████▏    | 26/50 [01:11<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[37]\ttraining's binary_logloss: 0.115548\tvalid_1's binary_logloss: 0.138995\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010037 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12996\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 52%|█████▏    | 26/50 [01:12<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[32]\ttraining's binary_logloss: 0.119523\tvalid_1's binary_logloss: 0.136814\n\r 52%|█████▏    | 26/50 [01:13<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:13<01:13,  3.05s/trial, best loss: -0.8365225708987197]\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009837 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12993\n\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 54%|█████▍    | 27/50 [01:13<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[97]\ttraining's binary_logloss: 0.119337\tvalid_1's binary_logloss: 0.131417\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010306 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13086\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 54%|█████▍    | 27/50 [01:14<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.114456\tvalid_1's binary_logloss: 0.139157\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008807 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12996\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 54%|█████▍    | 27/50 [01:15<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[97]\ttraining's binary_logloss: 0.11659\tvalid_1's binary_logloss: 0.136713\n\r 54%|█████▍    | 27/50 [01:16<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:16<01:07,  2.92s/trial, best loss: -0.8365225708987197]\r 56%|█████▌    | 28/50 [01:16<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:16<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:16<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:16<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 56%|█████▌    | 28/50 [01:16<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008596 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 56%|█████▌    | 28/50 [01:16<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 56%|█████▌    | 28/50 [01:16<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 56%|█████▌    | 28/50 [01:16<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[22]\ttraining's binary_logloss: 0.121698\tvalid_1's binary_logloss: 0.132138\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008173 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12998\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 56%|█████▌    | 28/50 [01:17<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.11611\tvalid_1's binary_logloss: 0.139307\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008090 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12958\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[17]\ttraining's binary_logloss: 0.122317\tvalid_1's binary_logloss: 0.136889\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:18<01:06,  3.03s/trial, best loss: -0.8365225708987197]\r 58%|█████▊    | 29/50 [01:18<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:18<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:18<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:18<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 58%|█████▊    | 29/50 [01:18<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009576 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 58%|█████▊    | 29/50 [01:18<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.117385\tvalid_1's binary_logloss: 0.131388\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 58%|█████▊    | 29/50 [01:19<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008772 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 58%|█████▊    | 29/50 [01:20<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12998\n\r 58%|█████▊    | 29/50 [01:20<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r 58%|█████▊    | 29/50 [01:20<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:20<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:20<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 58%|█████▊    | 29/50 [01:20<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 58%|█████▊    | 29/50 [01:20<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 58%|█████▊    | 29/50 [01:20<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[98]\ttraining's binary_logloss: 0.113488\tvalid_1's binary_logloss: 0.139105\n\r 58%|█████▊    | 29/50 [01:20<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:20<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:20<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:20<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:21<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 58%|█████▊    | 29/50 [01:21<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008569 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 58%|█████▊    | 29/50 [01:21<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12958\n\r 58%|█████▊    | 29/50 [01:21<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 58%|█████▊    | 29/50 [01:21<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:21<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:21<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 58%|█████▊    | 29/50 [01:21<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 58%|█████▊    | 29/50 [01:21<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 58%|█████▊    | 29/50 [01:21<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.114829\tvalid_1's binary_logloss: 0.136714\n\r 58%|█████▊    | 29/50 [01:21<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:21<00:57,  2.74s/trial, best loss: -0.8365225708987197]\r 60%|██████    | 30/50 [01:21<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:21<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:21<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008604 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12993\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.136137\tvalid_1's binary_logloss: 0.135864\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007794 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13059\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 60%|██████    | 30/50 [01:22<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.131758\tvalid_1's binary_logloss: 0.143909\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008173 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12996\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 60%|██████    | 30/50 [01:23<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.133319\tvalid_1's binary_logloss: 0.140365\n\r 60%|██████    | 30/50 [01:24<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:24<00:56,  2.84s/trial, best loss: -0.8365225708987197]\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007810 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12902\n\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 62%|██████▏   | 31/50 [01:24<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[52]\ttraining's binary_logloss: 0.120557\tvalid_1's binary_logloss: 0.131463\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008104 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[42]\ttraining's binary_logloss: 0.119216\tvalid_1's binary_logloss: 0.138844\n\r 62%|██████▏   | 31/50 [01:25<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008458 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[43]\ttraining's binary_logloss: 0.120672\tvalid_1's binary_logloss: 0.136077\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:26<00:52,  2.78s/trial, best loss: -0.8365225708987197]\r 64%|██████▍   | 32/50 [01:26<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:26<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:26<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008051 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.116782\tvalid_1's binary_logloss: 0.132291\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008398 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12998\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 64%|██████▍   | 32/50 [01:27<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.112525\tvalid_1's binary_logloss: 0.139834\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008790 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12958\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 64%|██████▍   | 32/50 [01:28<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[26]\ttraining's binary_logloss: 0.116376\tvalid_1's binary_logloss: 0.13759\n\r 64%|██████▍   | 32/50 [01:29<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:29<00:47,  2.65s/trial, best loss: -0.8365225708987197]\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007899 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13047\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 210\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.121235\tvalid_1's binary_logloss: 0.131795\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:29<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:30<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:30<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:30<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 66%|██████▌   | 33/50 [01:30<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010711 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 66%|██████▌   | 33/50 [01:30<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13161\n\r 66%|██████▌   | 33/50 [01:30<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208\n\r 66%|██████▌   | 33/50 [01:30<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:30<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:30<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 66%|██████▌   | 33/50 [01:30<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 66%|██████▌   | 33/50 [01:30<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 66%|██████▌   | 33/50 [01:30<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.117131\tvalid_1's binary_logloss: 0.139355\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009935 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13044\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 66%|██████▌   | 33/50 [01:31<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.11886\tvalid_1's binary_logloss: 0.136817\n\r 66%|██████▌   | 33/50 [01:32<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:32<00:43,  2.55s/trial, best loss: -0.8365225708987197]\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009479 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13047\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 210\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[87]\ttraining's binary_logloss: 0.119217\tvalid_1's binary_logloss: 0.131162\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009390 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13130\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 68%|██████▊   | 34/50 [01:32<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[95]\ttraining's binary_logloss: 0.11377\tvalid_1's binary_logloss: 0.138774\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008385 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13000\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 68%|██████▊   | 34/50 [01:33<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[71]\ttraining's binary_logloss: 0.119355\tvalid_1's binary_logloss: 0.136516\n\r 68%|██████▊   | 34/50 [01:34<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:34<00:44,  2.76s/trial, best loss: -0.8365225708987197]\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008260 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12993\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.117227\tvalid_1's binary_logloss: 0.132479\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:34<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007966 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13059\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[22]\ttraining's binary_logloss: 0.110745\tvalid_1's binary_logloss: 0.140016\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007917 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12996\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 70%|███████   | 35/50 [01:35<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.116325\tvalid_1's binary_logloss: 0.136868\n\r 70%|███████   | 35/50 [01:36<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:36<00:37,  2.51s/trial, best loss: -0.8365225708987197]\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007671 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12902\n\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 72%|███████▏  | 36/50 [01:36<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.133676\tvalid_1's binary_logloss: 0.135443\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007838 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 72%|███████▏  | 36/50 [01:37<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.129111\tvalid_1's binary_logloss: 0.143846\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008862 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 72%|███████▏  | 36/50 [01:38<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.131021\tvalid_1's binary_logloss: 0.140157\n\r 72%|███████▏  | 36/50 [01:39<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:39<00:32,  2.33s/trial, best loss: -0.8365225708987197]\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007790 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 74%|███████▍  | 37/50 [01:39<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[65]\ttraining's binary_logloss: 0.118118\tvalid_1's binary_logloss: 0.131584\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007983 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 74%|███████▍  | 37/50 [01:40<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[65]\ttraining's binary_logloss: 0.113718\tvalid_1's binary_logloss: 0.139017\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008166 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12906\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 74%|███████▍  | 37/50 [01:41<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[59]\ttraining's binary_logloss: 0.116916\tvalid_1's binary_logloss: 0.136382\n\r 74%|███████▍  | 37/50 [01:42<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:42<00:34,  2.62s/trial, best loss: -0.8365225708987197]\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008362 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 76%|███████▌  | 38/50 [01:42<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[43]\ttraining's binary_logloss: 0.120211\tvalid_1's binary_logloss: 0.131444\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011524 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12998\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[47]\ttraining's binary_logloss: 0.114602\tvalid_1's binary_logloss: 0.139106\n\r 76%|███████▌  | 38/50 [01:43<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008487 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12968\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[40]\ttraining's binary_logloss: 0.118651\tvalid_1's binary_logloss: 0.136544\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:44<00:32,  2.68s/trial, best loss: -0.8365225708987197]\r 78%|███████▊  | 39/50 [01:44<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:44<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:44<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007906 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12947\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[40]\ttraining's binary_logloss: 0.119116\tvalid_1's binary_logloss: 0.131438\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010484 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13059\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 78%|███████▊  | 39/50 [01:45<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[37]\ttraining's binary_logloss: 0.116085\tvalid_1's binary_logloss: 0.138771\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008602 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12996\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[34]\ttraining's binary_logloss: 0.11889\tvalid_1's binary_logloss: 0.136703\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:46<00:28,  2.62s/trial, best loss: -0.8365225708987197]\r 80%|████████  | 40/50 [01:46<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009081 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12947\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.119904\tvalid_1's binary_logloss: 0.131539\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:47<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011067 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13055\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.115561\tvalid_1's binary_logloss: 0.139612\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007772 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12996\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 80%|████████  | 40/50 [01:48<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[26]\ttraining's binary_logloss: 0.118624\tvalid_1's binary_logloss: 0.136879\n\r 80%|████████  | 40/50 [01:49<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:49<00:24,  2.49s/trial, best loss: -0.8365225708987197]\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012833 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[39]\ttraining's binary_logloss: 0.121601\tvalid_1's binary_logloss: 0.131732\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:49<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012323 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12998\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[34]\ttraining's binary_logloss: 0.118977\tvalid_1's binary_logloss: 0.13905\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008469 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12958\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:50<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 82%|████████▏ | 41/50 [01:51<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 82%|████████▏ | 41/50 [01:51<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 82%|████████▏ | 41/50 [01:51<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[34]\ttraining's binary_logloss: 0.120814\tvalid_1's binary_logloss: 0.136438\n\r 82%|████████▏ | 41/50 [01:51<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:51<00:21,  2.40s/trial, best loss: -0.8365225708987197]\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008567 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12947\n\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 84%|████████▍ | 42/50 [01:51<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.119106\tvalid_1's binary_logloss: 0.131122\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011181 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12998\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 84%|████████▍ | 42/50 [01:52<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[90]\ttraining's binary_logloss: 0.116567\tvalid_1's binary_logloss: 0.138873\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007625 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12968\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 84%|████████▍ | 42/50 [01:53<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[85]\ttraining's binary_logloss: 0.118801\tvalid_1's binary_logloss: 0.136111\n\r 84%|████████▍ | 42/50 [01:54<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:54<00:18,  2.35s/trial, best loss: -0.8365225708987197]\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008375 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13047\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 210\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 86%|████████▌ | 43/50 [01:54<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.12624\tvalid_1's binary_logloss: 0.132688\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008360 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13130\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 86%|████████▌ | 43/50 [01:55<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.121959\tvalid_1's binary_logloss: 0.140097\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012750 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13000\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 86%|████████▌ | 43/50 [01:56<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.123583\tvalid_1's binary_logloss: 0.137169\n\r 86%|████████▌ | 43/50 [01:57<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:57<00:17,  2.52s/trial, best loss: -0.8365225708987197]\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009549 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12902\n\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 88%|████████▊ | 44/50 [01:57<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[23]\ttraining's binary_logloss: 0.114805\tvalid_1's binary_logloss: 0.132779\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007723 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.11472\tvalid_1's binary_logloss: 0.140404\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:58<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012523 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[19]\ttraining's binary_logloss: 0.115511\tvalid_1's binary_logloss: 0.137588\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:59<00:16,  2.70s/trial, best loss: -0.8365225708987197]\r 90%|█████████ | 45/50 [01:59<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:59<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:59<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:59<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 90%|█████████ | 45/50 [01:59<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008368 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 90%|█████████ | 45/50 [01:59<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12835\n\r 90%|█████████ | 45/50 [01:59<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 90%|█████████ | 45/50 [01:59<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:59<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:59<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 90%|█████████ | 45/50 [01:59<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 90%|█████████ | 45/50 [01:59<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 90%|█████████ | 45/50 [02:00<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[70]\ttraining's binary_logloss: 0.115612\tvalid_1's binary_logloss: 0.131625\n\r 90%|█████████ | 45/50 [02:00<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [02:00<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [02:00<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [02:00<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [02:00<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 90%|█████████ | 45/50 [02:00<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007622 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 90%|█████████ | 45/50 [02:00<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 90%|█████████ | 45/50 [02:00<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 90%|█████████ | 45/50 [02:00<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[57]\ttraining's binary_logloss: 0.114417\tvalid_1's binary_logloss: 0.139373\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007511 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 90%|█████████ | 45/50 [02:01<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [02:02<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [02:02<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 90%|█████████ | 45/50 [02:02<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 90%|█████████ | 45/50 [02:02<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 90%|█████████ | 45/50 [02:02<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[62]\ttraining's binary_logloss: 0.114805\tvalid_1's binary_logloss: 0.136936\n\r 90%|█████████ | 45/50 [02:02<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [02:02<00:12,  2.56s/trial, best loss: -0.8365225708987197]\r 92%|█████████▏| 46/50 [02:02<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008690 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12943\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[14]\ttraining's binary_logloss: 0.123339\tvalid_1's binary_logloss: 0.132372\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009379 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 92%|█████████▏| 46/50 [02:03<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[13]\ttraining's binary_logloss: 0.119633\tvalid_1's binary_logloss: 0.141193\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008788 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12906\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[13]\ttraining's binary_logloss: 0.12138\tvalid_1's binary_logloss: 0.137428\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [02:04<00:10,  2.75s/trial, best loss: -0.8365225708987197]\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008990 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12835\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[52]\ttraining's binary_logloss: 0.119292\tvalid_1's binary_logloss: 0.131268\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:04<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007926 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[51]\ttraining's binary_logloss: 0.11486\tvalid_1's binary_logloss: 0.139012\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007646 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [02:05<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 94%|█████████▍| 47/50 [02:06<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 94%|█████████▍| 47/50 [02:06<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 94%|█████████▍| 47/50 [02:06<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[45]\ttraining's binary_logloss: 0.118593\tvalid_1's binary_logloss: 0.13685\n\r 94%|█████████▍| 47/50 [02:06<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [02:06<00:07,  2.52s/trial, best loss: -0.8365225708987197]\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009040 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12902\n\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 96%|█████████▌| 48/50 [02:06<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.123923\tvalid_1's binary_logloss: 0.132366\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009230 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12988\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 96%|█████████▌| 48/50 [02:07<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.119581\tvalid_1's binary_logloss: 0.140569\n\r 96%|█████████▌| 48/50 [02:08<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:08<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:08<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:08<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:09<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 96%|█████████▌| 48/50 [02:09<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010048 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 96%|█████████▌| 48/50 [02:09<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12898\n\r 96%|█████████▌| 48/50 [02:09<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 96%|█████████▌| 48/50 [02:09<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:09<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:09<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 96%|█████████▌| 48/50 [02:09<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 96%|█████████▌| 48/50 [02:09<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 96%|█████████▌| 48/50 [02:09<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.121237\tvalid_1's binary_logloss: 0.137601\n\r 96%|█████████▌| 48/50 [02:10<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:10<00:04,  2.25s/trial, best loss: -0.8365225708987197]\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1647, number of negative: 38897\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010404 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12947\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -> initscore=-3.161962\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.161962\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[26]\ttraining's binary_logloss: 0.118459\tvalid_1's binary_logloss: 0.131829\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:10<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1572, number of negative: 38972\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010339 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 13059\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -> initscore=-3.210495\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.210495\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.11189\tvalid_1's binary_logloss: 0.139652\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1619, number of negative: 38925\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010263 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Total Bins 12996\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -> initscore=-3.179828\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.179828\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 98%|█████████▊| 49/50 [02:11<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \rEarly stopping, best iteration is:\n[26]\ttraining's binary_logloss: 0.115607\tvalid_1's binary_logloss: 0.137612\n\r 98%|█████████▊| 49/50 [02:12<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:12<00:02,  2.66s/trial, best loss: -0.8365225708987197]\r100%|██████████| 50/50 [02:12<00:00,  2.55s/trial, best loss: -0.8365225708987197]\r100%|██████████| 50/50 [02:12<00:00,  2.65s/trial, best loss: -0.8365225708987197]\n{'learning_rate': 0.028291797782733982, 'max_depth': 154.0, 'min_child_samples': 64.0, 'num_leaves': 32.0, 'subsample': 0.9145203867432408}\n```\n:::\n:::\n\n\n### 재학습\n\n::: {#305e505b .cell execution_count=15}\n``` {.python .cell-code}\nlgbm_clf = LGBMClassifier(n_estimators=500, \n                          num_leaves=int(best['num_leaves']),\n                          max_depth=int(best['max_depth']),\n                          min_child_samples=int(best['min_child_samples']),\n                          subsample=round(best['subsample'], 5),\n                          learning_rate=round(best['learning_rate'], 5),\n                          early_stopping_rounds=100, \n                          eval_metric='auc')\n\neval_set = [(X_tr, y_tr), (X_val, y_val)]\nlgbm_clf.fit(X_tr, y_tr, eval_set=eval_set)\n\nlgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\nprint(f'{lgbm_roc_score:.3f}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Info] Number of positive: 1694, number of negative: 40877\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012601 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13334\n[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 209\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039792 -> initscore=-3.183475\n[LightGBM] [Info] Start training from score -3.183475\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[131]\ttraining's binary_logloss: 0.118645\tvalid_1's binary_logloss: 0.137022\n[LightGBM] [Warning] Unknown parameter: eval_metric\n0.839\n```\n:::\n:::\n\n\n## 제출\n\n::: {#4640afe3 .cell execution_count=16}\n``` {.python .cell-code}\ntarget = lgbm_clf.predict(test_df)\n\nsubmit = pd.read_csv('_data/santander/sample_submission.csv', encoding='latin-1')\nsubmit['TARGET'] = target\nsubmit.to_csv('_data/santander/submission.csv', encoding='latin-1', index=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[LightGBM] [Warning] Unknown parameter: eval_metric\n```\n:::\n:::\n\n\n",
    "supporting": [
      "03_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}