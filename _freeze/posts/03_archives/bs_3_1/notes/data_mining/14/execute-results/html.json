{
  "hash": "2b0e7db24d99a10847137de347039364",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"preprocessing\"\ndate: 2025-05-22\ncategories: [\"data mining\"]\n---\n\n\n![](/img/human-thumb.jpg){.post-thumbnail}\n\n## Data Load\n\n::: {#96cbebf4 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nfrom matplotlib import font_manager, rc\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nID_VAR = \"id\"\nWEIGHT_VAR = \"wt2\"\nOUTCOME_VAR = \"status_category\"\nRANDOM_STATE = 54321\ntarget_pred_var = [ID_VAR, \"wt1\", \"q33a01\", \"q33a02\", \"q33a03\", \"q33a04\", \"q33a05\", \"q33a06\",\n                    \"q48a07\", \"q48a08\", \"q48a09\", \"q48a10\",\n                    \"q49a01\", \"q49a02\", \"q49a03\", \"q49a04\",\n                    \"q33a07\", \"q33a08\", \"q33a09\",\n                    \"q49a15\", \"q49a16\", \"q49a17\",\n                    \"q49a09\", \"q49a10\", \"q49a11\",\n                    \"q48b1\", \"q48b2\", \"q48b3\",\n                    \"q12a01\", \"q12a02\", \"q12a03\",\n                    \"q48a04\", \"q48a05\", \"q48a06\",\n                    \"q49a05\", \"q49a06\", \"q49a08\"]\ncfa_model = \"\"\"\n  # 1. 부모애착\n  parent_attachment =~ q33a01 + q33a02 + q33a03 + q33a04 + q33a05 + q33a06\n  # 2. 일탈적 자아 낙인\n  deviant_esteem =~ q48a07 + q48a08 + q48a09 + q48a10\n  # 3. 부모에 의한 스트레스\n  parent_stress =~ q49a01 + q49a02 + q49a03 + q49a04\n  # 4. 부모감독\n  parent_monitoring =~ q33a07 + q33a08 + q33a09\n  # 5. 물질적 요인으로 인한 스트레스\n  desire_stress =~ q49a15 + q49a16 + q49a17\n  # 6. 친구로 인한 스트레스\n  friend_stress =~ q49a09 + q49a10 + q49a11\n  # 7. 자기신뢰감\n  self_confidence =~ q48b1 + q48b2 + q48b3\n  # 8. 상급학교 의존도\n  higher_school_dependence =~ q12a01 + q12a02 + q12a03\n  # 9. 부정적 자아존중감\n  neg_esteem =~ q48a04 + q48a05 + q48a06\n  # 10. 학업으로 인한 스트레스\n  academic_stress =~ q49a05 + q49a06 + q49a08\n\"\"\"\ndf1_origin = pd.read_csv('_data/student_1.csv')\ndf2_origin = pd.read_csv('_data/student_2.csv')\ndf3_origin = pd.read_csv('_data/student_3.csv')\ndf4_origin = pd.read_csv('_data/student_4.csv')\ndf5_origin = pd.read_csv('_data/student_5.csv')\ndf6_origin = pd.read_csv('_data/student_6.csv')\ndf_origin = [df1_origin, df2_origin, df3_origin, df4_origin, df5_origin]\n```\n:::\n\n\n## CFA (Confirmatory Factor Analysis)\n\n::: {#e67822ae .cell execution_count=2}\n``` {.python .cell-code}\nimport rpy2.robjects as ro\nfrom rpy2.robjects.packages import importr\nfrom rpy2.robjects import pandas2ri\nfrom rpy2.robjects.conversion import localconverter\nfrom rpy2.robjects.packages import importr\n\npandas2ri.activate()\nlavaan = importr('lavaan')\nbase_r = importr('base')\n\nmerged_df_pd = pd.DataFrame()\nfor i, df in enumerate(df_origin):\n    wave = i + 1\n    df_analysis = df[target_pred_var].copy()\n    df_clean = df_analysis.dropna()\n    with localconverter(ro.default_converter + pandas2ri.converter):\n        df_clean_r = ro.conversion.py2rpy(df_clean)\n    cfa_fit_r = lavaan.cfa(\n        model=cfa_model,\n        data=df_clean_r,\n        sampling_weights=\"wt1\",\n        estimator=\"MLR\",\n        warn=False,\n        verbose=False\n    )\n    print(f\"\\n--- Wave {wave} CFA 적합도 지수 ---\")\n    desired_fit_measures = ro.StrVector([\n        'cfi.scaled', 'tli.scaled',\n        'rmsea.scaled', 'rmsea.ci.lower.scaled', 'rmsea.ci.upper.scaled',\n        'srmr_bentler'\n    ])\n    fit_measures_values_r = lavaan.fitMeasures(cfa_fit_r, fit_measures=desired_fit_measures)\n    fit_values_py = [val if val is not ro.NA_Real else float('nan') for val in list(fit_measures_values_r)]\n    fit_measures_s = pd.Series(fit_values_py, index=list(desired_fit_measures))\n    print(fit_measures_s.to_string())\n    print(\"------------------------------------\")\n    factor_scores_r = lavaan.lavPredict(cfa_fit_r, type=\"lv\")\n    factor_scores_pd = pd.DataFrame(factor_scores_r, columns=[\"parent_attachment\", \"deviant_esteem\", \"parent_stress\", \"parent_monitoring\",\n                                                             \"desire_stress\", \"friend_stress\", \"self_confidence\",\n                                                             \"higher_school_dependence\", \"neg_esteem\", \"academic_stress\"])\n    ids_for_scores = df_clean[ID_VAR].reset_index(drop=True)\n    factor_scores_pd[ID_VAR] = ids_for_scores\n    new_colnames = {col: f\"{col}_w{wave}\" for col in factor_scores_pd.columns if col != ID_VAR}\n    factor_scores_pd = factor_scores_pd.rename(columns=new_colnames)\n    if wave == 1:\n        merged_df_pd = factor_scores_pd\n    else:\n        merged_df_pd = pd.merge(merged_df_pd, factor_scores_pd, on=ID_VAR, how='outer')\n\ndef classify_status(q11_value):\n    if q11_value in [1, 7, 8, 9, 71, 81, 91, 10, 101, 11, 111]:\n        return \"stable\"\n    elif q11_value in [2, 3, 4, 5, 6, 12, 13, 14]:\n        return \"explorative\"\n    else:\n        return None\n\npandas2ri.deactivate()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n--- Wave 1 CFA 적합도 지수 ---\ncfi.scaled               0.927641\ntli.scaled               0.916400\nrmsea.scaled             0.041374\nrmsea.ci.lower.scaled    0.040245\nrmsea.ci.upper.scaled    0.042511\nsrmr_bentler             0.042360\n------------------------------------\n\n--- Wave 2 CFA 적합도 지수 ---\ncfi.scaled               0.937524\ntli.scaled               0.927819\nrmsea.scaled             0.039718\nrmsea.ci.lower.scaled    0.038552\nrmsea.ci.upper.scaled    0.040894\nsrmr_bentler             0.037124\n------------------------------------\n\n--- Wave 3 CFA 적합도 지수 ---\ncfi.scaled               0.930504\ntli.scaled               0.919708\nrmsea.scaled             0.039424\nrmsea.ci.lower.scaled    0.038270\nrmsea.ci.upper.scaled    0.040586\nsrmr_bentler             0.043117\n------------------------------------\n\n--- Wave 4 CFA 적합도 지수 ---\ncfi.scaled               0.925239\ntli.scaled               0.913625\nrmsea.scaled             0.045518\nrmsea.ci.lower.scaled    0.044364\nrmsea.ci.upper.scaled    0.046681\nsrmr_bentler             0.046338\n------------------------------------\n\n--- Wave 5 CFA 적합도 지수 ---\ncfi.scaled               0.934303\ntli.scaled               0.924098\nrmsea.scaled             0.042005\nrmsea.ci.lower.scaled    0.040850\nrmsea.ci.upper.scaled    0.043169\nsrmr_bentler             0.045346\n------------------------------------\n```\n:::\n:::\n\n\n### 상관행렬\n\n::: {#f98a4091 .cell execution_count=3}\n``` {.python .cell-code}\nplt.rcParams['font.family'] = 'Noto Sans KR'\n\nplt.figure(figsize=(25, 22))\ncorr_matrix = merged_df_pd.drop(columns=[ID_VAR]).corr()\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(\n    corr_matrix,\n    annot=False,\n    vmax=1.0, \n    vmin=-1.0,\n    center=0,\n    linewidths=.5,\n    cmap=cmap,\n    cbar_kws={\"shrink\": .5, \"label\": \"Correlation Coefficient\"}\n)\n\nplt.title('Correlation Matrix', fontsize=16, pad=20)\nplt.tight_layout()\nplt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\nplt.show()\n\ncorr_pairs = corr_matrix.unstack().reset_index()\ncorr_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n\ncorr_pairs = corr_pairs[corr_pairs['Variable 1'] != corr_pairs['Variable 2']]\ncorr_pairs['Pair'] = corr_pairs.apply(lambda x: tuple(sorted([x['Variable 1'], x['Variable 2']])), axis=1)\ncorr_pairs = corr_pairs.drop_duplicates('Pair')\n\ncorr_pairs = corr_pairs.sort_values(by='Correlation', key=abs, ascending=False)\ntop_corr = corr_pairs[['Variable 1', 'Variable 2', 'Correlation']]\n\nprint(\"Highest Absolute Correlations:\")\nprint(top_corr.head(40))\n```\n\n::: {.cell-output .cell-output-display}\n![](14_files/figure-html/cell-4-output-1.png){width=2173 height=2102}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nHighest Absolute Correlations:\n                Variable 1            Variable 2  Correlation\n619       parent_stress_w2    academic_stress_w2     0.757157\n109       parent_stress_w1    academic_stress_w1     0.737240\n2043  parent_attachment_w5  parent_monitoring_w5     0.713755\n1533  parent_attachment_w4  parent_monitoring_w4     0.692874\n513   parent_attachment_w2  parent_monitoring_w2     0.689347\n2149      parent_stress_w5    academic_stress_w5     0.663941\n3     parent_attachment_w1  parent_monitoring_w1     0.658326\n1023  parent_attachment_w3  parent_monitoring_w3     0.655997\n1129      parent_stress_w3    academic_stress_w3     0.608676\n1540  parent_attachment_w4  parent_attachment_w5     0.604272\n1030  parent_attachment_w3  parent_attachment_w4     0.601522\n10    parent_attachment_w1  parent_attachment_w2     0.582573\n520   parent_attachment_w2  parent_attachment_w3     0.579379\n719       desire_stress_w2    academic_stress_w2     0.574989\n1639      parent_stress_w4    academic_stress_w4     0.566123\n614       parent_stress_w2      desire_stress_w2     0.559798\n409          neg_esteem_w1    academic_stress_w1     0.559204\n209       desire_stress_w1    academic_stress_w1     0.556277\n1040  parent_attachment_w3  parent_attachment_w5     0.539659\n58       deviant_esteem_w1         neg_esteem_w1     0.534314\n104       parent_stress_w1      desire_stress_w1     0.530970\n715       desire_stress_w2      friend_stress_w2     0.530456\n2144      parent_stress_w5      desire_stress_w5     0.519393\n1693  parent_monitoring_w4  parent_monitoring_w5     0.518281\n1132      parent_stress_w3      parent_stress_w4     0.513876\n20    parent_attachment_w1  parent_attachment_w3     0.512048\n1124      parent_stress_w3      desire_stress_w3     0.507338\n1489    academic_stress_w3    academic_stress_w4     0.507213\n163   parent_monitoring_w1  parent_monitoring_w2     0.507147\n1234      desire_stress_w3      desire_stress_w4     0.505383\n530   parent_attachment_w2  parent_attachment_w4     0.504675\n2     parent_attachment_w1      parent_stress_w1    -0.501466\n673   parent_monitoring_w2  parent_monitoring_w3     0.497952\n540   parent_attachment_w2  parent_attachment_w5     0.492200\n1183  parent_monitoring_w3  parent_monitoring_w4     0.489749\n1642      parent_stress_w4      parent_stress_w5     0.489084\n1744      desire_stress_w4      desire_stress_w5     0.486436\n112       parent_stress_w1      parent_stress_w2     0.481296\n1588     deviant_esteem_w4         neg_esteem_w4     0.480133\n1846    self_confidence_w4    self_confidence_w5     0.478809\n```\n:::\n:::\n\n\n::: {#cfd40e56 .cell execution_count=4}\n``` {.python .cell-code}\nextra_df_pd = df6_origin[[ID_VAR, \"q11\", WEIGHT_VAR, \"sex\", \"yy\", \"area\"]].copy()\nextra_df_pd['status_category'] = extra_df_pd['q11'].apply(classify_status)\nmerged_df = pd.merge(merged_df_pd, extra_df_pd, on=ID_VAR, how='left').dropna()\n```\n:::\n\n\n## 인구통계학적 분포 분석\n\n### 분포 테이블\n\n::: {#0a80c757 .cell execution_count=5}\n``` {.python .cell-code}\nsex_dist_py = merged_df['sex'].value_counts().rename_axis('sex').reset_index(name='n')\nsex_dist_py['percentage'] = (sex_dist_py['n'] / sex_dist_py['n'].sum()) * 100\n\nbirth_year_dist_py = merged_df['yy'].value_counts().rename_axis('yy').reset_index(name='n')\nbirth_year_dist_py['percentage'] = (birth_year_dist_py['n'] / birth_year_dist_py['n'].sum()) * 100\nbirth_year_dist_py = birth_year_dist_py.sort_values(by='yy').reset_index(drop=True)\n\narea_dist_py = merged_df['area'].value_counts().rename_axis('area').reset_index(name='n')\narea_dist_py['percentage'] = (area_dist_py['n'] / area_dist_py['n'].sum()) * 100\narea_dist_py = area_dist_py.sort_values(by='area').reset_index(drop=True) # 지역 순으로 정렬\n\nstatus_dist_py = merged_df['status_category'].value_counts(dropna=False).rename_axis('status_category').reset_index(name='n')\nstatus_dist_py['percentage'] = (status_dist_py['n'] / status_dist_py['n'].sum()) * 100\n\nprint(sex_dist_py)\nprint(birth_year_dist_py)\nprint(status_dist_py)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   sex     n  percentage\n0  2.0  1280   52.523595\n1  1.0  1157   47.476405\n     yy     n  percentage\n0  88.0     2    0.082068\n1  89.0  1884   77.308166\n2  90.0   551   22.609766\n  status_category     n  percentage\n0          stable  1369   56.175626\n1     explorative  1068   43.824374\n```\n:::\n:::\n\n\n### 분포 시각화\n\n::: {#70f448da .cell execution_count=6}\n``` {.python .cell-code}\narea_mapping_py = {\n    100: \"서울\", 110: \"서울\", 120: \"서울\", 121: \"서울\", 122: \"서울\",\n    130: \"서울\", 131: \"서울\", 132: \"서울\", 133: \"서울\", 134: \"서울\",\n    135: \"서울\", 136: \"서울\", 137: \"서울\", 138: \"서울\", 139: \"서울\",\n    140: \"서울\", 142: \"서울\", 143: \"서울\", 150: \"서울\", 151: \"서울\",\n    152: \"서울\", 153: \"서울\", 156: \"서울\", 157: \"서울\", 158: \"서울\",\n    200: \"강원\", 209: \"강원\", 210: \"강원\", 215: \"강원\", 217: \"강원\",\n    219: \"강원\", 220: \"강원\", 225: \"강원\", 230: \"강원\", 232: \"강원\",\n    233: \"강원\", 235: \"강원\", 240: \"강원\", 245: \"강원\", 250: \"강원\",\n    252: \"강원\", 255: \"강원\", 269: \"강원\",\n    300: \"대전\", 301: \"대전\", 302: \"대전\", 305: \"대전\", 306: \"대전\",\n    312: \"충남\", 314: \"충남\", 320: \"충남\", 321: \"충남\", 323: \"충남\",\n    325: \"충남\", 330: \"충남\", 336: \"충남\", 339: \"충남\", 340: \"충남\",\n    343: \"충남\", 345: \"충남\", 350: \"충남\", 355: \"충남\", 356: \"충남\",\n    357: \"충남\",\n    360: \"충북\", 361: \"충북\", 363: \"충북\", 365: \"충북\", 367: \"충북\",\n    368: \"충북\", 369: \"충북\", 370: \"충북\", 373: \"충북\", 376: \"충북\",\n    380: \"충북\", 390: \"충북\", 395: \"충북\",\n    400: \"인천\", 401: \"인천\", 402: \"인천\", 403: \"인천\", 404: \"인천\",\n    405: \"인천\", 406: \"인천\", 407: \"인천\", 409: \"인천\", 417: \"인천\",\n    411: \"경기\", 412: \"경기\", 413: \"경기\", 415: \"경기\",\n    420: \"경기\", 421: \"경기\", 422: \"경기\", 423: \"경기\", 425: \"경기\",\n    426: \"경기\", 427: \"경기\", 429: \"경기\", 430: \"경기\", 431: \"경기\",\n    435: \"경기\", 437: \"경기\", 440: \"경기\", 441: \"경기\", 442: \"경기\",\n    443: \"경기\", 445: \"경기\", 447: \"경기\", 449: \"경기\", 456: \"경기\",\n    459: \"경기\", 461: \"경기\", 462: \"경기\", 463: \"경기\", 464: \"경기\",\n    465: \"경기\", 467: \"경기\", 469: \"경기\", 471: \"경기\", 472: \"경기\",\n    476: \"경기\", 477: \"경기\", 480: \"경기\", 481: \"경기\", 482: \"경기\",\n    483: \"경기\", 487: \"경기\",\n    500: \"광주\", 501: \"광주\", 502: \"광주\", 503: \"광주\", 506: \"광주\",\n    513: \"전남\", 515: \"전남\", 516: \"전남\", 517: \"전남\", 519: \"전남\",\n    520: \"전남\", 525: \"전남\", 526: \"전남\", 527: \"전남\", 529: \"전남\",\n    530: \"전남\", 534: \"전남\", 535: \"전남\", 536: \"전남\", 537: \"전남\",\n    539: \"전남\", 540: \"전남\", 542: \"전남\", 545: \"전남\", 546: \"전남\",\n    548: \"전남\", 550: \"전남\",\n    560: \"전북\", 561: \"전북\", 565: \"전북\", 566: \"전북\", 567: \"전북\",\n    568: \"전북\", 570: \"전북\", 573: \"전북\", 576: \"전북\", 579: \"전북\",\n    580: \"전북\", 585: \"전북\", 590: \"전북\", 595: \"전북\", 597: \"전북\",\n    600: \"부산\", 601: \"부산\", 602: \"부산\", 604: \"부산\", 606: \"부산\",\n    607: \"부산\", 608: \"부산\", 609: \"부산\", 611: \"부산\", 612: \"부산\",\n    613: \"부산\", 614: \"부산\", 616: \"부산\", 617: \"부산\", 618: \"부산\",\n    619: \"부산\",\n    621: \"경남\", 626: \"경남\", 627: \"경남\", 631: \"경남\", 635: \"경남\",\n    636: \"경남\", 637: \"경남\", 638: \"경남\", 641: \"경남\", 645: \"경남\",\n    650: \"경남\", 656: \"경남\", 660: \"경남\", 664: \"경남\", 666: \"경남\",\n    667: \"경남\", 668: \"경남\", 670: \"경남\", 676: \"경남\", 678: \"경남\",\n    680: \"울산\", 681: \"울산\", 682: \"울산\", 683: \"울산\", 689: \"울산\",\n    690: \"제주\", 695: \"제주\", 697: \"제주\", 699: \"제주\",\n    700: \"대구\", 701: \"대구\", 702: \"대구\", 703: \"대구\", 704: \"대구\",\n    705: \"대구\", 706: \"대구\", 711: \"대구\",\n    712: \"경북\", 714: \"경북\", 716: \"경북\", 717: \"경북\", 718: \"경북\",\n    719: \"경북\", 730: \"경북\", 740: \"경북\", 742: \"경북\", 745: \"경북\",\n    750: \"경북\", 755: \"경북\", 757: \"경북\", 760: \"경북\", 763: \"경북\",\n    764: \"경북\", 766: \"경북\", 767: \"경북\", 769: \"경북\", 770: \"경북\",\n    780: \"경북\", 790: \"경북\", 791: \"경북\", 799: \"경북\",\n    999: \"국외\"\n}\n\nsns.barplot(x='sex', y='percentage', data=sex_dist_py, palette='pastel')\nplt.title('Gender Distribution (%)')\nplt.ylabel('Percentage (%)')\nplt.xticks(ticks=[0, 1], labels=['Male', 'Female'])\nplt.tight_layout()\nplt.savefig('sex_dis.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nsns.barplot(x='yy', y='percentage', data=birth_year_dist_py, palette='viridis')\nplt.title('Birth Year Distribution (%)')\nplt.ylabel('Percentage (%)')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.savefig('birth_dis.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nmerged_df['area_name'] = merged_df['area'].map(area_mapping_py)\narea_name_dist_py = merged_df['area_name'].value_counts(dropna=False).rename_axis('area_name').reset_index(name='n')\narea_name_dist_py['percentage'] = (area_name_dist_py['n'] / area_name_dist_py['n'].sum()) * 100\narea_name_dist_py = area_name_dist_py.sort_values(by='percentage', ascending=False).reset_index(drop=True)\nsns.barplot(x='area_name', y='percentage', data=area_name_dist_py, palette='colorblind')\nplt.title('Regional Distribution (%)')\nplt.ylabel('Percentage (%)')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.savefig('area_dis.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nsns.barplot(x='status_category', y='percentage', data=status_dist_py, palette='Set2')\nplt.title('Dependent Variable Distribution (%)')\nplt.ylabel('Percentage (%)')\nplt.tight_layout()\nplt.savefig('status_dis.png', dpi=300, bbox_inches='tight')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](14_files/figure-html/cell-7-output-1.png){width=662 height=469}\n:::\n\n::: {.cell-output .cell-output-display}\n![](14_files/figure-html/cell-7-output-2.png){width=662 height=469}\n:::\n\n::: {.cell-output .cell-output-display}\n![](14_files/figure-html/cell-7-output-3.png){width=662 height=470}\n:::\n\n::: {.cell-output .cell-output-display}\n![](14_files/figure-html/cell-7-output-4.png){width=662 height=469}\n:::\n:::\n\n\n## 데이터 전처리 및 train test split\n\n::: {#44003a1c .cell execution_count=7}\n``` {.python .cell-code}\nimport re\nfrom sklearn.model_selection import train_test_split\n\npred_vars = [col for col in merged_df.columns if re.search(r\"_w[1-5]$\", col)]\nmerged_df[OUTCOME_VAR] = merged_df[OUTCOME_VAR].astype('category')\n\nX = merged_df[pred_vars]\ny = merged_df[OUTCOME_VAR]\ncomposite_stratify_key = y.astype(str) + '_' + \\\n                         merged_df['area_name'].astype(str) + '_' + \\\n                         merged_df['sex'].astype(str)\nweights = merged_df[WEIGHT_VAR]\nX_train, X_test, y_train, y_test, weights_train, weights_test = train_test_split(X, y, weights, test_size=0.3, random_state=RANDOM_STATE, stratify=composite_stratify_key)\n```\n:::\n\n\n## 데이터 저장\n\n::: {#1d19f29a .cell execution_count=8}\n``` {.python .cell-code}\ntrain_data_to_save = X_train.copy()\ntrain_data_to_save.insert(0, 'y', y_train)\ntrain_data_to_save.insert(1, 'weights', weights_train)\ntrain_data_to_save.to_csv('_data/train_data.csv', index=False)\ntest_data_to_save = X_test.copy()\ntest_data_to_save.insert(0, 'y', y_test)\ntest_data_to_save.insert(1, 'weights', weights_test)\ntest_data_to_save.to_csv('_data/test_data.csv', index=False)\n```\n:::\n\n\n",
    "supporting": [
      "14_files"
    ],
    "filters": [],
    "includes": {}
  }
}