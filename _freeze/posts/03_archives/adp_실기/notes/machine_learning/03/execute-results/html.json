{
  "hash": "a3e7365f8318821985f39810546c71c4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"분류 - 산탄데르 고객 만족 예측\"\ndate: 2025-07-27\ncategories: [\"머신 러닝\"]\n---\n\n\n![](/img/stat-thumb.jpg){.post-thumbnail}\n\n## Preprocessing\n\n::: {#b48296b0 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\n\nplt.rcParams['font.family'] = 'Noto Sans KR'\nwarnings.filterwarnings('ignore')\n\ndf = pd.read_csv('_data/santander/train.csv', encoding='latin-1')\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 76020 entries, 0 to 76019\nColumns: 371 entries, ID to TARGET\ndtypes: float64(111), int64(260)\nmemory usage: 215.2 MB\n```\n:::\n:::\n\n\n::: {#9a8ce19d .cell execution_count=2}\n``` {.python .cell-code}\ndf.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>var3</th>\n      <th>var15</th>\n      <th>imp_ent_var16_ult1</th>\n      <th>imp_op_var39_comer_ult1</th>\n      <th>imp_op_var39_comer_ult3</th>\n      <th>imp_op_var40_comer_ult1</th>\n      <th>imp_op_var40_comer_ult3</th>\n      <th>imp_op_var40_efect_ult1</th>\n      <th>imp_op_var40_efect_ult3</th>\n      <th>...</th>\n      <th>saldo_medio_var33_hace2</th>\n      <th>saldo_medio_var33_hace3</th>\n      <th>saldo_medio_var33_ult1</th>\n      <th>saldo_medio_var33_ult3</th>\n      <th>saldo_medio_var44_hace2</th>\n      <th>saldo_medio_var44_hace3</th>\n      <th>saldo_medio_var44_ult1</th>\n      <th>saldo_medio_var44_ult3</th>\n      <th>var38</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>...</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>7.602000e+04</td>\n      <td>76020.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>75964.050723</td>\n      <td>-1523.199277</td>\n      <td>33.212865</td>\n      <td>86.208265</td>\n      <td>72.363067</td>\n      <td>119.529632</td>\n      <td>3.559130</td>\n      <td>6.472698</td>\n      <td>0.412946</td>\n      <td>0.567352</td>\n      <td>...</td>\n      <td>7.935824</td>\n      <td>1.365146</td>\n      <td>12.215580</td>\n      <td>8.784074</td>\n      <td>31.505324</td>\n      <td>1.858575</td>\n      <td>76.026165</td>\n      <td>56.614351</td>\n      <td>1.172358e+05</td>\n      <td>0.039569</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>43781.947379</td>\n      <td>39033.462364</td>\n      <td>12.956486</td>\n      <td>1614.757313</td>\n      <td>339.315831</td>\n      <td>546.266294</td>\n      <td>93.155749</td>\n      <td>153.737066</td>\n      <td>30.604864</td>\n      <td>36.513513</td>\n      <td>...</td>\n      <td>455.887218</td>\n      <td>113.959637</td>\n      <td>783.207399</td>\n      <td>538.439211</td>\n      <td>2013.125393</td>\n      <td>147.786584</td>\n      <td>4040.337842</td>\n      <td>2852.579397</td>\n      <td>1.826646e+05</td>\n      <td>0.194945</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>-999999.000000</td>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.163750e+03</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>38104.750000</td>\n      <td>2.000000</td>\n      <td>23.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.787061e+04</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>76043.000000</td>\n      <td>2.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.064092e+05</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>113748.750000</td>\n      <td>2.000000</td>\n      <td>40.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.187563e+05</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>151838.000000</td>\n      <td>238.000000</td>\n      <td>105.000000</td>\n      <td>210000.000000</td>\n      <td>12888.030000</td>\n      <td>21024.810000</td>\n      <td>8237.820000</td>\n      <td>11073.570000</td>\n      <td>6600.000000</td>\n      <td>6600.000000</td>\n      <td>...</td>\n      <td>50003.880000</td>\n      <td>20385.720000</td>\n      <td>138831.630000</td>\n      <td>91778.730000</td>\n      <td>438329.220000</td>\n      <td>24650.010000</td>\n      <td>681462.900000</td>\n      <td>397884.300000</td>\n      <td>2.203474e+07</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 371 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#0f47ab55 .cell execution_count=3}\n``` {.python .cell-code}\ndf['var3'].replace(-999999, 2, inplace=True)\ndf.drop('ID', axis=1, inplace=True)\n\nX_features = df.iloc[:, :-1]\nlabels = df.iloc[:, -1]\n```\n:::\n\n\n::: {#b93d9cbe .cell execution_count=4}\n``` {.python .cell-code}\ntest_df = pd.read_csv('_data/santander/test.csv', encoding='latin-1')\ntest_df['var3'].replace(-999999, 2, inplace=True)\ntest_df.drop('ID', axis=1, inplace=True)\n```\n:::\n\n\n::: {#0d4e0858 .cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_features, labels, test_size=0.2)\n```\n:::\n\n\n- train, test의 label의 비율이 동일한게 좋은걸까\n\n## XGBoost\n\n::: {#7f3b82db .cell execution_count=6}\n``` {.python .cell-code}\nX_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3)\n```\n:::\n\n\n::: {#a358cfe4 .cell execution_count=7}\n``` {.python .cell-code}\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\nevals = [(X_tr, y_tr), (X_val, y_val)]\nxgb_clf = XGBClassifier(n_estimators=400, \n                    learning_rate=0.05, \n                    early_stopping_rounds=100,\n                    eval_metric=['auc'])\nxgb_clf.fit(X_tr, y_tr, eval_set=evals, verbose=False)\nxgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\nprint(f'{xgb_roc_score:.3f}')\n```\n:::\n\n\n### 베이지안 최적화\n\n::: {#f3129a98 .cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\ndef objective_func(search_space):\n    xgb_clf = XGBClassifier(n_estimators=100, \n                            early_stopping_rounds=30,\n                            eval_metric='auc',\n                            max_depth=int(search_space['max_depth']),\n                            min_child_weight=int(search_space['min_child_weight']),\n                            colsample_bytree=search_space['colsample_bytree'],\n                            learning_rate=search_space['learning_rate'])\n    roc_auc_list = []\n    kf = KFold(n_splits=3)\n    for tr_index, val_index in kf.split(X_train):\n        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n        X_val, y_val =  X_train.iloc[val_index], y_train.iloc[val_index]\n\n        xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])\n        roc_auc_list.append(score)\n\n    return -1 * np.mean(roc_auc_list)\n```\n:::\n\n\n::: {#ac29c9be .cell execution_count=9}\n``` {.python .cell-code}\nfrom hyperopt import hp, fmin, tpe, Trials\n\nxgb_search_space = {\n  'max_depth': hp.quniform('max_depth', 5, 15, 1),\n  'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n  'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95),\n  'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n}\n\ntrials = Trials()\nbest = fmin(fn=objective_func,\n            space=xgb_search_space,\n            algo=tpe.suggest,\n            max_evals=50,\n            trials=trials)\nprint(best)\n```\n:::\n\n\n### 재 학습\n\n::: {#2bc96cdf .cell execution_count=10}\n``` {.python .cell-code}\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\nevals = [(X_tr, y_tr), (X_val, y_val)]\nxgb_clf = XGBClassifier(n_estimators=500, \n                    learning_rate=round(best['learning_rate'], 5),\n                    max_depth=int(best['max_depth']),\n                    min_child_weight=int(best['min_child_weight']),\n                    colsample_bytree=round(best['colsample_bytree'], 5),\n                    early_stopping_rounds=100,\n                    eval_metric=['auc'])\nxgb_clf.fit(X_tr, y_tr, eval_set=evals, verbose=False)\nxgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\nprint(f'{xgb_roc_score:.3f}')\n```\n:::\n\n\n### plot importance\n\n::: {#1552ed87 .cell execution_count=11}\n``` {.python .cell-code}\nfrom xgboost import plot_importance\n\nplot_importance(xgb_clf, max_num_features=20, height=0.4)\n```\n:::\n\n\n## LightGBM\n\n::: {#8be1ef0a .cell execution_count=12}\n``` {.python .cell-code}\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier\n\nlgbm_clf = LGBMClassifier(n_estimators=500, early_stopping_rounds=100, eval_metric='auc')\n\neval_set = [(X_tr, y_tr), (X_val, y_val)]\nlgbm_clf.fit(X_tr, y_tr, eval_set=eval_set)\n\nlgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\nprint(f'{lgbm_roc_score:.3f}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Info] Number of positive: 1743, number of negative: 40828\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009326 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 13424\n[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 246\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040943 -> initscore=-3.153760\n[LightGBM] [Info] Start training from score -3.153760\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[37]\ttraining's binary_logloss: 0.118028\tvalid_1's binary_logloss: 0.131886\n[LightGBM] [Warning] Unknown parameter: eval_metric\n0.827\n```\n:::\n:::\n\n\n### 베이지안 최적화\n\n::: {#95aedcfe .cell execution_count=13}\n``` {.python .cell-code}\nfrom sklearn.model_selection import KFold\n\ndef objective_func(search_space):\n    lgbm_clf = LGBMClassifier(n_estimators=100, \n                            early_stopping_rounds=30,\n                            eval_metric='auc',\n                            num_leaves=int(search_space['num_leaves']),\n                            max_depth=int(search_space['max_depth']),\n                            min_child_samples=int(search_space['min_child_samples']),\n                            subsample=search_space['subsample'],\n                            learning_rate=search_space['learning_rate'])\n    roc_auc_list = []\n    kf = KFold(n_splits=3)\n    for tr_index, val_index in kf.split(X_train):\n        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n        X_val, y_val =  X_train.iloc[val_index], y_train.iloc[val_index]\n\n        lgbm_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1])\n        roc_auc_list.append(score)\n\n    return -1 * np.mean(roc_auc_list)\n```\n:::\n\n\n::: {#1ea04c19 .cell execution_count=14}\n``` {.python .cell-code}\nfrom hyperopt import hp, fmin, tpe, Trials\n\nlgbm_search_space = {\n  'num_leaves': hp.quniform('num_leaves', 32, 64, 1),\n  'max_depth': hp.quniform('max_depth', 100, 160, 1),\n  'min_child_samples': hp.quniform('min_child_samples', 60, 100, 1),\n  'subsample': hp.uniform('subsample', 0.7, 1),\n  'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n}\n\ntrials = Trials()\nbest = fmin(fn=objective_func,\n            space=lgbm_search_space,\n            algo=tpe.suggest,\n            max_evals=50,\n            trials=trials)\nprint(best)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010018 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Total Bins 12871\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Start training from score -3.175334\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \rTraining until validation scores don't improve for 30 rounds\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \rEarly stopping, best iteration is:\n[42]\ttraining's binary_logloss: 0.115339\tvalid_1's binary_logloss: 0.135273\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009143 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Total Bins 12838\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Start training from score -3.170220\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \rTraining until validation scores don't improve for 30 rounds\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.120183\tvalid_1's binary_logloss: 0.136543\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015029 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Total Bins 12895\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  0%|          | 0/50 [00:01<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Info] Start training from score -3.175334\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \rTraining until validation scores don't improve for 30 rounds\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \rEarly stopping, best iteration is:\n[36]\ttraining's binary_logloss: 0.117259\tvalid_1's binary_logloss: 0.136158\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r                                                      \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  0%|          | 0/50 [00:02<?, ?trial/s, best loss=?]\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009276 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12871\n\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  2%|▏         | 1/50 [00:02<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.119582\tvalid_1's binary_logloss: 0.135587\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009408 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12838\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.170220\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  2%|▏         | 1/50 [00:03<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[24]\ttraining's binary_logloss: 0.120518\tvalid_1's binary_logloss: 0.136973\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020503 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12833\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  2%|▏         | 1/50 [00:04<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[27]\ttraining's binary_logloss: 0.118781\tvalid_1's binary_logloss: 0.136262\n\r  2%|▏         | 1/50 [00:05<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  2%|▏         | 1/50 [00:05<02:05,  2.56s/trial, best loss: -0.8388021622195062]\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007758 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12871\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.120345\tvalid_1's binary_logloss: 0.136441\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:05<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008801 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12838\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.170220\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[17]\ttraining's binary_logloss: 0.121152\tvalid_1's binary_logloss: 0.137855\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008859 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12786\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[13]\ttraining's binary_logloss: 0.124141\tvalid_1's binary_logloss: 0.136685\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  4%|▍         | 2/50 [00:06<02:05,  2.62s/trial, best loss: -0.8388021622195062]\r  6%|▌         | 3/50 [00:06<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013940 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12871\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.118052\tvalid_1's binary_logloss: 0.13619\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007335 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12838\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.170220\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  6%|▌         | 3/50 [00:07<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[17]\ttraining's binary_logloss: 0.120359\tvalid_1's binary_logloss: 0.136752\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009413 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12895\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.118057\tvalid_1's binary_logloss: 0.137087\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  6%|▌         | 3/50 [00:08<01:44,  2.23s/trial, best loss: -0.8388021622195062]\r  8%|▊         | 4/50 [00:08<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007451 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12871\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[60]\ttraining's binary_logloss: 0.113152\tvalid_1's binary_logloss: 0.135425\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:09<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009906 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12838\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.170220\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[49]\ttraining's binary_logloss: 0.116715\tvalid_1's binary_logloss: 0.136816\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:10<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008587 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12833\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[47]\ttraining's binary_logloss: 0.117522\tvalid_1's binary_logloss: 0.136409\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r  8%|▊         | 4/50 [00:11<01:37,  2.11s/trial, best loss: -0.8388021622195062]\r 10%|█         | 5/50 [00:11<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:11<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:11<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010033 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12871\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[64]\ttraining's binary_logloss: 0.116884\tvalid_1's binary_logloss: 0.135204\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007548 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12838\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 10%|█         | 5/50 [00:12<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.170220\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[47]\ttraining's binary_logloss: 0.121231\tvalid_1's binary_logloss: 0.136393\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008461 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Total Bins 12786\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 10%|█         | 5/50 [00:13<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \rEarly stopping, best iteration is:\n[54]\ttraining's binary_logloss: 0.119523\tvalid_1's binary_logloss: 0.136026\n\r 10%|█         | 5/50 [00:14<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 10%|█         | 5/50 [00:14<01:48,  2.42s/trial, best loss: -0.8388021622195062]\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008722 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Total Bins 12931\n\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 12%|█▏        | 6/50 [00:14<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.110196\tvalid_1's binary_logloss: 0.137986\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011217 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Total Bins 12930\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.170220\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \rEarly stopping, best iteration is:\n[11]\ttraining's binary_logloss: 0.119379\tvalid_1's binary_logloss: 0.139145\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:15<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:16<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 12%|█▏        | 6/50 [00:16<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008658 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 12%|█▏        | 6/50 [00:16<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Total Bins 12941\n\r 12%|█▏        | 6/50 [00:16<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 12%|█▏        | 6/50 [00:16<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:16<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 12%|█▏        | 6/50 [00:16<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 12%|█▏        | 6/50 [00:16<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r 12%|█▏        | 6/50 [00:16<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 12%|█▏        | 6/50 [00:16<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \rEarly stopping, best iteration is:\n[12]\ttraining's binary_logloss: 0.118159\tvalid_1's binary_logloss: 0.138415\n\r 12%|█▏        | 6/50 [00:16<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 12%|█▏        | 6/50 [00:16<01:46,  2.43s/trial, best loss: -0.8392289554989807]\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009495 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Total Bins 12968\n\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 14%|█▍        | 7/50 [00:16<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \rEarly stopping, best iteration is:\n[40]\ttraining's binary_logloss: 0.114779\tvalid_1's binary_logloss: 0.135659\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008197 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Total Bins 12940\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.170220\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \rEarly stopping, best iteration is:\n[33]\ttraining's binary_logloss: 0.118118\tvalid_1's binary_logloss: 0.136966\n\r 14%|█▍        | 7/50 [00:17<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008496 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Total Bins 12989\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \rEarly stopping, best iteration is:\n[33]\ttraining's binary_logloss: 0.118416\tvalid_1's binary_logloss: 0.136128\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 14%|█▍        | 7/50 [00:18<01:40,  2.35s/trial, best loss: -0.8392289554989807]\r 16%|█▌        | 8/50 [00:18<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:18<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:18<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:18<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 16%|█▌        | 8/50 [00:18<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008955 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Total Bins 12931\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \rEarly stopping, best iteration is:\n[38]\ttraining's binary_logloss: 0.117406\tvalid_1's binary_logloss: 0.135414\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008978 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Total Bins 12940\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.170220\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 16%|█▌        | 8/50 [00:19<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \rEarly stopping, best iteration is:\n[36]\ttraining's binary_logloss: 0.118496\tvalid_1's binary_logloss: 0.137043\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008446 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Total Bins 12941\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.120895\tvalid_1's binary_logloss: 0.136238\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 16%|█▌        | 8/50 [00:20<01:37,  2.31s/trial, best loss: -0.8392289554989807]\r 18%|█▊        | 9/50 [00:20<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013107 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Total Bins 12972\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \rEarly stopping, best iteration is:\n[47]\ttraining's binary_logloss: 0.11026\tvalid_1's binary_logloss: 0.135983\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007816 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Total Bins 12940\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.170220\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \rEarly stopping, best iteration is:\n[37]\ttraining's binary_logloss: 0.114586\tvalid_1's binary_logloss: 0.137114\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:21<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008270 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Total Bins 13019\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Info] Start training from score -3.175334\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \rTraining until validation scores don't improve for 30 rounds\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \rEarly stopping, best iteration is:\n[35]\ttraining's binary_logloss: 0.115785\tvalid_1's binary_logloss: 0.136625\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r                                                                                 \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 18%|█▊        | 9/50 [00:22<01:33,  2.27s/trial, best loss: -0.8392289554989807]\r 20%|██        | 10/50 [00:22<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:22<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:22<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:22<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 20%|██        | 10/50 [00:22<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007585 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 20%|██        | 10/50 [00:22<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 20%|██        | 10/50 [00:22<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 20%|██        | 10/50 [00:22<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:22<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:22<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 20%|██        | 10/50 [00:23<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 20%|██        | 10/50 [00:23<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 20%|██        | 10/50 [00:23<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[98]\ttraining's binary_logloss: 0.115397\tvalid_1's binary_logloss: 0.135652\n\r 20%|██        | 10/50 [00:23<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:23<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:23<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:23<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:24<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 20%|██        | 10/50 [00:24<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008310 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 20%|██        | 10/50 [00:24<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 20%|██        | 10/50 [00:24<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 20%|██        | 10/50 [00:24<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:24<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:24<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 20%|██        | 10/50 [00:24<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 20%|██        | 10/50 [00:24<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 20%|██        | 10/50 [00:24<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[99]\ttraining's binary_logloss: 0.115583\tvalid_1's binary_logloss: 0.136994\n\r 20%|██        | 10/50 [00:24<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:24<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:25<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:25<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:25<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 20%|██        | 10/50 [00:25<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007615 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 20%|██        | 10/50 [00:25<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12895\n\r 20%|██        | 10/50 [00:25<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 20%|██        | 10/50 [00:25<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:25<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 20%|██        | 10/50 [00:25<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 20%|██        | 10/50 [00:25<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 20%|██        | 10/50 [00:25<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 20%|██        | 10/50 [00:25<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[99]\ttraining's binary_logloss: 0.115519\tvalid_1's binary_logloss: 0.136158\n\r 20%|██        | 10/50 [00:26<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 20%|██        | 10/50 [00:26<01:24,  2.11s/trial, best loss: -0.8392289554989807]\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008511 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[16]\ttraining's binary_logloss: 0.122029\tvalid_1's binary_logloss: 0.136173\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007786 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 22%|██▏       | 11/50 [00:26<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.120888\tvalid_1's binary_logloss: 0.136955\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008869 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.120551\tvalid_1's binary_logloss: 0.136814\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 22%|██▏       | 11/50 [00:27<01:38,  2.53s/trial, best loss: -0.8392289554989807]\r 24%|██▍       | 12/50 [00:27<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008053 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[50]\ttraining's binary_logloss: 0.118897\tvalid_1's binary_logloss: 0.135374\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 24%|██▍       | 12/50 [00:28<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008099 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[48]\ttraining's binary_logloss: 0.120057\tvalid_1's binary_logloss: 0.136268\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010876 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12895\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 24%|██▍       | 12/50 [00:29<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[43]\ttraining's binary_logloss: 0.121339\tvalid_1's binary_logloss: 0.135992\n\r 24%|██▍       | 12/50 [00:30<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 24%|██▍       | 12/50 [00:30<01:28,  2.32s/trial, best loss: -0.8392289554989807]\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007516 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 26%|██▌       | 13/50 [00:30<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[21]\ttraining's binary_logloss: 0.113248\tvalid_1's binary_logloss: 0.136898\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007834 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.116048\tvalid_1's binary_logloss: 0.138246\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:31<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:32<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 26%|██▌       | 13/50 [00:32<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007633 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 26%|██▌       | 13/50 [00:32<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12895\n\r 26%|██▌       | 13/50 [00:32<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 26%|██▌       | 13/50 [00:32<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:32<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 26%|██▌       | 13/50 [00:32<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 26%|██▌       | 13/50 [00:32<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 26%|██▌       | 13/50 [00:32<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 26%|██▌       | 13/50 [00:32<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[19]\ttraining's binary_logloss: 0.115359\tvalid_1's binary_logloss: 0.137007\n\r 26%|██▌       | 13/50 [00:32<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 26%|██▌       | 13/50 [00:32<01:27,  2.36s/trial, best loss: -0.8392289554989807]\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012108 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 28%|██▊       | 14/50 [00:32<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[22]\ttraining's binary_logloss: 0.111546\tvalid_1's binary_logloss: 0.136236\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010883 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[16]\ttraining's binary_logloss: 0.11728\tvalid_1's binary_logloss: 0.138139\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:33<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008486 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[16]\ttraining's binary_logloss: 0.117555\tvalid_1's binary_logloss: 0.137344\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 28%|██▊       | 14/50 [00:34<01:21,  2.25s/trial, best loss: -0.8392289554989807]\r 30%|███       | 15/50 [00:34<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:34<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:34<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:34<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 30%|███       | 15/50 [00:34<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008547 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 30%|███       | 15/50 [00:34<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12931\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.112448\tvalid_1's binary_logloss: 0.136518\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009170 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12940\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 30%|███       | 15/50 [00:35<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[27]\ttraining's binary_logloss: 0.113698\tvalid_1's binary_logloss: 0.13722\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008075 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12941\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 30%|███       | 15/50 [00:36<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[23]\ttraining's binary_logloss: 0.115788\tvalid_1's binary_logloss: 0.136738\n\r 30%|███       | 15/50 [00:37<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 30%|███       | 15/50 [00:37<01:19,  2.26s/trial, best loss: -0.8392289554989807]\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008068 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[29]\ttraining's binary_logloss: 0.11315\tvalid_1's binary_logloss: 0.13605\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:37<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012014 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.119589\tvalid_1's binary_logloss: 0.137673\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008026 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 32%|███▏      | 16/50 [00:38<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 32%|███▏      | 16/50 [00:39<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.114105\tvalid_1's binary_logloss: 0.136277\n\r 32%|███▏      | 16/50 [00:39<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 32%|███▏      | 16/50 [00:39<01:17,  2.29s/trial, best loss: -0.8392289554989807]\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007663 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 34%|███▍      | 17/50 [00:39<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[22]\ttraining's binary_logloss: 0.113856\tvalid_1's binary_logloss: 0.136826\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014484 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[18]\ttraining's binary_logloss: 0.11691\tvalid_1's binary_logloss: 0.137717\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:40<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:41<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 34%|███▍      | 17/50 [00:41<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013373 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 34%|███▍      | 17/50 [00:41<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12895\n\r 34%|███▍      | 17/50 [00:41<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 34%|███▍      | 17/50 [00:41<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:41<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 34%|███▍      | 17/50 [00:41<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 34%|███▍      | 17/50 [00:41<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 34%|███▍      | 17/50 [00:41<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 34%|███▍      | 17/50 [00:41<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[15]\ttraining's binary_logloss: 0.119044\tvalid_1's binary_logloss: 0.136894\n\r 34%|███▍      | 17/50 [00:41<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 34%|███▍      | 17/50 [00:41<01:16,  2.32s/trial, best loss: -0.8392289554989807]\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007963 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 36%|███▌      | 18/50 [00:41<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.11077\tvalid_1's binary_logloss: 0.137157\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013965 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12901\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[15]\ttraining's binary_logloss: 0.116193\tvalid_1's binary_logloss: 0.137678\n\r 36%|███▌      | 18/50 [00:42<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008477 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12927\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[15]\ttraining's binary_logloss: 0.11618\tvalid_1's binary_logloss: 0.137519\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 36%|███▌      | 18/50 [00:43<01:10,  2.22s/trial, best loss: -0.8392289554989807]\r 38%|███▊      | 19/50 [00:43<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:43<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:43<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:43<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 38%|███▊      | 19/50 [00:43<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009515 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 38%|███▊      | 19/50 [00:43<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12972\n\r 38%|███▊      | 19/50 [00:43<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n\r 38%|███▊      | 19/50 [00:43<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[77]\ttraining's binary_logloss: 0.115716\tvalid_1's binary_logloss: 0.135148\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008386 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12940\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:44<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 38%|███▊      | 19/50 [00:45<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 38%|███▊      | 19/50 [00:45<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 38%|███▊      | 19/50 [00:45<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[70]\ttraining's binary_logloss: 0.117363\tvalid_1's binary_logloss: 0.136757\n\r 38%|███▊      | 19/50 [00:45<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:45<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:45<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:45<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:45<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 38%|███▊      | 19/50 [00:45<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008014 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 38%|███▊      | 19/50 [00:46<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 13019\n\r 38%|███▊      | 19/50 [00:46<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208\n\r 38%|███▊      | 19/50 [00:46<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:46<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 38%|███▊      | 19/50 [00:46<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 38%|███▊      | 19/50 [00:46<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 38%|███▊      | 19/50 [00:46<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 38%|███▊      | 19/50 [00:46<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[87]\ttraining's binary_logloss: 0.114388\tvalid_1's binary_logloss: 0.135959\n\r 38%|███▊      | 19/50 [00:46<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 38%|███▊      | 19/50 [00:46<01:09,  2.24s/trial, best loss: -0.8392289554989807]\r 40%|████      | 20/50 [00:46<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:46<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:46<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:46<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 40%|████      | 20/50 [00:46<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007714 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 40%|████      | 20/50 [00:46<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 40%|████      | 20/50 [00:46<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 40%|████      | 20/50 [00:46<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:46<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:46<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[56]\ttraining's binary_logloss: 0.113852\tvalid_1's binary_logloss: 0.135391\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011061 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12901\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 40%|████      | 20/50 [00:47<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[44]\ttraining's binary_logloss: 0.117712\tvalid_1's binary_logloss: 0.13702\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011576 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12937\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 40%|████      | 20/50 [00:48<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[47]\ttraining's binary_logloss: 0.116351\tvalid_1's binary_logloss: 0.136231\n\r 40%|████      | 20/50 [00:49<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 40%|████      | 20/50 [00:49<01:13,  2.46s/trial, best loss: -0.8392289554989807]\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008373 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 42%|████▏     | 21/50 [00:49<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.123881\tvalid_1's binary_logloss: 0.136385\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010068 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 42%|████▏     | 21/50 [00:50<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.124054\tvalid_1's binary_logloss: 0.137325\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009148 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 42%|████▏     | 21/50 [00:51<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.124164\tvalid_1's binary_logloss: 0.136819\n\r 42%|████▏     | 21/50 [00:52<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 42%|████▏     | 21/50 [00:52<01:13,  2.54s/trial, best loss: -0.8392289554989807]\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009815 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 44%|████▍     | 22/50 [00:52<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[54]\ttraining's binary_logloss: 0.117668\tvalid_1's binary_logloss: 0.135427\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010237 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12901\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[44]\ttraining's binary_logloss: 0.120439\tvalid_1's binary_logloss: 0.13648\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009198 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12937\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[47]\ttraining's binary_logloss: 0.11963\tvalid_1's binary_logloss: 0.135865\n\r 44%|████▍     | 22/50 [00:53<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 44%|████▍     | 22/50 [00:54<01:15,  2.70s/trial, best loss: -0.8392289554989807]\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012613 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 46%|████▌     | 23/50 [00:54<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[87]\ttraining's binary_logloss: 0.115959\tvalid_1's binary_logloss: 0.135197\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008941 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 46%|████▌     | 23/50 [00:55<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[75]\ttraining's binary_logloss: 0.118366\tvalid_1's binary_logloss: 0.136609\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007477 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12895\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 46%|████▌     | 23/50 [00:56<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[83]\ttraining's binary_logloss: 0.116771\tvalid_1's binary_logloss: 0.13633\n\r 46%|████▌     | 23/50 [00:57<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 46%|████▌     | 23/50 [00:57<01:03,  2.36s/trial, best loss: -0.8392289554989807]\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008876 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[28]\ttraining's binary_logloss: 0.11791\tvalid_1's binary_logloss: 0.135895\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [00:57<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007717 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[23]\ttraining's binary_logloss: 0.12056\tvalid_1's binary_logloss: 0.136948\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010490 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 48%|████▊     | 24/50 [00:58<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[20]\ttraining's binary_logloss: 0.122776\tvalid_1's binary_logloss: 0.136368\n\r 48%|████▊     | 24/50 [00:59<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 48%|████▊     | 24/50 [00:59<01:06,  2.56s/trial, best loss: -0.8392289554989807]\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008674 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[45]\ttraining's binary_logloss: 0.114831\tvalid_1's binary_logloss: 0.13512\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [00:59<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008398 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12847\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[38]\ttraining's binary_logloss: 0.117537\tvalid_1's binary_logloss: 0.136936\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:00<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:01<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 50%|█████     | 25/50 [01:01<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010585 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 50%|█████     | 25/50 [01:01<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12927\n\r 50%|█████     | 25/50 [01:01<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 50%|█████     | 25/50 [01:01<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:01<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 50%|█████     | 25/50 [01:01<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 50%|█████     | 25/50 [01:01<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 50%|█████     | 25/50 [01:01<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 50%|█████     | 25/50 [01:01<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[38]\ttraining's binary_logloss: 0.117531\tvalid_1's binary_logloss: 0.136522\n\r 50%|█████     | 25/50 [01:01<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 50%|█████     | 25/50 [01:01<00:59,  2.38s/trial, best loss: -0.8392289554989807]\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007302 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 52%|█████▏    | 26/50 [01:01<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.133342\tvalid_1's binary_logloss: 0.140267\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007364 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 52%|█████▏    | 26/50 [01:02<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.133434\tvalid_1's binary_logloss: 0.140567\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015915 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12824\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 52%|█████▏    | 26/50 [01:03<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.133567\tvalid_1's binary_logloss: 0.140502\n\r 52%|█████▏    | 26/50 [01:04<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 52%|█████▏    | 26/50 [01:04<00:58,  2.43s/trial, best loss: -0.8392289554989807]\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011792 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 54%|█████▍    | 27/50 [01:04<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[72]\ttraining's binary_logloss: 0.118897\tvalid_1's binary_logloss: 0.134938\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014739 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 54%|█████▍    | 27/50 [01:05<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \rEarly stopping, best iteration is:\n[59]\ttraining's binary_logloss: 0.121656\tvalid_1's binary_logloss: 0.136129\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008777 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 54%|█████▍    | 27/50 [01:06<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[71]\ttraining's binary_logloss: 0.119117\tvalid_1's binary_logloss: 0.135705\n\r 54%|█████▍    | 27/50 [01:07<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 54%|█████▍    | 27/50 [01:07<00:59,  2.58s/trial, best loss: -0.8392289554989807]\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011169 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 56%|█████▌    | 28/50 [01:07<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[70]\ttraining's binary_logloss: 0.118593\tvalid_1's binary_logloss: 0.135079\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009737 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 56%|█████▌    | 28/50 [01:08<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[70]\ttraining's binary_logloss: 0.118942\tvalid_1's binary_logloss: 0.136383\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009279 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 56%|█████▌    | 28/50 [01:09<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[64]\ttraining's binary_logloss: 0.119887\tvalid_1's binary_logloss: 0.135867\n\r 56%|█████▌    | 28/50 [01:10<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 56%|█████▌    | 28/50 [01:10<00:58,  2.64s/trial, best loss: -0.8401410657281506]\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007173 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[88]\ttraining's binary_logloss: 0.117369\tvalid_1's binary_logloss: 0.135067\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:10<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007359 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[81]\ttraining's binary_logloss: 0.119048\tvalid_1's binary_logloss: 0.13651\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:11<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007674 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[73]\ttraining's binary_logloss: 0.119922\tvalid_1's binary_logloss: 0.135908\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 58%|█████▊    | 29/50 [01:12<00:56,  2.70s/trial, best loss: -0.8401410657281506]\r 60%|██████    | 30/50 [01:12<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007517 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.133514\tvalid_1's binary_logloss: 0.139597\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:13<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007678 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.133767\tvalid_1's binary_logloss: 0.140047\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008211 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 60%|██████    | 30/50 [01:14<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.133574\tvalid_1's binary_logloss: 0.139731\n\r 60%|██████    | 30/50 [01:15<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 60%|██████    | 30/50 [01:15<00:54,  2.71s/trial, best loss: -0.8401410657281506]\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009983 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 62%|██████▏   | 31/50 [01:15<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.121626\tvalid_1's binary_logloss: 0.135216\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008694 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 62%|██████▏   | 31/50 [01:16<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.121889\tvalid_1's binary_logloss: 0.136447\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007451 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 62%|██████▏   | 31/50 [01:17<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.12183\tvalid_1's binary_logloss: 0.136042\n\r 62%|██████▏   | 31/50 [01:18<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 62%|██████▏   | 31/50 [01:18<00:50,  2.68s/trial, best loss: -0.8401410657281506]\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008112 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 64%|██████▍   | 32/50 [01:18<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[56]\ttraining's binary_logloss: 0.116683\tvalid_1's binary_logloss: 0.135398\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010157 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 64%|██████▍   | 32/50 [01:19<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[65]\ttraining's binary_logloss: 0.114815\tvalid_1's binary_logloss: 0.136466\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007926 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12824\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 64%|██████▍   | 32/50 [01:20<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[58]\ttraining's binary_logloss: 0.116072\tvalid_1's binary_logloss: 0.136172\n\r 64%|██████▍   | 32/50 [01:21<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 64%|██████▍   | 32/50 [01:21<00:48,  2.71s/trial, best loss: -0.8401410657281506]\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007543 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 66%|██████▌   | 33/50 [01:21<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.117343\tvalid_1's binary_logloss: 0.135031\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009537 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 66%|██████▌   | 33/50 [01:22<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[99]\ttraining's binary_logloss: 0.117695\tvalid_1's binary_logloss: 0.136703\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008192 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12895\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 66%|██████▌   | 33/50 [01:23<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[88]\ttraining's binary_logloss: 0.119177\tvalid_1's binary_logloss: 0.136252\n\r 66%|██████▌   | 33/50 [01:24<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 66%|██████▌   | 33/50 [01:24<00:47,  2.81s/trial, best loss: -0.8401410657281506]\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008218 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[46]\ttraining's binary_logloss: 0.115523\tvalid_1's binary_logloss: 0.135633\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008632 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[43]\ttraining's binary_logloss: 0.117079\tvalid_1's binary_logloss: 0.136427\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:24<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010686 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[42]\ttraining's binary_logloss: 0.117023\tvalid_1's binary_logloss: 0.136091\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 68%|██████▊   | 34/50 [01:25<00:45,  2.84s/trial, best loss: -0.8401410657281506]\r 70%|███████   | 35/50 [01:25<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:25<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:25<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008555 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12931\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[58]\ttraining's binary_logloss: 0.117847\tvalid_1's binary_logloss: 0.135165\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008116 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12901\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:26<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[53]\ttraining's binary_logloss: 0.119517\tvalid_1's binary_logloss: 0.1365\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008153 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12937\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 70%|███████   | 35/50 [01:27<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[53]\ttraining's binary_logloss: 0.119509\tvalid_1's binary_logloss: 0.1364\n\r 70%|███████   | 35/50 [01:28<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 70%|███████   | 35/50 [01:28<00:37,  2.47s/trial, best loss: -0.8401410657281506]\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007611 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 72%|███████▏  | 36/50 [01:28<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.110921\tvalid_1's binary_logloss: 0.136296\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007256 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[25]\ttraining's binary_logloss: 0.114336\tvalid_1's binary_logloss: 0.137818\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:29<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011210 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12895\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[23]\ttraining's binary_logloss: 0.116128\tvalid_1's binary_logloss: 0.136477\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 72%|███████▏  | 36/50 [01:30<00:34,  2.47s/trial, best loss: -0.8401410657281506]\r 74%|███████▍  | 37/50 [01:30<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:30<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:30<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009461 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[24]\ttraining's binary_logloss: 0.115599\tvalid_1's binary_logloss: 0.136052\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008508 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 74%|███████▍  | 37/50 [01:31<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[26]\ttraining's binary_logloss: 0.114202\tvalid_1's binary_logloss: 0.137009\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009656 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 74%|███████▍  | 37/50 [01:32<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[19]\ttraining's binary_logloss: 0.119242\tvalid_1's binary_logloss: 0.136837\n\r 74%|███████▍  | 37/50 [01:33<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 74%|███████▍  | 37/50 [01:33<00:32,  2.48s/trial, best loss: -0.8401410657281506]\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009321 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 76%|███████▌  | 38/50 [01:33<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[74]\ttraining's binary_logloss: 0.116269\tvalid_1's binary_logloss: 0.135375\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009568 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 76%|███████▌  | 38/50 [01:34<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[69]\ttraining's binary_logloss: 0.117874\tvalid_1's binary_logloss: 0.136441\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011686 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12824\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 76%|███████▌  | 38/50 [01:35<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[64]\ttraining's binary_logloss: 0.118636\tvalid_1's binary_logloss: 0.136199\n\r 76%|███████▌  | 38/50 [01:36<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 76%|███████▌  | 38/50 [01:36<00:29,  2.42s/trial, best loss: -0.8401410657281506]\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007454 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 78%|███████▊  | 39/50 [01:36<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[46]\ttraining's binary_logloss: 0.119454\tvalid_1's binary_logloss: 0.135326\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009127 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[39]\ttraining's binary_logloss: 0.121636\tvalid_1's binary_logloss: 0.136171\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:37<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:38<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 78%|███████▊  | 39/50 [01:38<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008580 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 78%|███████▊  | 39/50 [01:38<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 78%|███████▊  | 39/50 [01:38<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 78%|███████▊  | 39/50 [01:38<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:38<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 78%|███████▊  | 39/50 [01:38<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 78%|███████▊  | 39/50 [01:38<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 78%|███████▊  | 39/50 [01:38<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 78%|███████▊  | 39/50 [01:38<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[43]\ttraining's binary_logloss: 0.120504\tvalid_1's binary_logloss: 0.136376\n\r 78%|███████▊  | 39/50 [01:38<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 78%|███████▊  | 39/50 [01:38<00:29,  2.68s/trial, best loss: -0.8401410657281506]\r 80%|████████  | 40/50 [01:38<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:38<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:38<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:38<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 80%|████████  | 40/50 [01:38<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008975 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 80%|████████  | 40/50 [01:38<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 80%|████████  | 40/50 [01:38<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 80%|████████  | 40/50 [01:38<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:38<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:38<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[43]\ttraining's binary_logloss: 0.114799\tvalid_1's binary_logloss: 0.135355\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010786 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 80%|████████  | 40/50 [01:39<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[32]\ttraining's binary_logloss: 0.119583\tvalid_1's binary_logloss: 0.136884\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010068 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12895\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 80%|████████  | 40/50 [01:40<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[37]\ttraining's binary_logloss: 0.117254\tvalid_1's binary_logloss: 0.136219\n\r 80%|████████  | 40/50 [01:41<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 80%|████████  | 40/50 [01:41<00:25,  2.54s/trial, best loss: -0.8401410657281506]\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008405 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12931\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[41]\ttraining's binary_logloss: 0.114041\tvalid_1's binary_logloss: 0.135758\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:41<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007557 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12930\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[30]\ttraining's binary_logloss: 0.11895\tvalid_1's binary_logloss: 0.137068\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008607 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12937\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 82%|████████▏ | 41/50 [01:42<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 82%|████████▏ | 41/50 [01:43<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 82%|████████▏ | 41/50 [01:43<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 82%|████████▏ | 41/50 [01:43<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[36]\ttraining's binary_logloss: 0.115662\tvalid_1's binary_logloss: 0.136485\n\r 82%|████████▏ | 41/50 [01:43<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 82%|████████▏ | 41/50 [01:43<00:23,  2.59s/trial, best loss: -0.8401410657281506]\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007897 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12968\n\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 84%|████████▍ | 42/50 [01:43<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.124337\tvalid_1's binary_logloss: 0.136185\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007875 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12940\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 84%|████████▍ | 42/50 [01:44<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.124676\tvalid_1's binary_logloss: 0.136978\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008982 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12989\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.124605\tvalid_1's binary_logloss: 0.13651\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 84%|████████▍ | 42/50 [01:45<00:19,  2.42s/trial, best loss: -0.8401410657281506]\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007514 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 86%|████████▌ | 43/50 [01:46<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[88]\ttraining's binary_logloss: 0.113571\tvalid_1's binary_logloss: 0.135507\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008891 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 86%|████████▌ | 43/50 [01:47<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[92]\ttraining's binary_logloss: 0.113631\tvalid_1's binary_logloss: 0.136665\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007723 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12927\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 86%|████████▌ | 43/50 [01:48<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[72]\ttraining's binary_logloss: 0.117206\tvalid_1's binary_logloss: 0.136248\n\r 86%|████████▌ | 43/50 [01:49<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 86%|████████▌ | 43/50 [01:49<00:17,  2.50s/trial, best loss: -0.8401410657281506]\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008905 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 88%|████████▊ | 44/50 [01:49<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[55]\ttraining's binary_logloss: 0.113718\tvalid_1's binary_logloss: 0.135566\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007600 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[50]\ttraining's binary_logloss: 0.11545\tvalid_1's binary_logloss: 0.136695\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:50<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:51<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 88%|████████▊ | 44/50 [01:51<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007699 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 88%|████████▊ | 44/50 [01:51<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12895\n\r 88%|████████▊ | 44/50 [01:51<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 88%|████████▊ | 44/50 [01:51<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:51<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 88%|████████▊ | 44/50 [01:51<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 88%|████████▊ | 44/50 [01:51<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 88%|████████▊ | 44/50 [01:51<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 88%|████████▊ | 44/50 [01:51<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[47]\ttraining's binary_logloss: 0.11622\tvalid_1's binary_logloss: 0.13621\n\r 88%|████████▊ | 44/50 [01:51<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 88%|████████▊ | 44/50 [01:51<00:16,  2.70s/trial, best loss: -0.8401410657281506]\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007271 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 90%|█████████ | 45/50 [01:51<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[78]\ttraining's binary_logloss: 0.118204\tvalid_1's binary_logloss: 0.135158\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008255 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 90%|█████████ | 45/50 [01:52<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[61]\ttraining's binary_logloss: 0.121472\tvalid_1's binary_logloss: 0.136311\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007988 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[66]\ttraining's binary_logloss: 0.120258\tvalid_1's binary_logloss: 0.135811\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 90%|█████████ | 45/50 [01:53<00:13,  2.63s/trial, best loss: -0.8401410657281506]\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009441 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[43]\ttraining's binary_logloss: 0.118438\tvalid_1's binary_logloss: 0.134946\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009510 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:54<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[35]\ttraining's binary_logloss: 0.121187\tvalid_1's binary_logloss: 0.136716\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014955 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 92%|█████████▏| 46/50 [01:55<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[38]\ttraining's binary_logloss: 0.120031\tvalid_1's binary_logloss: 0.136103\n\r 92%|█████████▏| 46/50 [01:56<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 92%|█████████▏| 46/50 [01:56<00:10,  2.55s/trial, best loss: -0.8401410657281506]\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010003 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.123968\tvalid_1's binary_logloss: 0.137192\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009865 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 94%|█████████▍| 47/50 [01:56<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.124124\tvalid_1's binary_logloss: 0.137834\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011321 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12833\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 94%|█████████▍| 47/50 [01:57<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[100]\ttraining's binary_logloss: 0.124074\tvalid_1's binary_logloss: 0.137653\n\r 94%|█████████▍| 47/50 [01:58<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 94%|█████████▍| 47/50 [01:58<00:07,  2.41s/trial, best loss: -0.8401410657281506]\r 96%|█████████▌| 48/50 [01:58<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [01:58<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [01:58<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [01:59<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 96%|█████████▌| 48/50 [01:59<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008261 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 96%|█████████▌| 48/50 [01:59<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 96%|█████████▌| 48/50 [01:59<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 96%|█████████▌| 48/50 [01:59<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [01:59<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [01:59<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 96%|█████████▌| 48/50 [01:59<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 96%|█████████▌| 48/50 [01:59<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 96%|█████████▌| 48/50 [01:59<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[89]\ttraining's binary_logloss: 0.112538\tvalid_1's binary_logloss: 0.135863\n\r 96%|█████████▌| 48/50 [01:59<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007792 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12838\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 96%|█████████▌| 48/50 [02:00<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[85]\ttraining's binary_logloss: 0.113782\tvalid_1's binary_logloss: 0.136966\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008718 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12786\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 189\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 96%|█████████▌| 48/50 [02:01<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \rDid not meet early stopping. Best iteration is:\n[82]\ttraining's binary_logloss: 0.11439\tvalid_1's binary_logloss: 0.136229\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 96%|█████████▌| 48/50 [02:02<00:04,  2.49s/trial, best loss: -0.8401410657281506]\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007612 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12871\n\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 98%|█████████▊| 49/50 [02:02<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[54]\ttraining's binary_logloss: 0.116715\tvalid_1's binary_logloss: 0.135332\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1634, number of negative: 38910\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007527 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12901\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040302 -> initscore=-3.170220\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.170220\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[46]\ttraining's binary_logloss: 0.119685\tvalid_1's binary_logloss: 0.136482\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:03<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of positive: 1626, number of negative: 38918\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011639 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Total Bins 12927\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040105 -> initscore=-3.175334\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Info] Start training from score -3.175334\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \rTraining until validation scores don't improve for 30 rounds\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \rEarly stopping, best iteration is:\n[42]\ttraining's binary_logloss: 0.120545\tvalid_1's binary_logloss: 0.135894\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r                                                                                  \r[LightGBM] [Warning] Unknown parameter: eval_metric\n\r 98%|█████████▊| 49/50 [02:04<00:02,  2.83s/trial, best loss: -0.8401410657281506]\r100%|██████████| 50/50 [02:04<00:00,  2.65s/trial, best loss: -0.8401410657281506]\r100%|██████████| 50/50 [02:04<00:00,  2.49s/trial, best loss: -0.8401410657281506]\n{'learning_rate': 0.055108871382598304, 'max_depth': 123.0, 'min_child_samples': 96.0, 'num_leaves': 32.0, 'subsample': 0.8742157574210713}\n```\n:::\n:::\n\n\n### 재학습\n\n::: {#3d5bea57 .cell execution_count=15}\n``` {.python .cell-code}\nlgbm_clf = LGBMClassifier(n_estimators=500, \n                          num_leaves=int(best['num_leaves']),\n                          max_depth=int(best['max_depth']),\n                          min_child_samples=int(best['min_child_samples']),\n                          subsample=round(best['subsample'], 5),\n                          learning_rate=round(best['learning_rate'], 5),\n                          early_stopping_rounds=100, \n                          eval_metric='auc')\n\neval_set = [(X_tr, y_tr), (X_val, y_val)]\nlgbm_clf.fit(X_tr, y_tr, eval_set=eval_set)\n\nlgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\nprint(f'{lgbm_roc_score:.3f}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Info] Number of positive: 1743, number of negative: 40828\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008662 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 12991\n[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 192\n[LightGBM] [Warning] Unknown parameter: eval_metric\n[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040943 -> initscore=-3.153760\n[LightGBM] [Info] Start training from score -3.153760\nTraining until validation scores don't improve for 100 rounds\nEarly stopping, best iteration is:\n[69]\ttraining's binary_logloss: 0.121536\tvalid_1's binary_logloss: 0.131346\n[LightGBM] [Warning] Unknown parameter: eval_metric\n0.828\n```\n:::\n:::\n\n\n## 제출\n\n::: {#b911f0e7 .cell execution_count=16}\n``` {.python .cell-code}\ntarget = lgbm_clf.predict(test_df)\n\nsubmit = pd.read_csv('_data/santander/sample_submission.csv', encoding='latin-1')\nsubmit['TARGET'] = target\nsubmit.to_csv('_data/santander/submission.csv', encoding='latin-1', index=False)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[LightGBM] [Warning] Unknown parameter: eval_metric\n```\n:::\n:::\n\n\n",
    "supporting": [
      "03_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}