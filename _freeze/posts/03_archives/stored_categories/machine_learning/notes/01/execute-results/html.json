{
  "hash": "2ef98fda0d2bfd59bbe841de83af1b3e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"data preprocessing\"\ndate: 2025-02-26\ncategories: [\"machine learning\"]\n---\n\n\n\n\n![](/img/stat-thumb.jpg){.post-thumbnail}\n\n## Load Library and data\n\n::: {#efb01a86 .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndataset = pd.read_csv('_data/00-data.csv')\nx = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n```\n:::\n\n\n::: {#57b7a7e7 .cell execution_count=2}\n``` {.python .cell-code}\nx\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\narray([['France', 44.0, 72000.0],\n       ['Spain', 27.0, 48000.0],\n       ['Germany', 30.0, 54000.0],\n       ['Spain', 38.0, 61000.0],\n       ['Germany', 40.0, nan],\n       ['France', 35.0, 58000.0],\n       ['Spain', nan, 52000.0],\n       ['France', 48.0, 79000.0],\n       ['Germany', 50.0, 83000.0],\n       ['France', 37.0, 67000.0]], dtype=object)\n```\n:::\n:::\n\n\n::: {#0c70861e .cell execution_count=3}\n``` {.python .cell-code}\ny\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\narray(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n      dtype=object)\n```\n:::\n:::\n\n\n## Taking care of Missing data\n\n1. delete\n1. replace\n\n::: {#396e3e82 .cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer.fit(x[:, 1:3])\nx[:, 1:3] = imputer.transform(x[:, 1:3])\nprint(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[['France' 44.0 72000.0]\n ['Spain' 27.0 48000.0]\n ['Germany' 30.0 54000.0]\n ['Spain' 38.0 61000.0]\n ['Germany' 40.0 63777.77777777778]\n ['France' 35.0 58000.0]\n ['Spain' 38.77777777777778 52000.0]\n ['France' 48.0 79000.0]\n ['Germany' 50.0 83000.0]\n ['France' 37.0 67000.0]]\n```\n:::\n:::\n\n\n## Encoding Cagegorical data\n\n- 단순히 categorical 변수를 1, 2, 3으로 변형하면 순서가 고려된 것으로 간주될 수 있다.\n- 그래서 [0, 0, 1], [1, 0, 1] 이런 식으로 one hot encoding을 진행한다.\n\n::: {#2e650771 .cell execution_count=5}\n``` {.python .cell-code}\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nx = np.array(ct.fit_transform(x))\nprint(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1.0 0.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [0.0 1.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [0.0 1.0 0.0 40.0 63777.77777777778]\n [1.0 0.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [1.0 0.0 0.0 48.0 79000.0]\n [0.0 1.0 0.0 50.0 83000.0]\n [1.0 0.0 0.0 37.0 67000.0]]\n```\n:::\n:::\n\n\n::: {#521de896 .cell execution_count=6}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ny = le.fit_transform(y)\nprint(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[0 1 0 0 1 1 0 1 0 1]\n```\n:::\n:::\n\n\n## Split dataset into training set and test set\n\n- feature scaling 이전에 진행되어야함. (test set은 모델이 모르는 정보가 되야하기 때문)\n\n::: {#bfe8e56c .cell execution_count=7}\n``` {.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n```\n:::\n\n\n## feature scaling\n\n::: {#82d55d12 .cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\nX_test[:, 3:] = sc.transform(X_test[:, 3:])\n```\n:::\n\n\n::: {#f1ce28c4 .cell execution_count=9}\n``` {.python .cell-code}\nprint(X_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n [0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]\n [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n [1.0 0.0 0.0 0.566708506533324 0.633562432710455]]\n```\n:::\n:::\n\n\n::: {#88307253 .cell execution_count=10}\n``` {.python .cell-code}\nprint(X_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n```\n:::\n:::\n\n\n",
    "supporting": [
      "01_files"
    ],
    "filters": [],
    "includes": {}
  }
}