[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "Inboxes\n\n\n\n\n\n\n분류되지 않은 노트 (1)\n    \n\n\n\nTitle\nDate\nCategories\n\n\n\n\n인간 관계론 - 데일 카네기\n2025-02-02\n독서, 인간 관계\n\n\n\n\n    \n\n\n\n\n\n\n\n\nProjects\n\n\n\n\n\n현재 진행중인 프로젝트\n\n\n\n\n    \n    \n    \n        \n            \n                \n                    ADP 필기 준비\n                    on-going\n                \n                \n                    Started: 2025-02-02\n                    \n                    Calculating...\n                \n                \n                    자격증 데이터 분석\n                \n                과연 2번째 도전은 성공할 것인가\n            \n        \n        \n        \n            \n                \n                    학부 3학년 1학기\n                    on-going\n                \n                \n                    Started: 2024-12-21\n                    \n                    Calculating...\n                \n                \n                    산업공학 학부\n                \n                3학년 1학기 학부 할 일 총 정리\n            \n        \n        \n\n\n\n\n\n\n\n\nAreas\n\n\n\n\n\n관리 / 책임 영역\n\n\n\n\n    \n    \n        \n            Blog\n        \n        \n        \n            42 Seoul\n        \n        \n        \n            선형대수\n        \n        \n        \n            Terraform\n        \n        \n\n\n\n\n\n\n\n\nResources\n\n\n\n\n\n진행 전인 프로젝트\n\n\n\n\n    \n    \n    \n        \n            \n                \n                    TOFEL 준비\n                    before-start\n                \n                \n                    Started: None\n                    \n                    Calculating...\n                \n                \n                    English\n                \n                준비해 봅시다\n            \n        \n        \n\n\n\n관심 분야\n\n\n\n\n    \n    \n        \n            Problem Solving\n        \n        \n        \n            금융\n        \n        \n\n\n\n\n\n\n\n\nArchives\n\n\n\n\n\n완료된 프로젝트\n\n\n\n\n    \n    \n    \n        \n            \n                \n                    ADP 실기 준비\n                    failed\n                \n                \n                    Started: 2024-12-21\n                    \n                    Calculating...\n                \n                \n                    자격증 데이터 분석 python\n                \n                ADP 실기를 준비해 봅시다.\n            \n        \n        \n        \n            \n                \n                    AWS SAA 준비\n                    completed\n                \n                \n                    Started: 2024-04-15\n                    \n                    Calculating...\n                \n                \n                    자격증 cloud\n                \n                AWS SAA를 준비해 봅시다.\n            \n        \n        \n        \n            \n                \n                    2학년 2학기 학부 정리\n                    completed\n                \n                \n                    Started: 2024-09-02\n                    \n                    Calculating...\n                \n                \n                    산업공학 학부\n                \n                2학년 2학기 학부 개념 정리\n            \n        \n        \n\n\n\n보관중인 자료\n\n\n\n\n    \n    \n        \n            vault\n        \n        \n        \n            k8s"
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/scholarships/1.html",
    "href": "posts/01_projects/bs_3_1/notes/scholarships/1.html",
    "title": "자기 소개서",
    "section": "",
    "text": "자기소개 및 가치관 (500자 이내)\n\n저는 데이터 분석과 IT 인프라 설계 분야에 깊은 관심을 가지고 있는 산업공학과 학생입니다. 산업공학을 전공하며 시스템 최적화와 데이터 기반 의사결정에 대한 이론을 배우며 데이터 분석 및 IT 인프라 설계 분야에 관심을 가지게 되었고, 이를 실무에 적용할 수 있는 지식을 학습하고자 42서울 교육기관에서 2년 동안 IT 관련 학습을 진행했습니다. 또한 이 기간 동안 AWS와 ADsP(Advanced Data Analytics Semi-Professional) 자격증을 취득하며 클라우드 컴퓨팅과 데이터 분석에 대한 기초 역량을 쌓았습니다.\n저는 효율적이고 신뢰할 수 있는 시스템을 구축하는 것을 가장 중요한 가치로 삼고 있습니다. 이러한 시스템은 데이터 손실과 보안 위협을 방지할 뿐만 아니라, 장기적인 성장의 토대가 되기 때문입니다. 현재는 데이터와 블록체인 기술을 활용하여 복잡한 문제를 단순화하고, 효율적인 해결책을 찾는 데 큰 관심을 가지고 있습니다. 앞으로도 지속적인 학습과 경험을 통해 해당 분야에서 전문성을 키워가고자 합니다.\n\n졸업 후 IT 및 블록체인 분야에 관련해서 이루고자 하는 꿈과 선정 사유 (500자 이내)\n\n저는 데이터 분석, IT 인프라, 블록체인 기술을 융합하여 현실의 복잡한 문제들을 해결하고 혁신적인 가치를 창출하는 데 기여하고 싶습니다. 전공 수업과 프로젝트를 통해 데이터가 지닌 잠재력을 배워가면서, 동시에 데이터의 신뢰성과 보안이라는 중요한 과제에 대해서도 깊이 고민하게 되었습니다. 특히 42서울에서의 학습 경험을 통해, 안전하고 효율적인 데이터 활용을 위해서는 IT 인프라와 블록체인 기술의 역할이 매우 중요하다는 것을 깨달았습니다. 이러한 경험들을 바탕으로 IT 인프라와 블록체인 기술에 더욱 관심을 가지게 되었고, 관련 기술 서적과 온라인 자료를 통해 꾸준히 학습하며 이해의 폭을 넓혀가고 있습니다. 앞으로도 끊임없이 배우고 성장하여 데이터의 가치를 안전하게 실현할 수 있는 시스템을 만드는 데 기여하고 싶습니다.\n\n목표 달성을 위한 그간의 성과 및 계획 (500자 이내)\n\n저의 주요 성과로는 42서울에서의 프로젝트 경험과 AWS, ADsP 자격증 취득을 들 수 있습니다. 42서울에서 진행한 Solidity 기반 이더리움 스마트 컨트랙트 설계 및 배포 프로젝트를 통해 블록체인의 핵심 원리와 실제 활용 방안을 학습했습니다. 또한 Vagrant, Kubernetes(K8s), ArgoCD, GitLab helm 배포 프로젝트를 수행하며 온프레미스 환경에서의 인프라 설계와 개발 환경 관리 역량을 키웠고, 이를 통해 클라우드와 온프레미스 환경의 IT 인프라 운영에 대한 실질적인 이해도를 높일 수 있었습니다. 향후 계획으로는 학부 과정에 충실히 임하면서 데이터사이언스 대학원 진학을 위한 준비를 체계적으로 진행하고자 합니다. 대학원에서는 빅데이터 처리, 머신러닝, 딥러닝 등 데이터 분석의 핵심 기술을 심도 있게 학습하고자 합니다. 이와 병행하여 온라인 강좌 수강과 실전 프로젝트 수행을 통해 IT 인프라 및 블록체인 분야의 역량을 지속적으로 강화하고, 각종 공모전 참여를 통해 실력을 검증받고자 합니다. 궁극적으로는 이러한 기술들을 융합하여 데이터의 신뢰성과 보안을 보장하고, 효율적인 시스템을 설계하는 전문가로 성장하고 싶습니다.\n\n\n\n 맨 위로",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Scholarships",
      "자기 소개서"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/2.html",
    "href": "posts/01_projects/bs_3_1/notes/OR/2.html",
    "title": "Integer Programming",
    "section": "",
    "text": "all or nothing problem에서 사용\nex) knapsack problem → 아이템을 0.8개 넣을 수 없다",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Integer Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/2.html#requirements-on-selecting-variables",
    "href": "posts/01_projects/bs_3_1/notes/OR/2.html#requirements-on-selecting-variables",
    "title": "Integer Programming",
    "section": "Requirements on selecting variables",
    "text": "Requirements on selecting variables\n\nAt Least\nat least one of variables among items 1, 3, 4:\n\\(x_1 + x_3 + x_4 ≥ 1\\)\nAt Most\nat most two of variables among items 1, 3, 4:\n\\(x_1 + x_3 + x_4 ≤ 2\\)\nOr\nselect variable 1 or 2:\n\\(x_1 + x_2 ≥ 1\\)\nselect 2 otherwise item 3 and 4 together:\n\\(2x_2 + x_3 + x_4 ≥ 2\\)\nIf-else\nif variable 1 is selected, then variable 2 is also selected:\n\\(x_1 ≤ x_2\\)\nif variable 1 is selected, do not select item 3 and 4:\n\\(2(1 - x_1) ≥ x_3 + x_4\\)",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Integer Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/2.html#at-leastmost-some-constraints",
    "href": "posts/01_projects/bs_3_1/notes/OR/2.html#at-leastmost-some-constraints",
    "title": "Integer Programming",
    "section": "At least/most some constraints",
    "text": "At least/most some constraints\nconstraints를 유연하게 선택하는 방법\n\\(g_1(x) ≤ b_1\\)과 \\(g_2(x) ≥ b_2\\)를 둘 다 만족하는 경우를 표현하려면 union으로 표현할 수 있다.\n이는 linear program에 적합하지 않기 때문에 variable로 표현한다.\n\\[z = \\begin{cases}\n0 & \\text{if } g_1(x) ≤ b_1 \\\\\n1 & \\text{if } g_2(x) ≤ b_2\n\\end{cases}\\]\n이는 아래의 수식으로 표현할 수 있다\n\\[\\begin{align}\n&g_1(x) - b_1 ≤ M_1z \\\\\n&g_2(x) - b_2 ≤ M_2(1 - z)\n\\end{align}\\]\n이때\\(M_1\\)과 \\(M_2\\)는 충분히 큰 상수이다.",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Integer Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/2.html#일반적인-예시",
    "href": "posts/01_projects/bs_3_1/notes/OR/2.html#일반적인-예시",
    "title": "Integer Programming",
    "section": "일반적인 예시",
    "text": "일반적인 예시\nFacility location problem\n\nwhere to open convenience stores?\nwhere to build warehouses or distribution centers?\nwhere to build factories?\nwhere to build power stations, fire stations, or police stations?\n\n→ where to locate scarce resource?\ndemoand nodes potential locations\n\nset covering problem\nmaximum covering problem\nfixed charge location problem\n\n\nmachine scheduling problem\n\nproduction mode\n\nsingle machine serial production\nmultiple parallel machines\nflow shop scheduling: all jobs must follow the same sequence\njob shop scheduling: each job has its own sequence\n\n\n\njob splitting\n\npreemptive problem: 특정 작업을 중단하고 시급한 다른 작업을 수행한 후, 다시 돌아올 수 있음\nnon-preemptive problem\n\n\n\nperformance measurement\n\nMakespan: 모든 작업이 끝나는 시간\ntotal completion time\nnumber of delayed jobs\ntotal lateness: completion time이 due time보다 앞서는 경우 negative lateness\ntotal tardiness: completion time이 due time보다 뒤에 있는 경우에만 completion time - due time, 그 외 0",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Integer Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/0.html#process-of-conducting-an-or-study",
    "href": "posts/01_projects/bs_3_1/notes/OR/0.html#process-of-conducting-an-or-study",
    "title": "Overview",
    "section": "process of conducting an OR study",
    "text": "process of conducting an OR study\n\n\n\n\n\nflowchart TD\n  A(Collect data) --&gt; B(Define the problem)\n  B --&gt; C{Data are sufficient?}\n  C --&gt;|No| A\n  C --&gt;|Yes| D(Formulate a model)\n  D --&gt; E(Solve the model)\n  E --&gt; F{Model is good?}\n  F --&gt;|Yes| G(Interpret results make suggestions)\n  F --&gt;|No| D\n\n\n\n\n\n\n\nOR cant solve everything\nAim of course: know what may be solved by OR and what cannot be solve by OR",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Overview"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/0.html#model",
    "href": "posts/01_projects/bs_3_1/notes/OR/0.html#model",
    "title": "Overview",
    "section": "model",
    "text": "model\n\ndescision variables\nobjective function\nconstraints\n\n\nKnapSack(backpack) Problem\n\nLinear Programming\n\n\\[\\begin{aligned}\nmax & \\sum_{i=1}^{n} v_i x_i \\\\\ns.t. & \\sum_{i=1}^{n} w_i x_i \\leq B \\\\\n& 0 \\leq x_i \\leq 1\n\\end{aligned}\\]\n\nInteger Programming\n\n\\[\\begin{aligned}\nmax & \\sum_{i=1}^{n} v_i x_i \\\\\ns.t. & \\sum_{i=1}^{n} w_i x_i \\leq B \\\\\n& x_i \\in \\{0, 1\\}\n\\end{aligned}\\]",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Overview"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/index.html",
    "href": "posts/01_projects/adp_필기/index.html",
    "title": "ADP 필기 준비",
    "section": "",
    "text": "ON-GOING\n    \n    \n        시작일: 2025-02-02\n        종료일: 2025-02-22\n    \n    \n        \n            \n        \n        계산 중...\n    \n    \n    \n        자격증데이터 분석",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/index.html#details",
    "href": "posts/01_projects/adp_필기/index.html#details",
    "title": "ADP 필기 준비",
    "section": "Details",
    "text": "Details\n1회차 시도는 실패했지만, 이번엔 잘 되겠죠",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/index.html#참고-자료",
    "href": "posts/01_projects/adp_필기/index.html#참고-자료",
    "title": "ADP 필기 준비",
    "section": "참고 자료",
    "text": "참고 자료\n\n왜 2025버전 안내주는지 모르겠는 참고서\n머신러닝 유튜브\n이 통계 유튜브\n이 블로그 글",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/index.html#tasks",
    "href": "posts/01_projects/adp_필기/index.html#tasks",
    "title": "ADP 필기 준비",
    "section": "Tasks",
    "text": "Tasks\n\n\n\n    \n    \n    \n            \n                \n                    \n                    원서 접수 (2025.01.20 10 am)\n                \n                2025.02.22 10:00 수원공업고등학교",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/index.html#related-posts",
    "href": "posts/01_projects/adp_필기/index.html#related-posts",
    "title": "ADP 필기 준비",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/05.html",
    "href": "posts/01_projects/adp_필기/notes/통계/05.html",
    "title": "회귀 분석",
    "section": "",
    "text": "예측을 위해 사용",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "회귀 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/05.html#가정",
    "href": "posts/01_projects/adp_필기/notes/통계/05.html#가정",
    "title": "회귀 분석",
    "section": "가정",
    "text": "가정\n\n선형성: 독립변수와 종속변수 사이에 선형관계가 존재\n정규성: 독립변수 값에 대응되는 종속변수 값들의 분포가 정규분포를 따름\n\n대각선을 따라야함\n\n등분산성: 독립변수 값에 대응되는 종속변수 값들의 분산이 동일\n\n수평선을 따라야함\n\n독립성: 모든 관측값은 서로 독립\n\n→ 가정을 충족하지 않을 경우, 회귀모델을 수정해야함\n\n이상치 → 관측값 제거\n선형성 → 독립변수 변환\n정규성, 등분산성 미충족 → 종속변수 변환\n\n변환: \\(x\\) → \\(x^λ\\)",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "회귀 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/05.html#다중공선성",
    "href": "posts/01_projects/adp_필기/notes/통계/05.html#다중공선성",
    "title": "회귀 분석",
    "section": "다중공선성",
    "text": "다중공선성\n\n독립변수들 간에 강한 상관관계가 존재하는 경우\n\nVIF: 10 이상이면 다중공선성이 존재한다고 판단 (\\(\\frac{1}{1-R^2}\\))\n→ 변수 제거\n\n\n\n전진 선택법: 상수항부터 시작해, 한번에 한개씩 독립변수 추가\n후진 선택법: 모든 독립변수를 포함한 후, 하나씩 제거. AIC가 더 이상 작아지지 않을 때까지\n단계 선택법: 전진, 후진 선택법을 혼합. 이미 선택된 변수를 제거할 수 있음",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "회귀 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/04.html#피어슨-상관계수",
    "href": "posts/01_projects/adp_필기/notes/통계/04.html#피어슨-상관계수",
    "title": "상관 분석",
    "section": "피어슨 상관계수",
    "text": "피어슨 상관계수\n\n정규성의 가정 필요",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "상관 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/04.html#스피어만-상관계수",
    "href": "posts/01_projects/adp_필기/notes/통계/04.html#스피어만-상관계수",
    "title": "상관 분석",
    "section": "스피어만 상관계수",
    "text": "스피어만 상관계수\n\n이상치에 덜 민감",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "상관 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/03.html#etl",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/03.html#etl",
    "title": "2 - 데이터 처리 프로세스",
    "section": "ETL",
    "text": "ETL\n\n1. ETL 개요\n\nETL(Extract, Transformation, Load): 데이터 이동 및 변환 절차\nbatch ETL, real-time ETL으로 나뉨\n\n\n\n\nETL 작업 단계\n\n\n\nInterface: 다양한 소스로부터 데이터 휙득을 위한 인터페이스(OLEDB, ODBC, FTP)\nStaging: 정기적으로 데이터 원천으로 부터 저장. 아직은 정규화 x\nProfiling: staging table의 데이터 특성을 식별하고, 품질 측정\nCleansing: profiling된 데이터를 보정\nIntegration: 데이터 충돌을 해소하고, 데이터를 통합. 아마 여기서 정규화가 이루어질듯(왜 책에 설명 똑바로 안해놓지)\nExport: 운영보고서 생성, 데이터웨어하우스 / 데이터마트에 적재하기 위한 최적화(denormalization) 진행\n\n\n\n2. ODS 구성\n\n통합된 데이터를 저정하는 중간 저장소\n실시간, 거의 실시간으로 데이터 적재\n\n\n\n3. 데이터 웨어하우스\n\nODS를 통해 정제 / 통합된 데이터를 분석 및 보고서 생성을 위해 저장\n\n특징\n\n주제중심성\n영속성/비휘발성\n통합성\n시계열성\n\n모델링 기법\n\n스타 스키마(조인 스키마)\n\n제 3정규형의 fact 테이블과 제 2정규형의 차원 테이블로 구성\n복잡성이 낮지만, 데이터 무결성이 떨어짐\n\n\n\n\n스노우플레이크 스키마\n\n스타 스키마의 차원 테이블을 제 3정규형으로 정규화한 상태\n데이터 무결성이 높지만, 복잡성이 높음\n\n\n\n\n\n\n\n\n\n제 1 정규형: 반복되는 record나 다치 attribute를 포함하지 않음 제 2 정규형: 부분 종속성(primary key의 일부가 다른 일부를 종속함)이 없음 제 3 정규형: 이행적 종속성(primary key가 아닌 attribute의 종속성)이 없음\n\n\n\n\n\n4. ODS vs DW",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "2 - 데이터 처리 프로세스"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/03.html#cdcchange-data-capture",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/03.html#cdcchange-data-capture",
    "title": "2 - 데이터 처리 프로세스",
    "section": "CDC(change data capture)",
    "text": "CDC(change data capture)\n\n1. CDC 개념 및 특징\n\n데이터 변경을 감지하고, 변경된 데이터를 추출하는 기술\n하드웨어 계층부터 어플리케이션 계층까지 다양한 수준에서 적용 가능\n\n\n\n2. CDC 구현 기법\n\nTime Stamp on Rows\nVersion Numbers on Rows: 참조테이블을 같이 사용하는게 일반적이라고 한다.\nStatus on Rows: time stamp, version number 보완 용도로, 사람이 레코드 반영 여부를 직접 판단할 수 있게 적용할 수 있음\nTime/Version/Status on Rows\nTriggers on Tables: message queue로 변경 발생시 subscribe 된 대상에 publish하는 방식. 시스템 관리 복잡도가 높아짐\nEvent Programming: 어플리케이션에 데이터 변경 식별 기능을 추가\nLog Scanner on Database: 데이터 스키마 변경 불필요, 어플리케이션 영향 최소화, 지연시간 최소화\n\n\n\n3. CDC 구현 방식\n\nPush: 데이터 원천에서 변경 식별(agent)\nPull: 대상 시스템에서 원천을 주기적으로 모니터링",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "2 - 데이터 처리 프로세스"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/03.html#eai",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/03.html#eai",
    "title": "2 - 데이터 처리 프로세스",
    "section": "EAI",
    "text": "EAI\n\n1. EAI의 개념 및 특징\n\n기업 내 혹은 기업 간 정보시스템을 연계하여 동기화.\nETL은 batch 처리 중심, EAI는 실시간 혹은 근접 실시간 처리 중심\n\n\n\n2. 데이터 연계 방식\n\n\nETL/CDC는 운영 데이터와 분석을 위한 데이터베이스가 구분되지만, EAI는 그냥 통합\n\n\n\n3. EAI 구성요소\n\nAdapter: 시스템 간 데이터 변환\nBroker: 데이터 전송\nBus: 데이터 전송 경로 설정\nTransformer: 데이터 형식 변환\n\n\n\n4. EAI 구현 유형\n\nMediation: Publish/Subscribe 방식\nFederaion: Request/Reply 방식\n\n\n\n5. EAI 활용 효과\n\n협력사, 파트너, 고객과의 상호 협력 프로세스 연계\n그룹 및 지주 회사 계열사들 간 상호 관련 데이터 동기화 등을 위한 데이터 표준화 기반 제공\n\n\n\n6. EAI vs ESB\n\n추가적인 자료",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "2 - 데이터 처리 프로세스"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/03.html#데이터-통합-및-연계-기법",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/03.html#데이터-통합-및-연계-기법",
    "title": "2 - 데이터 처리 프로세스",
    "section": "데이터 통합 및 연계 기법",
    "text": "데이터 통합 및 연계 기법\n\n\n빅데이터는 시각화도 하고, NoSQL 같은 환경에서도 사용한다.",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "2 - 데이터 처리 프로세스"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/03.html#대용량의-비정형-데이터-처리-방법",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/03.html#대용량의-비정형-데이터-처리-방법",
    "title": "2 - 데이터 처리 프로세스",
    "section": "대용량의 비정형 데이터 처리 방법",
    "text": "대용량의 비정형 데이터 처리 방법\n\n2. 대규모 분산 병렬 처리\n\n하둡:\n\nMapReduce와 HDFS를 기반으로 한 분산 병렬 처리 프레임워크\n비공유 분산 아키텍쳐\n선형적인 성능과 용량 확장\nMapReduce failover\n\n\n\nHadoop ecosystem\n\n\n\n3. 데이터 연동\n대규모 연산을 데이터베이스에서 처리하기 어렵기 때문에, 하둡으로 복사해와서 MapReduce 연산 후, 결과를 다시 데이터베이스에 기록하기 위해 스쿱 사용\n\nSqoop\n\nJDBC를 지원하는 RDBMS, Hbase와 Hadoop 간 데이터 전송(Import, Export)\nSQL 질의로 데이터 추출\nMapReduce 사용\n\n\n\n\n4. 데이터 질의 기술\n\nHive: SQL과 유사한 HiveQL 질의, batch 처리\nSQL on Hadoop: SQL 질의, 실시간 처리\n\napache Drill, Stinger, Shark, Tajo, Impala, HAWQ, Presto",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "2 - 데이터 처리 프로세스"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/05.html#분석-과제-발굴",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/05.html#분석-과제-발굴",
    "title": "3 - 데이터 분석 기획의 이해",
    "section": "분석 과제 발굴",
    "text": "분석 과제 발굴\n\n풀어야 할 다양한 문제를 데이터 분석 문제로 변환 후, 프로젝트를 수행할 수 있는 과제 정의서 형태로 도출\n\n\n\n\n도출을 위한 접근 방법\n\n\n최적의 의사결정은 두 접근 방식이 상호 보완 관계에 있을 때 가능하다.\n\n\n1. 하향식 접근법\n\n사물을 why 관점에서 보는 방식\n\n\n\n문제 탐색: 문제를 해결함으로써 발생하는 가치에 중점\n\n비즈니스 모델기반\n분석 기회 발굴의 범위 확장\n외부참조 모델 기반\n분석 유즈 케이스\n\n문제 정의: 식별된 비즈니스 문제를 데이터의 문제로 변환\n해결방안 탐색: 분석 역량과, 분석 기법 및 시스템 존재 여부를 고려한다.\n타당성 검토\n\n경제적 타당성: 비용대비 편익 분석 관점의 접근\n데이터 및 기술적 타당성\n\n\n\n\n2. 상향식 접근법\n\n사물을 what 관점에서 보는 방식\n\n\n비지도 학습\n지도 학습\n\n\n프로토타이핑 접근법",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "3 - 데이터 분석 기획의 이해"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/05.html#분석-기획-방향성-도출",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/05.html#분석-기획-방향성-도출",
    "title": "3 - 데이터 분석 기획의 이해",
    "section": "분석 기획 방향성 도출",
    "text": "분석 기획 방향성 도출\n\n1. 분석기획의 특징\n\n과제를 발굴, 정의하고 의도했던 결과를 도출할 수 있도록 적절하게 관리할 수 있는 방안을 사전에 계획하는 일련의 작업 (말 그대로 기획)\n\n\n\n3. 목표 시점 별 분석 기획 방안\n\n\n\n4. 분석 기획시 고려사항\n\n가용 데이터\n적절한 활용방안과 유즈케이스\n장애요소들에 대한 사전계획 수립",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "3 - 데이터 분석 기획의 이해"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/05.html#분석-방법론",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/05.html#분석-방법론",
    "title": "3 - 데이터 분석 기획의 이해",
    "section": "분석 방법론",
    "text": "분석 방법론\n\n방법론은 절차, 방법, 도구와 기법, 템플릿과 산출물로 구성된다.\n\n\n\n\n방법론 절차의 구성 요소\n\n\n\n폭포수 모델\n프로토타입 모델\n나선형 모델\n\n\n1. KDD 분석 방법론\n\n비즈니스 도메인에 대한 이해, 프로젝트 목표 설정\n데이터셋 선택\n데이터 전처리: 잡음, 이상치, 결측치 처리. 추가로 요구되는 데이터 셋이 필요한 경우, 데이터 선택 프로세스로 돌아감\n데이터 변환: 데이터 차원 축소, 학습용 데이터, 시험용 데이터 분리\n데이터 마이닝\n데이터 마이닝 결과 평가\n\n\n\n2. CRISP-DM 분석 방법론\n\n\n\nCRISP-DM 4레벨 구조\n\n\nGeneric Tasks 예시: 데이터 정제\nSpecialized Tass 예시: 범주형 데이터 정제, 연속형 데이터 정제\n\n\n\nCRISP-DM 6Phase\n\n\n\n업무 이해\n데이터 이해: 데이터셋 선택, 데이터 전처리\n데이터 준비: 데이터 변환\n모델링: 모델 평가\n평가: 모델 적용성 평가\n전개\n\n\n\n3. 빅데이터 분석 방법론\n\n\n\n빅데이터 분석 방법론의 5단계\n\n\n\n분석 기획\n\n비즈니스 이해 및 범위 설정\n프로젝트 정의 및 계획 수립 → SOW\n프로젝트 위험 계획 수립 → 회피, 전이, 완화, 수용\n\n데이터 준비\n\n필요 데이터 정의\n데이터 스토어 설계\n데이터 수집 및 정합성 점검\n\n데이터 분석\n\n분석 데이터 준비\n텍스트 분석\n탐색적 분석\n모델링 → 훈련용, 테스트용 데이터 분리\n모델 평가\n\n시스템 구현\n평가 및 전개",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "3 - 데이터 분석 기획의 이해"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/05.html#분석-프로젝트-관리-방안",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/05.html#분석-프로젝트-관리-방안",
    "title": "3 - 데이터 분석 기획의 이해",
    "section": "분석 프로젝트 관리 방안",
    "text": "분석 프로젝트 관리 방안\n\n1. 분석과제 관리를 위한 5가지 주요 영역\n\nData Size\nData Complexity\nSpeed: 분석 모델의 성능 및 속도를 고려해야한다.\nAnalytic Complexity: 분석 모델의 정확도를 높이면서 해석이 가능하도록 최적 모델을 찾아야 한다.\nAccurancy & Precision: 정확도, 정밀도\n\n\n\n3. 분석 프로젝트 관리방안\n\n범위\n시간\n원가\n품질\n통합\n조달\n자원\n리스크\n의사소통\n이해관계자",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "3 - 데이터 분석 기획의 이해"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/04.html#분산-데이터-저장-기술",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/04.html#분산-데이터-저장-기술",
    "title": "2 - 데이터 처리 기술",
    "section": "분산 데이터 저장 기술",
    "text": "분산 데이터 저장 기술\n\n1. 분산 파일 시스템\n\nGFS(Google File System): 구글의 분산 파일 시스템\n\nchunk: 64MB\n트리 구조가 아닌, 해시 테이블 구조로 관리\nPOSIX 인터페이스 지원하지 않음\n단일 마스터 노드가 메모리상에서 메타데이터 관리\n마스터 노드에 대한 로그를 기록하고, 마스터의 상태를 섀도우 마스터 노드에 복제\n하나의 파일에 대한 primary node를 정하고, 다른 노드에 복제본 분산 저장\n낮은 응답 지연시간보다 높은 처리율 중시\nMaster Node, Chunk Node, Client 구성\n\nHDFS(Hadoop Distributed File System): 아파치 하둡의 분산 파일 시스템\n\nGFS의 clone project\nPOSIX 인터페이스 지원하지 않음\nblock: 128MB\nNameNode가 메타데이터 관리\n낮은 응답 지연시간보다 높은 처리율 중시\nNameNode, DataNode, 보조 네임 노드, job tracker, task tracker 구성\n\nLustre: 고성능 컴퓨팅을 위한 분산 파일 시스템\n\nPOSIX 인터페이스 지원\nchunk가 아닌 striping 방식 데이터 저장\nClient Filesystem, Metadata Server, 객체 저장 서버로 구성\n\n\n\n\n2. 데이터베이스 클러스터\n\n\n\n\n\n\n\n무공유 디스크\n\n각 노드가 완전히 분리된 데이터를 가짐\nOracle RAC를 제외한 대부분의 클러스터가 채택\n노드 확장에 제한이 없음\n\n공유 디스크\n\nSAN과 같은 네트워크로 모든 노드가 디스크 공유\n노드 확장시 디스크 병목현상 고려 필요\n\n\n\n\n\n\nOrace RAC 데이터베이스 서버: 확장성보다는 고가용성이 중요한 서비스에 적합\nIBM DB2 ICE(integrated cluster environment)\n마이크로소프트 SQL Server: 전역 스키마가 없어서 모든 노드에 질의를 해야함. active-stanby 구성\nMySQL:\n\n클러스터에 참여하는 노드는 최대 255, 그 중 데이터 노드는 최대 48개까지 가능\n운영중에 노드를 추가 삭제 불가\n\n\n\n\n3. NoSQL\n\nGoogle BigTable:\n\n공유 디스크 방식\nRow Key 순으로 정렬 되어 있고, Row 내부적으로는 Column Key 순으로 정렬\nColumn Key, Value, Timestamp로 구성\nChubby를 이용해 마스터 노드 관리\n\nHBase\nAmazon SimpleDB\n\nschema가 없고, Domain(table), Item(record), Attribute(column), Value으로 구성\n\n마이크로소프트 SSDS: Container(table), Entity(record), Property(column)로 구성",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "2 - 데이터 처리 기술"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/04.html#분산-컴퓨팅-기술",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/04.html#분산-컴퓨팅-기술",
    "title": "2 - 데이터 처리 기술",
    "section": "분산 컴퓨팅 기술",
    "text": "분산 컴퓨팅 기술\n\n1. MapReduce\n\n대용량 데이터를 분산 처리할 수 있는 모델\n보통 64MB를 기준으로 데이터 분할\n하나의 블록당 하나의 Map Task, 사용자가 지정한 갯수만큼의 Reduce Task 생성\nCount 작업에 적합하고, Sort 작업에는 적합하지 않음\n\n\nGoogle MapReduce\nHadoop MapReduce\n\n절차: 1. Split 1. Map 1. Combine 1. Partition 1. Shuffle 1. Sort 1. Reduce\n\n\n2. 병렬 쿼리 시스템\n\nGoogle Sawzall: MapReduce에 대한 이해가 없어도 쉽게 사용 가능\nApache Pig\nApache Hive\n\n\n\n3. SQL on Hadoop",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "2 - 데이터 처리 기술"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/04.html#클라우드-인프라-기술",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/04.html#클라우드-인프라-기술",
    "title": "2 - 데이터 처리 기술",
    "section": "클라우드 인프라 기술",
    "text": "클라우드 인프라 기술\n\n2. CPU 가상화\n\n하이퍼바이저: 하드웨어 리소스를 가상화하여 여러 개의 가상 머신을 생성하는 소프트웨어\n\nbare-metal hypervisor: 하드웨어와 host 운영체제 사이에 hypervisor가 존재  \nhosted hypervisor: host 운영체제와 guest 운영체제 사이에 hypervisor가 존재\n\nContainer\n\n\n\n3. 메모리 가상화\n\nVMKernnel: hypervisor 내에 Show Page Table을 두고, 각 VM의 Guest OS의 Page Table을 관리\nMemory Ballooning: Guest OS의 메모리를 빼앗아서 다른 VM에 할당\nTransparent Page Sharing: 같은 내용의 메모리 페이지는 VM들이 공유\nMemory Overcommitment: VM에 할당된 메모리보다 더 많은 메모리를 할당할 수 있음\n\n\n\n4. I/O 가상화\n\n가상 이더넷: 가상 머신 간의 네트워크 통신을 위한 가상 네트워크. LAN 세그먼트를 가상화\n공유 이더넷 어댑터: 하나의 물리적 네트워크 어댑터를 여러 VM이 공유. 병목현상 발생 가능\n가상 디스크 어댑터",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "2 - 데이터 처리 기술"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/01.html#빅데이터의-이해",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/01.html#빅데이터의-이해",
    "title": "1 - 데이터의 가치와 미래",
    "section": "빅데이터의 이해",
    "text": "빅데이터의 이해\n\n1. 빅데이터의 정의\n\n\n좁은 범위\n\n데이터 자체의 특성에 초점을 맞춘 정의\n3V(다양성, 속도, 규모)를 강조\n\n중간 범위\n\n데이터 자체뿐 아니라 처리, 분석 방법도 포함하는 정의\n\n넓은 관점\n\n인재, 조직 변화까지 포함한 정의\n\n\n\n∴ 기존 방식으로는 얻을 수 없는 통찰 및 가치 창출\n\n\n2. 출현 배경과 변화\n\n산업계: 고객 데이터가 축적되며 새로운 가치 활용\n학계: 거대 데이터 활용 분야가 늘어나며 통계 도구들이 발전\n기술발전: 관련기술의 발전\n\n\n\n3. 빅데이터의 기능\n\n산업혁명의 석탄, 철: 산업 전반에 혁명적 변화를 가져옴\n21세기의 원유: 생산성을 향상시키고, 기존에 없던 새로운 범주의 산업을 만들어낼 것으로 전망\n렌즈: 데이터가 산업에 영향을 미침\n플랫폼\n\n\n\n4. 빅데이터가 만들어 내는 본질적인 변화\n\n사전처리 → 사후처리\n표본조사 → 전수조사\n질 → 양\n인과관계 → 상관관계",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "1 - 데이터의 가치와 미래"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/01.html#빅데이터의-가치와-영향",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/01.html#빅데이터의-가치와-영향",
    "title": "1 - 데이터의 가치와 미래",
    "section": "빅데이터의 가치와 영향",
    "text": "빅데이터의 가치와 영향\n\n1. 빅데이터의 가치\n빅데이터는 아래와 같은 이유로 가치 선정이 어렵다.\n\n데이터 활용방식: 데이터를 언제 어디서 누가 사용할지 미리 예측하기 어려움\n새로운 가치 창출: 기존에 없던 가치를 창출하기 때문에 가치를 예측하기 어려움\n분석 기술 발전: 현재 가치가 없더라도, 추후 기술이 발전하면 가치가 생길 수 있음\n\n\n\n2. 빅데이터의 영향\n빅데이터는 다양한 주체(기업, 정부, 개인)에 영향을 미친다.",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "1 - 데이터의 가치와 미래"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/01.html#비즈니스-모델",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/01.html#비즈니스-모델",
    "title": "1 - 데이터의 가치와 미래",
    "section": "비즈니스 모델",
    "text": "비즈니스 모델\n\n1. 빅데이터 활용 사례\n여러가지 활용 사례가 있다.\n\n\n2. 빅데이터 활용 기본 테크닉\n\n연관규칙학습: 범주형 데이터의 변인들간의 규칙을 발견. 비지도 학습 (ex. 장바구니 분석)\n유형(군집)분석: 데이터를 분류하거나 군집화. 비지도 학습 (not 분류분석)\n유전자 알고리즘: 최적해를 찾는 알고리즘\n기계학습: 훈련한 데이터로 예측\n회귀분석: 연속형 데이터의 독립변수와 종속변수의 관계를 수학적으로 모델링해서 예측\n감정분석: 비정형 데이터 분석\n소셜네트워크분석(사회관계망분석): 비정형 데이터 분석",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "1 - 데이터의 가치와 미래"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/01.html#위기-요인과-통제-방안",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/01.html#위기-요인과-통제-방안",
    "title": "1 - 데이터의 가치와 미래",
    "section": "위기 요인과 통제 방안",
    "text": "위기 요인과 통제 방안\n\n1. 빅데이터 시대의 위기 요인과 통제 방안\n\n사생활 침해: 동의에서 책임으로\n책임 원칙 훼손: 결과 기반 책임 원칙 고수\n데이터 오용: 알고리즘 접근 허용, 알고리즈미스트",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "1 - 데이터의 가치와 미래"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/01.html#미래의-빅데이터",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/01.html#미래의-빅데이터",
    "title": "1 - 데이터의 가치와 미래",
    "section": "미래의 빅데이터",
    "text": "미래의 빅데이터\n\n1. 빅데이터 활용의 3요소\n\n데이터: 모든것의 데이터화\n기술: 인공지능\n인력: 데이터 사이언티스트, 알고리즈미스트",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "1 - 데이터의 가치와 미래"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/14.html#시각화의-정의",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/14.html#시각화의-정의",
    "title": "5 - 시각화 디자인",
    "section": "시각화의 정의",
    "text": "시각화의 정의\n\n1. 데이터 시각화의 중요성\n데이터 시각화의 목적은 데이터 분석과 의사소통\n\n\n2. 시각 이해와 시각화\n\n\n데이터: 디자인의 대상이 될 수 없음\n정보\n\n데이터가 의미를 전달하기위한 형태를 가짐\n자기조직화 되지 않은 일반적인 의미를 가지고 있고, 생산자와 사용자의 관점에 따라 다르게 전달될 수 있다.\n\n지식: 다른 영역의 정보가 자기조직화된 형태\n지혜: 지식이 내면화되어 개인적 맥락에 포함된 형태. 명시적으로 상대에게 전달하기 어려움\n\n\n\n\n정보 인터랙션 디자인(사진좀 보이게 올려둬라 좀..)\n\n\n\n\n3. 시각화 분류와 구분\n\n\n데이터 시각화\n정보 시각화\n정보 디자인 \n\n데이터 시각화, 정보 시각화, 인포그래픽도 정보 디자인의 범위에 속한다고 볼 수 있다.\n대표적인 예시로 나폴레옹 행군 다이어그램, 나이팅게일 폴라 지역 다이어그램이 있다.\n\n인포그래픽(뉴스 그래픽): 중요한 정보를 한 장의 그래픽으로 표현한 것. 원 데이터는 취급 안함.\n\n정보형 메세지: 객관적인 정보를 전달하는데 목적을 둠. 대표적인 예시: 워싱턴 지하철 지도\n설득형 메세지: 대충 포스터 생각하면 됨",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "5 - 시각화 디자인"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/14.html#시각화-프로세스",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/14.html#시각화-프로세스",
    "title": "5 - 시각화 디자인",
    "section": "시각화 프로세스",
    "text": "시각화 프로세스\n\n1. 정보 디자인 프로세스\n\n데이터 수집\n모든 것을 읽기\n내리티브 찾기\n문제의 정의\n계층 구조 만들기\n와이어프레임 그리기\n포맷 선택하기\n시각 접근 방법 결정하기\n정제와 테스트\n세상에 선보이기\n\n\n\n2. 빅데이터 시각화 프로세스\n\n\n\n시각화 프로세스\n\n\n\n\n\n방법론\n\n\n\n\n\n에드워드 터프티 시각 정보 디자인 7원칙",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "5 - 시각화 디자인"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/14.html#시각화-방법",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/14.html#시각화-방법",
    "title": "5 - 시각화 디자인",
    "section": "시각화 방법",
    "text": "시각화 방법\n\n2. 정보 구조화\n\n데이터 수집 및 탐색\n데이터 분류: 확장자 맞게 분류\n데이터 배열: LATCH\n\nLocation\nAlphabet\nTime\nCategory\nHierarchy: 정보의 변화에 따라 데이터의 값이나 중요도 순서로 정렬\n\n데이터 재배열(관계 맺기):\n\n\n\n3. 정보 시각화\n\n\n\n\n좋은 그래프 디자인\n\n\n\n범례 만들지 말고, 직접 그려 넣은거\n테두리, 보조선 없는거\n굵은 글씨 대신 글자를 흐리게\n색깔은 최대한 적게 사용\n\n\n\n4. 정보 시각 표현\n\n자크 베르탱의 그래픽 7요소\n\n위치: 가장 중요한거는 좌측 상단에 배치\n크기\n모양\n색\n명도\n기울기\n질감\n\n타이포그래피\n\n산세리프: 돌기가 없음. 제목에 적합\n세리프: 돌기가 있음. 본문에 적합\n\n아이소타이프",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "5 - 시각화 디자인"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/14.html#빅데이터-시각화-디자인",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/14.html#빅데이터-시각화-디자인",
    "title": "5 - 시각화 디자인",
    "section": "빅데이터 시각화 디자인",
    "text": "빅데이터 시각화 디자인\n\n1. 빅데이터와 시각화 이슈\n\n\n2. 빅데이터와 시각화 디자인 사례\n\n\n3. 빅데이터와 시각화 디자인의 방향",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "5 - 시각화 디자인"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/00.html#데이터와-정보",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/00.html#데이터와-정보",
    "title": "1 - 데이터 이해",
    "section": "데이터와 정보",
    "text": "데이터와 정보\n\n1. 데이터\n\n객관적 사실을 나타내는 존재적 특성과, 추론 예측 전망 추정을 위한 근거가 되는 당위적 특성을 모두 포함하는 개념\n단위: 바이트(byte), 킬로바이트(KB), 메가바이트(MB), 기가바이트(GB), 테라바이트(TB), 페타바이트(PB), 엑사바이트(EB), 제타바이트(ZB), 요타바이트(YB)\n유형:\n\n정성적 데이터: 비정형 데이터, 주관적 내용, 통계분석이 어려움\n정량적 데이터: 정형 데이터, 객관적 내용, 통계분석이 용이함\n\n지식 경영의 핵심 이슈인 암묵지와 형식지를 연결하는 역할을 함\n\n\n\n\n\n\n\n\n정형 데이터: 표 형태로 정리된 데이터\n반정형 데이터: HTML, XML, JSON 등의 형태(스키마, 메타데이터)가 있고, 연산이 불가능한 데이터\n비정형 데이터: 형태가 없고, 연산이 불가능한 데이터\n\n\n\n\n\n\n\n\n\n\n\n암묵지:\n\n학습과 경험을 통해 개인에게 체화되어 잇지만 겉으로 드러나지 않는 지식\n개인에게 축적된 내면화된 지식 → 조직의 지식으로 공통화\n\n형식지:\n\n문서나 메뉴얼처럼 형상화된 지식\n언어, 기호, 숫자로 표출화된 지식 → 개인의 지식으로 연결화\n\n\n∴ 내면화 → 공통화 → 표출화 → 연결화 → 내면화\n\n\n\n\n\n2. 데이터와 정보의 관계\n\n데이터(data): 그 자체로는 의미가 중요하지 않은 객관적인 사실\nex) A마트는 100원, B마트는 200원에 휴지를 판다.\n정보(information): 데이터를 가공하여 의미를 부여한 결과물\nex) A마트가 100원에 판 휴지는 B마트보다 100원 싸다.\n지식(knowledge): 정보를 구조화하여 유의미한 정보를 분류하고 개인적인 경험을 결합시켜 고유의 지식으로 내재화된 것\nex) 가격이 더 저렴한 A마트에 가서 휴지를 사야겠다.\n지혜(wisdom): 지식의 축적과 아이디어가 결합된 창의적인 결과물\nex) A마트의 다른 물건도 B마트보다 저렴할 것이다.\n\n\n\n\nDIKW 피라미드",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "1 - 데이터 이해"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/00.html#데이터베이스-정의와-특징",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/00.html#데이터베이스-정의와-특징",
    "title": "1 - 데이터 이해",
    "section": "데이터베이스 정의와 특징",
    "text": "데이터베이스 정의와 특징\n\n1. 데이터베이스의 정의\n기존에는 정형 데이터 관리의 의미로 사용되다가, 빅데이터의 출현으로 비정형 데이터까지 포함하는 개념으로 확장됨\n\n\n2. 데이터베이스의 일반적인 특징\n\n통합된 데이터: 동일한 내용의 데이터가 중복되어 있지 않다.\n저장된 데이터\n공용 데이터\n변화되는 데이터: 데이터베이스에는 항상 현재의 정확한 데이터를 유지한다.",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "1 - 데이터 이해"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/00.html#데이터베이스의-활용",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/00.html#데이터베이스의-활용",
    "title": "1 - 데이터 이해",
    "section": "데이터베이스의 활용",
    "text": "데이터베이스의 활용\n\n1. 1980년대 기업 내부 데이터베이스\n\nOLTP(On-Line Transaction Processing)\n\n데이터베이스의 데이터를 실시간으로 갱신하는 프로세싱.\n구조가 복잡하고, 현재의 단기간 데이터.\n갱신이 동적이고, 엑세스 빈도가 높다.\n질의가 단순하고, 주기적이다.\n\nOLAP(On-Line Analytical Processing)\n\n데이터 조회, 분석 위주.\n구조가 단순하고, 과거의 장기간 요약 데이터.\n갱신이 정적이고, 엑세스 빈도가 보통이다.\n질의가 복잡하다.\n\n\n\n\n2. 2000년대 기업 내부 데이터베이스\n\nCRM(Customer Relationship Management): 고객 관리 시스템\nSCM(Supply Chain Management): 공급망 관리 시스템\n\n\n\n3. 각 분야별 내부 데이터베이스\n\n제조부문\n\nERP(Enterprise Resource Planning): 기업 내부 자료를 하나의 통합 시스템으로 재구축\nBI(Business Intelligence): 기업의 수많은 데이터를 정리, 분석해 의사결정에 활용하는 프로세스\nCRM\nRTE(Real-Time Enterprise): ERP, SCM, CRM 등의 부문별 전산화 시스템을 하나로 통합\n\n금융부문\n\nEAI(Enterprise Application Integration)\nEDW(Enterprise Data Warehouse): BPR, CRM, BSC 등의다양한 분석 시스템을 위한 원천\n\n유통부문\n\nKMS(Knowledge Management System)\nRFID(Radio Frequency Identification): 주파수를 이용해 ID를 식별\n\n\n\n\n4. 사회기반구조로서의 데이터베이스\n\nEDI(Electronic Data Interchange): 전자상거래를 위한 표준화된 데이터 포맷\nVAN(Value Added Network): EDI를 위한 통신망 (카드 결제 시, 가맹점과 카드사 사이에서 승인 요청 및 결과 전달을 중계함.)\nCALS(Commerce At Light Speed): 제품의 설계, 생산, 유통, 판매 등의 모든 과정을 통합한 경영정보시스템",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "1 - 데이터 이해"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/09.html#데이터-변경-및-요약",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/09.html#데이터-변경-및-요약",
    "title": "4 - 데이터 마트",
    "section": "데이터 변경 및 요약",
    "text": "데이터 변경 및 요약\n\n요약 변수: 전체적 특성을 대표하여 aggregate한 변수. 제활용성이 높다.\n파생 변수: 기존 데이터를 변환, 조합, 계산하여 새롭게 만든 변수. 주관이 개입될 수 있다.\n\n\n\n\n요약 변수 예시\n\n\n\n1. reshape 패키지 활용",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 데이터 마트"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/index.html",
    "href": "posts/04_archives/bs_2_2/index.html",
    "title": "2학년 2학기 학부 정리",
    "section": "",
    "text": "COMPLETED\n    \n    \n        시작일: 2024-09-02\n        종료일: 2024-12-20\n    \n    \n        \n            \n        \n        계산 중...\n    \n    \n    \n        산업공학 학부",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/index.html#details",
    "href": "posts/04_archives/bs_2_2/index.html#details",
    "title": "2학년 2학기 학부 정리",
    "section": "Details",
    "text": "Details\n산업정보시스템공학과 2학년 2학기 수강 과목들에 대한 개념 정리 노트입니다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/index.html#tasks",
    "href": "posts/04_archives/bs_2_2/index.html#tasks",
    "title": "2학년 2학기 학부 정리",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/index.html#related-posts",
    "href": "posts/04_archives/bs_2_2/index.html#related-posts",
    "title": "2학년 2학기 학부 정리",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/11.html#concurrency-control",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/11.html#concurrency-control",
    "title": "Database Administration",
    "section": "Concurrency control",
    "text": "Concurrency control\nEnsuring that one user’s work does not inappropriately influence another user’s work\n\nStrict concurrency control requires locking the database, 다른 사용자의 동시 사용 허가 x\nLower concurrency control allows more throughput\n\n\nTransactions\nUsers submit Transactions(LUWs)\n\nAtmomic Transaction: 데이터베이스에서 일련의 작업들이 모두 성공적으로 수행되거나, 그렇지 않을 경우 작업이 전혀 수행되지 않아 데이터베이스가 변경되지 않는 상태를 유지하는 트랜잭션\n→ Before committed, all LUWs must be successfully completed, or rollback\nConcurrent Transactions: 여러 트랜잭션이 동시에 실행되는 것\n\nLost update problem: 두 트랜잭션이 동시에 같은 데이터를 수정할 때, 하나의 트렌잭션이 다른 트랜잭션의 변경을 덮어쓰는 문제\nInconsistent read problem: 한 트랜잭션이 데이터를 읽는 도중 다른 트랜잭션이 데이터를 수정하는 문제\n\nDirty read: commit 되기 이전에 수정된 데이터를 읽는 것. 만약 rollback이 될 경우 문제가 발생.\nNonrepeatable read: 데이터를 두 번 읽었는데 commit된 transaction 때문에 값이 다른 경우\nPhantom read: 데이터를 두 번 읽었는데 commit된 transaction 때문에 새로운 row가 추가된 경우\n\nResource locking\n\nImplicit locks: DBMS가 자동으로 수행하는 lock\nExplicit locks\nLOCK TABLES table_name READ -- or WRITE\nUNLOCK TABLES\nExclusive locks: 다른 트랜잭션에서 읽기/쓰기 불가\nShared locks: 다른 트랜잭션에서 읽기 가능, 쓰기 불가\nrock granularity: row-level vs table-level vs database-level\n\n\nSerializable Transactions: 가장 강력한 격리 수준 보장\n\nTwo-pase locking(2PL): growing phase와 shrinking phase로 나뉨\n\nACID Transaction\n\nAtomic: 성공한 transaction만 저장되어야 한다\nConsistent: 현재의 transaction이 마무리 되기 전 까지 record를 저장할 수 없다\n→ 트랜잭션의 살향 결과로 데이터베이스 상태가 모순되지 않음\nIsolated\n\nread uncommitted: 다른 트랜잭션에서 commit되지 않은 데이터도 읽을 수 있음\nread committed: 다른 트랜잭션이 commit된 데이터만 읽을 수 있음\nrepeatable read: 한 트랜잭션에서 하나의 스냅션만 사용\nserializable: 가장 강력한 격리 수준 보장\n\nDurable: 트랜잭션이 성공적으로 완료되면, 그 결과는 영구적으로 저장되어야 한다\n\n\n\n\n\nDeadlock / deadly embrace\n두 개 이상의 트랜잭션이 서로 unlock을 무한히 기다리는 상태\n\n\nlock\n\noptimistic locking\n\nassumption: No conflict will occur\nif no conflict occurs, the transaction is committed else it is rolled back and repeated\n\npessimistic locking\n\nassumption: Conflict will occur\nlock the data before the transaction starts\n\n\n\n\nCursor\nA cursor is a pointer into a set of rows that are the result set from an SQL SELECT statement\nDECLARE cursor_name CURSOR FOR SELECT column_name FROM table_name",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Administration"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/11.html#backup-and-recovery",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/11.html#backup-and-recovery",
    "title": "Database Administration",
    "section": "Backup and recovery",
    "text": "Backup and recovery\n\nRecovery\n\nvia Reprocessing\nvia Rollback and Rollforward\n\nlog file transaction을 undo할 때, before-images가 존재해함. (rollback) transaction을 redo할 때, after-images가 존재해함.(rollforward)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Administration"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/11.html#security",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/11.html#security",
    "title": "Database Administration",
    "section": "Security",
    "text": "Security\nonly authenticated users perform authorized activities\n\nAuthentication: User ID와 password를 사용하여 사용자를 인증\nAuthorization: user groups(roles): dbcreator, public, … sql  GRANT SELECT, INSERT, UPDATE, DELETE ON table_name TO user_name",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Administration"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/11.html#database-performance",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/11.html#database-performance",
    "title": "Database Administration",
    "section": "Database Performance",
    "text": "Database Performance\n\nindex\ndisk mirroring: 데이터 복제 말씀하신 듯\nRAID\nSANs\nDistributed database: service cluster partitioned replicated\n\n\nDBA Responsibilities\n\nuser reported errors를 모아서 system이 잘 돌아갈 수 있게 해야함\ndatabase 설정을 잘 관리해야함\n문서화 잘 해야함\ncloud로 db 관리(service level agreement)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Administration"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/04-1.html#normalization",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/04-1.html#normalization",
    "title": "Database Normalization",
    "section": "Normalization",
    "text": "Normalization\n\nprocess of organizing a database to reduce redundancy problem and improve data integrity",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Normalization"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/04-1.html#functional-dependency",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/04-1.html#functional-dependency",
    "title": "Database Normalization",
    "section": "Functional Dependency",
    "text": "Functional Dependency\n\n하나의 atrribute가 다른 attribute의 value를 결정하는지 여부를 판단\nwell formed인지 판별할 수 있는 기준\nA(Determinant) -&gt; B(dependent): A가 결정되면 B도 결정된다면 B는 A에 함수적 종속\nEvery determinant must be a Candidate Key",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Normalization"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/04-1.html#normalization-process",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/04-1.html#normalization-process",
    "title": "Database Normalization",
    "section": "Normalization Process",
    "text": "Normalization Process\n\nBCFNF: Boyce-Codd Normal Form =&gt; Each relation has only one theme\n\n\nIdentify all the Candidate Keys.\nIdentify all the Functional Dependencies.\nExamine the determinants of the functional dependencies\n\nplace the columns of the functional dependency in a new relation of their own\nmake the determinant of the functianl dependency the primary key of the new relation\nLeabe a copy of the determinant as a foreign key in the original relation\ncreate a referential integrity constraint between the original and new relation\n\nRepeat the process until every determinant of every relation is a candidate key",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Normalization"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#entity",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#entity",
    "title": "The Relational Model",
    "section": "entity",
    "text": "entity\na formal name for a thing that is being tracked one theme or topic (just single table)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#relation",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#relation",
    "title": "The Relational Model",
    "section": "Relation",
    "text": "Relation\n\na two-dimensional table that has specific charateristics\nCell of the table hold single value\nAll entries in a column are of the same kind\nNo two rows in a table are identical",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#domain-cartesian-product",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#domain-cartesian-product",
    "title": "The Relational Model",
    "section": "domain & cartesian product",
    "text": "domain & cartesian product\n\ndomain: set of possible values for a column\ncartesian product: set of all possible combinations of rows from two tables",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#presenting-relation-structures",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#presenting-relation-structures",
    "title": "The Relational Model",
    "section": "Presenting Relation Structures",
    "text": "Presenting Relation Structures\nRELATION_NAME(PrimaryKey, ForeignKey, ColumnName, …)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#key",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#key",
    "title": "The Relational Model",
    "section": "key",
    "text": "key\n\nidentify a row\nUnique Key(Primary Key)\nNonUnique Key(Foreign Key)\nComposite Key: Primary key가 두개 이상. Surrogate Key로 대체되곤 함.\nCandidate Key: unique한 columns\nSurrogate Key: 자동으로 할당되는 일련번호\nIDENTITY (start, increment)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#referential-integrity-constraint",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#referential-integrity-constraint",
    "title": "The Relational Model",
    "section": "Referential Integrity Constraint",
    "text": "Referential Integrity Constraint\n\n모든 foriegn key는 존재하는 primary key와 매칭되야한다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/03.html#null-values",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/03.html#null-values",
    "title": "The Relational Model",
    "section": "Null values",
    "text": "Null values\n\nrequired, allow nulls 설정으로 null값을 허용할지 결정",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "The Relational Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/04-2.html#ddl-data-definition-language",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/04-2.html#ddl-data-definition-language",
    "title": "SQL",
    "section": "DDL (Data Definition Language)",
    "text": "DDL (Data Definition Language)\n\nCREATE (database, tables, views, indexes)\nALTER: modify columns / constraints\nDROP (database, tables, views, indexes)\nTRUNCATE: delete table data while keeping structure.\nMS Access에서는 지원하지 않음 =&gt; DELETE FROM table\n\nCREATE TABLE student (\n    id INT NOT NULL,\n    CourseID INT NOT NULL,\n    Name VARCHAR(100) UNIQUE, # unique는 자동으로 index 생성\n    Age INT,\n    CONSTRAINT STUDENT_PK PRIMARY KEY (id),\n    CONSTRAINT \n    COURSE_FK FOREIGN KEY (CourseID) \n    REFERENCES Course(CourseID) \n    ON UPDATE CASACADE \n    ON DELETE NO ACTION\n);\nALTER TABLE student ADD COLUMN major VARCHAR(100);\nALTER TABLE student ADD CONSTRAINT STUDENT_FK FOREIGN KEY (CourseID) REFERENCES Course(CourseID) ON DELETE CASCADE;\nALTER TABLE student ADD CONSTRAINT AGE_CHECK CHECK (Age &gt; 0);\nALTER TABLE student DROP CONSTRAINT AGE_CHECK;\nDROP TABLE student;\nTRUNCATE TABLE student;\n\nCREATE VIEW [view name] AS SELECT * FROM student;\n\nDML (Data Manipulation Language)\nINSERT INTO student VALUES (1, 'Alice', 20);\nUPDATE student SET age = 21, Name = 'babo' WHERE id = 1;\nDELETE FROM student WHERE id = 1;\n\n\nDQL (Data Query Language)\nA query create temporarily a new table.\nthis allows a query to create a new relation and feed information to another query as a subquery\nSELECT * FROM student;\nSELECT name \nFROM student \nWHERE age &gt; 20\nORDER BY name DESC, age ASC;\nSELECT DISTINCT name FROM student;\nSELECT name, age FROM student WHERE Age &gt; (SELECT AVG(Age) FROM student);\n\n\nJOIN\n\ninner join(equijoin)\n\nexplicit join: FROM table1 INNER JOIN table2 ON table1.id = table2.id\n(MS Access에서는 INNER를 명시해야됨)\nimplicit join: FROM table1, table2 WHERE table1.id = table2.id\n\nouter join\n\nleft outer join: FROM table1 LEFT JOIN table2 ON table1.id = table2.id\nright outer join: FROM table1 RIGHT JOIN table2 ON table1.id = table2.id",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "SQL"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#좋은-추정량이-되기-위한-조건",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#좋은-추정량이-되기-위한-조건",
    "title": "표본의 분포",
    "section": "좋은 추정량이 되기 위한 조건",
    "text": "좋은 추정량이 되기 위한 조건\n\n불편성 (Unbiasedness) - 기본 조건\n추정량의 기대값이 추정하려는 모수와 같아야 함\n\\(E(\\hat{X}) = μ\\)\n\\(E(X_1) = μ\\)\n최소분산 (Minimum Variance)\n추정량의 분산이 가능한 작아야 함.\n표본의 갯수를 늘릴수록 분산이 줄어들어서 더 좋은 추정량이 됨\n\\(Var(\\hat{X}) = \\frac{σ^2}{n}\\)\n\\(Var(X_1) = \\sigma^2\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "표본의 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#표본평균의-분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#표본평균의-분포",
    "title": "표본의 분포",
    "section": "표본평균의 분포",
    "text": "표본평균의 분포",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "표본의 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#표본분산의-분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#표본분산의-분포",
    "title": "표본의 분포",
    "section": "표본분산의 분포",
    "text": "표본분산의 분포\n정규분포로 부터 추출된 표본의 \\(\\sum_{i=1}^{n} Z^2\\)은 자유도가 n인 카이제곱분포를 따름\n정규분포로 부터 추출된 표본의 \\(\\frac{(n-1)s^2}{\\sigma^2}\\)은 자유도가 n-1인 카이제곱분포를 따름",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "표본의 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#평균",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#평균",
    "title": "표본의 분포",
    "section": "평균",
    "text": "평균\n\\(\\frac{\\hat{X} - μ}{s/\\sqrt{n}}\\) t-분포를 따름\nT분포: 표준 정규분포 Z, 자유도가 n인 카이제곱분포가 서로 독립일 때 \\(T=\\frac{Z}{\\sqrt{Y/n}}\\)\nT분포는 정규분포와 비슷하지만, 표본의 크기가 작을 때 정규분포보다 두꺼운 꼬리를 가짐\nT분포가 값이 더 작고, 신뢰도가 감소함",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "표본의 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#분산",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/7-표본의-분포.html#분산",
    "title": "표본의 분포",
    "section": "분산",
    "text": "분산\n확률변수 U와 V가 자유도가 n1, n2인 카이제곱분포를 따르고 서로 독립이면, \\(F=\\frac{U/n1}{V/n2}\\)는 F분포를 따름",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "표본의 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/3-확률변수의-기댓값.html#확률변수의-기댓값",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/3-확률변수의-기댓값.html#확률변수의-기댓값",
    "title": "확률변수의 기댓값",
    "section": "확률변수의 기댓값",
    "text": "확률변수의 기댓값\n\n\\(μ = E(x)\\)로 가정. (모집단)\ncovariance는 선형관계를 보여준다.\nx와 y는 독립이다 -&gt; cov(x, y) = 0",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수의 기댓값"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/3-확률변수의-기댓값.html#moment-generationg-functions",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/3-확률변수의-기댓값.html#moment-generationg-functions",
    "title": "확률변수의 기댓값",
    "section": "Moment Generationg Functions",
    "text": "Moment Generationg Functions\n\n평균과 분산만으로 확률분포를 설명하기에는 부족하다.\n\nmoment: \\(μ_k′ = E(X^k), k ∈ ℤ+\\)\nVar(x) = \\(μ_2′ - μ_1′^2\\)\nE(x) = \\(μ_1′\\)\n모든 k에 대해 검증 불가 =&gt; mgf(moment generating function)\nmgf: \\(M_X(t) = E(e^{tx})\\)\n\n\n\\(M_X(t) = 1 + tμ_1′ + \\frac{t^2}{2!}μ_2′ + \\frac{t^3}{3!}μ_3′ + ...\\)\n\\(M′(t) = μ_1′ + \\frac{2t}{2!}μ_2′ + \\frac{3t^2}{3!}μ_3′ + ...\\)\n\\(M′(0) = μ_1′\\)\n\\(M′′(0) = μ_2′\\)\n\\(M^{(k)}(0) = μ_k′\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수의 기댓값"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#통계학의-정의",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#통계학의-정의",
    "title": "확률과 통계의 정의",
    "section": "통계학의 정의",
    "text": "통계학의 정의\n\n불확실한 상황에서 데이터에 근거하여 과학적인 의사결정을 도출하기 위한 이론과 방법 체계\n모집단으로부터 수집된 데이터(sample)를 기반으로 모집단의 특성을 추론하는 것을 목표로 함\n\n\n\n모집단: 통계분석의 대상이 되는 모든 개체들의 집합\n표본: 모집단으로부터 일정한 규칙에 의해 추출한 부분집합",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#확률의-개념",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#확률의-개념",
    "title": "확률과 통계의 정의",
    "section": "확률의 개념",
    "text": "확률의 개념\n\n모집단에서 특정 사건(event)의 상대도수의 극한\n\n\nLaw of Large Numbers\n무수히 많은 시행이 반복되면 상대도수에 의해 계산되는 확률(통계적 확률)이 이론적 확률로 수렴한다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#sample-space-and-events",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#sample-space-and-events",
    "title": "확률과 통계의 정의",
    "section": "Sample Space and Events",
    "text": "Sample Space and Events\n\nExperiment(확률실험): 동일한 조건에서 독립적으로 반복할 수 있는 실험이나 관측\nSample space(표본공간): 모든 simple event의 집합\nEvent(사건): 실험에서 발생하는 결과 (부분 집합)\nSimple event(단순사건): 원소가 하나인 사건\n\n\n\n\nevent는 여러 원소를 가질 수 있다",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#확률의-정의",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#확률의-정의",
    "title": "확률과 통계의 정의",
    "section": "확률의 정의",
    "text": "확률의 정의\n\n고전적 확률: 모든 simple event가 동일한 확률을 가질 때 P(A)는 sample space가 n개의 원소로 이루어져 있을 때 k개의 원소를 가지는 event A의 확률\n통계적 확률: simple event가 동일한 확률을 가지지 않아도 된다. 표본의 수가 무한대로 갈 때, 표본의 확률이 수렴하는 값\n\n\n확률의 성질\n\n모든x에 대하여 P(x) &gt;= 0\nP(sample space) = 1\nA와 B가 배반사건이면 P(A or B) = P(A) + P(B)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#조건부-확률",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#조건부-확률",
    "title": "확률과 통계의 정의",
    "section": "조건부 확률",
    "text": "조건부 확률\n\nEvent B가 발생했을 때 Event A의 확률 \\[P(A|B) = \\frac{P(A∩B)}{P(B)}\\]\n결합확률 (joint probability): P(A∩B)\n주변확률 (marginal probability): P(A), P(B), …\n\n\nMultiplication Law\n\\[P(A∩B) = P(A|B)P(B)\\]",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#independent-events",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#independent-events",
    "title": "확률과 통계의 정의",
    "section": "Independent Events",
    "text": "Independent Events\n\n두 사건 A와 B가 독립일 때, P(A|B) = P(A), P(B|A) = P(B)\nsample space는 임의의 event와 독립이다.\n공집합은 임의의 event와 독립이다. (P(∅∩A) = P(∅) * P(A) = 0 * P(A) = 0 = P(∅))",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#베이즈-정리",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/1-통계학의-개념.html#베이즈-정리",
    "title": "확률과 통계의 정의",
    "section": "베이즈 정리",
    "text": "베이즈 정리\n\n\nsample space를 상호 배반인 {B1, B2, …, Bn}으로 분할 (partition)\n\\(P(A) = P(A∩B_1) + P(A∩B_2) + ... + P(A∩B_n)\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률과 통계의 정의"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/6-정규분포.html#정규-분포의-합",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/6-정규분포.html#정규-분포의-합",
    "title": "정규 분포",
    "section": "정규 분포의 합",
    "text": "정규 분포의 합\n두 분포의 합이 같은 분포가 되는 경우는 흔치 않다 (uniform distribution도 같지 않다)\n두 정규분포의 합은 정규분포가 된다\n\\(X + Y \\sim N(μ_1 + μ_2, σ_1^2 + σ_2^2)\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "정규 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/6-정규분포.html#chi-square-분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/6-정규분포.html#chi-square-분포",
    "title": "정규 분포",
    "section": "Chi-square 분포",
    "text": "Chi-square 분포\nα = ν/2, θ = 2인 감마분포\n\\(Z \\sim N(0,1)\\)일 때, \\(Z^2 \\sim χ^2(1)\\)\n\\(Z_i \\sim N(0,1)\\)일 때, \\(Z_1^2 + Z_2^2 + ...  + Z_n^2 \\sim χ^2(n)\\)\n\\(X_i\\)가 서로 독립이고, 자유도가 \\(ν_i\\)인 카이제곱분포를 따른다면, \\(X_1 + X_2 + ... + X_n \\sim x^2(ν_1 + ν_2 + ... + ν_n)\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "정규 분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#귀의-구조",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#귀의-구조",
    "title": "Auditory Haptic",
    "section": "귀의 구조",
    "text": "귀의 구조",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#sound-waves",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#sound-waves",
    "title": "Auditory Haptic",
    "section": "Sound Waves",
    "text": "Sound Waves\n\n소리는 압력이 변하는 것\n소리는 vibrating object에 의해 발생한다\n연못에 돌을 던지면 생기는 wave와 비슷함\n어떤 분자든 움직이고 압력을 만들 수 있는건 전달 가능함\n물속에서도 소리가 전달됨. (밀도가 높아서 더 빨리 전달됨)\n고체(층간소음, 철로), gas\n진공에서는 매질이 없어서 소리가 안들림(우주 공간) &lt;-&gt; 빛은 매질이 없어도 이동됨\n파동이 전기신호로 바뀌어서 들림\n\n\n물리적 특성\n\n\namplitude: 진폭의 크기 -&gt; volume\nwavelength: 진폭의 넓이 -&gt; pitch, 1초 안에 몇 번 진동하는지(주파수 10Hz = 10번 진동)\n\n\n\n사람이 느끼는 perception\n\nPitch(소리의 높낮이)\n사람이 들을 수 있는 주파수는 20Hz ~ 15kHz\n어릴 때는 고주파를 잘 들음 (고주파에 고막이 반응을 못해서)\n사람은 고주파에 반응을 잘 못함\n절대 음감이랑 관련\nTimbre(음색)\n음악에서는 악기마다 다른 음색이 있음\n음색은 여러 주파수의 하모니(complex set of resonance공명)로 결정됨\nAmplitude and loudness\n소리의 물리적 강도가 2배 증가할 때 우리가 느끼는 소리의 크기(loudness)가 배로 느껴짐(찾아보니까 2배는 아니긴 함) 160db까지 들을 수 있음 130db부터는 고통스러움\nSpatialisation\n소리는 어느 방향에서 소리가 나도 들을 수 있음 (omnidirectional).\n시각은 볼 수 있는 방향만 볼 수 있음\n\n\n\nSound intensity (dB)\n\n데시벨(dB)은 기준점에서 로그 스케일만큼 증가. (선형적 x)\nthreshold: 주변의 소음에 비해 소리가 들리는 정도. 주파수에 따라 다른 특성을 가짐.\n\n\n\n85 dB에 장시간 노출되면 청력 손상\n\n신경의 손상: 장시간 센 자극에 hair cell이 손상됨\nconduction damage: 소리의 세기가 너무 커서 고막이나 뼈에서 손상이 생김",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#masking-effect",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#masking-effect",
    "title": "Auditory Haptic",
    "section": "Masking Effect",
    "text": "Masking Effect\n\n청각에서만 주로 나타남.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#equal-loudness-contour",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#equal-loudness-contour",
    "title": "Auditory Haptic",
    "section": "Equal Loudness Contour",
    "text": "Equal Loudness Contour\n\n곡선은 사람들이 소리가 같은 크기라고 느끼는 지점을 나타냄\n인간 청력의 threshold가 주파수마다 다르다.\n저주파수와 고주파수는 중간 주파수에 비해 같은 강도에서 상대적으로 작게 들립니다",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#locating-sounds",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#locating-sounds",
    "title": "Auditory Haptic",
    "section": "Locating Sounds",
    "text": "Locating Sounds\n왼쪽 귀와 오른쪽 귀에서 들리는 소리의 차이\n\ndifference in phase(위상): 소리의 파장이 오목한 phase, 볼록한 phase 차이\ndifference in loudness: 가까운게 더 크게 들림\ndifference in onset: 가까운게 더 빨리 도달함\n\n\n여기까지가 소리의 mechanical한 특성이고, 이후는 이 소리를 인간이 어떻게 perception하는지에 관한 내용",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#hearing-without-awareness",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#hearing-without-awareness",
    "title": "Auditory Haptic",
    "section": "Hearing Without Awareness",
    "text": "Hearing Without Awareness\n\nCocktail Party Effect: 주변 소음에서도 특정 소리를 들을 수 있음\nEx) 친구 이름을 듣고 반응하는 것, 한국인들이 한국말을 잘 듣는것\nDichotic Listening: 두 귀에 다른 소리를 들려주고 정보를 인식했는지 확인\nignored 귀에서 여전히 정보를 인식할 수 있다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#alarms",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#alarms",
    "title": "Auditory Haptic",
    "section": "Alarms",
    "text": "Alarms\n\nOverview\nomnidirectional한 특성때문에 visual alarm에 비해 자주 사용된다\nEx) 소방차 사이렌 소리\n\n주변 소음에 비해 충분히 db이 커야함 주변 소음과의 차이가 15dB minimal, 30dB required\n하지만 소리가 너무 크면 청각에 손상을 일으킬 수 있음\n안전상의 이유로 소리는 85 ~ 90dB 이하로 유지되어야 함\nmasking 위협때문에 여러 주파수를 혼합해서 냄\n다른 signal과 헷갈리지 않아야함\nEx) 병원의 환자실에 여러 장비가 있는데 장비마다 알람이 구분이 안되면 안됨.\nInformative and distinctive\n각각의 physical dimension(pitch(4), duration(4), amplitude(4))은 4개를 넘게 쓰지 마라\nEx) 컴퓨터 메인보드, 장비 고장 시 비프음 기준이 있음\nEx) 자동차\n\nstereotypic: 어디서 소리가 오는지\n\npitch\n\n\n\n\nNon-speech Alarm\n\nlanguage independent\n글로벌하게 가고 싶다면\nNSA가 유용하다는 증거\n클릭을할 때 딸깍 소리가 나면 실수가 덜 함\n비디오 게이머들은 소리가 없으면 게임을 못함\n일시적이고 부수적인 상태 정보 전달에 효과적\n예시) 게임에서:\n\nHP가 부족할 때 주기적인 경고음\n\n아이템 획득 시 짧은 효과음\n\n배경에서 지속적으로 재생되는 상태 알림음\n\nstereo sound로 방향을 알려줄 수 있음\n비쥬얼로는 3d 표현하기 어려움\n\n\n\nVoice Alarm\n\n자연스러운 방법으로 기기와 통신할 수 있음\nSymbolic alarm에 비해 더 많은 정보를 전달할 수 있음\nSymbolic alarm은 학습을 해야한다는 단점이 있음\nNon-Speech에 비한 한계\n\n소리가 섞이면 헷갈림\n\nmore susceptible to frequency-specific masking\n사람의 voice는 정해진 주파수가 있다.\n그 주파수에 소리가 섞이면 소리를 못들을 수 있음\n다국어 환경을 고려해야함\n\nSound Transmission Problem\n말하고자 하는 바가 전달이 잘 안될 수 있음\nEx) 파일럿 안내. 라디오에서 사용할 수 있는 대역폭이 제한되있음",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#voice-recognition",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#voice-recognition",
    "title": "Auditory Haptic",
    "section": "Voice Recognition",
    "text": "Voice Recognition\nSound Transmission Problem을 해결하기 위해 사용됨\n\nArticulation index: pure bottom-up(signal의 특성에 의존) approach\nsignal이 얼마나 명확하게 잘 들리는지 평가\n1.0: 주변소음에 상관없이 잘 들리는 상태\n0.0: 주변소음에 묻혀서 소리가 들리지 않는 상태\nSpeech intelligibility measure\npoor signal quality is compensated by top-down processing =&gt; 어떻게 top-down processing을 잘 할까?를 테스트 해 보았다.\n전달하는 정보의 양을 제한, 문장의 형태로 전달하는게 좋음\n긍정이나 부정이 잘 나타나는 단어를 사용(Ok는 애매함)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#tactile-perception",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#tactile-perception",
    "title": "Auditory Haptic",
    "section": "Tactile Perception",
    "text": "Tactile Perception\n\nTouch is complex\nOnly bi-directional communication channel: 접촉하거나 움직이거나 한 다음에 반응을 얻는 등, input과 output이 동시에 일어남\n환경에 대한 정보를 포괄해서 전달함\n온도, 표면의 거칠기, 등등\nfeedback을 제공함\n수용체가 피부 변형을 감지함\n민감도는 단위 면적당 촉점이 얼마나 분포되어 있는지에 따라 결정됨",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#tactile-information",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/4_Auditory_Haptic.html#tactile-information",
    "title": "Auditory Haptic",
    "section": "Tactile information",
    "text": "Tactile information\n\n운동 감각을 통해 받아들이는 것 (force feedback)\n\n\n\n큰 물체는 움직이기 어렵게 함 =&gt; 더 세밀하게 조종 가능\n\n게임에서 많이 사용됨\n\n\n촉감을 통해 받아들이는 것 (vibration feedback)\n\n\n\nusing vibration for information transfer\nsimilar physical characteristics to auditory signal\n\namplitude, frequency, duration, wave pattern\n\nused for navigation aid\n중요한 정보는 시각, 나머지 feedback은 촉각, 청각으로 받아들임.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Auditory Haptic"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/2_human_information_processing_model.html#인간-정보-처리-과정",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/2_human_information_processing_model.html#인간-정보-처리-과정",
    "title": "Human Information Processing Model",
    "section": "인간 정보 처리 과정",
    "text": "인간 정보 처리 과정\n\n\n1. 감각 처리 (Sensory Processing)\n\n주요 감각: 시각, 청각, 운동 감각(proprioception)\n운동 감각: 생리적 신호, 중력과 가속도에 따른 몸의 위치 감각\nSTSS (Short Term Sensory Store)\n\n각 감각기관별 정보 저장 공간\n주의 집중 불필요, 정보 그대로 저장\n빠르게 소멸 (예: 시각 - Iconic Memory 200-300ms, 청각 - Echoic Memory 2-8s)\n\n\n\n\n2. 지각 (Perception)\n\n정보 해석 과정\nTop-Down Processing: 과거 기억으로 정보 해석 (Long Term Memory 활용)\nBottom-Up Processing: 새로운/익숙하지 않은 정보 해석\nPreattentive Processing: 주의 집중 없이 자동적 정보 해석 (예: Stroop Effect)\n\n\n\n3. 주의 자원 (Attention Resources)\n\n전반적인 정보 처리 과정에 영향\nSearch Light Metaphor: 주의 집중의 비유적 설명\n주의 실패 유형:\n\nSelective Attention: 잘못된 곳에 집중\nFocused Attention: 주의 집중 부족\nDivided Attention: 다중 작업 시 주의 분산\nSustained Attention: 장시간 주의 유지 실패\n\n\n\n\n4. 장기 기억 (Long Term Memory)\n\n학습을 통한 정보 저장\n유형:\n\nDeclarative Memory (What): 사실적 지식 (Episodic, Semantic)\nProcedural Memory (How): 절차적 지식\n\n기억 실패: Encoding, Storage, Retrieval 단계에서 발생 가능\n\n\n\n5. 인지 (Cognition)\n\nWorking Memory:\n\n단기적 정보 처리 및 조작\n제한된 용량 (7±2 items)\nLong Term Memory와 Perception으로부터 정보 획득\n\n\n\n\n6. 반응 선택 (Response Selection)\n\n의사결정 이론:\n\nSignal Detection Theory\nExpected Value\nBayesian Decision Theory\nMulti-attribute Theory\n\nInformation Processing\n\nAttention and working memory\nHeuristics and biases: 인간은 합리적이지 않음\n\nNaturalistic Decision Making: Recognition-Primed Decision Model (직감)\n\n\n\n7. 반응 실행 (Response Execution)\n\n\n8. 시스템 환경 (System Environment)\n\nclosed-loop 형태의 피드백 제공\ndelay가 발생시 성능 저하",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Human Information Processing Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#display-purpose",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#display-purpose",
    "title": "Display",
    "section": "Display Purpose",
    "text": "Display Purpose\n\n사람의 인지와 시스템의 실제 정보 사이의 커뮤니케이션을 위한 중간 다리 역할.\n시스템이 무엇을 하는 중이고, 무엇을 해야 하고, 어떻게 작동하는지 오퍼레이터에게 전달하기 위한 목적(mental model을 만들기 위함)\n설계된 sensory input을 통해서 파악하게 해야함\n다른 sensory input과 구별이 되야함.\n사용자가 이해할 수 있어야함(Compatible)\n\nConceptual Compatibility\nex) 플로피 디스크 심볼은 저장 용도로 사용됨\nmovement compatibility(pictorial realism): 실제와 유사한 모양을 사용하면 이해하기 쉬움\nex) 엘리베이터가 위 아래로 움직이니까 스케일을 linear로 맞춤",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Display"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#display-rules",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#display-rules",
    "title": "Display",
    "section": "Display Rules",
    "text": "Display Rules\n\nFour Cardinal Rules\n\n꼭 필요한 정보만 제공해라\n필요한 수준의 정확도만 제공하라 (ex. 소숫점 3자리까지만. 굳이 다 보여주지 않아도 됨)\n가장 direct, simple, understandable, and usable하게 정보를 제공하라\nex) 지하철 디스플레이에서 열차가 언제 도착하는지 알려줘야 하는데 이상한걸 보여줘서 멘탈 워크로드가 높아진다.\n고장이나 작업 실패의 경우 명확히 어디서 문제가 발생했는지 바로 알아차리게 제공하라\n첫번째 원칙을 위반할 수도 있다(alarm flooding)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Display"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#types-of-displays",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#types-of-displays",
    "title": "Display",
    "section": "Types of Displays",
    "text": "Types of Displays\n\nAuditory\n\nDetectable\nDiscrmination\nMeaningful\nMain problem: hearing ability depends on environments / background noise (auditory spatial coding 인지하기 힘듦)\n\nTactual(Haptic)\n\nDetectable: 손처럼 민감한 부분은 가능하지만, 둔감한 부분은 어렵다\nDiscrimination: nomal job이랑 구분되어야 한다\nMeaningful: tactual display에서는 어려운 부분. convention이 없음\nMain problem: 잘 안쓰이고, 손 이외에는 사용하기 어렵다\n\nOlfactory Displays - smell\n\nDetectable\nDiscrimination\nMeaningful\nMain problem: 냄새에 대한 민감도가 사람마다 다르다. regenerate 하기가 어렵다. 후각이 금방 마비된다. 전쟁에서 후각을 이용한 의사전달을 시도하기도 함",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Display"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#visual-displays",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#visual-displays",
    "title": "Display",
    "section": "Visual Displays",
    "text": "Visual Displays\n\nAppropriate if:\n\nNoisy environment\n한 자리에 머무는 경우(traditional. 옛날엔 들고 다니기 어려웠음)\nmessage가 길거나 복잡한 경우, spatial coding이 필요한 경우\n\nGuiding principles for design:\n\n눈에 잘 띄어야함(배경과 전경의 차이가 구분되어야함)\nLegible, 쉽게 보고 읽을 수 있어야함(ex. 엠뷸런스의 글씨)\nUnderstandable\nmain problem: 시각이 overload됨. 정보가 너무 많음\n\n\n\nDynamic Information\n변화하는 정보를 보여주는 것에는 4가지 원칙이 있다.\n\nSituation awareness\n가까운 미래에 무슨 일이 일어날 지 예측할 수 있어야함\n상황 인식 3단계:\n\nPerception: 무엇이 일어나고 있는지 인지(check readings)\nComprehension: 그것이 무엇을 의미하는지 이해\nProjection: 미래에 무슨 일이 일어날지 예측\n\n\n\nQuantitative readings\n정확한 값을 보여주는 용도로 사용됨\n\n고정 스케일의 움직이는 초점 (generally best)\n움직이는 스케일의 고정 초점\ndigital display (변동성이 큰 경우 그냥 숫자만 보여주는것보다 스케일, 초점을 사용하는게 더 효과적임)\nDesign of Analog Scales\n\n일반적으로 fixed scale, moving pointer가 좋다\n숫자의 증가는, linear 스케일에 움직이는 포인터가 자연스럽다.\nex) 온도계, 엘리베이터\n같은 작업을 하는 여러개의 pointer, scale indicator를 섞어 쓰지 말아라.\ncontrol, display가 혼합된경우 control로 pointer로 움직여라\n작은 변화 감지가 중요한 경우는 moving pointer가 더 좋다\n범위가 너무 큰 경우는 moving scale이 더 좋다\n\n\n\n\nQualitative readings\n대략적인 값, 트렌드, 변화의 비율, 변화의 방향을 보여주는 용도로 주로 사용됨.\n\ncontinuous data converted to range\n의미를 강조하고 싶을 때 color를 보조 도구로써 보여주기도 함\nShape coding\nex) 교통 표지판 8각형은 stop을 의미\nZone coding\nex) 신호등의 위치가 고정되어 있음\n\nRedundancy gain: 시각 청각 촉각, 혹은 칼라코드, 위치코드 같이 여러가지 정보(multi-modal)를 제공하면 정확히 해석할 수 있다.\n\n\nCheck readings\n시스템의 상태를 확인할 수 있어야함\n\nqualitaative reading의 특별한 case\n정상인 상태는 명확히 보여줘야함\n정상적인 것은 align해서, 비정상적인 것은 삐뚤어지게 설계해서 pre-attentive processing을 유도하라\n시각 정보를 보완하기 위해 청각 시그널을 제공하라",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Display"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#signal-and-warning-lights",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/7_display.html#signal-and-warning-lights",
    "title": "Display",
    "section": "Signal and Warning Lights",
    "text": "Signal and Warning Lights\n실질적인, 잠재적인 위험 상황을 알리는 용도\n일반적으로 하나의 라이트만 사용함\n\nsteady-state light: 지속적인 싱태를 나타냄\nflashing light: 위급 상황 (flash 비율은 3-10 per seconds)\n배경에 비해 최소 두 배 이상 밝아야함\n유효 시야 30도 안쪽에 배치해야함",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Display"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#눈의-구조",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#눈의-구조",
    "title": "Sensor System (Visual)",
    "section": "눈의 구조",
    "text": "눈의 구조\n\n결막 (conjunctiva): 눈을 보호\n각막 (cornea): 빛을 굴절\n홍채(iris): 빛의 양을 조절\n동공 (pupil): 빛이 들어오는 곳\n수정체(lens): 빛을 집중하는 역할\n공막 (sclera): 눈을 보호\n유리체 (vitreous humor): 눈을 유지\n망막(retina): 빛을 감지\n망막의 세포\n\nNerve cell: 빛을 감지\nPhotoreceptor: 빛을 감지\n\n간상세포(cone): 세부적인 정보, 색상 인식, photopic conditions. fovea에 몰려있음. 짧은 파장의 색에 더 민감함\n막대세포(rod): 어두운 곳에서 활동, 주변 시야 빛을 받으면 rhodopsin이 분해됨, scotopic conditions. 긴 파장의 색에 더 민감함.\n\nChoroid: 영양 공급\n\n시신경(optic nerve): 망막에서 뇌로 정보 전달\n맹점(optic disk)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Sensor System (Visual)"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#light-adaption",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#light-adaption",
    "title": "Sensor System (Visual)",
    "section": "light adaption",
    "text": "light adaption\n\n눈이 어두운 곳에서 밝은 곳으로 이동할 때, 시간이 걸림\n명순응동안 rod sensitivity가 감소하고 cone sensitivity가 증가\n어두운 곳에서 밝은 곳으로 이동할 때, 눈이 눈부실 수 있음\n암순응동안 cone sensitivity가 감소하고 rod sensitivity가 증가",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Sensor System (Visual)"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#color-vision",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#color-vision",
    "title": "Sensor System (Visual)",
    "section": "color vision",
    "text": "color vision\n\ncone cell의 photo-pigment(RGB 64:32:2)로 색상을 인식\n망막 중앙에는 파란색이 없음\nsharpness는 brightness와 color difference에 영향을 받음\n사람은 7백만가지 색상을 인식할 수 있음",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Sensor System (Visual)"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#design-with-color",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#design-with-color",
    "title": "Sensor System (Visual)",
    "section": "design with color",
    "text": "design with color\n\nMono-chromatic: 단색\nAnalogous: 비슷한 색\nComplementary: 반대 색\n\n\nbefore design\n\n굳이 흑백을 안쓰고 color를 사용해야하는 이유가 있는지\ncolor가 텍스트나 object에 적합한지\ncolor가 이해나 관습에 도움이 되는지\n노안 / 색맹 고려",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Sensor System (Visual)"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#depth-perception",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/3_sensory_system.html#depth-perception",
    "title": "Sensor System (Visual)",
    "section": "depth perception",
    "text": "depth perception\n\ndepth judgment\n\nobject-centered cues\n\n\nlinear perspective: 두 평행선이 좁을 수록 더 멀리 있는 것으로 인식\ninterposition(occlusion): 물체가 다른 물체를 가리면 가려진 물체가 더 멀리 있는 것으로 인식\nheight in the plane: 물체가 높이 있을수록 더 멀리 있는 것으로 인식\nlight and shadow: 빛과 그림자로 물체의 거리를 인식\nrelative size: 물체가 작을수록 더 멀리 있는 것으로 인식\ntexture gradient: 물체가 멀어질수록 세부적인 텍스처가 사라짐\nbrightness: 물체가 밝을수록 더 가까이 있는 것으로 인식\naerial perspective: 물체가 먼발에서 가까워질수록 색이 흐려짐\nmotion parallax: 물체가 빠르게 움직일수록 더 가까이 있는 것으로 인식 fixation point\n\n\nobserver-centered cues\n\n\nbinocular disparity: 두 눈의 시각적 차이\nconvergence: 눈이 물체를 바라볼 때 발생하는 각도\naccommodation: 눈의 렌즈가 물체를 바라볼 때 발생하는 조절. 가까운 물체일수록 렌즈가 더 둥글어짐",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Sensor System (Visual)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/index.html",
    "href": "posts/04_archives/aws_saa/index.html",
    "title": "AWS SAA 준비",
    "section": "",
    "text": "COMPLETED\n    \n    \n        시작일: 2024-04-15\n        종료일: 2024-05-22\n    \n    \n        \n            \n        \n        계산 중...\n    \n    \n    \n        자격증cloud",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/index.html#details",
    "href": "posts/04_archives/aws_saa/index.html#details",
    "title": "AWS SAA 준비",
    "section": "Details",
    "text": "Details\nAWS Solution Architect Associate 자격증을 취득하였습니다.\n자격증 링크",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/index.html#tasks",
    "href": "posts/04_archives/aws_saa/index.html#tasks",
    "title": "AWS SAA 준비",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/index.html#참고-자료",
    "href": "posts/04_archives/aws_saa/index.html#참고-자료",
    "title": "AWS SAA 준비",
    "section": "참고 자료",
    "text": "참고 자료\n\nAWS Udemy 강의",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/index.html#related-posts",
    "href": "posts/04_archives/aws_saa/index.html#related-posts",
    "title": "AWS SAA 준비",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/09_aws_storage.html",
    "href": "posts/04_archives/aws_saa/notes/09_aws_storage.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "AWS Snow Family is a collection of physical devices designed for use in edge locations, data centers, and in disconnected environments.\nData Migration: snowcone, snowball edge, snowmobile\nEdge Computing: snowcone, snowball edge  ### use process\n\n\nOrder: Order a Snow device from the AWS Management Console.\ninstall: Install the Snow client / AWS ops hub on your server\nTransfer: Transfer data to the Snow device using the Snow client.\nShip: Ship the Snow device back to AWS.\nLoad: Load the data into your S3 bucket.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Snow Family"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-snow-family",
    "href": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-snow-family",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "AWS Snow Family is a collection of physical devices designed for use in edge locations, data centers, and in disconnected environments.\nData Migration: snowcone, snowball edge, snowmobile\nEdge Computing: snowcone, snowball edge  ### use process\n\n\nOrder: Order a Snow device from the AWS Management Console.\ninstall: Install the Snow client / AWS ops hub on your server\nTransfer: Transfer data to the Snow device using the Snow client.\nShip: Ship the Snow device back to AWS.\nLoad: Load the data into your S3 bucket.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Snow Family"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-fsx",
    "href": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-fsx",
    "title": "김형훈의 학습 블로그",
    "section": "AWS FSx",
    "text": "AWS FSx\n\nAmazon FSx for Windows File Server: fully managed Windows file system\nAmazon FSx for Lustre: fully managed Lustre file system, seamlessly integrated with S3 (can read and write data directly to S3)\nAmazon FSx for NetApp ONTAP: fully managed NetApp ONTAP file system, point-in-time snapshots, data deduplication, and data compression\nAmazon FSx for OpenZFS: fully managed OpenZFS file system, point-in-time snapshots, data deduplication, and data compression\n\n\nFile System Deployment Options\n\nScratch File System: temporary storage for data processing. no replication.\nPersistent File System: long-term storage for data processing. replicate data across multiple Availability Zones.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Snow Family"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-storage-gateway",
    "href": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-storage-gateway",
    "title": "김형훈의 학습 블로그",
    "section": "AWS Storage Gateway",
    "text": "AWS Storage Gateway\n\nAWS Storage Gateway is a hybrid cloud storage service that gives you on-premises access to virtually unlimited cloud storage.\nS3 File Gateway: store and retrieve objects in Amazon S3 using file protocols (NFS, SMB), cache data locally, not glacier.\nFSx File Gateway: store and retrieve objects in Amazon FSx using file protocols (NFS, SMB) for window file server.\nVolume Gateway: store and retrieve objects in Amazon S3, EBS Snapshot using iSCSI protocol.\n\ncached volume: cache frequently accessed data locally.\nstored volume: entire dataset stored locally, asynchronously backed up to S3.\n\nTape Gateway: store and retrieve objects in Amazon S3 using virtual tape library (VTL) interface",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Snow Family"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-datasync",
    "href": "posts/04_archives/aws_saa/notes/09_aws_storage.html#aws-datasync",
    "title": "김형훈의 학습 블로그",
    "section": "AWS DataSync",
    "text": "AWS DataSync\n\nAWS DataSync is a data transfer service that makes it easy for you to automate moving data between on-premises storage and Amazon S3, Amazon Elastic File System (Amazon EFS), or Amazon FSx for Windows File Server.\nFile permissions and metadata are preserved during transfer.\nif not aws to aws, need agent to transfer data.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Snow Family"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/19_DR.html",
    "href": "posts/04_archives/aws_saa/notes/19_DR.html",
    "title": "Disaster Recovery(DR)",
    "section": "",
    "text": "Disaster Recovery(DR)\n\nRPO: Recovery Point Objective\n\nthe maximum acceptable amount of data loss measured in time\n\nRTO: Recovery Time Objective\n\nthe maximum acceptable amount of time to recover the system  ## DR Strategies\n\nBackup and Restore: Simple but RPO and RTO are high\nPilot Light: Minimal version of the environment is always running\nWarm Standby: A scaled-down version of a fully functional environment is always running\nHot-site / Multi-Site Approach: Fully functional environment is always running\n\n\n\nDatabase Migration Service(DMS)\n\nmigrate data from one database to another\nsource is available during migration\nHomogeneous Migration: same database engine\nHeterogeneous Migration: different database engine. must use Schema Conversion Tool(SCT)\nContinuous Data Replication using CDC\n\n\n\n\n\n 맨 위로",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Disaster Recovery(DR)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/06_route53.html",
    "href": "posts/04_archives/aws_saa/notes/06_route53.html",
    "title": "Route53",
    "section": "",
    "text": "Domain/subdomain\nRecord type (A, AAAA, CNAME, NS)\n\nA: IPv4\nAAAA: IPv6\nCNAME: Canonical name. cant be used for root domain\nNS: Name server (another DNS server)\nalias: Route53 specific. can be used for root domain. free. health check. no TTL, can’t be used for ec2 instance\n\nValue\nRouting policy\n\nSimple: one record with multiple values, choose randomly by client, no health check, if alias then specify only one\nWeighted: split traffic based on weight\nLatency based: split traffic based on latency\nFailover: primary and secondary\nGeolocation\nMultivalue answer: multiple values, health check, choose randomly by client\nGeo-proximity\n\nTTL\n\n\n\n\nEndpoint\nCalculated\nCloudWatch alarm",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Route53"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/06_route53.html#health-check",
    "href": "posts/04_archives/aws_saa/notes/06_route53.html#health-check",
    "title": "Route53",
    "section": "",
    "text": "Endpoint\nCalculated\nCloudWatch alarm",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Route53"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/03_ebs.html",
    "href": "posts/04_archives/aws_saa/notes/03_ebs.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "EBS is a network device designed to work with AWS EC2 instances.\nEBS volumes are placed in a specific AZ and are automatically replicated to protect you from component failure.\nEBS volumes attached only to one instance at a time.\nEBS volumes can be detached from one instance and attached to another.\nEBS volumes can be used as a boot volume.\nEBS volumes have a provisioned size and IOPS can be resized.\nEBS volumes can exist independently of an EC2 instance.\nmultiple EBS volumes can be attached to a single EC2 instance.\n\n\n\n\nBy default, the root EBS volume is deleted when the EC2 instance is terminated.\nAdditional EBS volumes are not deleted when the EC2 instance is terminated.\n\n\n\n\n\nEBS snapshots archive tier:\n75% cheaper than the general-purpose tier.\ntakes 24 to 72 hours to restore.\nrecycle bin:\nset up rule to retain deleted snapshots\ncan specify period\nFast Snapshot Restore(FSR):\nforce full initialization of the EBS volume to have no latency\ntakes money\n\n\n\n\nAmazon Machine Image - AMI is a template that contains a software configuration (OS, application server, and applications) required to launch an EC2 instance. - AMI is built for a specific region. - can be copied to other regions.\n\n\n\n\nbetter IO performance than EBS volumes\ndata is lost when the instance is stopped or terminated.\ncan’t be resized.\n\n\n\n\n\nGeneral Purpose SSD (gp2, gp3): can be used for boot volumes\n\ngenerally used for system boot volumes, virtual desktops, low-latency interactive apps, development, and test environments\ngp2: 1GiB - 16TiB, burst up to 3000 IOPS linked to volume size\ngp3: 1GiB - 16TiB, 3000 IOPS, 125MiB/s, burst up to 16000 IOPS, 1000MiB/s independently\n\nHigh Performance SSD (io1, io2): can be used for boot volumes\n\ncritical business applications that require sustained IOPS performance\nmore than 16000 IOPS\ngenerally used for databases\n4GiB - 16TiB\nMax PIOPS: 64000 for Nitro EC2, 32000 for other EC2\nCan increase PIOPS independently from volume size\nio2 have more durability and more IOPS per GiB\nio2 Block Express: 4GiB - 64TiB, 256000 IOPS\nsupport Multi-Attach\n\nbound in AZ\nup to 16 EC2 instances\nMust use a file system that is cluster-aware (GFS, OCFS2, NTFS)\n\n\nLow cost, designed for frequently accessed HDD (st1)\n\n125MiB - 16TiB\n500MiB/s - 500MiB/s\nused for big data, data warehouses, log processing\n\nLow cost, designed for less frequently accessed HDD (sc1)\n\n125MiB - 16TiB\n250MiB/s - 250MiB/s\nused for file servers, infrequently accessed workloads\n\n\n\n\n\n\nElastic File System\nscalable storage solution for EC2 instances\ncan be shared across multiple instances in multi-AZ\ncan be accessed by multiple instances simultaneously\nexpensive than EBS\ncan be used for `content management, web serving\nuse NFSv4.1 protocol\nuse security group to control access\ncompatible with Linux-based AMI\nPerformance Mode:\n\nGeneral Purpose: latency-sensitive use cases\nMax I/O: higher latency, higher throughput\n\nThroughput Mode:\n\nBursting: burstable throughput\nProvisioned: provisioned throughput\nElastic: elastic throughput\n\nstorage classes:\n\nStandard: frequently accessed\nInfrequent Access: infrequently accessed\nOne Zone: infrequently accessed, stored in a single AZ. 90% cheaper than Regional",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "what is ebs"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/03_ebs.html#what-is-ebs",
    "href": "posts/04_archives/aws_saa/notes/03_ebs.html#what-is-ebs",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "EBS is a network device designed to work with AWS EC2 instances.\nEBS volumes are placed in a specific AZ and are automatically replicated to protect you from component failure.\nEBS volumes attached only to one instance at a time.\nEBS volumes can be detached from one instance and attached to another.\nEBS volumes can be used as a boot volume.\nEBS volumes have a provisioned size and IOPS can be resized.\nEBS volumes can exist independently of an EC2 instance.\nmultiple EBS volumes can be attached to a single EC2 instance.\n\n\n\n\nBy default, the root EBS volume is deleted when the EC2 instance is terminated.\nAdditional EBS volumes are not deleted when the EC2 instance is terminated.\n\n\n\n\n\nEBS snapshots archive tier:\n75% cheaper than the general-purpose tier.\ntakes 24 to 72 hours to restore.\nrecycle bin:\nset up rule to retain deleted snapshots\ncan specify period\nFast Snapshot Restore(FSR):\nforce full initialization of the EBS volume to have no latency\ntakes money\n\n\n\n\nAmazon Machine Image - AMI is a template that contains a software configuration (OS, application server, and applications) required to launch an EC2 instance. - AMI is built for a specific region. - can be copied to other regions.\n\n\n\n\nbetter IO performance than EBS volumes\ndata is lost when the instance is stopped or terminated.\ncan’t be resized.\n\n\n\n\n\nGeneral Purpose SSD (gp2, gp3): can be used for boot volumes\n\ngenerally used for system boot volumes, virtual desktops, low-latency interactive apps, development, and test environments\ngp2: 1GiB - 16TiB, burst up to 3000 IOPS linked to volume size\ngp3: 1GiB - 16TiB, 3000 IOPS, 125MiB/s, burst up to 16000 IOPS, 1000MiB/s independently\n\nHigh Performance SSD (io1, io2): can be used for boot volumes\n\ncritical business applications that require sustained IOPS performance\nmore than 16000 IOPS\ngenerally used for databases\n4GiB - 16TiB\nMax PIOPS: 64000 for Nitro EC2, 32000 for other EC2\nCan increase PIOPS independently from volume size\nio2 have more durability and more IOPS per GiB\nio2 Block Express: 4GiB - 64TiB, 256000 IOPS\nsupport Multi-Attach\n\nbound in AZ\nup to 16 EC2 instances\nMust use a file system that is cluster-aware (GFS, OCFS2, NTFS)\n\n\nLow cost, designed for frequently accessed HDD (st1)\n\n125MiB - 16TiB\n500MiB/s - 500MiB/s\nused for big data, data warehouses, log processing\n\nLow cost, designed for less frequently accessed HDD (sc1)\n\n125MiB - 16TiB\n250MiB/s - 250MiB/s\nused for file servers, infrequently accessed workloads\n\n\n\n\n\n\nElastic File System\nscalable storage solution for EC2 instances\ncan be shared across multiple instances in multi-AZ\ncan be accessed by multiple instances simultaneously\nexpensive than EBS\ncan be used for `content management, web serving\nuse NFSv4.1 protocol\nuse security group to control access\ncompatible with Linux-based AMI\nPerformance Mode:\n\nGeneral Purpose: latency-sensitive use cases\nMax I/O: higher latency, higher throughput\n\nThroughput Mode:\n\nBursting: burstable throughput\nProvisioned: provisioned throughput\nElastic: elastic throughput\n\nstorage classes:\n\nStandard: frequently accessed\nInfrequent Access: infrequently accessed\nOne Zone: infrequently accessed, stored in a single AZ. 90% cheaper than Regional",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "what is ebs"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/11_serverless.html",
    "href": "posts/04_archives/aws_saa/notes/11_serverless.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "AWS Lambda is a serverless compute service that lets you run code without provisioning or managing servers.\nLambda runs your code only when needed and scales automatically, from a few requests per day to thousands per second.\nYou pay only for the compute time you consume - there is no charge when your code is not running. ### limitation (per region)\nmemory: 128MB - 10GB (more memory, need more vCPU)\nmax execution time: 15 minutes\nenvironment variables: 4KB\n/tmp directory storage: 512MB to 10GB\nconcurrent executions: 1000\ndeployment package: 50MB (zipped)\ndeployment package: 250MB (unzipped)\n\n\n\n\n\n\n\n\n\nLambda@Edge",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Lambda"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/11_serverless.html#aws-lambda",
    "href": "posts/04_archives/aws_saa/notes/11_serverless.html#aws-lambda",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "AWS Lambda is a serverless compute service that lets you run code without provisioning or managing servers.\nLambda runs your code only when needed and scales automatically, from a few requests per day to thousands per second.\nYou pay only for the compute time you consume - there is no charge when your code is not running. ### limitation (per region)\nmemory: 128MB - 10GB (more memory, need more vCPU)\nmax execution time: 15 minutes\nenvironment variables: 4KB\n/tmp directory storage: 512MB to 10GB\nconcurrent executions: 1000\ndeployment package: 50MB (zipped)\ndeployment package: 250MB (unzipped)\n\n\n\n\n\n\n\n\n\nLambda@Edge",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Lambda"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/11_serverless.html#dynamodb",
    "href": "posts/04_archives/aws_saa/notes/11_serverless.html#dynamodb",
    "title": "김형훈의 학습 블로그",
    "section": "DynamoDB",
    "text": "DynamoDB\n\nAmazon DynamoDB is a fully managed, serverless, key-value and document database that delivers single-digit millisecond performance at any scale.\nstandard table: high availability, durability, and performance\nIA table: infrequently accessed data\nmax item size: 400KB\nprovisioned mode, on-demand mode\n\n\nDynamoDB Accelerator (DAX)\n\nAmazon DynamoDB Accelerator (DAX) is a fully managed, highly available, in-memory cache for DynamoDB that delivers up to a 10x performance improvement - from milliseconds to microseconds - even at millions of requests per second.\nmicroseconds latency\nno need to modify application \n\n\n\nDynamoDB Streams\n\nDynamoDB Streams is an optional feature that captures data modification events in DynamoDB tables.\ncan trigger lambda function, SQS, Kinesis\n24 hours retention period\nlimit: 5 active streams per table\n\n\n\nGlobal Tables\n\nAmazon DynamoDB global tables provide a fully managed solution for deploying a multi-region, multi-master database, without having to build and maintain your own replication solution.\nautomatic replication\nmust enable DynamoDB Streams\n\n\n\nbackup and restore\n\nPoint-in-Time Recovery\n\nPoint-in-time recovery helps protect your DynamoDB tables from accidental write or delete operations.\nrestore to any point in time within 35 days\nthe recovery process creates a new table\n\non-demand backup\n\nrestore to any point\nthe recovery process creates a new table",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Lambda"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/11_serverless.html#api-gateway",
    "href": "posts/04_archives/aws_saa/notes/11_serverless.html#api-gateway",
    "title": "김형훈의 학습 블로그",
    "section": "API Gateway",
    "text": "API Gateway\n\nAmazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale.\nEdge-optimized API: global, use CloudFront\nRegional API: regional, use API Gateway\nPrivate API: VPC endpoint",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Lambda"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/11_serverless.html#step-functions",
    "href": "posts/04_archives/aws_saa/notes/11_serverless.html#step-functions",
    "title": "김형훈의 학습 블로그",
    "section": "Step Functions",
    "text": "Step Functions\n\nAWS Step Functions is a serverless function orchestrator that makes it easy to sequence AWS Lambda functions and multiple AWS services into business-critical applications.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Lambda"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/11_serverless.html#amazon-cognito",
    "href": "posts/04_archives/aws_saa/notes/11_serverless.html#amazon-cognito",
    "title": "김형훈의 학습 블로그",
    "section": "Amazon Cognito",
    "text": "Amazon Cognito\n\nAmazon Cognito lets you add user sign-up, sign-in, and access control to your web and mobile apps quickly and easily.\nUser Pools: user directory\nIdentity Pools: federated identity, temporary access AWS resources",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Lambda"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/10_message_queue.html",
    "href": "posts/04_archives/aws_saa/notes/10_message_queue.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "Amazon Simple Queue Service (SQS) is a fully managed message queuing service that makes it easy to decouple and scale microservices, distributed systems, and serverless applications.\nunlimited throughput, no limit on the number of messages\nmessage retention period: default 4 days, maximum 14 days.\nlimit on message size 256kb\ncan have duplicate messages, out of order messages =&gt; need to handle in application or use FIFO queue\nSQS Access Policy\n\n\n\n\nthe amount of time that the message is invisible in the queue after a reader picks up the message.\ncan increase timeout by calling ChangeMessageVisibility API\n\n\n\n\n\nif no message in queue, the request will wait for a message to arrive for a certain amount of time.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS SQS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/10_message_queue.html#aws-sqs",
    "href": "posts/04_archives/aws_saa/notes/10_message_queue.html#aws-sqs",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "Amazon Simple Queue Service (SQS) is a fully managed message queuing service that makes it easy to decouple and scale microservices, distributed systems, and serverless applications.\nunlimited throughput, no limit on the number of messages\nmessage retention period: default 4 days, maximum 14 days.\nlimit on message size 256kb\ncan have duplicate messages, out of order messages =&gt; need to handle in application or use FIFO queue\nSQS Access Policy\n\n\n\n\nthe amount of time that the message is invisible in the queue after a reader picks up the message.\ncan increase timeout by calling ChangeMessageVisibility API\n\n\n\n\n\nif no message in queue, the request will wait for a message to arrive for a certain amount of time.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS SQS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/10_message_queue.html#aws-sns",
    "href": "posts/04_archives/aws_saa/notes/10_message_queue.html#aws-sns",
    "title": "김형훈의 학습 블로그",
    "section": "AWS SNS",
    "text": "AWS SNS\n\npublish/subscribe messaging service\nSNS FIFO (only SQS can subscribe)\nmessage filtering\n\n\nFanout\nSNS + multiple SQS",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS SQS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/10_message_queue.html#amazon-kinesis",
    "href": "posts/04_archives/aws_saa/notes/10_message_queue.html#amazon-kinesis",
    "title": "김형훈의 학습 블로그",
    "section": "Amazon Kinesis",
    "text": "Amazon Kinesis\n\nKinesis Data Streams\n\nreal-time data streaming service\ndata retention: default 24 hours, maximum 365 days\nonce data inserted, cannot be deleted\nprovisioned mode, on-demand mode\nVPC endpoint available \n\n\n\nKinensis Data Firehose\n\ndata transformation, compression, encryption\nbatch data delivery\nserverless  \n\n\n\nKinesis Data Analytics\n\n\nKinesis Video Streams",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS SQS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/13_data_analytics.html",
    "href": "posts/04_archives/aws_saa/notes/13_data_analytics.html",
    "title": "Amazon Redshift",
    "section": "",
    "text": "SQLqueries -S3as data source - supportsCSV,JSON,Parquet,ORCdata formats - 5$ per TB scanned ## Performance Improvement - usecolumnardata formats (less scan) =&gt;Parquet,ORCby usingAWS Glue- compress data =&gt;GZIP,Snappy,LZO-partition datasetsin S3 for easy querying on virtual columns (path) -Use larger files` (&gt; 128MB) to minimize overhead",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Performance Improvement"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/13_data_analytics.html#federated-query",
    "href": "posts/04_archives/aws_saa/notes/13_data_analytics.html#federated-query",
    "title": "Amazon Redshift",
    "section": "Federated Query",
    "text": "Federated Query\nallows you to query data in relational, non-relational, object, … in a single query on AWS or on-premises",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Performance Improvement"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/13_data_analytics.html#cluster",
    "href": "posts/04_archives/aws_saa/notes/13_data_analytics.html#cluster",
    "title": "Amazon Redshift",
    "section": "cluster",
    "text": "cluster\n\nleader node\ncompute node",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Performance Improvement"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/13_data_analytics.html#snapshots-and-dr",
    "href": "posts/04_archives/aws_saa/notes/13_data_analytics.html#snapshots-and-dr",
    "title": "Amazon Redshift",
    "section": "snapshots and DR",
    "text": "snapshots and DR\n\nMulti-AZ for some cluster\nsnapshots are point-in-time backups in S3\nchange is saved\nautomate snapshot, manual snapshote",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Performance Improvement"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/13_data_analytics.html#loading-data-into-redshift",
    "href": "posts/04_archives/aws_saa/notes/13_data_analytics.html#loading-data-into-redshift",
    "title": "Amazon Redshift",
    "section": "loading data into redshift",
    "text": "loading data into redshift\n\nAmazon Kinesis Data Firehose\nAmazon S3 copy\nEC2 instance JDBC driver",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Performance Improvement"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/13_data_analytics.html#redshift-spectrum",
    "href": "posts/04_archives/aws_saa/notes/13_data_analytics.html#redshift-spectrum",
    "title": "Amazon Redshift",
    "section": "Redshift Spectrum",
    "text": "Redshift Spectrum\n: query data directly in S3 without loading it into Redshift",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Performance Improvement"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/07_S3.html",
    "href": "posts/04_archives/aws_saa/notes/07_S3.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "Simple Storage Service\nobject storage service\nunlimited storage\ndefined at region level\nmax object size: 5TB (larger objects than 5GB can be stored using multipart upload)\nkey: full path\nvalue: body\nversion ID: enabled at the bucket level\nmetadata\ntags\n\n\n\n\nuser-based\n\nIAM policies\n\nresource-based\n\nbucket policies: allows cross account\nbucket ACL(Access Control List)\nobject ACL\n\nblock public access\n\n\n\n\n\nCRR: Cross-Region Replication\nSRR: Same-Region Replication\nversioning must be enabled on both source and destination buckets\nreplication is asynchronous\nreplication is cross-account\n\n\n\n\ndelete marker is replicated\noptional setting\n\n\n\n\n\ncan replicate existing objects and failed replication\n\n\n\n\n\n\nS3 Standard: 99.99% availability, general purpose #### infrequent access : for data that is less frequently accessed but requires rapid access when needed\nS3 Standard-IA: 99.9% availability\nS3 One Zone-IA: 99.5% availability #### Glacier : lower cost, for archive / backup\nS3 Glacier instant retrieval: milliseconds retrieval, 90 days minimum storage\nS3 Glacier flexible retireval: minutes to hours retrieval, 90 days minimum storage\nS3 Glacier Deep Archive: 12 hours to 48 hours retrieval, 180 days minimum storage\nS3 Intelligent-Tiering: auto pricing, auto move between IA and Standard\n\n\n\n\n: automate moving objects between storage classes - transition action - expriation action\n\n\n\n\nS3 event notification: SNS, SQS, Lambda\n\n\n\n\n\n3,500 PUT/COPY/POST/DELETE and 5,500 GET/HEAD requests per second per prefix in a bucket\n\n\n\n\n\nCloudFront edge locations\nmultipart upload is compatible\n\n\n\n\n\n\n\nS3 byte-range fetches\n\n\n\n\n\n\nS3 select: SQL query on S3 objects\nGlacier select: SQL query on Glacier objects\n\n\n\n\n\nS3 Batch Operations: S3 operations on large number of objects use cases: encrypt unencrypted objects, copy objects, … \n\n\n\n\n\nmulti-account, multi-region analyze dashboard\n\n\n\n\n\nSSE\n\nSSE-S3: S3 managed keys, enabled by default, must set request header x-amz-server-side-encryption: AES256\nSSE-KMS: KMS managed, must set request header x-amz-server-side-encryption: aws:kms, request limits\nSSE-C: customer managed, must set request header x-amz-server-side-encryption-customer-algorithm: AES256, must provide encryption key\n\nCSE\n\nclient-side encryption\n\n\n\n\n\n\npermanently delete objects\nsuspend versioning on bucket\nto enable, must enable versioning on bucket and only the bucket owner(root account) can enable MFA\n\n\n\n\n\ncompliance and WORM (Write Once Read Many) model\nbucket level lock\n\n\n\n\n\ncompliance and WORM (Write Once Read Many) model\nblock object deletion for a specified retention period\nmust set versioning\ncompliance and governance mode\nlegal hold: protect object from deletion indefinitely",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS S3"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/07_S3.html#aws-s3",
    "href": "posts/04_archives/aws_saa/notes/07_S3.html#aws-s3",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "Simple Storage Service\nobject storage service\nunlimited storage\ndefined at region level\nmax object size: 5TB (larger objects than 5GB can be stored using multipart upload)\nkey: full path\nvalue: body\nversion ID: enabled at the bucket level\nmetadata\ntags\n\n\n\n\nuser-based\n\nIAM policies\n\nresource-based\n\nbucket policies: allows cross account\nbucket ACL(Access Control List)\nobject ACL\n\nblock public access\n\n\n\n\n\nCRR: Cross-Region Replication\nSRR: Same-Region Replication\nversioning must be enabled on both source and destination buckets\nreplication is asynchronous\nreplication is cross-account\n\n\n\n\ndelete marker is replicated\noptional setting\n\n\n\n\n\ncan replicate existing objects and failed replication\n\n\n\n\n\n\nS3 Standard: 99.99% availability, general purpose #### infrequent access : for data that is less frequently accessed but requires rapid access when needed\nS3 Standard-IA: 99.9% availability\nS3 One Zone-IA: 99.5% availability #### Glacier : lower cost, for archive / backup\nS3 Glacier instant retrieval: milliseconds retrieval, 90 days minimum storage\nS3 Glacier flexible retireval: minutes to hours retrieval, 90 days minimum storage\nS3 Glacier Deep Archive: 12 hours to 48 hours retrieval, 180 days minimum storage\nS3 Intelligent-Tiering: auto pricing, auto move between IA and Standard\n\n\n\n\n: automate moving objects between storage classes - transition action - expriation action\n\n\n\n\nS3 event notification: SNS, SQS, Lambda\n\n\n\n\n\n3,500 PUT/COPY/POST/DELETE and 5,500 GET/HEAD requests per second per prefix in a bucket\n\n\n\n\n\nCloudFront edge locations\nmultipart upload is compatible\n\n\n\n\n\n\n\nS3 byte-range fetches\n\n\n\n\n\n\nS3 select: SQL query on S3 objects\nGlacier select: SQL query on Glacier objects\n\n\n\n\n\nS3 Batch Operations: S3 operations on large number of objects use cases: encrypt unencrypted objects, copy objects, … \n\n\n\n\n\nmulti-account, multi-region analyze dashboard\n\n\n\n\n\nSSE\n\nSSE-S3: S3 managed keys, enabled by default, must set request header x-amz-server-side-encryption: AES256\nSSE-KMS: KMS managed, must set request header x-amz-server-side-encryption: aws:kms, request limits\nSSE-C: customer managed, must set request header x-amz-server-side-encryption-customer-algorithm: AES256, must provide encryption key\n\nCSE\n\nclient-side encryption\n\n\n\n\n\n\npermanently delete objects\nsuspend versioning on bucket\nto enable, must enable versioning on bucket and only the bucket owner(root account) can enable MFA\n\n\n\n\n\ncompliance and WORM (Write Once Read Many) model\nbucket level lock\n\n\n\n\n\ncompliance and WORM (Write Once Read Many) model\nblock object deletion for a specified retention period\nmust set versioning\ncompliance and governance mode\nlegal hold: protect object from deletion indefinitely",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS S3"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/02_ec2.html",
    "href": "posts/04_archives/aws_saa/notes/02_ec2.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "EC2 stands for Elastic Compute Cloud. It is a web service provided by Amazon Web Services (AWS) that allows users to rent virtual servers in the cloud.\nEC2 instances can be easily scaled up or down based on the user’s needs, providing flexibility and cost efficiency.\nThese instances can be used to run applications, host websites, process large amounts of data, and perform various other computing tasks.\nEC2 offers a wide range of instance types to cater to different workloads, and users have full control over the configuration and management of their instances.\n\n\n\nlaunch virtual servers\nmanage storage (EBS, EFS, S3)\nscale up or down based on demand (ASG)\ndistribute traffic across multiple instances (ELB)\n\n\n\n\n\nos\nCPU\nmemory\nstorage\nnetwork\nsecurity (IAM, security groups, key pairs)\nbootstrap scripts (user data)\n\n\n\n\n\ngeneral purpose (t2, m5)\ncompute optimized (c5)\nmemory optimized (r5)\nstorage optimized (i3)\naccelerated computing (p3, g4)\n\n\n\n\n\nact as a virtual firewall for your EC2 instances\ncontrol inbound and outbound traffic\ncan be associated with multiple instances\nlocked down to a region/VPC combination\ndoes live outside the EC2 - if traffic is blocked, the EC2 instance won’t see it (time out)\ncan reference other security groups\n\n\n\n\n\non-demand: pay for what you use\nreserved: capacity reservation for 1 or 3 years\n\n\nreserved\nconvertible reserved instances\ngood for steady-state usage application(db)\nreserve a specific instance attributes (instance type, region, tenancy, os)\nyou can buy and sell in marketplace\n\n\nspot: bid for unused capacity\nsavings plan: commit to a consistent amount of usage for a discount\nif beyond pay, converted to on-demand\nlocked to a specific instance family, aws region\nflexible: instance size, os, tenancy\ndedicated hosts: physical server dedicated for your use\ndedicated instances: instance running on a dedicated host\ncapacity reservation: reserve capacity for specific instance type in a specific AZ\n\n\n\n\n\ncluster: low latency, high throughput\npartition: multiple EC2 instances within a single AZ\nspread: EC2 instances on distinct hardware, maximum 7",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "what is EC2"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/02_ec2.html#what-is-ec2",
    "href": "posts/04_archives/aws_saa/notes/02_ec2.html#what-is-ec2",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "EC2 stands for Elastic Compute Cloud. It is a web service provided by Amazon Web Services (AWS) that allows users to rent virtual servers in the cloud.\nEC2 instances can be easily scaled up or down based on the user’s needs, providing flexibility and cost efficiency.\nThese instances can be used to run applications, host websites, process large amounts of data, and perform various other computing tasks.\nEC2 offers a wide range of instance types to cater to different workloads, and users have full control over the configuration and management of their instances.\n\n\n\nlaunch virtual servers\nmanage storage (EBS, EFS, S3)\nscale up or down based on demand (ASG)\ndistribute traffic across multiple instances (ELB)\n\n\n\n\n\nos\nCPU\nmemory\nstorage\nnetwork\nsecurity (IAM, security groups, key pairs)\nbootstrap scripts (user data)\n\n\n\n\n\ngeneral purpose (t2, m5)\ncompute optimized (c5)\nmemory optimized (r5)\nstorage optimized (i3)\naccelerated computing (p3, g4)\n\n\n\n\n\nact as a virtual firewall for your EC2 instances\ncontrol inbound and outbound traffic\ncan be associated with multiple instances\nlocked down to a region/VPC combination\ndoes live outside the EC2 - if traffic is blocked, the EC2 instance won’t see it (time out)\ncan reference other security groups\n\n\n\n\n\non-demand: pay for what you use\nreserved: capacity reservation for 1 or 3 years\n\n\nreserved\nconvertible reserved instances\ngood for steady-state usage application(db)\nreserve a specific instance attributes (instance type, region, tenancy, os)\nyou can buy and sell in marketplace\n\n\nspot: bid for unused capacity\nsavings plan: commit to a consistent amount of usage for a discount\nif beyond pay, converted to on-demand\nlocked to a specific instance family, aws region\nflexible: instance size, os, tenancy\ndedicated hosts: physical server dedicated for your use\ndedicated instances: instance running on a dedicated host\ncapacity reservation: reserve capacity for specific instance type in a specific AZ\n\n\n\n\n\ncluster: low latency, high throughput\npartition: multiple EC2 instances within a single AZ\nspread: EC2 instances on distinct hardware, maximum 7",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "what is EC2"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/14_machine_learning.html",
    "href": "posts/04_archives/aws_saa/notes/14_machine_learning.html",
    "title": "Amazon Rekognition",
    "section": "",
    "text": "Amazon Rekognition\n\nfind objects, people, text, scenes in image and video analysis ## content moderation\ndetect explicit and suggestive content\na2i for human review\n\n\n\nAmazon Transcribe\n: speech-to-text service\n\n\nAmazon Polly\n: text-to-speech service\n\n\nAmazon Translate\n: language translation service\n\n\nAmazon Comprehend\n: natural language processing service\n\n\nAmazon Lex\n: chatbot service\n\n\nAmazon SageMaker\n: machine learning service\n\n\nAmazon Forecast\n: time series forecasting service\n\n\nkendra\n: document search service\n\n\nAmazon Personalize\n: personalized recommendation service\n\n\nTextract\n: OCR service\n\n\n\n\n 맨 위로",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon Rekognition"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/01.html",
    "href": "posts/04_archives/adp_실기/notes/01.html",
    "title": "pandas data 구조",
    "section": "",
    "text": "pandas: numpy를 라벨링한거",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "pandas data 구조"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/01.html#before",
    "href": "posts/04_archives/adp_실기/notes/01.html#before",
    "title": "pandas data 구조",
    "section": "Before",
    "text": "Before\n데이터를 호출하고, 데이터 내용과 요약 / 통계 정보를 확인해야함\n칼럼명이 칼럼 타입을 변경해야할 때도 있음\n\nPandas 사용 준비\n\n라이브러리 설치\n라이브러리 호출\n\n\nimport pandas as pd\n\npd.set_option('display.max_rows', 10)\n\n\n\nDataFrame 선언\n\nimport numpy as np\ndataset = np.array([['kor', 70], ['math', 80]])\n# declare df 1\ndf = pd.DataFrame(dataset, columns=['class', 'score'])\n# declare df 2\ndf = pd.DataFrame([['kor', 70], ['math', 80]], columns=['class', 'score'])\n# declare df 3\ndf = pd.DataFrame({'class': ['kor', 'math'], 'score': [70, 80]})\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n\n\n\n\n0\nkor\n70\n\n\n1\nmath\n80\n\n\n\n\n\n\n\n\n\nDataFrame 읽고 저장\n\n# filepath = '../book/data/data.csv'\n# data = pd.read_csv(filepath, na_values='NA', encoding='utf8')\n# data.to_csv('result.csv', header=True, index=True, encoding='utf8')\n\n\n\nDataFrame 출력\n\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\niris\n\n{'data': array([[5.1, 3.5, 1.4, 0.2],\n        [4.9, 3. , 1.4, 0.2],\n        [4.7, 3.2, 1.3, 0.2],\n        [4.6, 3.1, 1.5, 0.2],\n        [5. , 3.6, 1.4, 0.2],\n        [5.4, 3.9, 1.7, 0.4],\n        [4.6, 3.4, 1.4, 0.3],\n        [5. , 3.4, 1.5, 0.2],\n        [4.4, 2.9, 1.4, 0.2],\n        [4.9, 3.1, 1.5, 0.1],\n        [5.4, 3.7, 1.5, 0.2],\n        [4.8, 3.4, 1.6, 0.2],\n        [4.8, 3. , 1.4, 0.1],\n        [4.3, 3. , 1.1, 0.1],\n        [5.8, 4. , 1.2, 0.2],\n        [5.7, 4.4, 1.5, 0.4],\n        [5.4, 3.9, 1.3, 0.4],\n        [5.1, 3.5, 1.4, 0.3],\n        [5.7, 3.8, 1.7, 0.3],\n        [5.1, 3.8, 1.5, 0.3],\n        [5.4, 3.4, 1.7, 0.2],\n        [5.1, 3.7, 1.5, 0.4],\n        [4.6, 3.6, 1. , 0.2],\n        [5.1, 3.3, 1.7, 0.5],\n        [4.8, 3.4, 1.9, 0.2],\n        [5. , 3. , 1.6, 0.2],\n        [5. , 3.4, 1.6, 0.4],\n        [5.2, 3.5, 1.5, 0.2],\n        [5.2, 3.4, 1.4, 0.2],\n        [4.7, 3.2, 1.6, 0.2],\n        [4.8, 3.1, 1.6, 0.2],\n        [5.4, 3.4, 1.5, 0.4],\n        [5.2, 4.1, 1.5, 0.1],\n        [5.5, 4.2, 1.4, 0.2],\n        [4.9, 3.1, 1.5, 0.2],\n        [5. , 3.2, 1.2, 0.2],\n        [5.5, 3.5, 1.3, 0.2],\n        [4.9, 3.6, 1.4, 0.1],\n        [4.4, 3. , 1.3, 0.2],\n        [5.1, 3.4, 1.5, 0.2],\n        [5. , 3.5, 1.3, 0.3],\n        [4.5, 2.3, 1.3, 0.3],\n        [4.4, 3.2, 1.3, 0.2],\n        [5. , 3.5, 1.6, 0.6],\n        [5.1, 3.8, 1.9, 0.4],\n        [4.8, 3. , 1.4, 0.3],\n        [5.1, 3.8, 1.6, 0.2],\n        [4.6, 3.2, 1.4, 0.2],\n        [5.3, 3.7, 1.5, 0.2],\n        [5. , 3.3, 1.4, 0.2],\n        [7. , 3.2, 4.7, 1.4],\n        [6.4, 3.2, 4.5, 1.5],\n        [6.9, 3.1, 4.9, 1.5],\n        [5.5, 2.3, 4. , 1.3],\n        [6.5, 2.8, 4.6, 1.5],\n        [5.7, 2.8, 4.5, 1.3],\n        [6.3, 3.3, 4.7, 1.6],\n        [4.9, 2.4, 3.3, 1. ],\n        [6.6, 2.9, 4.6, 1.3],\n        [5.2, 2.7, 3.9, 1.4],\n        [5. , 2. , 3.5, 1. ],\n        [5.9, 3. , 4.2, 1.5],\n        [6. , 2.2, 4. , 1. ],\n        [6.1, 2.9, 4.7, 1.4],\n        [5.6, 2.9, 3.6, 1.3],\n        [6.7, 3.1, 4.4, 1.4],\n        [5.6, 3. , 4.5, 1.5],\n        [5.8, 2.7, 4.1, 1. ],\n        [6.2, 2.2, 4.5, 1.5],\n        [5.6, 2.5, 3.9, 1.1],\n        [5.9, 3.2, 4.8, 1.8],\n        [6.1, 2.8, 4. , 1.3],\n        [6.3, 2.5, 4.9, 1.5],\n        [6.1, 2.8, 4.7, 1.2],\n        [6.4, 2.9, 4.3, 1.3],\n        [6.6, 3. , 4.4, 1.4],\n        [6.8, 2.8, 4.8, 1.4],\n        [6.7, 3. , 5. , 1.7],\n        [6. , 2.9, 4.5, 1.5],\n        [5.7, 2.6, 3.5, 1. ],\n        [5.5, 2.4, 3.8, 1.1],\n        [5.5, 2.4, 3.7, 1. ],\n        [5.8, 2.7, 3.9, 1.2],\n        [6. , 2.7, 5.1, 1.6],\n        [5.4, 3. , 4.5, 1.5],\n        [6. , 3.4, 4.5, 1.6],\n        [6.7, 3.1, 4.7, 1.5],\n        [6.3, 2.3, 4.4, 1.3],\n        [5.6, 3. , 4.1, 1.3],\n        [5.5, 2.5, 4. , 1.3],\n        [5.5, 2.6, 4.4, 1.2],\n        [6.1, 3. , 4.6, 1.4],\n        [5.8, 2.6, 4. , 1.2],\n        [5. , 2.3, 3.3, 1. ],\n        [5.6, 2.7, 4.2, 1.3],\n        [5.7, 3. , 4.2, 1.2],\n        [5.7, 2.9, 4.2, 1.3],\n        [6.2, 2.9, 4.3, 1.3],\n        [5.1, 2.5, 3. , 1.1],\n        [5.7, 2.8, 4.1, 1.3],\n        [6.3, 3.3, 6. , 2.5],\n        [5.8, 2.7, 5.1, 1.9],\n        [7.1, 3. , 5.9, 2.1],\n        [6.3, 2.9, 5.6, 1.8],\n        [6.5, 3. , 5.8, 2.2],\n        [7.6, 3. , 6.6, 2.1],\n        [4.9, 2.5, 4.5, 1.7],\n        [7.3, 2.9, 6.3, 1.8],\n        [6.7, 2.5, 5.8, 1.8],\n        [7.2, 3.6, 6.1, 2.5],\n        [6.5, 3.2, 5.1, 2. ],\n        [6.4, 2.7, 5.3, 1.9],\n        [6.8, 3. , 5.5, 2.1],\n        [5.7, 2.5, 5. , 2. ],\n        [5.8, 2.8, 5.1, 2.4],\n        [6.4, 3.2, 5.3, 2.3],\n        [6.5, 3. , 5.5, 1.8],\n        [7.7, 3.8, 6.7, 2.2],\n        [7.7, 2.6, 6.9, 2.3],\n        [6. , 2.2, 5. , 1.5],\n        [6.9, 3.2, 5.7, 2.3],\n        [5.6, 2.8, 4.9, 2. ],\n        [7.7, 2.8, 6.7, 2. ],\n        [6.3, 2.7, 4.9, 1.8],\n        [6.7, 3.3, 5.7, 2.1],\n        [7.2, 3.2, 6. , 1.8],\n        [6.2, 2.8, 4.8, 1.8],\n        [6.1, 3. , 4.9, 1.8],\n        [6.4, 2.8, 5.6, 2.1],\n        [7.2, 3. , 5.8, 1.6],\n        [7.4, 2.8, 6.1, 1.9],\n        [7.9, 3.8, 6.4, 2. ],\n        [6.4, 2.8, 5.6, 2.2],\n        [6.3, 2.8, 5.1, 1.5],\n        [6.1, 2.6, 5.6, 1.4],\n        [7.7, 3. , 6.1, 2.3],\n        [6.3, 3.4, 5.6, 2.4],\n        [6.4, 3.1, 5.5, 1.8],\n        [6. , 3. , 4.8, 1.8],\n        [6.9, 3.1, 5.4, 2.1],\n        [6.7, 3.1, 5.6, 2.4],\n        [6.9, 3.1, 5.1, 2.3],\n        [5.8, 2.7, 5.1, 1.9],\n        [6.8, 3.2, 5.9, 2.3],\n        [6.7, 3.3, 5.7, 2.5],\n        [6.7, 3. , 5.2, 2.3],\n        [6.3, 2.5, 5. , 1.9],\n        [6.5, 3. , 5.2, 2. ],\n        [6.2, 3.4, 5.4, 2.3],\n        [5.9, 3. , 5.1, 1.8]]),\n 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n 'frame': None,\n 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='&lt;U10'),\n 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. dropdown:: References\\n\\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n    Mathematical Statistics\" (John Wiley, NY, 1950).\\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n    Structure and Classification Rule for Recognition in Partially Exposed\\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n    on Information Theory, May 1972, 431-433.\\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n    conceptual clustering system finds 3 classes in the data.\\n  - Many, many more ...\\n',\n 'feature_names': ['sepal length (cm)',\n  'sepal width (cm)',\n  'petal length (cm)',\n  'petal width (cm)'],\n 'filename': 'iris.csv',\n 'data_module': 'sklearn.datasets.data'}\n\n\n\niris = pd.DataFrame(iris.data, columns=iris.feature_names)\niris\n\n\n\n\n\n\n\n\nsepal length (cm)\nsepal width (cm)\npetal length (cm)\npetal width (cm)\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\n\n\n1\n4.9\n3.0\n1.4\n0.2\n\n\n2\n4.7\n3.2\n1.3\n0.2\n\n\n3\n4.6\n3.1\n1.5\n0.2\n\n\n4\n5.0\n3.6\n1.4\n0.2\n\n\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\n\n\n146\n6.3\n2.5\n5.0\n1.9\n\n\n147\n6.5\n3.0\n5.2\n2.0\n\n\n148\n6.2\n3.4\n5.4\n2.3\n\n\n149\n5.9\n3.0\n5.1\n1.8\n\n\n\n\n150 rows × 4 columns\n\n\n\n\niris.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 4 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   sepal length (cm)  150 non-null    float64\n 1   sepal width (cm)   150 non-null    float64\n 2   petal length (cm)  150 non-null    float64\n 3   petal width (cm)   150 non-null    float64\ndtypes: float64(4)\nmemory usage: 4.8 KB\n\n\n\niris.describe()\n\n\n\n\n\n\n\n\nsepal length (cm)\nsepal width (cm)\npetal length (cm)\npetal width (cm)\n\n\n\n\ncount\n150.000000\n150.000000\n150.000000\n150.000000\n\n\nmean\n5.843333\n3.057333\n3.758000\n1.199333\n\n\nstd\n0.828066\n0.435866\n1.765298\n0.762238\n\n\nmin\n4.300000\n2.000000\n1.000000\n0.100000\n\n\n25%\n5.100000\n2.800000\n1.600000\n0.300000\n\n\n50%\n5.800000\n3.000000\n4.350000\n1.300000\n\n\n75%\n6.400000\n3.300000\n5.100000\n1.800000\n\n\nmax\n7.900000\n4.400000\n6.900000\n2.500000\n\n\n\n\n\n\n\nsepal length와 petal width의 값의 차이가 크다.\n전처리 과정에서 변수 정규화 수행의 근거가 된다.\n\n\nindex / column 명 변경\n\ndf.index\n\nRangeIndex(start=0, stop=2, step=1)\n\n\n\nlist(df.index)\n\n[0, 1]\n\n\n\ndf.index = ['A', 'B']\ndf.index\n\nIndex(['A', 'B'], dtype='object')\n\n\n\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n\n\n\n\nA\nkor\n70\n\n\nB\nmath\n80\n\n\n\n\n\n\n\n\ndf.set_index('class', drop=True, append=False, inplace=True)\ndf\n\n\n\n\n\n\n\n\nscore\n\n\nclass\n\n\n\n\n\nkor\n70\n\n\nmath\n80\n\n\n\n\n\n\n\n\ndf.reset_index(drop=False, inplace=True)\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n\n\n\n\n0\nkor\n70\n\n\n1\nmath\n80\n\n\n\n\n\n\n\n\niris.columns\n\nIndex(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n       'petal width (cm)'],\n      dtype='object')\n\n\n\niris.columns = ['sepal length', 'sepal width', 'petal length', 'petal width']\niris\n\n\n\n\n\n\n\n\nsepal length\nsepal width\npetal length\npetal width\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\n\n\n1\n4.9\n3.0\n1.4\n0.2\n\n\n2\n4.7\n3.2\n1.3\n0.2\n\n\n3\n4.6\n3.1\n1.5\n0.2\n\n\n4\n5.0\n3.6\n1.4\n0.2\n\n\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\n\n\n146\n6.3\n2.5\n5.0\n1.9\n\n\n147\n6.5\n3.0\n5.2\n2.0\n\n\n148\n6.2\n3.4\n5.4\n2.3\n\n\n149\n5.9\n3.0\n5.1\n1.8\n\n\n\n\n150 rows × 4 columns\n\n\n\n\niris.columns = iris.columns.str.replace(' ', '_')\niris\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\n\n\n1\n4.9\n3.0\n1.4\n0.2\n\n\n2\n4.7\n3.2\n1.3\n0.2\n\n\n3\n4.6\n3.1\n1.5\n0.2\n\n\n4\n5.0\n3.6\n1.4\n0.2\n\n\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\n\n\n146\n6.3\n2.5\n5.0\n1.9\n\n\n147\n6.5\n3.0\n5.2\n2.0\n\n\n148\n6.2\n3.4\n5.4\n2.3\n\n\n149\n5.9\n3.0\n5.1\n1.8\n\n\n\n\n150 rows × 4 columns\n\n\n\n\n\n데이터 타입 변경\n사용 가능한 타입\n\nint\nfloat\nbool\ndatetime\ncategory\nobject\n\n\niris.dtypes\n\nsepal_length    float64\nsepal_width     float64\npetal_length    float64\npetal_width     float64\ndtype: object\n\n\n\niris['sepal_length'] = iris['sepal_length'].astype('int')\niris[['sepal_width', 'petal_length']] = \\\niris[['sepal_width', 'petal_length']].astype('int')\niris\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\n0\n5\n3\n1\n0.2\n\n\n1\n4\n3\n1\n0.2\n\n\n2\n4\n3\n1\n0.2\n\n\n3\n4\n3\n1\n0.2\n\n\n4\n5\n3\n1\n0.2\n\n\n...\n...\n...\n...\n...\n\n\n145\n6\n3\n5\n2.3\n\n\n146\n6\n2\n5\n1.9\n\n\n147\n6\n3\n5\n2.0\n\n\n148\n6\n3\n5\n2.3\n\n\n149\n5\n3\n5\n1.8\n\n\n\n\n150 rows × 4 columns",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "pandas data 구조"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/01.html#row-coumn-선택-추가-삭제",
    "href": "posts/04_archives/adp_실기/notes/01.html#row-coumn-선택-추가-삭제",
    "title": "pandas data 구조",
    "section": "row / coumn 선택 추가 삭제",
    "text": "row / coumn 선택 추가 삭제\n\nrow 선택\n\niris[0:4]\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\n0\n5\n3\n1\n0.2\n\n\n1\n4\n3\n1\n0.2\n\n\n2\n4\n3\n1\n0.2\n\n\n3\n4\n3\n1\n0.2\n\n\n\n\n\n\n\n\n\ncolumn 선택\nSeries 형식으로 출력\n\niris['sepal_length']\n\n0      5\n1      4\n2      4\n3      4\n4      5\n      ..\n145    6\n146    6\n147    6\n148    6\n149    5\nName: sepal_length, Length: 150, dtype: int64\n\n\nDataFrame 형식으로 출력\n\niris[['sepal_length', 'sepal_width']]\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\n\n\n\n\n0\n5\n3\n\n\n1\n4\n3\n\n\n2\n4\n3\n\n\n3\n4\n3\n\n\n4\n5\n3\n\n\n...\n...\n...\n\n\n145\n6\n3\n\n\n146\n6\n2\n\n\n147\n6\n3\n\n\n148\n6\n3\n\n\n149\n5\n3\n\n\n\n\n150 rows × 2 columns\n\n\n\n\n\ncolumn, row 선택\n\niris.loc[0:4, ['sepal_length', 'sepal_width']]\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\n\n\n\n\n0\n5\n3\n\n\n1\n4\n3\n\n\n2\n4\n3\n\n\n3\n4\n3\n\n\n4\n5\n3\n\n\n\n\n\n\n\n\niris.iloc[0:4, [1, 2]]\n\n\n\n\n\n\n\n\nsepal_width\npetal_length\n\n\n\n\n0\n3\n1\n\n\n1\n3\n1\n\n\n2\n3\n1\n\n\n3\n3\n1\n\n\n\n\n\n\n\n\n\nrow 추가\n\n# 방법 1: concat 사용\n# df = pd.concat([df, pd.DataFrame([{'class': 'eng', 'score': 90}])], ignore_index=True)\n\n# 방법 2: loc 사용 \ndf.loc[len(df)] = {'class': 'eng', 'score': 90}\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n\n\n\n\n0\nkor\n70\n\n\n1\nmath\n80\n\n\n2\neng\n90\n\n\n\n\n\n\n\n\n\ncolumn 추가\n\ndf['yo'] = df['score'] + 10\ndf\n\n\n\n\n\n\n\n\nclass\nscore\nyo\n\n\n\n\n0\nkor\n70\n80\n\n\n1\nmath\n80\n90\n\n\n2\neng\n90\n100\n\n\n\n\n\n\n\n\n\nrow 삭제\n\ndf.drop(2, inplace=True)\ndf\n\n\n\n\n\n\n\n\nclass\nscore\nyo\n\n\n\n\n0\nkor\n70\n80\n\n\n1\nmath\n80\n90\n\n\n\n\n\n\n\n\n\ncolumn 삭제\n\ndf.drop(columns=['yo'], inplace=True)\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n\n\n\n\n0\nkor\n70\n\n\n1\nmath\n80",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "pandas data 구조"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/01.html#조건-선택",
    "href": "posts/04_archives/adp_실기/notes/01.html#조건-선택",
    "title": "pandas data 구조",
    "section": "조건 선택",
    "text": "조건 선택\n\niris[(iris['sepal_length'] &gt; 5) & (iris['sepal_width'] &lt; 3)]\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\n54\n6\n2\n4\n1.5\n\n\n58\n6\n2\n4\n1.3\n\n\n62\n6\n2\n4\n1.0\n\n\n63\n6\n2\n4\n1.4\n\n\n68\n6\n2\n4\n1.5\n\n\n...\n...\n...\n...\n...\n\n\n130\n7\n2\n6\n1.9\n\n\n132\n6\n2\n5\n2.2\n\n\n133\n6\n2\n5\n1.5\n\n\n134\n6\n2\n5\n1.4\n\n\n146\n6\n2\n5\n1.9\n\n\n\n\n29 rows × 4 columns\n\n\n\n\ndf.loc[df['score'] &gt; 70, '합격'] = 'Pass'\ndf.loc[df['합격'] != 'Pass', '합격'] = 'Fail'\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n합격\n\n\n\n\n0\nkor\n70\nFail\n\n\n1\nmath\n80\nPass\n\n\n\n\n\n\n\n\nimport numpy as np\n\ncondition_list = [(df['score'] &gt;= 70), \n                  (df['score'] &lt; 70) & (df['score'] &gt;= 60),\n                  (df['score'] &lt; 60)]\ngrade_list = ['A', 'B', 'C']\ndf['grade'] = np.select(condition_list, grade_list, default='F')\ndf\n\n\n\n\n\n\n\n\nclass\nscore\n합격\ngrade\n\n\n\n\n0\nkor\n70\nFail\nA\n\n\n1\nmath\n80\nPass\nA\n\n\n\n\n\n\n\n\n결측치 탐색\n\ndf.isna().sum()\n\nclass    0\nscore    0\n합격       0\ngrade    0\ndtype: int64\n\n\n\ndf.notna().sum(1) # 행 기준\n\n0    4\n1    4\ndtype: int64\n\n\n\n\n결측치 제거\n\n# dropna(axis=0, how='any' or 'all', thresh=None, subset=None, inplace=False)\ndf.dropna()\n\n\n\n\n\n\n\n\nclass\nscore\n합격\ngrade\n\n\n\n\n0\nkor\n70\nFail\nA\n\n\n1\nmath\n80\nPass\nA\n\n\n\n\n\n\n\n\n\n결측치 대체\n\n# fillna(value=None, method=None ('pad', 'ffill', 'backfill', 'bfill'), axis=None, inplace=False, limit=None)",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "pandas data 구조"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#edaexploratory-data-analysis",
    "href": "posts/04_archives/adp_실기/notes/02.html#edaexploratory-data-analysis",
    "title": "EDA와 시각화",
    "section": "EDA(Exploratory Data Analysis)",
    "text": "EDA(Exploratory Data Analysis)\n: 데이터의 특징과 데이터에 내재된 관계를 알아내기 위해 그래프와 통계적 분석 방법을 활용하여 탐구하는 것\n\n주제\n\n저항성 강조: 부분적 변동(이상치 등)에 대한 민감성 확인\n잔차 계산\n자료변수의 재표현: 변수를 적당한 척도로 바꾸는 것\n그래프를 통한 현시성",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#막대-그래프",
    "href": "posts/04_archives/adp_실기/notes/02.html#막대-그래프",
    "title": "EDA와 시각화",
    "section": "막대 그래프",
    "text": "막대 그래프\n범주형 데이터를 요약하고 시각적으로 비교하는 데 활용\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_wine\n\nwine_load = load_wine()\nwine = pd.DataFrame(wine_load.data, columns=wine_load.feature_names)\nwine_load\nwine['Class'] = wine_load.target\nwine['Class'] = wine['Class'].map({0: 'class_0', 1: 'class_1', 2: 'class_2'})\n\nwine_type = wine['Class'].value_counts()\nwine_type\n\nClass\nclass_1    71\nclass_0    59\nclass_2    48\nName: count, dtype: int64\n\n\n\n# 수직 막대\nplt.bar(wine_type.index, wine_type.values, width=0.8, bottom=None, align = 'center')\nplt.show()\n\n\n\n\n\n\n\n\n\n# 수평 막대\nplt.barh(wine_type.index, wine_type.values, height=0.8, left=None, align = 'center')\nplt.show()\n\n\n\n\n\n\n\n\n각 범주의 값의 갯수 차이가 극단적인지 확인한다. 극단적일 경우, 전처리 과정에서 업/다운 샘플링 등을 통해 갯수가 유사해지도록 조정해야한다.",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#히스토그램",
    "href": "posts/04_archives/adp_실기/notes/02.html#히스토그램",
    "title": "EDA와 시각화",
    "section": "히스토그램",
    "text": "히스토그램\n연속형 데이터의 분포를 확인하는 데 활용\n\nplt.title('Wine alcohol histogram')\nplt.hist('alcohol', bins=8, range=(11, 15), color='purple', data=wine)\nplt.show()",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#box-plot",
    "href": "posts/04_archives/adp_실기/notes/02.html#box-plot",
    "title": "EDA와 시각화",
    "section": "box plot",
    "text": "box plot\n수치형 변수의 분포를 확인하는 그래프\n\nfrom sklearn.datasets import load_iris\n\niris_load = load_iris()\niris = pd.DataFrame(iris_load.data, columns=iris_load.feature_names)\niris['class'] = iris_load.target\niris['class'] = iris['class'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n\nplt.boxplot(iris.drop(columns='class'))\nplt.show()\n\n\n\n\n\n\n\n\n\nimport seaborn as sns\n\nsns.boxplot(x=\"class\", y=\"sepal width (cm)\", data=iris)\nplt.show()",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#산점도",
    "href": "posts/04_archives/adp_실기/notes/02.html#산점도",
    "title": "EDA와 시각화",
    "section": "산점도",
    "text": "산점도\n두 개의 수치형 변수의 분포와 관계를 확인하는 그래프\n\nplt.title('iris scatter')\nplt.xlabel('sepal length (cm)')\nplt.ylabel('sepal width (cm)')\n\nplt.scatter('sepal length (cm)', 'sepal width (cm)', data=iris, alpha=0.5)\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.scatterplot(x='sepal length (cm)', y='sepal width (cm)', hue='class', data=iris, style='class')\nplt.show()",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#선그래프",
    "href": "posts/04_archives/adp_실기/notes/02.html#선그래프",
    "title": "EDA와 시각화",
    "section": "선그래프",
    "text": "선그래프\n\n수평 / 수직 선\n\nplt.hlines(y=-6, xmin=-10, xmax=10, colors='red', linestyles='solid')\nplt.vlines(x=0, ymin=-10, ymax=10, colors='blue', linestyles='dashed')\n\n\n\n\n\n\n\n\n\n\n함수식\n\ndef linear_func(x):\n    return 2*x + 1\n\nX = iris['sepal length (cm)']\nplt.plot(X, linear_func(X), c='red')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n회귀선\n\nimport numpy as np\n\nX, Y = iris['sepal length (cm)'], iris['sepal width (cm)']\nplt.scatter(X, Y, alpha=0.5)\na, b = np.polyfit(X, Y, 1)\nplt.plot(X, a*X + b, c='red')\nplt.show()\n\n\n\n\n\n\n\n\n2차 이상의 그래프는 X값에 대하여 정렬해야 한다.\n\niris2 = iris.sort_values(by='sepal length (cm)')\nX, Y = iris2['sepal length (cm)'], iris2['petal length (cm)']\nb2, b1, b0 = np.polyfit(X, Y, 2)\nplt.scatter(X, Y, alpha=0.5)\nplt.plot(X, b0 + b1*X + b2*X**2, color='red')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n꺾은선\n\nplt.plot('sepal length (cm)', 'petal length (cm)', data=iris2)\nplt.show()",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#상관관계-시각화",
    "href": "posts/04_archives/adp_실기/notes/02.html#상관관계-시각화",
    "title": "EDA와 시각화",
    "section": "상관관계 시각화",
    "text": "상관관계 시각화\n\n산점도 행렬\n\nfrom pandas.plotting import scatter_matrix\n\nscatter_matrix(iris, alpha=0.5, figsize= (8, 8), diagonal='hist')\nplt.show()\n\n\n\n\n\n\n\n\n\nsns.pairplot(iris, diag_kind='auto', hue='class')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n상관계수 행렬 그래프\n\niris_corr = iris.drop(columns='class').corr(method='pearson')\nsns.heatmap(iris_corr, xticklabels=iris_corr.columns, yticklabels=iris_corr.columns, cmap=\"RdBu_r\", annot=True)",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/02.html#pandas-profiling",
    "href": "posts/04_archives/adp_실기/notes/02.html#pandas-profiling",
    "title": "EDA와 시각화",
    "section": "Pandas Profiling",
    "text": "Pandas Profiling\n\n# from pandas_profiling import ProfileReport\n#\n# ProfileReport(iris)",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "EDA와 시각화"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/3_cluster_maintainance.html",
    "href": "posts/04_archives/k8s/notes/3_cluster_maintainance.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "k8s wait for 5 minutes to mark a node as ‘dead’ in default\nif a node is marked as ‘dead’, the pods on the node will be rescheduled to other nodes\ndrain: remove all the pods from a node and reschedule them to other nodes\ncordon: mark a node as ‘unschedulable’ so that no new pods will be scheduled to the node\nuncordon: mark a node as ‘schedulable’ so that new pods can be scheduled to the node but the original pods will not be rescheduled",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "fail tolerance"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/3_cluster_maintainance.html#fail-tolerance",
    "href": "posts/04_archives/k8s/notes/3_cluster_maintainance.html#fail-tolerance",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "k8s wait for 5 minutes to mark a node as ‘dead’ in default\nif a node is marked as ‘dead’, the pods on the node will be rescheduled to other nodes\ndrain: remove all the pods from a node and reschedule them to other nodes\ncordon: mark a node as ‘unschedulable’ so that no new pods will be scheduled to the node\nuncordon: mark a node as ‘schedulable’ so that new pods can be scheduled to the node but the original pods will not be rescheduled",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "fail tolerance"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/3_cluster_maintainance.html#cluster-upgrade-process",
    "href": "posts/04_archives/k8s/notes/3_cluster_maintainance.html#cluster-upgrade-process",
    "title": "김형훈의 학습 블로그",
    "section": "cluster upgrade process",
    "text": "cluster upgrade process\n - k8s supports up to recent 3 minor versions  ### kubeadm upgrade 1. upgrade kubeadm 2. command: kubeadm upgrade apply 3. upgrade kubelet and kubectl",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "fail tolerance"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/7_design_cluster.html",
    "href": "posts/04_archives/k8s/notes/7_design_cluster.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "api-server: multiple instances, active-active, load balancer\ncontroller-manager: multiple instances, active-standby, leader election",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "HA in master node"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/7_design_cluster.html#ha-in-master-node",
    "href": "posts/04_archives/k8s/notes/7_design_cluster.html#ha-in-master-node",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "api-server: multiple instances, active-active, load balancer\ncontroller-manager: multiple instances, active-standby, leader election",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "HA in master node"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "if scheduler is not exist, user can mannually schedule pods to nodes - in pod spec, set nodeName field to the name of the node - if the node is not exist, the pod will be in Pending state - bind request",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#manual-scheduling",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#manual-scheduling",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "if scheduler is not exist, user can mannually schedule pods to nodes - in pod spec, set nodeName field to the name of the node - if the node is not exist, the pod will be in Pending state - bind request",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#taints-and-tolerations",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#taints-and-tolerations",
    "title": "김형훈의 학습 블로그",
    "section": "taints and tolerations",
    "text": "taints and tolerations\n\ntaints: a taint is a key-value pair that is applied to a node\ntolerations: a toleration is a key-value pair that is applied to a pod  \nnot garantee that the pod will be scheduled to the node",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#node-affinity",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#node-affinity",
    "title": "김형훈의 학습 블로그",
    "section": "node affinity",
    "text": "node affinity\n\n\n\nnode affinity",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#resource-limits-requests",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#resource-limits-requests",
    "title": "김형훈의 학습 블로그",
    "section": "resource limits, requests",
    "text": "resource limits, requests\n\nresource limits: the maximum amount of resources that a container can use\nresource requests: the amount of resources that a container is guaranteed to have\nresource quotas: the maximum amount of resources that a namespace can use\nlimit range: the minimum and maximum amount of resources that a container can use when it is created",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#static-pod",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#static-pod",
    "title": "김형훈의 학습 블로그",
    "section": "static pod",
    "text": "static pod\n\nstatic pod is a pod that is created by the kubelet on a node\nif kube-api is available, the kubelet will create the mirror pod in the api server. that is read-only  or in /etc/kubernetes/manifests",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#multiple-shedulers",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#multiple-shedulers",
    "title": "김형훈의 학습 블로그",
    "section": "multiple shedulers",
    "text": "multiple shedulers",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/1_scheduler.html#configuring-sheduler-profile",
    "href": "posts/04_archives/k8s/notes/1_scheduler.html#configuring-sheduler-profile",
    "title": "김형훈의 학습 블로그",
    "section": "configuring sheduler profile",
    "text": "configuring sheduler profile\n: single sheduler, multi profile",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "manual scheduling"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/5_storage.html",
    "href": "posts/04_archives/k8s/notes/5_storage.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "A persistant volume is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using a storage class.\nuser can create a persistant volume claim to request a persistant volume with specific storage capacity and access modes.\n1:1 mapping between a persistant volume and a persistant volume claim.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Persistant volume"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/5_storage.html#persistant-volume",
    "href": "posts/04_archives/k8s/notes/5_storage.html#persistant-volume",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "A persistant volume is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using a storage class.\nuser can create a persistant volume claim to request a persistant volume with specific storage capacity and access modes.\n1:1 mapping between a persistant volume and a persistant volume claim.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Persistant volume"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/5_storage.html#storage-class",
    "href": "posts/04_archives/k8s/notes/5_storage.html#storage-class",
    "title": "김형훈의 학습 블로그",
    "section": "storage class",
    "text": "storage class\n\ndynamically provisioned persistant volumes.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Persistant volume"
    ]
  },
  {
    "objectID": "posts/04_archives/vault/index.html",
    "href": "posts/04_archives/vault/index.html",
    "title": "vault",
    "section": "",
    "text": "vault 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Archives",
      "vault"
    ]
  },
  {
    "objectID": "posts/04_archives/vault/index.html#details",
    "href": "posts/04_archives/vault/index.html#details",
    "title": "vault",
    "section": "",
    "text": "vault 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Archives",
      "vault"
    ]
  },
  {
    "objectID": "posts/04_archives/vault/index.html#tasks",
    "href": "posts/04_archives/vault/index.html#tasks",
    "title": "vault",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Archives",
      "vault"
    ]
  },
  {
    "objectID": "posts/04_archives/vault/index.html#참고-자료",
    "href": "posts/04_archives/vault/index.html#참고-자료",
    "title": "vault",
    "section": "참고 자료",
    "text": "참고 자료\n\nvault Udemy 강의",
    "crumbs": [
      "PARA",
      "Archives",
      "vault"
    ]
  },
  {
    "objectID": "posts/04_archives/vault/index.html#related-posts",
    "href": "posts/04_archives/vault/index.html#related-posts",
    "title": "vault",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Archives",
      "vault"
    ]
  },
  {
    "objectID": "posts/02_areas/terraform/index.html",
    "href": "posts/02_areas/terraform/index.html",
    "title": "Terraform",
    "section": "",
    "text": "terraform 정리 노트입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "Terraform"
    ]
  },
  {
    "objectID": "posts/02_areas/terraform/index.html#details",
    "href": "posts/02_areas/terraform/index.html#details",
    "title": "Terraform",
    "section": "",
    "text": "terraform 정리 노트입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "Terraform"
    ]
  },
  {
    "objectID": "posts/02_areas/terraform/index.html#tasks",
    "href": "posts/02_areas/terraform/index.html#tasks",
    "title": "Terraform",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Areas",
      "Terraform"
    ]
  },
  {
    "objectID": "posts/02_areas/terraform/index.html#참고-자료",
    "href": "posts/02_areas/terraform/index.html#참고-자료",
    "title": "Terraform",
    "section": "참고 자료",
    "text": "참고 자료\n\nKodeKloud - Terraform cloud",
    "crumbs": [
      "PARA",
      "Areas",
      "Terraform"
    ]
  },
  {
    "objectID": "posts/02_areas/terraform/index.html#related-posts",
    "href": "posts/02_areas/terraform/index.html#related-posts",
    "title": "Terraform",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Areas",
      "Terraform"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/index.html",
    "href": "posts/02_areas/선형대수/index.html",
    "title": "선형대수",
    "section": "",
    "text": "다음 학기에 들을 OR 수업에 필요한 선형대수를 다시 공부해봅시다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/index.html#details",
    "href": "posts/02_areas/선형대수/index.html#details",
    "title": "선형대수",
    "section": "",
    "text": "다음 학기에 들을 OR 수업에 필요한 선형대수를 다시 공부해봅시다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/index.html#tasks",
    "href": "posts/02_areas/선형대수/index.html#tasks",
    "title": "선형대수",
    "section": "Tasks",
    "text": "Tasks\n\n\n\n    \n    \n    \n            \n                \n                \n                    Khan Academy 강의 완강\n                \n                \n            \n            \n            \n                \n                \n                    3Blue1Brown 강의 완강\n                \n                \n            \n            \n            \n                \n                \n                    이 강의 완강",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/index.html#related-posts",
    "href": "posts/02_areas/선형대수/index.html#related-posts",
    "title": "선형대수",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/0.html#what-is-linear-algebra",
    "href": "posts/02_areas/선형대수/notes/0.html#what-is-linear-algebra",
    "title": "what is linear algebra",
    "section": "what is linear algebra",
    "text": "what is linear algebra\n선형 방정식을 matrix와 vector로 표현해서 다루는 수학\n\\(ax^2 + bx + c = 0\\) (x)\n\\(ax_1 + bx_2 + c = 0\\) (0)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "what is linear algebra"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/0.html#what-is-vector",
    "href": "posts/02_areas/선형대수/notes/0.html#what-is-vector",
    "title": "what is linear algebra",
    "section": "what is vector",
    "text": "what is vector\nvector는 크기(magnitude)와 방향(direction)을 가지고 있다.\n2, 3, 4 차원 너머를 수학적으로 표현할 수 있다.\nvector는 수학적으로, 아래와 같이 표현할 수 있다.\n\\[\n\\vec{v} =\n\\begin{bmatrix}\n3 \\\\\n4\n\\end{bmatrix}\n\\]",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "what is linear algebra"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/0.html#example",
    "href": "posts/02_areas/선형대수/notes/0.html#example",
    "title": "what is linear algebra",
    "section": "Example",
    "text": "Example\n\\[\\begin{aligned}\nx + 2y \\quad  &= 4 \\\\\n2x + 5y \\quad &= 9\n\\end{aligned}\\]\n위의 연립 1차 방정식을 matrix와 vector로 표현해보자\n\\[\n\\underset{A}{\\begin{bmatrix}\n1 & 2 \\\\\n2 & 5\n\\end{bmatrix}}\n\\underset{x}{\\begin{bmatrix}\nx \\\\\ny\n\\end{bmatrix}} =\n\\begin{bmatrix}\n1x + 2y \\\\\n2x + 5y\n\\end{bmatrix} =\n\\underset{b}{\\begin{bmatrix}\n4 \\\\\n9\n\\end{bmatrix}}\n\\]",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "what is linear algebra"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/5.html#선형결합",
    "href": "posts/02_areas/선형대수/notes/5.html#선형결합",
    "title": "선형결합과 생성",
    "section": "선형결합",
    "text": "선형결합\n벡터들의 상수배 합으로 만들 수 있는 벡터의 집합",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "선형결합과 생성"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/2.html#행렬의-곱을-바라보는-관점",
    "href": "posts/02_areas/선형대수/notes/2.html#행렬의-곱을-바라보는-관점",
    "title": "2-기초(2)",
    "section": "행렬의 곱을 바라보는 관점",
    "text": "행렬의 곱을 바라보는 관점\n\n내적으로 바라보기\n\n\\[\nA = \\begin{bmatrix}\na_1^T \\\\\na_2^T \\\\\na_3^T\n\\end{bmatrix}\n\\quad (a_x = \\text{column vector})\n\\]\n\\[\nAB = \\begin{bmatrix}\na_1^T \\\\\na_2^T \\\\\na_3^T\n\\end{bmatrix}\n\\begin{bmatrix}\nb_1 & b_2 & b_3\n\\end{bmatrix} =\n\\begin{bmatrix}\na_1^Tb_1 & a_1^Tb_2 & a_1^Tb_3 \\\\\na_2^Tb_1 & a_2^Tb_2 & a_2^Tb_3 \\\\\na_3^Tb_1 & a_3^Tb_2 & a_3^Tb_3\n\\end{bmatrix}\n\\]\n\nrank-1 matrix의 합\n\n\\[\nAB = \\begin{bmatrix}\na_1 & a_2 & a_3\n\\end{bmatrix}\n\\begin{bmatrix}\nb_1^T \\\\\nb_2^T \\\\\nb_3^T\n\\end{bmatrix} =\na_1^Tb_1 + a_2^Tb_2 + a_3^Tb_3\n\\]\n\nColumn space로 바라보기\n\n\\[\nAx = \\begin{bmatrix}\na_1 & a_2 & a_3\n\\end{bmatrix}\n\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{bmatrix} = a_1x_1 + a_2x_2 + a_3x_3\n\\]\n\nRow space로 바라보기\n\n\\[\nx^TA = \\begin{bmatrix}\nx_1 & x_2 & x_3\n\\end{bmatrix}\n\\begin{bmatrix}\na_1^T \\\\\na_2^T \\\\\na_3^T\n\\end{bmatrix} = x_1a_1^T + x_2a_2^T + x_3a_3^T\n\\]",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/2.html#span과-column-space",
    "href": "posts/02_areas/선형대수/notes/2.html#span과-column-space",
    "title": "2-기초(2)",
    "section": "span과 column space",
    "text": "span과 column space\n\ncolumn space: column vector들이 span하는 영역\nspan: linear combination으로 만들어지는 모든 벡터들의 집합\nlinear combination: vector들을 scalar 배 하고 더한 것\nlinear independent: span하는 vector들이 서로 독립적인 경우\n수학적 정의: \\(a_1v_1 + a_2v_2 + \\cdots + a_nv_n = 0\\) 일 때 \\(a_1 = a_2 = \\cdots = a_n = 0\\) 인 경우\nbasis: 어떤 공간을 이루는 필수적인 구성요소 (linear independent, span)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/2.html#항등행렬",
    "href": "posts/02_areas/선형대수/notes/2.html#항등행렬",
    "title": "2-기초(2)",
    "section": "항등행렬",
    "text": "항등행렬\n\\(AI = IA = A\\)를 만족하는 행렬 \\(I\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/2.html#역행렬",
    "href": "posts/02_areas/선형대수/notes/2.html#역행렬",
    "title": "2-기초(2)",
    "section": "역행렬",
    "text": "역행렬\n\\(Ax = b\\)를 만족하는 \\(x\\)를 찾는 것은 \\(A^{-1}Ax = A^{-1}b\\)를 만족하는 \\(x\\)를 찾는 것과 같다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/2.html#대각-행렬",
    "href": "posts/02_areas/선형대수/notes/2.html#대각-행렬",
    "title": "2-기초(2)",
    "section": "대각 행렬",
    "text": "대각 행렬\ndiagonal을 제외한 모든 요소가 0인 행렬 (square, rectangular 모두 가능)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/2.html#orthogonal-행렬",
    "href": "posts/02_areas/선형대수/notes/2.html#orthogonal-행렬",
    "title": "2-기초(2)",
    "section": "Orthogonal 행렬",
    "text": "Orthogonal 행렬\n행렬의 모든 column들이 orthonormal vector인 경우\n\\(Q^{-1} = Q^T\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/2.html#행렬의-rank",
    "href": "posts/02_areas/선형대수/notes/2.html#행렬의-rank",
    "title": "2-기초(2)",
    "section": "행렬의 rank",
    "text": "행렬의 rank\nrank: 행렬이 가지는 independent한 column의 개수 → column space의 차원\nrank(A) = rank(A^T)\n\nfull-column rank: 해가 없거나 한 개 존재\nfull-row rank: 해가 무한하다\nfull rank: 해가 한 개 있다.\nrank-deficient: b가 column space에 속하지 않는 경우 해가 없고, 그렇지 않으면 해가 무한하다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/2.html#null-space",
    "href": "posts/02_areas/선형대수/notes/2.html#null-space",
    "title": "2-기초(2)",
    "section": "Null space",
    "text": "Null space\n\\(Ax = 0\\)을 만족하는 모든 \\(x\\)의 집합\nA가 m x n 행렬이라면, dim(N(A)) = n - rank(A)\nnull space와 row space는 orthogonal하다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(2)"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/1.html#intro",
    "href": "posts/02_areas/42_seoul/notes/1.html#intro",
    "title": "ft_transcendence - github action",
    "section": "intro",
    "text": "intro\n\n\n\n42 seoul 공통과정 6서클 과제\n\n\n42 Seoul 공통과정의 마지막 과제입니다. 이 프로젝트는 개발자가 선호하는 라이브러리와 프레임워크를 자유롭게 선택하여 구현할 수 있다는 점이 특징입니다.\n대형 협업 과제인 만큼, 과제에 명시되어있지 않지만 협업을 위한 툴도 공부해서 다양하게 적용해볼 수 있는 좋은 과제인것 같습니다. 저같은 경우에는 coursera, udemy 강의를 통해 agile 협업 방식과 github에서의 적용 방법에 대해 공부를 했고, 프로젝트 진행에 있어서 꽤 도움이 됐던걸로 기억합니다. 사실 프로젝트를 진행하다보니, agile 방식을 온전히 다 적용하기엔 적합하지 않다고 판단했지만, Kanban Board로 프로젝트를 관리하는 것 같은 부분은 꽤 유용하게 활용할 수 있었습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "ft_transcendence - github action"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/1.html#프로젝트-및-구현-설명",
    "href": "posts/02_areas/42_seoul/notes/1.html#프로젝트-및-구현-설명",
    "title": "ft_transcendence - github action",
    "section": "프로젝트 및 구현 설명",
    "text": "프로젝트 및 구현 설명\n\n개요\n과제 명세서\n해당 과제는 실시간 Pong 게임 매칭 웹사이트를 만드는게 목표입니다. 저는 이번 프로젝트에서 github action 설정, User Management Backend 설계와 42 API를 이용한 OAuth 인증, JWT 구현, Game History를 Block Chain으로 저장하는 파트를 담당했습니다.\n참고한 자료는 다음과 같습니다:\n\nGoogle Agile Project 관리\nGithub Action Docs\nGithub CLI Docs\nDjango udemy 강좌\nDjango Rest Framework Docs\nDjango Simple JWT\nJWT Token 탈취 대응 시나리오\nmicro service에서 JWT 활용 방법\nRefresh Token을 사용해야 하는 이유\nCookie에서의 same site 옵션\nBitcoin 백서\nSolidity Udemy 강의\nSolidity Docs\nnomad coder 블록체인 시리즈\n블록체인 강의\n\n\n\n\n\n\n\n이 포스팅에서는 github action setting, jwt, block chain 부분만 다루겠습니다.\n전체 코드는 비공개 되어있는 상태입니다.\n\n\n\n\n\nGithub Action Setting\ngithub를 이용해서 agile 방법론을 적용할 수 있도록 의도했고, 자동화와 template을 이용해 통일성 있는 구조를 유지하려고 했습니다.\n1. 회의를 통해 진행해야 하는 작업을 Kanban board에 정리한다.\n\n\n\nGithub Kanban Board\n\n\n각각의 column에는 다음과 같은 내용이 들어갑니다.\n\nDiscussion: 논의가 필요한 작업. 개개인이 자유롭게 올릴 수 있습니다\nBacklog: Discussion에 있는 내용 중 구현하기로 회의에서 정한 작업\nReady: Back log에 있는 작업 중 이번 Sprint에서 구현할 작업들\nIn Progress: Ready에 있는 작업 중 누군가가 작업중인 것\nDone: master branch에 merge가 완료된 작업\n\n자세한 내용은 meeting 부분을 참고해 주세요.\n참고로 Disccusion에 작업을 올리는 방법은 template에 맞게 issue를 올리면 됩니다.\n\n\n\nDiscussion template\n\n\n아래와 같이 설정 파일을 만들어서 ‘.github/ISSUE_TEMPLATE/’ 폴더 안에 저장하면 issue create 시 자동으로 template이 뜨게 할 수 있습니다.\nname: New discussion\ndescription: new discussion\ntitle: \"[DISCUSSION]\"\nlabels: [\"enhancement\"]\nprojects: [\"org_name/5\"]\nbody:\n  - type: markdown\n    attributes:\n      value: |\n        해당 기능과 관련된 request가 이미 존재하는지 확인해주세요.\n  - type: textarea\n    id: story\n    attributes:\n      label: Story\n      description: 해당 기능에 대한 설명이나 필요한 배경을 작성해주세요.\n      placeholder: 자유로운 양식으로 작성해주세요.\n    validations:\n      required: true\n2. Kanban board를 보고 개인이 능동적으로 고유 브랜치에 작업을 진행한다.\n\n\n\n빨간 밑줄 부분을 설정해줍니다.\n\n\nKanban board의 Ready section에 있는 작업을 클릭해서 들어간 후, assignees를 본인으로 선택해서 작업하면 됩니다. task completion criteria라는 내용이 보이는데, 이는 회의를 통해 결정하는 것으로, 나중에 작업이 완료되고 pull request 시, 평가자가 작업에 완성도에 대해 판단할 수 있는 기준으로 제공됩니다.\n자동화 코드는 아래와 같이 구현했습니다.\nname: Create branch\non:\n  issues:\n    types: [ assigned ]\n  pull_request:\n    types: [ opened, closed ]\njobs:\n  create_issue_branch_job:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Generate token\n        id: generate_token\n        uses: tibdex/github-app-token@v2\n        with:\n          app_id: ${{ secrets.APP_ID }}\n          private_key: ${{ secrets.PRIVATE_KEY }}\n\n      # gh 명령어를 이용해 project의 상태를 In progress로 수정해줍니다.\n      - name: Project in-progress\n        if: github.event.action == 'assigned'\n        run: |\n          PROJECT_ID=$(gh project view 5 --owner organization-for-practice --format=json --jq '.id')\n          ITEM_ID=$(gh project item-list 5 --owner organization-for-practice --format=json --jq \".items[] | select(.content.number == ${NUMBER}) | .id\")\n          FIELD_ID=$(gh project field-list 5 --owner organization-for-practice --format=json --jq '.fields[2].id')\n          SINGLE_ID=$(gh project field-list 5 --owner organization-for-practice --format=json --jq '.fields[2].options[] | select(.name == \"In progress\") | .id')\n          gh project item-edit --id ${ITEM_ID} --field-id ${FIELD_ID} --single-select-option-id ${SINGLE_ID} --project-id ${PROJECT_ID}\n        env:\n          GH_TOKEN: ${{ steps.generate_token.outputs.token }}\n          NUMBER: ${{ github.event.issue.number }}\n\n      # assign한 작업에 대한 branch를 새로 만들어줍니다.\n      - name: Create Issue Branch\n        uses: robvanderleek/create-issue-branch@main\n        env:\n          GITHUB_TOKEN: ${{ steps.generate_token.outputs.token }}\n위의 코드는 assign한 작업을 Ready column에서 In progress column으로 옮겨주고, 자동으로 작업할 branch를 만들어줍니다.\nbranch 자동 생성은 이 workflow를 사용하였고, 적용 시 아래와 같이 브랜치가 생성됩니다.\nautoLinkIssue: true\nautoCloseIssue: true\nbranchName: tiny\ncommentMessage: |\n  \\\"${branchName}\\\" branch 생성 완료.\n  해당 branch를 통해서 main에 pull request 올려주세요.\nbranches:\n  - label: 'task list'\n    prefix: feature/${issue.title[12,27],}/\n    copyIssueAssigneeToPR: true\n  - label: 'bug'\n    prefix: hot_fix/${issue.title[6,21],}/\n    copyIssueAssigneeToPR: true\n  - label: '*'\n    skip: true\n위의 config 파일을 작성해주면 아래와 같이 브랜치가 생성됩니다.\n\n\n\n자동 생성된 branch\n\n\n이름도 자동으로 생성되게 해서 convention을 지켜야 한다는 부담을 줄여줬습니다.\n3. 작업이 완료되면, 모든 조건을 충족하는지 확인한 후, master에 merge 한다.\n\n\n\npull request 화면\n\n\n작업이 완료됬다고 판단되면 위 화면과 같이 pull request를 생성하고, Reviewer를 설정해주면 됩니다.\n\n\n\ntask completion criteria\n\n\n그러면 이전에 설정했던 기준들이 자동으로 불러와지고, 모든 항목에 체크가 완료되어야 merge를 할 수 있게 설정했습니다. 구현 코드는 아래와 같습니다.\nname: Master merge rutine\non:\n  pull_request_target:\n    types: [ opened, synchronize ]\n    branches:\n      - master\nenv:\n  PR_NUM: ${{ github.event.pull_request.number }}\n  GH_REPO: ${{ github.repository }}\njobs:\n  get_checklist:\n    runs-on: ubuntu-latest\n    if: github.event.action == 'opened'\n    steps:\n      - name: Generate token\n        id: generate_token\n        uses: tibdex/github-app-token@v2\n        with:\n          app_id: ${{ secrets.APP_ID }}\n          private_key: ${{ secrets.PRIVATE_KEY }}\n      - name: Get issue\n        id: issue_num\n        env:\n          BRANCH: ${{ github.event.pull_request.head.ref }}\n        run: |\n          echo $BRANCH | grep -o 'feature\\/.*\\/i[0-9]\\+' || echo $BRANCH | grep -o 'hot_fix\\/.*\\/i[0-9]\\+'\n          TMP=$(echo $BRANCH | grep -o 'i[0-9]\\+')\n          echo \"NUMBER=${TMP#i}\" &gt;&gt; $GITHUB_OUTPUT\n      - name: Get issue body\n        id: issue_body\n        env:\n          GH_TOKEN: ${{ steps.generate_token.outputs.token }}\n          NUM: ${{ steps.issue_num.outputs.number }}\n        run: |\n          echo \"CONTENTS&lt;&lt;EOF\" &gt;&gt; $GITHUB_OUTPUT\n          gh issue view ${NUM} --json body --jq '.body' &gt;&gt; $GITHUB_OUTPUT\n          echo \"EOF\" &gt;&gt; $GITHUB_OUTPUT\n      - name: Update checklist\n        run: |\n          gh pr comment $PR_NUM --body \"${BODY}\"\n        env:\n          GH_TOKEN: ${{ steps.generate_token.outputs.token }}\n          BODY: \"${{ steps.issue_body.outputs.contents }}\"\nmerge가 완료된 branch는 자동으로 삭제가 되도록 설정을 해주었습니다.\n이제 아래는 실제 프로젝트를 진행할 때 만들었던 rule들입니다.\n\n1. work flow\ngithub flow로 진행됩니다.\n\n\n\ngithub flow\n\n\n\n매 작업은 master branch의 HEAD를 기반으로 이루어집니다.\npr을 올리지 않는 개인 작업용 local branch는 자유롭게 생성해주세요.\nmaster에 직접적인 push는 관리자를 제외하고는 불가능합니다.\nmaster에 대한 merge는 squash merge로 진행됩니다.\n그 외의 merge는 rebase로 진행해주세요.\n\n\n\n2. work\n\nkanban board의 'Ready' 섹션에서 하나를 정해서 새로운 기능에 대한 작업을 진행해주세요.\n선택한 작업은 assignees에 자신의 팀원을 등록 후, Start Date를 해당 날짜로 설정해주세요.\nassignees 등록이 완료되면 자동으로 target branch가 생성됩니다.\n해당 branch에 팀원들이 필요한 기능들을 자유로운 방식으로 구현한 후, master branch에 merge 해주세요.\n단, 해당 branch에 대한 merge는 rebase로 진행해주세요.\nhot_fix issue나, new feature request issue는 discussion의 필요성이 있을 경우에 등록해주세요.\n작업 중, 현재 작업하는 범위 외에서 추가적인 기능이 필요할 경우 관련 issue에 comment를 남기거나, reopen 해주세요.\n\n\n\n3. commit message convention\n아래의 명령어를 입력해주세요\ngit config commit.template .github/COMMIT_MESSAGE_TEMPLATE\n이후, -m 옵션 없이 ’git commit’으로 message를 입력해주세요.\n\n\nCOMMIT_MESSAGE_TEMPLATE\n\n# commit message template\n# ▼ &lt;Title&gt; 작성\n\n# ▼ &lt;빈 줄&gt;\n\n# ▼ &lt;body&gt; 작성\n\n# ▼ &lt;빈 줄&gt;\n\n# ▼ &lt;footer&gt; 작성\n\n\n# About Convention\n#   &lt;Title&gt;\n#       - 필수로 입력해주세요\n#       - 형식: &lt;type&gt;: &lt;short summary&gt;\n#\n#       &lt;type&gt;\n#           - config: 설정 관련 파일 작성 또는 변경\n#           - docs: 문서 변경사항\n#           - feat: 새로운 기능\n#           - fix: 버그 수정\n#           - refactor: 기능 추가나 버그 수정이 아닌 변경 사항\n#           - remove: 코드나 파일 제거\n#           - style: 스타일 작성 또는 수정\n#           - test: 누락된 테스트 추가 또는 기존 테스트 수정\n#           - core: 기능 구현 외 시스템 관련 작업\n#\n#       &lt;short summary&gt;\n#           - 변경 사항에 대한 간단한 설명\n#           - 첫글자 소문자, 현재 시제, 명령문으로 마지막에 .(마침표) 없이 작성\n#\n#   &lt;body&gt;\n#       - 선택적으로 입력 해주세요\n#       - 현재 시제, 명령문으로 작성\n#       - 변경 사항의 동기(왜)를 설명\n#       - 변경 효과를 설명하기 위해 이전 동작과 현재 동작의 비교를 포함할 수 있음\n#\n#   &lt;footer&gt;\n#       - 선택적으로 입력 해주세요\n#       - 해당 commit과 관련된 task의 issue 번호들을 적어주세요\n#       - 'bug'나 'task list' label이 붙은 issue는 제외해주세요\n#       - ex) closes #&lt;issue 번호&gt; closes #&lt;issue 번호&gt; ...\n\n\n\n\n\n\n\ncommit message template은 이 사이트를 참고해서 만들었습니다.\n\n\n\n\n\n4. pull request\n\npull request는 500줄의 코드를 넘어가지 않게 작성 바랍니다.\n모든 check list를 통과한 request만 master에 merge 가능합니다.\nreviewers에는 해당 작업과 관련된 domain의 팀원을 선택해주세요. 최소 1명 이상의 동료에게 평가를 받은 request만 merge 가능합니다.\n\n\n\n5. meeting\n\ndaily meeting\n\n매일 정해진 시간에 팀원들은 각각 다음과 같은 사안에 대해 논의합니다.\n\n개인이 어제 작업한 내용\n개인이 오늘 작업할 내용\n개인이 현재 도움이 필요한 내용\n\n이후, 새로운 내용이 추가된 ('Disccusion' 섹션에 있는) issue 중 다음과 같은 내용에 대해 논의합니다.\n\n해당 issue가 유효한가\n추가적으로 필요하거나 필요 없는 내용\n해당 issue의 priority (매우 급함 / 급함 / 안 급함)\n해당 issue의 estimate (작업하는데 필요한 노력의 정량적인 수치)\n\n추가적으로, project의 'Back log' 항목에서 'Ready' 항목으로 추가해야 할 작업에 대해 논의하거나 'Ready' 항목에서 'Back log' 항목으로 제외할 작업에 대해 논의할 수 있습니다.\n\nsprint planning / retrospective\n\n2주에 한번 진행.\n이전 sprint에 대한 평가와 이후 sprint를 위한 계획을 세웁니다.\n\nplanning\n\nProject의 'Back log' 항목 중 본격적으로 작업을 진행할 항목을 정합니다.\ndaily meeting 시간을 조정할 수 있습니다.\n\nretrospective\n\n이전 sprint의 문제점에 대해 서로 의논해봅니다.\n\n\n\n\n\n\n\n\n\n프로젝트를 하다보니, 생각보다 진행 속도가 빨라서 2주에 한번 진행하는 sprint는 유명무실해져버렸습니다. 실제로는 daily meeting만 진행을 했습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "ft_transcendence - github action"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/1.html#outro",
    "href": "posts/02_areas/42_seoul/notes/1.html#outro",
    "title": "ft_transcendence - github action",
    "section": "outro",
    "text": "outro\n내용이 너무 길어져서 2편에 계속 포스팅 하겠습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "ft_transcendence - github action"
    ]
  },
  {
    "objectID": "posts/02_areas/blog/index.html",
    "href": "posts/02_areas/blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "블로그 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "Blog"
    ]
  },
  {
    "objectID": "posts/02_areas/blog/index.html#details",
    "href": "posts/02_areas/blog/index.html#details",
    "title": "Blog",
    "section": "",
    "text": "블로그 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "Blog"
    ]
  },
  {
    "objectID": "posts/02_areas/blog/index.html#tasks",
    "href": "posts/02_areas/blog/index.html#tasks",
    "title": "Blog",
    "section": "Tasks",
    "text": "Tasks\n\n\n\n    \n    \n    \n            \n                \n                    \n                    PARA 구조에 맞게 블로그 구조 변경\n                \n                \n            \n\n            \n            \n                \n                    \n                    게시글에 관련 게시글, 관련 directory 추가\n                \n                별로 마음에 들진 않지만 일단 완성\n            \n\n            \n            \n                \n                    \n                    Hugo 적용\n                \n                \n            \n\n            \n            \n                \n                    \n                    google analytics 적용\n                \n                \n            \n\n            \n            \n                \n                    \n                    about me 페이지 작성\n                \n                \n            \n\n            \n            \n                \n                    \n                    link 미리보기 기능 추가\n                \n                \n            \n\n            \n            \n                \n                    \n                    task 리스트 캘린더 추가",
    "crumbs": [
      "PARA",
      "Areas",
      "Blog"
    ]
  },
  {
    "objectID": "posts/02_areas/blog/index.html#참고-자료",
    "href": "posts/02_areas/blog/index.html#참고-자료",
    "title": "Blog",
    "section": "참고 자료",
    "text": "참고 자료\n\nHugo vs Quarto",
    "crumbs": [
      "PARA",
      "Areas",
      "Blog"
    ]
  },
  {
    "objectID": "posts/02_areas/blog/index.html#related-posts",
    "href": "posts/02_areas/blog/index.html#related-posts",
    "title": "Blog",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Areas",
      "Blog"
    ]
  },
  {
    "objectID": "posts/02_areas/blog/notes/0.html#overview",
    "href": "posts/02_areas/blog/notes/0.html#overview",
    "title": "PARA Blog 제작",
    "section": "Overview",
    "text": "Overview\n유튜브에서 ‘제2의 두뇌’ 관련 영상을 보고 이 구조로 제 학습 블로그에 적용하면 좋겠다는 생각이 들었습니다. Quarto로 만들어진 제 블로그에 이 구조를 적용하는 것이 생각보다 쉽지 않긴 했지만, 나름 해볼만 했습니다.\n사실 이 글을 작성하는 시점에는 이미 블로그 리뉴얼이 어느 정도 완료된 상태입니다. 코드가 최적화되지 않아 따로 제작 과정을 상세히 공유하지는 않으려 합니다만, 제 GitHub 레포에서 전체 코드를 확인하실 수 있습니다. 이전 블로그는 여기에서 확인할 수 있습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "Blog",
      "Notes",
      "PARA Blog 제작"
    ]
  },
  {
    "objectID": "posts/02_areas/blog/notes/0.html#이후-목표",
    "href": "posts/02_areas/blog/notes/0.html#이후-목표",
    "title": "PARA Blog 제작",
    "section": "이후 목표",
    "text": "이후 목표\n블로그를 완성하고 보니 Quarto의 필요성에 대해 다시 한번 생각해보게 되었습니다. 데이터 분석을 공부하는 입장에서 Quarto는 분명 대체 불가능한 장점들이 있지만, 웹사이트 구조를 구축하는 데에는 일정 부분 한계가 있어 보입니다.\nDocument를 읽어보던 중 Quarto와 Hugo를 통합하는 방법이 있다는 것을 알게 되었습니다. 이를 통해 Hugo로 블로그의 기본 구조를 만들고, R과 Python 코드 실행 환경으로 Quarto를 활용하는 방안을 고려하고 있습니다.\n이번이 jekyll, framer 블로그에 이어서 세번째로 만드는 블로그입니다. 저는 웹 개발보다는 다른 분야에 집중하고 싶기 때문에, 다음 리뉴얼을 마지막으로 블로그 구조 개선을 마무리해보려 합니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "Blog",
      "Notes",
      "PARA Blog 제작"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#금융-행동의-개인차",
    "href": "posts/03_resources/금융/notes/00.html#금융-행동의-개인차",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "1. 금융 행동의 개인차",
    "text": "1. 금융 행동의 개인차\n금융 시장에서 개인의 행동 차이는 단순히 정보의 우위나 지적 능력의 차이가 아닌, 개인의 경험과 가치관에서 비롯된다. 우리는 각자의 경험을 바탕으로 나름의 합리적인 의사결정을 내린다. 따라서 겉보기에 비합리적으로 보이는 행동도 개인의 맥락에서는 충분히 이해될 수 있다. 돈 문제에 있어서 누구나 미친짓을 한다. 거의 모두가 이 게임이 처음이기 때문이다. 하지만 실제로 미친사람은 없다. 누구나 자신만의 경험에 근거해서 합리적으로 보이는 의사결정을 내릴 뿐이다",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#운과-리스크의-역할",
    "href": "posts/03_resources/금융/notes/00.html#운과-리스크의-역할",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "2. 운과 리스크의 역할",
    "text": "2. 운과 리스크의 역할\n금융 시장에서의 결과는 우리의 행동만으로 결정되지 않는다. 운의 영향력을 인정하고, 리스크를 적절히 관리하는 것이 중요하다. 이를 위해 우리는 다음과 같은 질문들을 스스로에게 던져야 한다\n\n추가적인 수익이 정말 필요한가?\n타인과의 비교가 판단을 흐리고 있지는 않은가?\n’충분함’의 기준은 무엇인가?\n돈보다 우선시해야 할 가치는 무엇인가?\n\n어느 정도가 충분한지 깨닫고 리스크를 멈출줄 알아야 한다",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#지속가능한-투자의-원칙",
    "href": "posts/03_resources/금융/notes/00.html#지속가능한-투자의-원칙",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "3. 지속가능한 투자의 원칙",
    "text": "3. 지속가능한 투자의 원칙\n일회성 수익보다는 지속가능한 수익이 더 가치있다. 투자에는 두 가지 다른 기술이 필요하다\n\n수익 창출: 리스크 감수, 낙관적 사고, 적극적 태도\n자산 보존: 신중함, 위험 관리, 절제\n\n최고의 수익률은 일회성이어서 반복할 수 없는 경향이 있다. 꽤 괜찮은 수익률을 오랫동안 반복할 수 있는게 훌륭한 투자다. 성공적인 투자자는 대중이 비이성적일 때도 침착함을 유지할 수 있는 사람이다.",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#돈과-시간의-관계",
    "href": "posts/03_resources/금융/notes/00.html#돈과-시간의-관계",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "4. 돈과 시간의 관계",
    "text": "4. 돈과 시간의 관계\n돈의 진정한 가치는 그것이 우리에게 주는 시간의 자유에 있다. 돈이 주는 가장 큰 배당금은 시간이다 단순히 부자(rich)가 되는 것과 진정한 부(wealthy)를 이루는 것은 다르다. 진정한 부자들은 겉으로 보이는 치장(rich)에 돈을 쓰기 보다는 부를 축적(wealthy)하여 자유를 얻는다.",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#금융시장의-불변요소와-가변요소",
    "href": "posts/03_resources/금융/notes/00.html#금융시장의-불변요소와-가변요소",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "5. 금융시장의 불변요소와 가변요소",
    "text": "5. 금융시장의 불변요소와 가변요소\n금융 시장에서 인간의 기본적인 행동 패턴은 크게 변하지 않는다. 탐욕, 공포, 스트레스 상황에서의 반응 등은 시대가 바뀌어도 유사하다. 반면, 시장 트렌드, 산업 구조, 투자 방식 등은 끊임없이 진화한다.",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#리스크-관리의-중요성",
    "href": "posts/03_resources/금융/notes/00.html#리스크-관리의-중요성",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "6. 리스크 관리의 중요성",
    "text": "6. 리스크 관리의 중요성\n\n파산 위험이 있는 리스크는 절대 감수하지 않는다\n계획이 실패했을 때를 대비한 백업 플랜이 필수적이다\n시장의 변동성은 피해야 할 벌금이 아닌, 수수료로 인식해야 한다",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#현실적인-목표-설정",
    "href": "posts/03_resources/금융/notes/00.html#현실적인-목표-설정",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "7. 현실적인 목표 설정",
    "text": "7. 현실적인 목표 설정\n\n이상적인 목표와 현실적인 스트레스 상황은 큰 차이가 있다\n과거의 비현실적 목표는 과감히 버려야 한다\n내가 지금과 다른 사람일 때 세웠던 목표는 생명 유지 장치를 달고 시간을 질질 끌 게 아니라 가차 없이 버리는 편이 낫다",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/notes/00.html#시장의-본질-이해",
    "href": "posts/03_resources/금융/notes/00.html#시장의-본질-이해",
    "title": "돈의 심리학 - 모건 하우절",
    "section": "8. 시장의 본질 이해",
    "text": "8. 시장의 본질 이해\n\n극단적 상황은 오래 지속되지 않는다\n투자 성공의 대가를 이해하고 지불할 준비가 필요하다\n시장을 완벽히 통제할 수 있다는 환상을 버려야 한다",
    "crumbs": [
      "PARA",
      "Resources",
      "금융",
      "Notes",
      "돈의 심리학 - 모건 하우절"
    ]
  },
  {
    "objectID": "posts/03_resources/tofel_준비/index.html",
    "href": "posts/03_resources/tofel_준비/index.html",
    "title": "TOFEL 준비",
    "section": "",
    "text": "BEFORE-START\n    \n    \n        시작일: None\n        종료일: None\n    \n    \n        \n            \n        \n        계산 중...\n    \n    \n    \n        English",
    "crumbs": [
      "PARA",
      "Resources",
      "TOFEL 준비"
    ]
  },
  {
    "objectID": "posts/03_resources/tofel_준비/index.html#details",
    "href": "posts/03_resources/tofel_준비/index.html#details",
    "title": "TOFEL 준비",
    "section": "Details",
    "text": "Details\nTOFEL을 준비해 봅시다.",
    "crumbs": [
      "PARA",
      "Resources",
      "TOFEL 준비"
    ]
  },
  {
    "objectID": "posts/03_resources/tofel_준비/index.html#tasks",
    "href": "posts/03_resources/tofel_준비/index.html#tasks",
    "title": "TOFEL 준비",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Resources",
      "TOFEL 준비"
    ]
  },
  {
    "objectID": "posts/03_resources/tofel_준비/index.html#related-posts",
    "href": "posts/03_resources/tofel_준비/index.html#related-posts",
    "title": "TOFEL 준비",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Resources",
      "TOFEL 준비"
    ]
  },
  {
    "objectID": "all.html",
    "href": "all.html",
    "title": "전체 게시글",
    "section": "",
    "text": "정렬\n       디폴트\n         \n          날짜 - 날짜(오름차순)\n        \n         \n          날짜 - 날짜(내림차순)\n        \n         \n          제목\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n제목\n\n\n날짜\n\n\n분류\n\n\n\n\n\n\n4 - 정형 데이터 마이닝\n\n\n \n\n\nadp\n\n\n\n\n4 - 비정형 데이터 마이닝\n\n\n \n\n\nadp\n\n\n\n\n5 - 시각화 구현\n\n\n2025-02-18\n\n\nadp\n\n\n\n\ninception-of-things part 1\n\n\n2025-02-17\n\n\nvagrant, k8s, argoCD, gitlab, 42 seoul\n\n\n\n\n회귀 분석\n\n\n2025-02-16\n\n\n통계\n\n\n\n\n4 - 통계분석\n\n\n2025-02-16\n\n\nadp\n\n\n\n\n상관 분석\n\n\n2025-02-15\n\n\n통계\n\n\n\n\n4 - 데이터 마트\n\n\n2025-02-15\n\n\nadp\n\n\n\n\nTerraform Cloud\n\n\n2025-02-11\n\n\nterraform, terraform cloud, devops, IaC\n\n\n\n\n5 - 시각화 인사이트 프로세스\n\n\n2025-02-11\n\n\nadp\n\n\n\n\n5 - 시각화 디자인\n\n\n2025-02-11\n\n\nadp\n\n\n\n\n분산 분석\n\n\n2025-02-10\n\n\n통계\n\n\n\n\n3 - 분석 마스터 플랜\n\n\n2025-02-10\n\n\nadp\n\n\n\n\n3 - 데이터 분석 기획의 이해\n\n\n2025-02-10\n\n\nadp\n\n\n\n\n2 - 데이터 처리 프로세스\n\n\n2025-02-08\n\n\nadp\n\n\n\n\n2 - 데이터 처리 기술\n\n\n2025-02-08\n\n\nadp\n\n\n\n\n성적 장학금\n\n\n2025-02-05\n\n\n장학금\n\n\n\n\n통계 기초\n\n\n2025-02-04\n\n\n통계\n\n\n\n\nt-test\n\n\n2025-02-04\n\n\n통계\n\n\n\n\n1 - 데이터의 가치와 미래\n\n\n2025-02-04\n\n\nadp\n\n\n\n\n1 - 데이터 이해\n\n\n2025-02-04\n\n\nadp\n\n\n\n\n1 - 가치 창조를 위한 데이터 사이언스와 전략 인사이트\n\n\n2025-02-04\n\n\nadp\n\n\n\n\n인간 관계론 - 데일 카네기\n\n\n2025-02-02\n\n\n독서, 인간 관계\n\n\n\n\n선형결합과 생성\n\n\n2025-01-31\n\n\n선형 대수\n\n\n\n\n벡터와 공간\n\n\n2025-01-30\n\n\n선형 대수\n\n\n\n\ncloud-1 코드 설명\n\n\n2025-01-30\n\n\naws, packer, terraform, ansible, 42 seoul\n\n\n\n\ncloud-1 개념 설명\n\n\n2025-01-28\n\n\naws, packer, terraform, ansible, 42 seoul\n\n\n\n\n3-몰라\n\n\n2025-01-22\n\n\n선형 대수\n\n\n\n\n자기 소개서\n\n\n2025-01-17\n\n\n자기 소개서\n\n\n\n\nft_transcendence - github action\n\n\n2025-01-17\n\n\nagile, github action, 42 seoul\n\n\n\n\n2-기초(2)\n\n\n2025-01-11\n\n\n선형 대수\n\n\n\n\nNonlinear Programming\n\n\n2025-01-10\n\n\nOperational Research, 1차\n\n\n\n\n2-기초(1)\n\n\n2025-01-10\n\n\n선형 대수\n\n\n\n\nSecond Brain - 티아고 포르테\n\n\n2025-01-09\n\n\n학습, 독서\n\n\n\n\nwhat is linear algebra\n\n\n2025-01-07\n\n\n선형 대수\n\n\n\n\n돈의 심리학 - 모건 하우절\n\n\n2025-01-02\n\n\n금융, 독서\n\n\n\n\n데이터 전처리\n\n\n2025-01-02\n\n\n데이터 분석\n\n\n\n\nInteger Programming\n\n\n2024-12-31\n\n\nOperational Research, 1차\n\n\n\n\nEDA와 시각화\n\n\n2024-12-30\n\n\n데이터 분석\n\n\n\n\nPARA Blog 제작\n\n\n2024-12-26\n\n\n블로그\n\n\n\n\nLinear Programming\n\n\n2024-12-23\n\n\nOperational Research, 1차\n\n\n\n\nOverview\n\n\n2024-12-21\n\n\nOperational Research, 1차\n\n\n\n\npandas data 구조\n\n\n2024-12-20\n\n\n데이터 분석\n\n\n\n\n맥도날드 키오스크 UI 개선 보고서\n\n\n2024-11-27\n\n\n보고서, 인간 공학\n\n\n\n\n숭실대학교 학생식당 식자제 SCM 설계\n\n\n2024-11-26\n\n\n보고서, database\n\n\n\n\nControl\n\n\n2024-11-21\n\n\n인간 공학\n\n\n\n\n표본의 분포\n\n\n2024-11-18\n\n\n확률과 통계\n\n\n\n\n중심 극한 정리\n\n\n2024-11-18\n\n\n확률과 통계\n\n\n\n\n정규 분포\n\n\n2024-11-18\n\n\n확률과 통계\n\n\n\n\nDisplay\n\n\n2024-11-14\n\n\n인간 공학\n\n\n\n\n연속형 확률분포\n\n\n2024-11-05\n\n\n확률과 통계\n\n\n\n\nAttention\n\n\n2024-11-05\n\n\n인간 공학\n\n\n\n\nDatabase Design\n\n\n2024-10-31\n\n\ndatabase\n\n\n\n\nDatabase Administration\n\n\n2024-10-31\n\n\ndatabase\n\n\n\n\nASP.NET\n\n\n2024-10-31\n\n\ndatabase\n\n\n\n\n4조 기말과제 제안서\n\n\n2024-10-30\n\n\n보고서, database\n\n\n\n\n이산형 확률분포\n\n\n2024-10-28\n\n\n확률과 통계\n\n\n\n\n데이터베이스설계및활용 개인과제 #2\n\n\n2024-10-27\n\n\n보고서, database\n\n\n\n\n확률변수의 기댓값\n\n\n2024-10-16\n\n\n확률과 통계\n\n\n\n\nSignal Detection Theory\n\n\n2024-10-15\n\n\n인간 공학\n\n\n\n\nAuditory Haptic\n\n\n2024-10-15\n\n\n인간 공학\n\n\n\n\nData Modeling and the Entity-Relationship Model\n\n\n2024-10-14\n\n\ndatabase\n\n\n\n\nSQL\n\n\n2024-09-27\n\n\ndatabase\n\n\n\n\nSensor System (Visual)\n\n\n2024-09-24\n\n\n인간 공학\n\n\n\n\nDatabase Normalization\n\n\n2024-09-24\n\n\ndatabase\n\n\n\n\nThe Relational Model\n\n\n2024-09-17\n\n\ndatabase\n\n\n\n\nHuman Information Processing Model\n\n\n2024-09-17\n\n\n인간 공학\n\n\n\n\nResearch Method in Human Factors\n\n\n2024-09-10\n\n\n인간 공학\n\n\n\n\n확률변수와 확률분포\n\n\n2024-09-03\n\n\n확률과 통계\n\n\n\n\nIntroduction to Human Factors\n\n\n2024-09-03\n\n\n인간 공학\n\n\n\n\nAn Overview of Database\n\n\n2024-09-03\n\n\ndatabase\n\n\n\n\n확률과 통계의 정의\n\n\n2024-09-02\n\n\n확률과 통계\n\n\n\n\nmetrics server\n\n\n2024-05-15\n\n\n \n\n\n\n\nmanual scheduling\n\n\n2024-05-15\n\n\n \n\n\n\n\nk8s cluster architecture\n\n\n2024-05-15\n\n\n \n\n\n\n\nfail tolerance\n\n\n2024-05-15\n\n\n \n\n\n\n\ncore DNS\n\n\n2024-05-15\n\n\n \n\n\n\n\nPersistant volume\n\n\n2024-05-15\n\n\n \n\n\n\n\nHA in master node\n\n\n2024-05-15\n\n\n \n\n\n\n\nAuthentication\n\n\n2024-05-15\n\n\n \n\n\n\n\nwhat is ebs\n\n\n2024-04-30\n\n\n \n\n\n\n\nwhat is EC2\n\n\n2024-04-30\n\n\n \n\n\n\n\ndatabase choice in aws\n\n\n2024-04-30\n\n\n \n\n\n\n\naws global infrastructure\n\n\n2024-04-30\n\n\n \n\n\n\n\nVPC\n\n\n2024-04-30\n\n\n \n\n\n\n\nRoute53\n\n\n2024-04-30\n\n\n \n\n\n\n\nPerformance Improvement\n\n\n2024-04-30\n\n\n \n\n\n\n\nOverview\n\n\n2024-04-30\n\n\nvault, devops\n\n\n\n\nKMS(Key Management Service)\n\n\n2024-04-30\n\n\n \n\n\n\n\nELB\n\n\n2024-04-30\n\n\n \n\n\n\n\nDisaster Recovery(DR)\n\n\n2024-04-30\n\n\n \n\n\n\n\nDefine IAM\n\n\n2024-04-30\n\n\n \n\n\n\n\nCloudFront\n\n\n2024-04-30\n\n\n \n\n\n\n\nAmazon Rekognition\n\n\n2024-04-30\n\n\n \n\n\n\n\nAmazon RDS\n\n\n2024-04-30\n\n\n \n\n\n\n\nAmazon CloudWatch\n\n\n2024-04-30\n\n\n \n\n\n\n\nAWS Snow Family\n\n\n2024-04-30\n\n\n \n\n\n\n\nAWS SQS\n\n\n2024-04-30\n\n\n \n\n\n\n\nAWS S3\n\n\n2024-04-30\n\n\n \n\n\n\n\nAWS Organization\n\n\n2024-04-30\n\n\n \n\n\n\n\nAWS Lambda\n\n\n2024-04-30\n\n\n \n\n\n\n\n\n일치 없음"
  },
  {
    "objectID": "posts/00_inboxes/notes/01.html#사람을-대하는-기본-기술",
    "href": "posts/00_inboxes/notes/01.html#사람을-대하는-기본-기술",
    "title": "인간 관계론 - 데일 카네기",
    "section": "사람을 대하는 기본 기술",
    "text": "사람을 대하는 기본 기술\n\n꿀을 얻으려면 벌집을 걷어차지 마라\n남을 비난하고 원망하며 불평하는 것은 어떤 바보라도 할 수 있다. 실제로 바보들은 그렇게 한다. 하지만 남을 이해하고 용서하려면 인격과 자제력이 필요하다.\n사람을 비난하는 대신 그들을 이해하려고 노력해 보자. 그들이 왜 그런 행동을 하는지 곰곰이 생각해 보자. 그편이 비난하는 것보다 훨씬 이롭고 흥미롭다.\n\n\n사람을 대하는 핵심 비결\n누군가에게 어떤 일을 하게 만드는 방법은 상대방이 그 일을 하고 싶게 만드는 것 뿐이다. 강제적인 방법들은 반드시 역효과를 일으킨다.\n타인에게 어떤 일을 하게 하려면 그 사람이 원하는 것을 주는 방법밖에 없다. 인간의 본성이 지닌 가장 깊은 충동이 바로 중요한 사람이 되고자 하는 욕망이다.\n이러한 갈망을 제대로 충족시켜 주는 사람은 다른 사람의 마음을 사로잡을 수 있다. 타인을 진실된 마음으로 칭찬하자. 이는 이기적이고 거짓인 아첨과는 다르다.\n\n\n이 일을 해내는 사람은 세상을 얻을 것이고, 그렇지 못한 사람은 외로운 길을 걸을 것이다.\n상대방에게 영향을 미치는  방법은 그사람이 원하는 것을 이야기하고, 이를 얻는 방법을 보여 주는 것이다.\n\n\n\n\n\n\n…이 부분 예시로 드는 것들이 조금 오버스럽다고 느껴진다.\n문화가 달라서 그런가? 아니면 번역 이슈인가?\n무슨 말을 하는진 알겠는데, 몇몇 부분은 별로 공감이 안 된다.",
    "crumbs": [
      "PARA",
      "Inboxes",
      "Notes",
      "인간 관계론 - 데일 카네기"
    ]
  },
  {
    "objectID": "posts/00_inboxes/notes/01.html#사람들에게-호감을-얻는-6가지-방법",
    "href": "posts/00_inboxes/notes/01.html#사람들에게-호감을-얻는-6가지-방법",
    "title": "인간 관계론 - 데일 카네기",
    "section": "사람들에게 호감을 얻는 6가지 방법",
    "text": "사람들에게 호감을 얻는 6가지 방법\n\n이렇게 하면 어디서든 환영받을 것이다.\n다른 사람에게 관심이 없는 사람은 인생에서 가장 큰 어려움을 겪고, 다른 사람에게 가장 큰 상처를 준다. 상대방에게 진심으로 관심을 가져라\n\n\n좋은 첫인상을 남기는 간단한 방법\n미소를 지어라\n\n\n이렇게 하지 않으면 문제가 생길 것이다.\n사람의 이름을 기억하라\n\n\n좋은 대화 상대가 되는 쉬운 방법\n상대의 이야기를 경청하고, 상대가 자신에 관해 이야기하도록 격려하라\n\n\n사람들의 관심을 얻는 방법\n상대방의 관심사에 대해 이야기하라\n\n\n사람들에게 즉시 호감을 얻는 방법\n모든 사람은 자신이 상대보다 우월하다고 생각한다. 항상 상대방이 자신을 중요하다고 느끼게 하라",
    "crumbs": [
      "PARA",
      "Inboxes",
      "Notes",
      "인간 관계론 - 데일 카네기"
    ]
  },
  {
    "objectID": "posts/00_inboxes/notes/01.html#사람들의-마음을-사로잡는-12가지-방법",
    "href": "posts/00_inboxes/notes/01.html#사람들의-마음을-사로잡는-12가지-방법",
    "title": "인간 관계론 - 데일 카네기",
    "section": "사람들의 마음을 사로잡는 12가지 방법",
    "text": "사람들의 마음을 사로잡는 12가지 방법\n\n논쟁으로는 이길 수 없다\n자기 의사에 반하여 설득당한 사람은 여전히 자기 생각을 바꾸지 않는 법이다. 논쟁에서 최선의 결과를 얻는 유일한 방법은 논쟁을 피하는 것뿐이다.\n\n\n적을 만드는 확실한 방법과 이를 피하는 방법\n되도록 남들보다 지혜로운 사람이 되거라. 하지만 남들에게 그렇다고 말하지 않도록 해라.\n상대가 틀린 말을 해도 굳이 지적하지 마라\n\n\n틀렸다면, 인정하라\n조금 잘못했는데, 상대가 비난할거 같으면 오바해서 자기 잘못을 시인하라\n\n\n이성에 호소하는 확실한 방법\n우호적인 방식으로 시작하라\n\n\n소크라테스의 비결\n상대방이 동의할 수 밖에 없는 질문을 유도하라.\n\n\n불만을 잠재우는 안전밸브",
    "crumbs": [
      "PARA",
      "Inboxes",
      "Notes",
      "인간 관계론 - 데일 카네기"
    ]
  },
  {
    "objectID": "posts/03_resources/problem_solve/index.html",
    "href": "posts/03_resources/problem_solve/index.html",
    "title": "Problem Solving",
    "section": "",
    "text": "Problem Solving에 대한 노트 모음입니다.\n이전 포스팅은 이곳에서 확인 가능합니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Problem Solving"
    ]
  },
  {
    "objectID": "posts/03_resources/problem_solve/index.html#details",
    "href": "posts/03_resources/problem_solve/index.html#details",
    "title": "Problem Solving",
    "section": "",
    "text": "Problem Solving에 대한 노트 모음입니다.\n이전 포스팅은 이곳에서 확인 가능합니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "Problem Solving"
    ]
  },
  {
    "objectID": "posts/03_resources/problem_solve/index.html#tasks",
    "href": "posts/03_resources/problem_solve/index.html#tasks",
    "title": "Problem Solving",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Resources",
      "Problem Solving"
    ]
  },
  {
    "objectID": "posts/03_resources/problem_solve/index.html#related-posts",
    "href": "posts/03_resources/problem_solve/index.html#related-posts",
    "title": "Problem Solving",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Resources",
      "Problem Solving"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/index.html",
    "href": "posts/03_resources/금융/index.html",
    "title": "금융",
    "section": "",
    "text": "금융 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "금융"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/index.html#details",
    "href": "posts/03_resources/금융/index.html#details",
    "title": "금융",
    "section": "",
    "text": "금융 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Resources",
      "금융"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/index.html#tasks",
    "href": "posts/03_resources/금융/index.html#tasks",
    "title": "금융",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Resources",
      "금융"
    ]
  },
  {
    "objectID": "posts/03_resources/금융/index.html#related-posts",
    "href": "posts/03_resources/금융/index.html#related-posts",
    "title": "금융",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Resources",
      "금융"
    ]
  },
  {
    "objectID": "posts/02_areas/blog/notes/1.html#second-brain의-핵심-기능",
    "href": "posts/02_areas/blog/notes/1.html#second-brain의-핵심-기능",
    "title": "Second Brain - 티아고 포르테",
    "section": "Second Brain의 핵심 기능",
    "text": "Second Brain의 핵심 기능\n\n아이디어를 구체화한다\n머릿속에서 아이디어를 분리하여 구체적인 형태로 만들어야 한다.\n아이디어 사이의 연관성을 새롭게 밝혀낸다.\n다양한 자료를 한곳에 보관하면 자료간 연결 작업이 촉진되며, 생각지 못한 연관성을 찾아낼 가능성을 높일 수 있다.\n시간을 두고 아이디어를 발전시킨다.\n사람들은 줄곧 아이디어를 떠올릴 때 최신 정보에 중요성을 더 부여하는 경향이 있다.\n몇년 간 축적된 아이디어를 마음껏 이용할 수 있다면 더 좋을 것이다.\n나만의 독특한 관점을 정교하게 다듬는다.\n작가의 벽에 부딪히는 것은 적절한 단어를 떠올릴 수 없다는 것이 아니라, 글을 쓸 탄약이 부족하다는 것이다.\n자신의 견해를 지지할 수 있는 자료를 지속적으로 모아야한다.\n\n\n머리는 아이디어를 생각하는 곳이지 보관하는 곳이어선 안된다.",
    "crumbs": [
      "PARA",
      "Areas",
      "Blog",
      "Notes",
      "Second Brain - 티아고 포르테"
    ]
  },
  {
    "objectID": "posts/02_areas/blog/notes/1.html#중요한-것을-기억하는-4-단계-code",
    "href": "posts/02_areas/blog/notes/1.html#중요한-것을-기억하는-4-단계-code",
    "title": "Second Brain - 티아고 포르테",
    "section": "중요한 것을 기억하는 4 단계 (CODE)",
    "text": "중요한 것을 기억하는 4 단계 (CODE)\n\nCapture: 공명하는 내용을 수집하라\n당신과 마음에 닿는 내용을 분별하여 보관하고 나머지는 버려라\nOrganazie: 실행을 목표로 정리하라\n실행을 염두에 두고 정리하라.\nDistill: 핵심을 찾아 추출하라\n메모의 요점을 정리하라.\n메모를 저장한 이유, 생각하던 내용, 무엇이 당신의 관심을 끌었는지에 대한 설명\nExpress: 작업한 결과물을 표현하라\n개인적이고 구체적이며 검증된 정보는 실제로 사용할 때에 비로소 지식이 된다.\n당신이 아는 내용을 다른 사람과 공유하기 전까지는 그저 이론에 불과하다.\n\n\nCapture\n미래에 어떻게 될지 전혀 모르는데 무엇을 저장할지 어떻게 결정할 수 있을까? 어떤 정보가 보관할 가치가 있는지 정확히 알아내도록 통찰력을 키우기 위해 리처드 파인만의 좋아하는 12가지 문제 방법을 제시한다. 자신에게 흥미를 불러일으키는 열린 질문들을 자유롭게 적어보자. 그후 해당 질문들을 학습의 방향을 제시하는 북극성으로 삼아 활용한다.\n\n\n\n\n\n\n직접 적어본 질문들\n\n\n\n\n쇠퇴하지 않는 사람이 되기 위해 꾸준히 해야하는 활동에는 어떤게 있을까?\n운에 좌절하지 않기 위해 어떤걸 준비해야 할까?\n학점을 잘 받으려면 어떻게 공부해야 할까?\n소중한 인연은 무엇인가?\n무엇을 위해 발전해야 하는가?\n시간이 지나도 가치있는건 무엇일까?\n공명하는 지식이 매번 진실일까?\n돈을 잘 벌려면 어떻게 해야할까?\n\n\n\n그런 다음, 해당 주제와 관련된 자료에서 아래의 기준에 해당하는 내용들을 선별한다. 수집하는 자료는 외부에 존재하는 자료뿐만 아니라 자료를 수집하면서 얻은 내면 세계의 아이디어 역시 그 대상이될 수 있다.\n\n영감을 불러일으키는가\n나와 내 일에 유용한가\n개인적인 정보인가\n가족이나 친구들과 나눈 문자 메세지들도 수집의 대상이 될 수 있다.\n놀랄 만한 사실인가\n기존의 알고있는 자료만 수집하면 확증편향의 위험이 있다.\nsecond brain은 이미 알고 있는 내용을 또 확인하는 방법이 되어서는 안 된다.\n\n다음과 같은 유형들은 보관하기에 적합하지 않다.\n\n민감한 정보\n포토샵 파일이나 비디오 영상처럼 전용 앱이 필요한 경우\n대용량 파일\n공동 편집이 필요한 경우\n\n\n\nOrganize\n수집한 자료를 정리할 때, 종류별로 나누지 않고, 얼마나 실행 가능한지에 따라 정리할 수 있다. 주제와 하위 항목으로 연달아 이루어진 복잡한 계층 체계에 따라 메모를 정리하는 대신, 이것은 어떤 프로젝트에 가장 도움이 될까?라는 간단한 질문 하나에만 답하면 된다.\n\nPARA\n\nProject: 일이나 생활에서 현재 진행 중이며 단기간 노력이 필요한 일\n시작과 끝이 존재. 완성, 승인, 착수, 발표처럼 구체적이고 확실한 결과가 있어야 한다.\nArea: 오랫동안 관리하고 싶고 장기적으로 책임지는 일\n정해진 종료 날짜와 최종 목표가 없음.\nResource: 향후 도움이 될 수 있는 주제 혹은 관심사\n현재 진행하는 프로젝트 혹은 영역과 관련 없는 자료, 당분간 실행할 수 없는 메모나 파일 등을 보관할 수 있다.\nArchive: 전에는 위의 세 가지 유형에 속했지만, 지금은 비활성화된 항목\n완료하거나 취소된 프로젝트, 이제는 관리하지 않는 책임 영역, 흥미를 잃은 자원 등을 보관할 수 있다.\n\nPARA 정리 방식은 부엌 정리 방식과 유사하다. 부엌에 있는 물건들은 전부 식사를 준비하도록 설계되고 정리된다. 각각의 상위 폴더들을 비유하면, archive는 냉동고, resource는 식료품 저장고, 영역은 냉장고, 프로젝트는 불 위에서 끓고 있는 냄비나 팬과 같다.\n부엌을 음식 종류에 따라 정리하면 얼마나 터무니없을지 상상해보라. 신선한 과일과 말린 과일, 과일 주스와 냉동 과일은 모두 과일로 만들었다는 이유로 같은 장소에 보관될 것이다. 그런데 이것이 바로 대부분의 사람들이 파일과 메모를 정리하는 방식이다. 책을 읽으며 메모했다는 이유만으로 책 메모는 책 메모끼리, 다른 사람의 말을 인용했다는 이유만으로 인용문은 인용문끼리 보관한다.\n\n\n\nDistill\n메모는 단순한 수집을 넘어 실제 활용이 가능한 형태로 정제되어야 한다. 이를 위해 다음과 같은 단계별 요약 과정을 거친다.\n\n메모 수집: 먼저 빠르게 수집, 정리 이후 정제는 나중에 진행\n굵게 처리: 중요한 문장이나 구절을 표시\n하이라이트 처리: 굵게 처리된 내용 중 핵심을 강조\n핵심 요약: 최종적으로 메모의 핵심을 추출\n\n이 과정에서 주의할 점들\n\n과다 하이라이트 처리: 이전 단계 내용의 10-20% 정도만 선별\n목적 없는 하이라이트 처리: 무작정 시작하지 않고, 메모를 어떻게 사용할지 알게 될 때까지 기다린 후, 필요에 따라 하이라이트 한다.\n어려운 방식의 하이라이트 처리: 본인의 직관에 맞게 흥미로운 구절들을 하이라이트 한다.\n\n\n\n\n\n\n\n메모의 생존 여부는 ’얼마나 쉽게 찾을 수 있는가’에 달려있다.\n\n\n\n\n\nExpress\n맡은일을 중간 단계로 나누어서 최대한 빠르게 결과물을 도출하라 도출한 작업물들을 중간단계로써 다른 프로젝트에 사용할 때, 도움을 얻을 수 있다. 도출한 결과물들을 다른사람들과 공유를 해서 피드백을 받아라",
    "crumbs": [
      "PARA",
      "Areas",
      "Blog",
      "Notes",
      "Second Brain - 티아고 포르테"
    ]
  },
  {
    "objectID": "posts/02_areas/blog/notes/1.html#창조력을-완성하는-과정",
    "href": "posts/02_areas/blog/notes/1.html#창조력을-완성하는-과정",
    "title": "Second Brain - 티아고 포르테",
    "section": "창조력을 완성하는 과정",
    "text": "창조력을 완성하는 과정\n언제든 참신한 아이디어를 떠올릴 수 있다고 기대해서는 안된다. 혁신과 문제 해결은 흥미로운 아이디어를 체계적으로 불러일으켜 우리가 인식하게 하는 일상에 달려 있다.\n세컨드브레인은 창의적인 과정들을 아이디어 수집, 정리, 핵심 추출, 조립의 단계로 표준화하여 우리의 뇌 활동을 돕는다.\n\n창의적인 프로젝트를 완료할 때 도움이 되는 전략\n\n아이디어 군도: 프로젝트 수행에 필요한 모든 문서를 모은다. 그리고 해당 문서들을 연결하라.\n헤밍웨이 다리: 현재 진행중인 프로젝트에서 다음과 같은 사항들을 메모에 기록하라.\n\n다음 단계에는 어떤 이야기를 쓸 지\n현재 상황\n잊어버리기 쉬운 세부 사항\n다음 작업 시간의 목표\n\n범위 조금씩 축소하기: 프로젝트의 복잡한 문제가 드러나면 과감하게 범위를 축소하라\n\n\n\n효율적인 실행을 위한 세 가지 습관\n\n\n\n\n\n\n정리정돈은 타고난 특성이 아닌 습관이다.\n\n\n\n\n체크리스트 습관\n\n수집: 프로젝트에 대한 내 생각을 수집하라\n\n이 프로젝트에 대해 이미 알고 있는 것은 무엇인가?\n알아내야 하지만 아직 모르는 것은 무엇인가?\n목표나 목적은 무엇인가?\n통찰력을 얻으려면 누구와 대화해야 하는가?\n아이디어를 얻으려면 어떤 것을 읽거나 들어야 하는가?\n\n검토: 관련 메모가 있을 만한 폴더나 태그를 검토하라\n검색: 모든 폴더에서 관련 용어를 검색하라\n이동: 관련 메모를 프로젝트 폴더로 이동하거나 태그를 설정하라\n작성: 수집한 메모로 개요를 작성하고 프로젝트를 계획하라\n\n\n\n리뷰 습관\n\n주간 리뷰\n일주일 동안 작업한 모든 메체의 메모를 검토하라 그리고 이번 주 할 과제를 정하라\n월간 리뷰\n솔직히 이런건 잘 안할거 같다.\n\n\n\n알아차리는 습관",
    "crumbs": [
      "PARA",
      "Areas",
      "Blog",
      "Notes",
      "Second Brain - 티아고 포르테"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/5.html#intro",
    "href": "posts/02_areas/42_seoul/notes/5.html#intro",
    "title": "cloud-1 개념 설명",
    "section": "intro",
    "text": "intro\n\n\n\n42 seoul outer 과제\n\n\n다음 학기 시작 전까지 개념공부만 하면서 시간을 보내려고 하니까 프로젝트가 하고 싶어졌습니다. 원래는 python 과제를 하려고 했는데, 이전에 cloud 과제를 진행하다가 말았던게 기억나서 이어서 해보면 괜찮겠다 생각했습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 개념 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/5.html#프로젝트-및-구현-설명",
    "href": "posts/02_areas/42_seoul/notes/5.html#프로젝트-및-구현-설명",
    "title": "cloud-1 개념 설명",
    "section": "프로젝트 및 구현 설명",
    "text": "프로젝트 및 구현 설명\n\n개요\n과제 명세서\n참고한 자료는 다음과 같습니다:\n\nAWS SAA Udemy 강의\nansible terraform Udemy 강의\n\n이 강의들도 본 지 1년이 다되어가긴 하지만..과제할 때 사용한 제 배경지식이 여기서 나온거니까요. 과제를 진행하실 분들은 한번 수강해보시면 도움이 될 것 같습니다.\n\n\n\n\n\n\n이 포스팅에서 docker와 nginx, wordpress, mysql 구조에 대한 설명은 생략하겠습니다.\n전체 코드는 github repo에서 확인하실 수 있습니다.\n\n\n\n\n\nWhat is IaC?\n이 프로젝트의 목표는 IaC(Infrastructure as Code) tool을 이용하여 wordpress 사이트를 cloud에 자동으로 배포하는 것입니다.\nIaC는 인프라 구성을 코드로 관리하는 방식으로, 수동으로 리소스를 생성하고 설정하는 방식에 비해 버전 관리가 간편하고, 동일한 환경을 쉽게 재현하거나, 코드 리뷰 등의 방식으로 휴먼 에러를 줄이는 데 용이하게 사용할 수 있습니다.\n이번 프로젝트에서는 Packer, Terraform, Ansible 세 가지 IaC tool을 조합해 사용했습니다\n\n\nPacker: 인프라 생성 전, 상세 설정이 되어있는 image를 build할 수 있는 tool 입니다.\nTerraform: cloud 인프라를 생성하는 tool입니다. packer에서 생성한 ami를 사용할 수 있습니다.\nAnsible: 서버 내부의 상세 설정을 자동화합니다. 일반적인 bash script와는 다르게 멱등성 있는 설정이 가능하다는 점이 큰 장점입니다. 이때, 서버는 python이 설치되어 있어야 하고, ssh로 접근 가능해야 합니다.\n\n위의 이미지 처럼, packer로 필요한 설정이 완료된 image를 생성한 뒤, 그 이미지를 기반으로 cloud infra를 terraform으로 생성하고, 생성된 infra의 상세 설정을 ansible을 이용해서 구현해줄 것입니다.\nPacker와 Ansible은 서버 설정 자동화라는 동일한 기능을 수행하는 도구입니다. 두 도구는 각각 다양한 특징과 장단점이 있지만, 이 과제에서 알아야 하는 차이점은 아래와 같습니다.\nPacker는 임시 EC2 인스턴스를 생성하여 그 위에서 필요한 설정을 완료한 후, 해당 인스턴스를 AMI로 변환하는 방식으로 동작합니다. 이렇게 생성된 AMI는 이후 실제 인프라 구축 시 그대로 사용할 수 있습니다. 따라서 최종 목적지 서버가 SSH 접근이 제한되는 환경이더라도, 미리 필요한 모든 설정이 완료된 이미지를 사용할 수 있다는 장점이 있습니다.\n반면에 Ansible은 SSH 접근이 가능한 서버에서만 동작하지만, Packer와 달리 인프라 구축 후에 얻을 수 있는 정보(예: EC2의 IP)를 활용할 수 있습니다.\n이러한 특성을 고려하여 이 프로젝트에서는 두 도구를 상황에 맞게 조합하여 사용했습니다.\n\n\n전체적인 구조\n\n\n\n구현 aws 구조\n\n\nPublic subnet의 EC2들에 대한 ssh 접근은 관리용 컴퓨터에서만(terraform, ansible 코드가 실행되는 컴퓨터) 접근이 가능하도록 제한했고, MySQL의 데이터는 Private subnet의 EC2에 저장한 뒤 Public subnet의 EC2만 접근할 수 있도록 설정했습니다. Public subnet의 EC2는 사용자가 원하는 갯수를 설정할 수 있고, 그 갯수에 맞춰서 private subnet의 dbms EC2가 생성되도록 설계했습니다.\n실제 프로덕션 환경이라면 위와 같은 구조로는 설계하지 않습니다. 일단 EC2 머신들을 Auto Scaling Group으로 묶고, 그 앞에 Network Load Balancer를 두어 단일 엔드포인트로 관리하는 것이 좋습니다. 또한 Database는 AWS RDS를 이용하고, WordPress의 파일 시스템은 EFS나 S3를 활용해 Stateless하게 구현하는게 좋습니다.\n\n\n\n조금 더 일반적인 구조(물론 docker compose는 잘 안쓸것 같긴 합니다)\n\n\n제 구현에서는 각 서버가 독립적인 상태와 엔드포인트를 가지고 있습니다.\n그렇게 한 이유는 일단 aws free tier 서비스만으로 과제를 구현하려고 했던게 제일 크고요..(NLB는 사용할 수 없었습니다.) 나머지는 과제 제약사항 때문인데,\n\n\n\n과제 제약사항\n\n\n모든 프로세스는 컨테이너 안에서 동작해야 한다는 제약때문에, aws RDS는 사용할 수 없었습니다. 그리고 database는 public internet에서 접근할 수 없다고 해서, db는 private subnet의 ec2에서 돌아가게 설계했습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 개념 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/5.html#outro",
    "href": "posts/02_areas/42_seoul/notes/5.html#outro",
    "title": "cloud-1 개념 설명",
    "section": "outro",
    "text": "outro\n여기서 구현된 infra 구조는 사실 별로 근본있는 구조는 아니니까, 이것보다는 IaC 툴을 얼마나 편리하게 사용할 수 있는지에 초점을 맞춰서 봐주시길 바라고 있습니다.\n이어서 코드에 대한 설명은 다음 게시글에 포스팅하겠습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 개념 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/4.html#intro",
    "href": "posts/02_areas/42_seoul/notes/4.html#intro",
    "title": "inception-of-things part 1",
    "section": "intro",
    "text": "intro\n\n\n\n42 seoul outer 과제\n\n\n42 Seoul의 공통 과정을 마무리하면, 원하는 분야를 선택하여 심화 과제를 수행할 수 있습니다. 그중에서도 ’Inception-of-Things’는 인프라 관련 심화 과제로, 가장 많은 경험치를 얻을 수 있는 과제입니다.\n얼핏 보면 매우 어려운 과제처럼 느껴질 수 있지만, 개념을 확실히 이해하고 공부한다면 누구나 빠르게 완료할 수 있다고 생각합니다. 저의 경우, CKA 자격증 취득을 목표로 k8s를 공부하던 중 우연히 팀원을 구하게 되어 이 과제를 수행하게 되었습니다. 배경지식이 어느 정도 있는 상태에서 진행하다 보니, 크게 어렵지 않게 잘 마무리할 수 있었던 것 같습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "inception-of-things part 1"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/4.html#프로젝트-및-구현-설명",
    "href": "posts/02_areas/42_seoul/notes/4.html#프로젝트-및-구현-설명",
    "title": "inception-of-things part 1",
    "section": "프로젝트 및 구현 설명",
    "text": "프로젝트 및 구현 설명\n\n개요\n과제 명세서\n참고한 자료는 다음과 같습니다:\n\nCKA Udemy 강의\nArgoCD Udemy 강의\ngitlab helm 베포 Docs\nVagrant Docs\n\n\n\n\n\n\n\n전체 코드는 비공개 되어있는 상태입니다\n\n\n\n\n\nPart 1\n\n\n\nPart 1 요구사항\n\n\ncluster는 노드(컴퓨터)들의 논리적인 집합을 의미합니다. 일반적으로, 하나의 컴퓨터로 처리하기 어려운 방대한 양의 작업을 처리하기 위해 도입을 합니다.\n클러스터는 특정한 목적을 가지고 있고, 그 안의 노드들을 각자 맡은 역할을 수행합니다. 이때, k8s는 분산된 노드(컴퓨터)들을 하나의 클러스터로 묶어주고, 관리해주는 도구로써 사용할 수 있습니다.\n한 가지 주의해야 하는 것은, k8s 자체는 노드를 생성(provision)해주는 도구가 아니라는 것입니다. 즉, provision 단계는 k8s clustering 이전에 진행되어야 합니다.\n\n\n\nPart 1 구조\n\n\nPart 1에서는 vagrant tool을 이용해서 master, agent 역할을 하는 두 대의 가상 머신을 local에서 provision하고, k3s를 이용해서 clustering 하는 것을 목표로 합니다. 참고로 k3s는 k8s의 경량화 버전입니다.\n파일 구조는 아래와 같습니다.\np1/\n├── scripts/\n│   ├── agent.yml\n│   └── server.yml\n└── Vagrantfile\nvagrant는 local에서 가상 머신을 생성하고, provision을 할 수 있는 도구입니다. 사용자가 원하는 스펙을 Vagrantfile 이름의 파일에 정의하면, vagrant up 명령어를 통해 간단하게 가상머신을 생성할 수 있습니다.\n과제 요구사항에 맞게 spec을 정의해줍니다.\n\n\nVagrantfile\n\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"bento/ubuntu-24.04\"\n  config.vm.box_version = \"202404.26.0\"\n\n  config.vm.define \"hyunghkiS\" do |control|\n    control.vm.hostname = \"hyunghkiS\"\n    control.vm.network \"private_network\", ip: \"192.168.56.110\"\n    control.vm.provider \"virtualbox\" do |v|\n      v.customize [\"modifyvm\", :id, \"--name\", \"hyunghkiS\"]\n      v.memory = \"1024\"\n      v.cpus = \"1\"\n    end\n    # just for evaluation\n    control.vm.provision \"shell\", inline: &lt;&lt;-SHELL\n      sudo apt-get update\n      sudo apt-get install -y net-tools\n    SHELL\n    control.vm.provision \"shell\", path: \"scripts/server.sh\"\n  end\n  config.vm.define \"hyunghkiSW\" do |control|\n    control.vm.hostname = \"hyunghkiSW\"\n    control.vm.network \"private_network\", ip: \"192.168.56.111\"\n    control.vm.provider \"virtualbox\" do |v|\n      v.customize [\"modifyvm\", :id, \"--name\", \"hyunghkiSW\"]\n      v.memory = \"1024\"\n      v.cpus = \"1\"\n    end\n    # just for evaluation\n    control.vm.provision \"shell\", inline: &lt;&lt;-SHELL\n      sudo apt-get update\n      sudo apt-get install -y net-tools\n    SHELL\n    control.vm.provision \"shell\", path: \"scripts/agent.sh\"\n  end\nend\n\n저 just for evaluation 부분은 아마 과제 명세서에 ifconfig 명령어를 입력해보는 부분 때문에 추가한 것 같습니다. (사실 이 글을 쓰는 시점은 과제를 수행하고 1년이 지난 시점이라 기억이 가물가물 합니다.)\n\n\nserver.sh\n\n#!/bin/bash\n\necho 'alias k=kubectl' &gt;&gt; /home/vagrant/.bashrc\nsource /home/vagrant/.bashrc\n\ncurl -sfL https://get.k3s.io | K3S_KUBECONFIG_MODE=\"644\" sh -s - server --node-ip 192.168.56.110\nK3S_TOKEN=$(sudo cat /var/lib/rancher/k3s/server/node-token)\necho $K3S_TOKEN &gt; /vagrant/k3s_token # vagrant 공유 폴더에 master token 정보를 저장해주었습니다.\n\n\n\nagent.sh\n\n#!/bin/bash\n\necho 'alias k=kubectl' &gt;&gt; /home/vagrant/.bashrc\nsource /home/vagrant/.bashrc\n\nK3S_TOKEN=$(cat /vagrant/k3s_token) # vagrant 공유 폴더에 저장된 master token 정보를 읽어옵니다.\ncurl -sfL https://get.k3s.io | K3S_URL=https://192.168.56.110:6443 K3S_TOKEN=$K3S_TOKEN sh -s - --node-ip 192.168.56.111\n\nk3s 공식 문서를 참고해서 master와 agent를 clustering 해주는 스크립트를 작성해주었습니다. 각각 노드 안에서 로직이 실행되어, 하나는 master로, 하나는 agent로 역할을 수행하게 됩니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "inception-of-things part 1"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/4.html#outro",
    "href": "posts/02_areas/42_seoul/notes/4.html#outro",
    "title": "inception-of-things part 1",
    "section": "outro",
    "text": "outro\n오랜만에 해당 과제의 로직을 다시 보니까 기억이 잘 안납니다.\n남은 부분은 천천히 포스팅하겠습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "inception-of-things part 1"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/6.html#intro",
    "href": "posts/02_areas/42_seoul/notes/6.html#intro",
    "title": "cloud-1 코드 설명",
    "section": "intro",
    "text": "intro\n\n\n\n42 seoul outer 과제\n\n\n개념 설명에 이어서 진행하도록 하겠습니다.\n\n\n\n\n\n\n전체 코드는 github repo에서 확인하실 수 있습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 코드 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/6.html#프로젝트-및-구현-설명",
    "href": "posts/02_areas/42_seoul/notes/6.html#프로젝트-및-구현-설명",
    "title": "cloud-1 코드 설명",
    "section": "프로젝트 및 구현 설명",
    "text": "프로젝트 및 구현 설명\n\npre requirements\n이 프로젝트를 진행하기 위해 필요한 것들은 다음과 같습니다.\n\nAWS IAM 계정\nPacker\nTerraform\nAnsible\njq\nboto3\n\n\n\nbuild\n최종 build는 (42 seoul 사람에게 익숙한) makefile을 사용했습니다.\n\n\n\n\n\n\n제가 아직 로컬에서 돌려볼만한 다른 build 툴을 배우지 않아서 makefile을 사용하긴 했지만, 사실 c언어도 아니고..이 과제 구현에서 이 tool이 그렇게 어울리진 않은거 같긴 합니다.\n\n\n\n\n\n.env\n\n# only 1 line variable is allowed\n\nAWS_REGION=\nAWS_ACCESS_KEY_ID=\nAWS_SECRET_ACCESS_KEY=\nSERVER_INSTANCE_COUNT=\n\n# public subnet에 접근할 수 있는 ip address를 지정해줍니다.\nSSH_IP=\n\n# public subnet에 접근할 때 사용할 ssh key path를 지정해줍니다.\nSSH_PUBLIC_KEY_PATH=\nSSH_PRIVATE_KEY_PATH=\n\n# docker compose setting\nMYSQL_USER=\nMYSQL_PASSWORD=\nMYSQL_ROOT_PASSWORD=\nDATABASE_NAME=\nSITE_TITLE=\nADMIN_NAME=\nADMIN_PASSWORD=\nADMIN_EMAIL=\nUSER_NAME=\nUSER_PASSWORD=\nUSER_EMAIL=\n\n\n\nMakefile\n\n# .env의 내용들을 makefile의 변수로 load 해줍니다.\n\ninclude .env\nexport\n\n먼저 필요한 변수들을 모두 .env에 저장해 한번에 관리할 수 있게 구현했습니다. 저장된 .env 내용은 makefile에서 위의 명령어로 불러와 build 명령어 실행시 사용할 수 있게 했습니다.\nmakefile이 .env 파일을 읽을 때 한 줄씩 읽기 때문에, 위의 방식으로 구현하면 여러 줄에 걸친 환경변수는 사용하기 어려울 수 있습니다. (그럴땐 그냥 makefile 말고 다른 tool을 쓰면 됩니다)\n\n\nMakefile\n\n.PHONY: provision deploy all destroy re build_ami\n\nall: build_ami provision deploy\n\nbuild_ami: packer\n    packer init $(PACKER_PATH)/database.pkr.hcl\n    @PKR_VAR_AWS_REGION=$(AWS_REGION) \\\n    PKR_VAR_MYSQL_USER=$(MYSQL_USER) \\\n    PKR_VAR_MYSQL_PASSWORD=$(MYSQL_PASSWORD) \\\n    PKR_VAR_DATABASE_NAME=$(DATABASE_NAME) \\\n    PKR_VAR_MYSQL_ROOT_PASSWORD=$(MYSQL_ROOT_PASSWORD) \\\n    packer build $(PACKER_PATH)/database.pkr.hcl\n\nprovision: build_ami terraform\n    terraform -chdir=$(PROVISION_PATH) init\n    @TF_VAR_AWS_REGION=$(AWS_REGION) \\\n    TF_VAR_SERVER_INSTANCE_COUNT=$(SERVER_INSTANCE_COUNT) \\\n    TF_VAR_SSH_IP=$(SSH_IP) \\\n    TF_VAR_SSH_PUBLIC_KEY_PATH=$(SSH_PUBLIC_KEY_PATH) \\\n    terraform -chdir=$(PROVISION_PATH) apply -auto-approve\n\ndeploy: ansible\n    @DB_PRIVATE_IP=\"$(shell terraform -chdir=$(PROVISION_PATH) output -json db_private_ip | jq -r '.[]' | tr '\\n' ' ')\" \\\n    ANSIBLE_HOST_KEY_CHECKING=False \\\n    ANSIBLE_REMOTE_USER=ubuntu \\\n    AWS_DEFAULT_REGION=$(AWS_REGION) \\\n    ANSIBLE_PYTHON_INTERPRETER=auto_silent \\\n    ansible-playbook \\\n    -i $(DEPLOY_PATH)/inventories \\\n    --private-key=$(SSH_PRIVATE_KEY_PATH) \\\n    $(DEPLOY_PATH)/server.yml \n\nbuild 과정은 ami 생성, provision, ansible deploy 순서로 진행됩니다.\n각 과정에 필요한 변수들은 명령어 수행 시 환경변수로 제공해줍니다. 대표적으로 ansible의 경우, provision 이후 생성된 database ec2의 private ip를 전달하고 있습니다.\n\n\nPacker 코드\n이 프로젝트에서는 데이터베이스 서버를 Private subnet에 위치시키고, Public subnet의 EC2만 이 데이터베이스에 접근할 수 있도록 설계했습니다. Private subnet에 있는 서버는 SSH 접근이 제한되기 때문에 Ansible로 직접 설정하기는 어렵습니다. 이런 경우 Packer로 미리 설정된 AMI를 생성하는 방법을 생각해볼 수 있습니다.\n구현한 Packer 파일 구조는 아래와 같습니다.\npacker/\n├── database.pkr.hcl\n└── ansible/\n    ├── _requirements/                      # docker compose setting files\n    ├── roles/setting_docker/tasks\n    │   └── main.yml\n    └── database.yml                        # playbook\n먼저 기본 이미지로 Ubuntu 20.04를 사용하도록 작성했습니다.\n\n\ndatabase.pkr.hcl\n\nsource \"amazon-ebs\" \"database\" {\n  region  = var.AWS_REGION\n  profile = \"default\"\n\n  ami_name      = \"hyunghki-database-${formatdate(\"YYYYMMDDhhmmss\", timestamp())}\"\n  instance_type = \"t2.micro\"\n  source_ami_filter {\n    filters = {\n      name                = \"ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*\"\n      root-device-type    = \"ebs\"\n      virtualization-type = \"hvm\"\n    }\n    most_recent = true\n    owners      = [\"099720109477\"]\n  }\n  ssh_username = \"ubuntu\"\n}\n\nPacker는 기본적으로 이미지 생성을 위한 최소한의 기능만 제공하지만, 다양한 플러그인을 지원합니다. 여기서는 Ansible 플러그인을 사용하여 데이터베이스 서버 설정을 자동화했습니다.\n\n\ndatabase.pkr.hcl\n\nbuild {\n  sources = [\"source.amazon-ebs.database\"]\n\n  provisioner \"ansible\" {\n    playbook_file = \"${path.root}/ansible/database.yml\"\n    user = \"ubuntu\"\n    ansible_env_vars = [\n      \"ANSIBLE_HOST_KEY_CHECKING=False\",\n      \"MYSQL_USER=${var.MYSQL_USER}\",\n      \"MYSQL_PASSWORD=${var.MYSQL_PASSWORD}\",\n      \"DATABASE_NAME=${var.DATABASE_NAME}\",\n      \"MYSQL_ROOT_PASSWORD=${var.MYSQL_ROOT_PASSWORD}\",\n      \"ANSIBLE_PYTHON_INTERPRETER=auto_silent\"\n    ]\n  }\n}\n\n\n\nansible/database.yml\n\n- hosts: all\n  gather_facts: false\n  become: true\n  roles:\n    # docker compose를 machine에 설치해줍니다.\n    - role: setting_docker\n\n  tasks:\n    # docker compose에 필요한 파일들을 옮겨줍니다.\n    - name: copy_requirements\n      copy:\n        src: \"./_requirements/\"\n        dest: \"/home/{{ ansible_user }}/app/\"\n        mode: '0755'\n        directory_mode: '0755'\n\n    # 적절한 환경변수와 함께 docker compose 명령어를 실행합니다.\n    - name: execute docker compose\n      shell:\n        cmd: docker-compose up -d\n        chdir: \"/home/{{ ansible_user }}/app/\"\n      environment:\n        MYSQL_USER: \"{{ lookup('env', 'MYSQL_USER') }}\"\n        MYSQL_PASSWORD: \"{{ lookup('env', 'MYSQL_PASSWORD') }}\"\n        DATABASE_NAME: \"{{ lookup('env', 'DATABASE_NAME') }}\"\n        MYSQL_ROOT_PASSWORD: \"{{ lookup('env', 'MYSQL_ROOT_PASSWORD') }}\"\n\n이렇게 Ansible과 Packer를 조합하면 멱등성이 보장되는 안정적인 서버 이미지를 생성할 수 있습니다.\n참고로 packer에서 ansible plugin을 사용할 때 taget host를 ami가 build되는 임시 EC2로 간주하기 때문에, inventory는 사용하지 않습니다. 자세한 내용은 ansible part를 참고해주세요.\n\n\nTerraform 코드\n이제 본격적으로 provision을 해보겠습니다. 잠시 전체적인 구조를 다시 한번 보겠습니다.\n\n\n\n구현 aws 구조\n\n\n필요한 리소스는 VPC, subnet, security group, ec2 입니다.\nserver ec2와 database ec2는 환경변수 SERVER_INSTANCE_COUNT에 지정된 갯수 만큼 생성됩니다. database ec2는 이전 단계에서 생성한 ami를 사용해줍니다.\npublic, private subnet의 갯수는 임의로 생성했습니다.\n파일 구조는 아래와 같습니다.\nterraform/\n├── main/\n│   ├── main.tf\n│   ├── data.tf\n│   ├── output.tf\n│   └── variables.tf\n└── modules/network/\n    ├── main.tf\n    ├── output.tf\n    └── variables.tf\nmain.tf에서는 aws_instance를 생성하고, 그 외 VPC, subnet과 같은 리소스는 network module로 분리해서 생성했습니다.\n\n\nmodules/network/main.tf\n\nresource \"aws_vpc\" \"main_vpc\" {\n  cidr_block           = \"10.0.0.0/16\"\n  instance_tenancy     = \"default\"\n  enable_dns_hostnames = \"true\"\n}\n\nresource \"aws_subnet\" \"public-1\" {\n  vpc_id                  = aws_vpc.main_vpc.id\n  cidr_block              = \"10.0.1.0/24\"\n  map_public_ip_on_launch = \"true\"\n  availability_zone       = \"${var.AWS_REGION}a\"\n}\n\nresource \"aws_subnet\" \"public-2\" {\n  vpc_id                  = aws_vpc.main_vpc.id\n  cidr_block              = \"10.0.2.0/24\"\n  map_public_ip_on_launch = \"true\"\n  availability_zone       = \"${var.AWS_REGION}c\"\n}\n\nresource \"aws_subnet\" \"private\" {\n  vpc_id                  = aws_vpc.main_vpc.id\n  cidr_block              = \"10.0.3.0/24\"\n  map_public_ip_on_launch = \"false\"\n  availability_zone       = \"${var.AWS_REGION}a\"\n}\n\n먼저 VPC와 subnet을 생성합니다.\ncidr_block은 private ip 중에서 겹치지 않는 범위로 지정해줍니다.\n\n\n\n\n\n\nPrivate IP ranges\n\n\n\n\nClass A: 10.0.0.0–10.255.255.255\nClass B: 172.16.0.0–172.31.255.255\nClass C: 192.168.0.0–192.168.255.255\n\n\n\nPublic subnet이 인터넷과 통신하기 위해서는 Internet Gateway와 Route Table이 필요합니다.\n\n\nmodules/network/main.tf\n\nresource \"aws_internet_gateway\" \"gate_way\" {\n  vpc_id = aws_vpc.main_vpc.id\n}\n\nresource \"aws_route_table\" \"public_route_table\" {\n  vpc_id = aws_vpc.main_vpc.id\n\n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.gate_way.id\n  }\n}\n\nresource \"aws_route_table_association\" \"public-1\" {\n  subnet_id      = aws_subnet.public-1.id\n  route_table_id = aws_route_table.public_route_table.id\n}\n\nresource \"aws_route_table_association\" \"public-2\" {\n  subnet_id      = aws_subnet.public-2.id\n  route_table_id = aws_route_table.public_route_table.id\n}\n\n모든 외부 트래픽을 Internet Gateway로 보내도록 Route Table을 설정하고, 이를 두 개의 Public subnet에 연결했습니다.\n참고로 VPC 내부 통신은 자동으로 라우팅됩니다. 같은 VPC 안에 있는 리소스들은 VPC의 기본 라우팅 테이블을 통해 서로 통신할 수 있기 때문에 내부 통신을 위한 route table은 따로 생성하지 않았습니다.\n\n\nmodules/network/main.tf\n\nresource \"aws_security_group\" \"server_sg\" {\n  vpc_id = aws_vpc.main_vpc.id\n  name   = \"server_sg\"\n\n  ingress {\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = var.SSH_CIDR_BLOCKS\n  }\n\n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  ingress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\nresource \"aws_security_group\" \"database_sg\" {\n  vpc_id = aws_vpc.main_vpc.id\n  name   = \"efs_sg\"\n\n  ingress {\n    from_port       = 3306\n    to_port         = 3306\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.server_sg.id]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\n마지막으로 security group입니다.\nserver ec2의 ssh 접근은 환경변수를 통해 ansible을 실행하는 머신의 ip에서만 접근 가능하도록 설정해줬습니다.\ndatabase ec2는 server ec2만 접근할 수 있도록 설정했습니다.\n\n\nmain/main.tf\n\n# 사용자가 지정한 경로의 ssh key를 사용해 ec2에 접근 가능하도록 설정했습니다.\nresource \"aws_key_pair\" \"my_labtop\" {\n  key_name   = \"my_labtop\"\n  public_key = file(var.SSH_PUBLIC_KEY_PATH)\n}\n\nmodule \"network\" {\n  source = \"../modules/network\"\n\n  AWS_REGION           = var.AWS_REGION\n  SSH_CIDR_BLOCKS      = [\"${var.SSH_IP}/32\"]\n}\n\nresource \"aws_instance\" \"server\" {\n  count         = var.SERVER_INSTANCE_COUNT\n  ami           = data.aws_ami.latest_ubuntu.id\n  instance_type = \"t2.micro\"\n\n  vpc_security_group_ids = [module.network.server_sg_id]\n  # subnet은 2개를 번걸아가면서 사용하도록 설정했습니다.\n  subnet_id              = module.network.public_subnets[count.index % 2]\n\n  key_name = aws_key_pair.my_labtop.key_name\n  tags = {\n    Name = \"serverNode\"\n  }\n}\n\nresource \"aws_instance\" \"database\" {\n  count         = var.SERVER_INSTANCE_COUNT\n  ami           = data.aws_ami.database_ami.id\n  instance_type = \"t2.micro\"\n\n  vpc_security_group_ids = [module.network.database_sg_id]\n  subnet_id              = module.network.private_subnets\n\n  key_name = aws_key_pair.my_labtop.key_name\n  tags = {\n    Name = \"dbNode\"\n  }\n}\n\n최종적으로 main.tf에서 network module을 불러와서 필요한 리소스를 생성한 후, server와 database ec2를 생성했습니다.\n\n\nmain/data.tf\n\ndata \"aws_ami\" \"latest_ubuntu\" {\n  most_recent = true\n\n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*\"]\n  }\n\n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n\n  owners = [\"099720109477\"]\n}\n\ndata \"aws_ami\" \"database_ami\" {\n  most_recent = true\n  owners = [\"self\"]\n  filter {\n    name = \"name\"\n    values = [\"hyunghki-database-*\"]\n  }\n  filter {\n    name = \"root-device-type\"\n    values = [\"ebs\"]\n  }\n  filter {\n    name = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n}\n\nserver ec2는 기본 ubuntu 20.04 이미지를 사용하고, database ec2는 이전에 생성한 ami를 사용했습니다.\n\n\nansible 코드\n이제 필요한 설정을 진행하겠습니다.\n파일 구조는 아래와 같습니다.\nterraform/\n├── _requirements/                      # docker compose setting files\n├── inventories/\n│   └── aws_ec2.yml\n├── roles/setting_docker/tasks\n│   └── main.yml\n└── server.yml\n먼저 용어를 알아야 합니다.\n\nInventory (인벤토리)\n인벤토리는 Ansible이 관리할 호스트(서버)의 목록입니다. 호스트를 그룹으로 묶어 관리할 수 있습니다.\nPlaybook (플레이북)\n플레이북은 Ansible에서 작업을 정의하는 YAML 파일입니다. 플레이북은 하나 이상의 플레이로 구성되며, 각 플레이는 특정 호스트 그룹에 대해 수행할 작업(task)을 정의합니다.\nRole (롤)\n롤은 Ansible에서 재사용 가능한 구성 단위입니다. 플레이북을 모듈화하고 구조화하여 재사용성을 높이는 데 사용됩니다.\n\nInventory에서 server 그룹을 정의한 후, playbook으로 docker compose 환경을 설정하겠습니다.\n\n\naws_ec2.yml\n\nplugin: aws_ec2\nkeyed_groups:\n  - key: tags\ncompose:\n  ansible_host: public_ip_address\nleading_separator: False\nfilters:\n  instance-state-name: running\n\nAWS EC2 동적 인벤토리 설정입니다. Terraform으로 생성한 EC2 인스턴스들을 자동으로 관리할 수 있습니다.\n\n\nserver.yml\n\n- hosts: \"Name_serverNode\"\n  gather_facts: false\n  become: true\n  roles:\n    - role: setting_docker\n  tasks:\n    - name: copy_requirements\n      copy:\n        src: \"./_requirements/\"\n        dest: \"/home/{{ ansible_user }}/app/\"\n        mode: '0755'\n        directory_mode: '0755'\n\n    - name: Split array values from DB_PRIVATE_IP\n      set_fact:\n        target: \"{{ lookup('env', 'DB_PRIVATE_IP') | split(' ') }}\"\n\n    - name: execute docker compose\n      shell:\n        cmd: docker-compose up -d\n        chdir: \"/home/{{ ansible_user }}/app/\"\n      environment:\n        DOMAIN_NAME: \"{{ ansible_host }}\"\n        MYSQL_USER: \"{{ lookup('env', 'MYSQL_USER') }}\"\n        MYSQL_PASSWORD: \"{{ lookup('env', 'MYSQL_PASSWORD') }}\"\n        DATABASE_NAME: \"{{ lookup('env', 'DATABASE_NAME') }}\"\n        SITE_TITLE: \"{{ lookup('env', 'SITE_TITLE') }}\"\n        ADMIN_NAME: \"{{ lookup('env', 'ADMIN_NAME') }}\"\n        ADMIN_PASSWORD: \"{{ lookup('env', 'ADMIN_PASSWORD') }}\"\n        ADMIN_EMAIL: \"{{ lookup('env', 'ADMIN_EMAIL') }}\"\n        USER_NAME: \"{{ lookup('env', 'USER_NAME') }}\"\n        USER_PASSWORD: \"{{ lookup('env', 'USER_PASSWORD') }}\"\n        USER_EMAIL: \"{{ lookup('env', 'USER_EMAIL') }}\"\n        DB_PRIVATE_IP: \"{{ target[ansible_play_hosts.index(inventory_hostname)] }}\"\n\n    - name: all done message\n      debug:\n        msg: \"https://{{ ansible_host }}\"\n\n’Name’이 ’serverNode’인 인스턴스들만 선택하여 설정을 진행하겠습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 코드 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/6.html#실행",
    "href": "posts/02_areas/42_seoul/notes/6.html#실행",
    "title": "cloud-1 코드 설명",
    "section": "실행",
    "text": "실행\n먼저 .env 파일에 환경변수를 설정해줍니다.\nip 정보도 알아낸 후, SSH_IP에 설정해줍니다.\n\n\n\nnaver에 내 ip 검색\n\n\n\n\n.env\n\n# only 1 line variable is allowed\nAWS_REGION=ap-northeast-2\nAWS_ACCESS_KEY_ID=********************\nAWS_SECRET_ACCESS_KEY=********************\nSERVER_INSTANCE_COUNT=2\nSSH_IP=121.135.181.56\nSSH_PUBLIC_KEY_PATH=~/.ssh/id_rsa.pub\nSSH_PRIVATE_KEY_PATH=~/.ssh/id_rsa\nMYSQL_USER=dudu\nMYSQL_PASSWORD=secret\nMYSQL_ROOT_PASSWORD=secret\nDATABASE_NAME=cloud\nSITE_TITLE='hyunghki blog'\nADMIN_NAME=admin\nADMIN_PASSWORD=secret\nADMIN_EMAIL=admin@example.com\nUSER_NAME=user\nUSER_PASSWORD=secret\nUSER_EMAIL=user@example.com\n\n그후 make 명령어를 입력하면 자동으로 build가 진행됩니다.\n\n\n\n명령어 실행 결과\n\n\nbuild가 완료되면 완료 메세지의 ip로 접속해줍니다.\n\n\n\n접속 페이지\n\n\nwordpress 접속 페이지가 잘 뜨는 것을 확인할 수 있습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 코드 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/6.html#결과",
    "href": "posts/02_areas/42_seoul/notes/6.html#결과",
    "title": "cloud-1 코드 설명",
    "section": "결과",
    "text": "결과\n\n\n\n최종 점수\n\n\n\n\n\n최종 평가",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 코드 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/6.html#outro",
    "href": "posts/02_areas/42_seoul/notes/6.html#outro",
    "title": "cloud-1 코드 설명",
    "section": "outro",
    "text": "outro\n솔직히 일반적으로 사용되는 cloud 구조를 적용한건 아니긴 하지만, 과제에 맞춰서 진행하기 위해 고민하는 과정에서 다양한 구조를 적용해봤는데, 그 과정이 나름 학습에 도움이 된거 같습니다. 이 분야에 공부를 꽤 했고, 그 내용들을 다양하게 고민하며 적용해보고 싶다면 이 프로젝트가 괜찮은 선택지가 될 수도 있어 보입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "cloud-1 코드 설명"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/index.html",
    "href": "posts/02_areas/42_seoul/index.html",
    "title": "42 Seoul",
    "section": "",
    "text": "42 seoul에서 진행한 프로젝트들에 대한 노트 모음입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/index.html#details",
    "href": "posts/02_areas/42_seoul/index.html#details",
    "title": "42 Seoul",
    "section": "",
    "text": "42 seoul에서 진행한 프로젝트들에 대한 노트 모음입니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/index.html#tasks",
    "href": "posts/02_areas/42_seoul/index.html#tasks",
    "title": "42 Seoul",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/index.html#related-posts",
    "href": "posts/02_areas/42_seoul/index.html#related-posts",
    "title": "42 Seoul",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/3.html#가우스-조던-소거법",
    "href": "posts/02_areas/선형대수/notes/3.html#가우스-조던-소거법",
    "title": "3-몰라",
    "section": "가우스 조던 소거법",
    "text": "가우스 조던 소거법\n\n선형대수의 목표는 \\(Ax = b\\)에서 x를 찾는 것이다.\n\n\\[\\begin{aligned}\nx + 2y \\quad  &= 4 \\\\\n2x + 5y \\quad &= 9\n\\end{aligned}\\]\n이 수식을 다시 살펴보자. 위의 수식은 아래와 같이 적용할 수 있다.\n\\[\\begin{aligned}\n2x + 4y \\quad  &= 8 \\\\\n2x + 5y \\quad &= 9\n\\end{aligned}\\]\n위의 열립방정식을 풀면 \\(y = 1\\)이라는 결과를 얻는다. 다시 \\(y=1\\)을 대입해서 \\(x=2\\)라는 값을 구할 수 있다.\n이제 이를 matrix와 vector로 풀어보자.\n\\[\n\\begin{bmatrix}\n1 & 2 \\\\\n2 & 5\n\\end{bmatrix}\n\\begin{bmatrix}\nx \\\\\ny\n\\end{bmatrix} =\n\\begin{bmatrix}\n4 \\\\\n9\n\\end{bmatrix}\n\\]\n이를 확장행렬로 표현하면 다음과 같다\n\\[\n[A|b] = \\begin{bmatrix}\n1 & 2 & | & 4 \\\\\n2 & 5 & | & 9\n\\end{bmatrix}\n\\]\n이제 가우스 조던 소거법을 적용해보자\n적용 순서는 다음과 같다.\n\n양 변에 0이 아닌 상수배를 해준다.\n상수배를 한 행을 다른행에 더하거나 뺀다.\n행끼리 자리 바꾼다.\n\n이에 맞춰서 위의 식을 풀이하면,\n\n두 번째 행에서 첫 번째 행의 2배를 빼면\n\n\\[\n\\begin{bmatrix}\n1 & 2 & | & 4 \\\\\n0 & 1 & | & 1\n\\end{bmatrix}\n\\]\n\n첫 번째 행에서 두 번째 행의 2배를 빼면\n\n\\[\n\\begin{bmatrix}\n1 & 0 & | & 2 \\\\\n0 & 1 & | & 1\n\\end{bmatrix}\n\\]\n따라서 \\(x = 2\\), \\(y = 1\\)이라는 해를 얻을 수 있다.\n즉 가우스조던 소거법은 왼쪽을 항등행렬로 만들고, 그 오른쪽에 있는 값이 답이되는 소거법이다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "3-몰라"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/3.html#역행렬-구하기",
    "href": "posts/02_areas/선형대수/notes/3.html#역행렬-구하기",
    "title": "3-몰라",
    "section": "역행렬 구하기",
    "text": "역행렬 구하기\n역행렬을 구할 수 있다면 x의 값을 쉽게 구할 수 있다. (\\(x = A^{-1}b\\))\n가우스 조던 소거법을 이용해 역행렬을 구해보자.\n\\[\n\\begin{bmatrix}\na & b & | & 1 & 0 \\\\\nc & d & | & 0 & 1\n\\end{bmatrix}\n\\]\n\\[\n\\begin{bmatrix}\na & b & | & 1 & 0 \\\\\n0 & \\frac{ad-bc}{a} & | & -\\frac{c}{a} & 1\n\\end{bmatrix}\n\\]\n\\[\n\\begin{bmatrix}\na & b & | & 1 & 0 \\\\\n0 & 1 & | & -\\frac{-c}{ad-bc} & \\frac{a}{ad-bc}\n\\end{bmatrix}\n\\]\n\\[\n\\begin{bmatrix}\na & 0 & | & \\frac{ad}{ad-bc} & \\frac{-ab}{ad-bc} \\\\\n0 & 1 & | & -\\frac{-c}{ad-bc} & \\frac{a}{ad-bc}\n\\end{bmatrix}\n\\]\n\\[\n\\begin{bmatrix}\n1 & 0 & | & \\frac{d}{ad-bc} & \\frac{-b}{ad-bc} \\\\\n0 & 1 & | & -\\frac{-c}{ad-bc} & \\frac{a}{ad-bc}\n\\end{bmatrix}\n\\]\n\\[\n∴ A^{-1} = \\frac{1}{ad-bc}\n\\begin{bmatrix}\nd & -b \\\\\n-c & a\n\\end{bmatrix}\n\\]\n\ninvertible\n역행렬이 존재할 경우 invertible하다고 한다.\n\nnon singular matrix\ndet(A) ≠ 0: ad - bc(determinant) = 0인 경우 역행렬이 존재하지 않는다.\nA가 full rank이다\nN(A) = 0",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "3-몰라"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/3.html#determinant",
    "href": "posts/02_areas/선형대수/notes/3.html#determinant",
    "title": "3-몰라",
    "section": "determinant",
    "text": "determinant\n정사각행렬의 element로 scalar 값을 만드는 함\n\n3 x 3 행렬의 det\n\\[\nA=\n\\begin{bmatrix}\na & b & c\\\\\nd & e & f \\\\\ng & h & i\n\\end{bmatrix}\n\\]\n\\(det(A) = a(ei - fh) - b(di-fg)+c(dh-eg)\\)\nLaplace expansion or cofactor expansion\n\n\nproperties\n\ndet(A) = 0 이면 A is singular\nA가 rank-deficient 이면 det(A) = 0\ndiagonal or triangular matrix, det(A) = 대각요소의 곱\n항등행렬의 det=1\ndet(cA) = \\(c^ndet(A)\\) (A = nxn)\n\\(det(A^T) = det(A)\\)\ndet(AB) = det(A)det(B)\n\\(\\color{red}{det(A^{-1}) = \\frac{1}{det(A)}}\\)\n\\(\\color{red}{det(A) = λ_1λ_2,...,λ_n}\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "3-몰라"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/3.html#trace",
    "href": "posts/02_areas/선형대수/notes/3.html#trace",
    "title": "3-몰라",
    "section": "Trace",
    "text": "Trace\n정사각 행렬에 대해서만 정의되는 것, diagonal 전부 더함\n\\(tr(A) = \\sum_{i=1}^{n}a_{ii}\\)\n\ntr(A + B) = tr(A) + tr(B)\ntr(cA) = ctr(A)\n\\(tr(A^T) = tr(A)\\)\ntr(AB) = tr(BA)\n\\(tr(a^Tb) = tr(ba^T)\\)\ntr(ABCD) = tr(BCDA) = tr(CDAB) = tr(DABC) (cyclic property)\n\\(tr(A) = \\sum_{i=1}^{n}\\lambda_i\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "3-몰라"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/3.html#최소자승법",
    "href": "posts/02_areas/선형대수/notes/3.html#최소자승법",
    "title": "3-몰라",
    "section": "최소자승법",
    "text": "최소자승법",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "3-몰라"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/1.html#vector",
    "href": "posts/02_areas/선형대수/notes/1.html#vector",
    "title": "2-기초(1)",
    "section": "Vector",
    "text": "Vector\nvector는 크기와 방향을 가지고 있다.\n\nExample\n\\[\\begin{bmatrix}\n3 \\\\\n2\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\n\n크기: \\(\\sqrt{9 + 4} = \\sqrt{13}\\)\n방향: \\(tan^{-1}(\\frac{2}{3})\\)\n\n크기와 방향이 같으면 같은 벡터이다.\n\n\n덧셈\n벡터의 덧셈을 기하학적으로 알아보자\n\\[\n\\begin{bmatrix}\n3 \\\\\n2\n\\end{bmatrix} +\n\\begin{bmatrix}\n-2 \\\\\n1\n\\end{bmatrix}\n\\]\n위의 수식을 좌표평면에 나타나면 다음과 같다.\n\n\n\n\n\n\n\n\n\n끝점을 다 더한 좌표와 시작 점을 연결한 벡터인 초록색 화살표가 두 벡터의 합이 된다.\n\n\nScalar 배\nvector에 scalar, 즉 숫자 하나를 곱하면 무슨 일이 생길까?\n\\[\n2 * \\begin{bmatrix}\n2 \\\\\n1\n\\end{bmatrix} =\n\\begin{bmatrix}\n4 \\\\\n2\n\\end{bmatrix}\n\\] \\[\n-2 * \\begin{bmatrix}\n2 \\\\\n1\n\\end{bmatrix} =\n\\begin{bmatrix}\n-4 \\\\\n-2\n\\end{bmatrix}\n\\]\n마찬가지로 좌표평면으로 나타내는건 귀찮아서 생략하겠다.\n\n\n\n\n\n\nScalar 배를 한 벡터끼리 더하면 모든 2차원 좌표를 표현할 수 있다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(1)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/1.html#전치-transpose",
    "href": "posts/02_areas/선형대수/notes/1.html#전치-transpose",
    "title": "2-기초(1)",
    "section": "전치 (Transpose)",
    "text": "전치 (Transpose)\n행렬 \\(A\\)의 요소 \\(a_{ij}\\)는 A의 Transpose인 \\(A^T\\)의 \\(a_{ji}\\)가 된다. 즉, 행렬 \\(A\\)를 전치하면 diagnal(대각선 요소)를 제외한 모든 요소가 대각선을 기준으로 서로 뒤바뀐다.\n\nSymmetrix matrix: \\(A = A^T\\)인 행렬, 즉 대각선을 기준으로 값이 전부 같은 행렬 Hermitian matrix: \\((A^*)^T = A^H(conjugate transpose) = A\\)를 만족하는 행렬\n\nVector의 경우에는 Column Vector의 경우, Transpose시 Row Vector로, Row Vector의 경우도 반대로 작용한다.\n\nProperties\n\n\\((A^T)^T = A\\)\n\\((A+B)^T = A^T + B^T\\)\n\\(\\color{red}{(AB)^T = B^TA^T}\\)\n\\((A^TA)^T\\)와 \\((AA^T)^T\\)의 결과는 항상 자기 자신이 된다. → Symmetrix matrix\n\\(C(A)^T = CA^T\\)\n\\(det(A^T) = det(A)\\)\n\\((A^T)^{-1} = (A^{-1})^T\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(1)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/1.html#inner-product-projection",
    "href": "posts/02_areas/선형대수/notes/1.html#inner-product-projection",
    "title": "2-기초(1)",
    "section": "Inner Product & Projection",
    "text": "Inner Product & Projection\n\\[\n\\underset{a}{\\begin{bmatrix}\n1 \\\\\n3\n\\end{bmatrix}} *\n\\underset{b}{\\begin{bmatrix}\n5 \\\\\n1\n\\end{bmatrix}} = 1 * 5 + 3 * 1 = 8 = a^Tb = b^Ta\n\\]\n갑자기 등장한 \\(a^Tb\\)가 의미하는건 아래와 같다.\n\\(a^Tb = ||a||*||b||cosθ\\)\n\n||a||는 a 벡터의 크기를 의미한다.\n\n위의 식을 그림으로 표현해보자\n\n\n\n\n\n\n\n\n\n내적은 초록색 화살표와 파란색 화살표의 곱으로 표현할 수 있다.\n이는 a 벡터가 b 벡터의 방향에 대해 얼마나 투영되었는지를 나타낸다.\n두 벡터의 방향이 일치할 때 내적의 값이 가장 크고, 수직일 때 0 (안 닮음을 의미), 반대 방향일 때 가장 작은 값이 된다.\n\n단위 벡터(크기가 1인 벡터) 계산\n위의 식으로 부터 다음의 추론 과정을 통해 단위 벡터를 계산할 수 있다.\n\\(a^Ta = ||a||^2\\)\n∴ \\(||a|| = \\sqrt{a^Ta}\\)\n∴ 단위 벡터는 \\(\\frac{a}{||a||}\\) = \\(\\frac{a}{\\sqrt{a^Ta}}\\)\n\n\n정사형 벡터의 좌표 계산\n벡터의 좌표는 방향과 크기의 곱으로 표현할 수 있다.\n\\(a^Tb = ||a||*||b||cosθ\\)\n정사형 벡터의 크기는 \\(\\frac{a^Tb}{||b||} = \\frac{a^Tb}{\\sqrt{b^Tb}}\\)\n장사형 벡터의 방향은 b의 단위 벡터와 같다.\n즉, 정사형 벡터의 좌표는 \\(\\frac{a^Tb}{\\sqrt{b^Tb}} * \\frac{b}{\\sqrt{b^Tb}} = \\frac{a^Tb}{b^Tb}b\\)\n\\(a^T\\frac{b}{\\sqrt{b^Tb}}*\\frac{b}{\\sqrt{b^Tb}}\\)로도 구할 수 있다.\n\na와 수직으로 연결되는 정사형 벡터 \\(\\hat{x}\\)\n\\((a-b\\hat{x})^Tb\\hat{x} = 0\\)\n\\(a^Tb - b^Tbb\\hat{x} = 0\\)\n\\(\\hat{x} = \\frac{a^Tb}{b^Tb}\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(1)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/1.html#norm",
    "href": "posts/02_areas/선형대수/notes/1.html#norm",
    "title": "2-기초(1)",
    "section": "Norm",
    "text": "Norm\n크기를 나타내는 것(0 포함, 양 음수 scalar)\n\n2-Norm (\\(l_2\\)-norm)\n벡터의 물리적인 길이.\n\\[\na = \\begin{bmatrix}\n1 \\\\\n2 \\\\\n3\n\\end{bmatrix}\n\\]\n\\(||a||_2 = \\sqrt{1^2+2^2+3^2} = (|1|^{\\color{red}{2}}+|2|^{\\color{red}{2}}+|3|^{\\color{red}{2}})^{\\color{red}{\\frac{1}{2}}}\\)\n2 제곱에, \\(\\frac{1}{2}\\)여서 2-norm이다.\n\n두 벡터 사이의 거리는 두 벡터의 차이의 2-norm이다.\n\n\n\n1-Norm (\\(l_1\\)-norm)\n1 제곱에 \\(\\frac{1}{1}\\)을 계산해주면 된다.\n\\(||a||_1 = (|1|^1+|2|^1+|3|^1)^{\\frac{1}{1}}\\)\n\n\np-Norm (\\(l_p\\)-norm)\n\\(||a||_p = (|x_1|^p+|x_2|^p+|x_3|^p+...)^{\\frac{1}{p}} = (\\underset{t}{\\Sigma} |x_t|^p)^{\\frac{1}{p}} \\quad (p ≥ 1)\\)\n\n\ninfinity-Norm\n\\(||a||_∞ = \\underset{t}{max}|x_t|\\)\n1-norm, 2-norm, infinity-norm의 값이 1이 되는 모든 벡터들을 좌표평면에 나타내면 다음과 같다.\n\n\n\n\n\n\n\n\n\n같은 벡터일 때, 1-norm ≥ 2-norm ≥ ∞-norm 순으로 크다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "2-기초(1)"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/4.html#what-is-vector",
    "href": "posts/02_areas/선형대수/notes/4.html#what-is-vector",
    "title": "벡터와 공간",
    "section": "what is vector",
    "text": "what is vector\nvector는 크기(magnitude)와 방향(direction)을 가지고 있고, 2, 3, 4 차원 너머를 수학적으로 표현할 수 있다.\n\nvector의 수학적 표현\nvector는 ordered list인 tuple 형태로 표현할 수 있다.\n\\[\n\\vec{v} =\n\\begin{bmatrix}\n3 \\\\\n4\n\\end{bmatrix}\n\\]\ndomain과 dimension에 따라 vector는 다음과 같이 표현할 수 있다.\n\\[\n\\vec{v} ∈ R^2\n\\]\n\n1차원: \\(R^1\\)\n2차원: \\(R^2\\)\n3차원: \\(R^3\\)\nn차원: \\(R^n\\)",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "벡터와 공간"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/4.html#vector의-합",
    "href": "posts/02_areas/선형대수/notes/4.html#vector의-합",
    "title": "벡터와 공간",
    "section": "vector의 합",
    "text": "vector의 합\nvector의 합은 각 성분별로 더한 결과를 반환한다.\n\n기하학적 의미\n\\[\n\\begin{bmatrix}\n3 \\\\\n2\n\\end{bmatrix} +\n\\begin{bmatrix}\n-2 \\\\\n1\n\\end{bmatrix}\n\\]\n위의 수식을 좌표평면에 나타나면 다음과 같다.\n\n\n\n\n\n\n\n\n\n끝점을 다 더한 좌표와 시작 점을 연결한 벡터인 초록색 화살표가 두 벡터의 합이 된다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "벡터와 공간"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/4.html#vector의-scalar-곱",
    "href": "posts/02_areas/선형대수/notes/4.html#vector의-scalar-곱",
    "title": "벡터와 공간",
    "section": "vector의 scalar 곱",
    "text": "vector의 scalar 곱\nvector에 scalar, 즉 숫자 하나를 곱하면 무슨 일이 생길까?\n\\[\n2 * \\begin{bmatrix}\n2 \\\\\n1\n\\end{bmatrix} =\n\\begin{bmatrix}\n4 \\\\\n2\n\\end{bmatrix}\n\\] \\[\n-2 * \\begin{bmatrix}\n2 \\\\\n1\n\\end{bmatrix} =\n\\begin{bmatrix}\n-4 \\\\\n-2\n\\end{bmatrix}\n\\]",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "벡터와 공간"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/4.html#vector의-차",
    "href": "posts/02_areas/선형대수/notes/4.html#vector의-차",
    "title": "벡터와 공간",
    "section": "vector의 차",
    "text": "vector의 차\nvector의 차는 각 성분별로 뺀 결과를 반환한다.\n기하학적으로는 두 벡터의 끝점을 연결한 벡터가 된다.\n\\(\\vec{x} - \\vec{y}\\)는 y에서 x를 연결한 벡터가 된다.\n\\(\\vec{y} - \\vec{x}\\)는 x에서 y를 연결한 벡터가 된다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "벡터와 공간"
    ]
  },
  {
    "objectID": "posts/02_areas/선형대수/notes/4.html#단위-벡터",
    "href": "posts/02_areas/선형대수/notes/4.html#단위-벡터",
    "title": "벡터와 공간",
    "section": "단위 벡터",
    "text": "단위 벡터\n\\[\n\\vec{v} = \\begin{bmatrix}\n3 \\\\\n4\n\\end{bmatrix}\n\\]\n위의 벡터를 단위 벡터의 합으로 만들면 다음과 같다.\n\\[\n\\hat{i} = \\begin{bmatrix}\n1 \\\\\n0\n\\end{bmatrix},\n\\hat{j} = \\begin{bmatrix}\n0 \\\\\n1\n\\end{bmatrix}\n\\]\n\\[\n\\vec{v} = 3\\hat{i} + 4\\hat{j}\n\\]\n\n\n\n\n\n\nScalar 배를 한 기저 벡터끼리 더하면 모든 2차원 좌표를 표현할 수 있다.",
    "crumbs": [
      "PARA",
      "Areas",
      "선형대수",
      "Notes",
      "벡터와 공간"
    ]
  },
  {
    "objectID": "posts/02_areas/terraform/notes/tfc/00.html#what-is-terraform-cloud",
    "href": "posts/02_areas/terraform/notes/tfc/00.html#what-is-terraform-cloud",
    "title": "Terraform Cloud",
    "section": "What is Terraform Cloud?",
    "text": "What is Terraform Cloud?\n\nTerraform Open-Source를 확장해주는 서비스\n\n\n\n\nTerraform Open-Source의 한계\n\n\n\n기존의 terraform을 대규모 팀 단위에서 사용하기엔 무리가 있음 → TFC\non-premise 환경을 위한 Terraform Enterpise 서비스도 존재함.\nTACOS: Terraform Automation & Collaboration Software",
    "crumbs": [
      "PARA",
      "Areas",
      "Terraform",
      "Notes",
      "Tfc",
      "Terraform Cloud"
    ]
  },
  {
    "objectID": "posts/02_areas/terraform/notes/tfc/00.html#what-is-organization",
    "href": "posts/02_areas/terraform/notes/tfc/00.html#what-is-organization",
    "title": "Terraform Cloud",
    "section": "What is Organization?",
    "text": "What is Organization?\n\nworkspaces, policies, terraform modules를 공유하는 공간\n\n\n\n\nOrganization level에서 모든 setting이 이루어짐\n\n\n\n하나의 조직을 운용하는 것이 일반적이나, 조직 구조에 따라 여러 조직을 생성해서 운용할 수 있다.",
    "crumbs": [
      "PARA",
      "Areas",
      "Terraform",
      "Notes",
      "Tfc",
      "Terraform Cloud"
    ]
  },
  {
    "objectID": "posts/02_areas/terraform/notes/tfc/00.html#authenticating-to-tfc",
    "href": "posts/02_areas/terraform/notes/tfc/00.html#authenticating-to-tfc",
    "title": "Terraform Cloud",
    "section": "Authenticating to TFC",
    "text": "Authenticating to TFC\n\nweb interface\nCLI\n\n\nToken\n\nUser Tokens\nTeam Tokens: CI/CD pipeline에 주로 사용됨\nOrganization Tokens",
    "crumbs": [
      "PARA",
      "Areas",
      "Terraform",
      "Notes",
      "Tfc",
      "Terraform Cloud"
    ]
  },
  {
    "objectID": "posts/04_archives/vault/notes/0_overview.html#how-vault-encrypt-data",
    "href": "posts/04_archives/vault/notes/0_overview.html#how-vault-encrypt-data",
    "title": "Overview",
    "section": "how vault encrypt data",
    "text": "how vault encrypt data",
    "crumbs": [
      "PARA",
      "Archives",
      "vault",
      "Notes",
      "Overview"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/0_core_concept.html",
    "href": "posts/04_archives/k8s/notes/0_core_concept.html",
    "title": "k8s cluster architecture",
    "section": "",
    "text": "- master nodes: manage the worker nodes and the pods in the cluster - etcd: key-value store for all cluster data - kube-scheduler: schedules pods to worker nodes - kube-controller-manager: runs controller processes - replication controller: ensures that the correct number of pods are running - node controller: monitors the nodes - worker nodes: host the pods that are the components of the application - kubelet: communicates with the master node - kube-proxy: forwards requests to the correct pod\n\n\n  - initially, k8s was built on top of docker - gradually, k8s started supporting other container runtimes like containerd, cri-o, etc. and built a container runtime interface (CRI) to support multiple container runtimes - docker was not designed to be a container runtime, it was designed to be a container engine so it has a lot of features that are not needed by k8s and removed.\n\n\n\n\nkey-value store for all cluster data\nstores nodes, pods, configs, secrets, accounts, roles, bindings, etc.\n\n\n\n\n\n\n\nkube-api-server\n\n\n\n\n\n\n\n\n\n\n\n\nmust be installed on every node in the cluster manually ## kube-proxy\nkubeadm automatically installs kube-proxy on every node using daemonset\nwhen a service is created, kube-proxy creates a set of iptables rules to forward traffic to the correct pod",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "k8s cluster architecture"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/0_core_concept.html#docker-vs-containerd",
    "href": "posts/04_archives/k8s/notes/0_core_concept.html#docker-vs-containerd",
    "title": "k8s cluster architecture",
    "section": "",
    "text": "- initially, k8s was built on top of docker - gradually, k8s started supporting other container runtimes like containerd, cri-o, etc. and built a container runtime interface (CRI) to support multiple container runtimes - docker was not designed to be a container runtime, it was designed to be a container engine so it has a lot of features that are not needed by k8s and removed.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "k8s cluster architecture"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/0_core_concept.html#etcd",
    "href": "posts/04_archives/k8s/notes/0_core_concept.html#etcd",
    "title": "k8s cluster architecture",
    "section": "",
    "text": "key-value store for all cluster data\nstores nodes, pods, configs, secrets, accounts, roles, bindings, etc.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "k8s cluster architecture"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/0_core_concept.html#kube-api-server",
    "href": "posts/04_archives/k8s/notes/0_core_concept.html#kube-api-server",
    "title": "k8s cluster architecture",
    "section": "",
    "text": "kube-api-server",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "k8s cluster architecture"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/0_core_concept.html#kubelet",
    "href": "posts/04_archives/k8s/notes/0_core_concept.html#kubelet",
    "title": "k8s cluster architecture",
    "section": "",
    "text": "must be installed on every node in the cluster manually ## kube-proxy\nkubeadm automatically installs kube-proxy on every node using daemonset\nwhen a service is created, kube-proxy creates a set of iptables rules to forward traffic to the correct pod",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "k8s cluster architecture"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/2_logging_monitoring.html",
    "href": "posts/04_archives/k8s/notes/2_logging_monitoring.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "in-memmory solution.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "metrics server"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/2_logging_monitoring.html#metrics-server",
    "href": "posts/04_archives/k8s/notes/2_logging_monitoring.html#metrics-server",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "in-memmory solution.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "metrics server"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/2_logging_monitoring.html#cadvisor",
    "href": "posts/04_archives/k8s/notes/2_logging_monitoring.html#cadvisor",
    "title": "김형훈의 학습 블로그",
    "section": "cAdvisor",
    "text": "cAdvisor\n\ncontainer advisor\nsub-component of kubelet\ncollects, aggregates, processes, and exports information about running containers",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "metrics server"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/6_network.html",
    "href": "posts/04_archives/k8s/notes/6_network.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "k8s uses coreDNS to provide DNS service",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "core DNS"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/6_network.html#core-dns",
    "href": "posts/04_archives/k8s/notes/6_network.html#core-dns",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "k8s uses coreDNS to provide DNS service",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "core DNS"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/6_network.html#network-plugin",
    "href": "posts/04_archives/k8s/notes/6_network.html#network-plugin",
    "title": "김형훈의 학습 블로그",
    "section": "network plugin",
    "text": "network plugin\n\nbridge type network\n - all container runtime solutions use same bridge script - and you can use third party plugins like flannel, calico, weave, etc.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "core DNS"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/4_security.html",
    "href": "posts/04_archives/k8s/notes/4_security.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "k8s does not support user authentication by default (except service accounts)\n\n\n\n\nk8s uses TLS to secure communication between components \nuser can grouped by certificate’s Common Name or Organization field\nnode’s group name is system:nodes\n\n\n\n\n\n~/.kube/config file is used to store k8s cluster information\nkubectl uses this file to connect to the cluster\nclusters, users, context",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Authentication"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/4_security.html#authentication",
    "href": "posts/04_archives/k8s/notes/4_security.html#authentication",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "k8s does not support user authentication by default (except service accounts)\n\n\n\n\nk8s uses TLS to secure communication between components \nuser can grouped by certificate’s Common Name or Organization field\nnode’s group name is system:nodes\n\n\n\n\n\n~/.kube/config file is used to store k8s cluster information\nkubectl uses this file to connect to the cluster\nclusters, users, context",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Authentication"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/4_security.html#authorization",
    "href": "posts/04_archives/k8s/notes/4_security.html#authorization",
    "title": "김형훈의 학습 블로그",
    "section": "Authorization",
    "text": "Authorization\n\nAPI groups\n\nk8s API is divided into groups\ncore group is the default group\ngroup has its own set of resources and verbs \n\n\n\nRBAC\n\ncreate Role object (namespace scoped resources)\ncreate RoleBinding object\n\nor\n\ncreate ClusterRole object (cluster scoped resources)\ncreate ClusterRoleBinding object\n\n\n\nservice account\n\ncreate ServiceAccount object\nthen it create token\nthen create secret object with the token\nthen secret object is linked to the service account\nand the token is automatically mounted to the pod\n\n=&gt; but this is not secure, and scalable =&gt; TokenRequest API is used",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Authentication"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/notes/4_security.html#image-security",
    "href": "posts/04_archives/k8s/notes/4_security.html#image-security",
    "title": "김형훈의 학습 블로그",
    "section": "image security",
    "text": "image security\nif you use private image registry, you need to create secret object 1. create docker-registry type secret 2. add imagePullSecrets field in the pod spec",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s",
      "Notes",
      "Authentication"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/index.html",
    "href": "posts/04_archives/k8s/index.html",
    "title": "k8s",
    "section": "",
    "text": "k8s 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/index.html#details",
    "href": "posts/04_archives/k8s/index.html#details",
    "title": "k8s",
    "section": "",
    "text": "k8s 관련 노트입니다.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/index.html#tasks",
    "href": "posts/04_archives/k8s/index.html#tasks",
    "title": "k8s",
    "section": "Tasks",
    "text": "Tasks\n\n\nNo tasks defined.",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/index.html#참고-자료",
    "href": "posts/04_archives/k8s/index.html#참고-자료",
    "title": "k8s",
    "section": "참고 자료",
    "text": "참고 자료\n\nCKA Udemy 강의",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s"
    ]
  },
  {
    "objectID": "posts/04_archives/k8s/index.html#related-posts",
    "href": "posts/04_archives/k8s/index.html#related-posts",
    "title": "k8s",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Archives",
      "k8s"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/03.html#데이터-전처리의-의미",
    "href": "posts/04_archives/adp_실기/notes/03.html#데이터-전처리의-의미",
    "title": "데이터 전처리",
    "section": "데이터 전처리의 의미",
    "text": "데이터 전처리의 의미\n\n데이터 클리닝\n데이터 통합\n데이터 변환\n데이터 축소\n불균형 데이터 처리\n데이터 분할",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "데이터 전처리"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/notes/03.html#이상치-확인-및-정제",
    "href": "posts/04_archives/adp_실기/notes/03.html#이상치-확인-및-정제",
    "title": "데이터 전처리",
    "section": "이상치 확인 및 정제",
    "text": "이상치 확인 및 정제\n\n이상치 확인\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_wine\n\nwine_load = load_wine()\nwine = pd.DataFrame(wine_load.data, columns=wine_load.feature_names)\nwine['class'] = wine_load.target\nwine['class'] = wine['class'].map({0: 'class_0', 1: 'class_1', 2: 'class_2'})\n\nplt.boxplot(wine['color_intensity'], whis=1.5)\nplt.title('Boxplot of color_intensity')\nplt.show()\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\ndef outliers_iqr(dt, col):\n    q1, q3 = np.percentile(dt[col], [25, 75])\n    iqr = q3 - q1\n    lower_bound = q1 - (iqr * 1.5)\n    upper_bound = q3 + (iqr * 1.5)\n    return dt[(dt[col] &lt; lower_bound) | (dt[col] &gt; upper_bound)]\n\noutliers = outliers_iqr(wine, 'color_intensity')\noutliers\n\n\n\n\n\n\n\n\nalcohol\nmalic_acid\nash\nalcalinity_of_ash\nmagnesium\ntotal_phenols\nflavanoids\nnonflavanoid_phenols\nproanthocyanins\ncolor_intensity\nhue\nod280/od315_of_diluted_wines\nproline\nclass\n\n\n\n\n151\n12.79\n2.67\n2.48\n22.0\n112.0\n1.48\n1.36\n0.24\n1.26\n10.80\n0.48\n1.47\n480.0\nclass_2\n\n\n158\n14.34\n1.68\n2.70\n25.0\n98.0\n2.80\n1.31\n0.53\n2.70\n13.00\n0.57\n1.96\n660.0\nclass_2\n\n\n159\n13.48\n1.67\n2.64\n22.5\n89.0\n2.60\n1.10\n0.52\n2.29\n11.75\n0.57\n1.78\n620.0\nclass_2\n\n\n166\n13.45\n3.70\n2.60\n23.0\n111.0\n1.70\n0.92\n0.43\n1.46\n10.68\n0.85\n1.56\n695.0\nclass_2\n\n\n\n\n\n\n\n\n\n이상치 정제\n\n이상치 제거\n\n\ndrop_outliers = wine.drop(index=outliers.index)\n\nprint(\"Original:\", wine.shape)\nprint(\"Drop outliers:\", drop_outliers.shape)\n\nOriginal: (178, 14)\nDrop outliers: (174, 14)\n\n\n\n이상치 대체\n\n이상치를 NULL로 만든 후, 결측치와 함께 대체\n\nwine.loc[outliers.index, 'color_intensity'] = np.NaN\n\nwine['color_intensity'].fillna(wine['color_intensity'].mean(), inplace=True)\nwine.loc[outliers.index, 'color_intensity']\n\n/tmp/ipykernel_18659/3568685677.py:3: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n\n\n151    4.908678\n158    4.908678\n159    4.908678\n166    4.908678\nName: color_intensity, dtype: float64",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비",
      "Notes",
      "데이터 전처리"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/index.html",
    "href": "posts/04_archives/adp_실기/index.html",
    "title": "ADP 실기 준비",
    "section": "",
    "text": "FAILED\n    \n    \n        시작일: 2024-12-21\n        종료일: 2025-02-05\n    \n    \n        \n            \n        \n        계산 중...\n    \n    \n    \n        자격증데이터 분석python",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/index.html#details",
    "href": "posts/04_archives/adp_실기/index.html#details",
    "title": "ADP 실기 준비",
    "section": "Details",
    "text": "Details",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/index.html#tasks",
    "href": "posts/04_archives/adp_실기/index.html#tasks",
    "title": "ADP 실기 준비",
    "section": "Tasks",
    "text": "Tasks\n\n\n\n    \n    \n    \n            \n                \n                \n                    파이썬 한권으로 끝내기 완독\n                \n                \n            \n            \n            \n                \n                    \n                    원서 접수 (2025.03.24 10 am)",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/index.html#why-failed",
    "href": "posts/04_archives/adp_실기/index.html#why-failed",
    "title": "ADP 실기 준비",
    "section": "Why failed?",
    "text": "Why failed?\nTOFEL이 더 급하다.\n4학년 때 도전하자.",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/adp_실기/index.html#related-posts",
    "href": "posts/04_archives/adp_실기/index.html#related-posts",
    "title": "ADP 실기 준비",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Archives",
      "ADP 실기 준비"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/12_database.html",
    "href": "posts/04_archives/aws_saa/notes/12_database.html",
    "title": "database choice in aws",
    "section": "",
    "text": "RDBMS(RDS, aurora): SQL, OLTP\nNoSQL: DynamoDB(JSON), ElasticCache(key / value), Neptune(graphs), DocumentDB(MongoDB), Keyspaces(Cassandra)\nObject storage: S3(for big), Glacier(for backup, archive)\nData warehouse: SQL analytics, Redshift(OLAP), athena, EMR\nSearch: openSearch(JSON)\nGraphs: Amazon Neptune\nLedger: QLDB\nTime series: Timestream\n\n\n\n\nMongoDB compatible\nFully managed\nhighly available with replication across 3 AZs\nAutomatically scales up to 10GB storage, millions of requests per seconds workloads\n\n\n\n\n\nGraph database\nFully managed\nHighl available with replication across 3 AZs, up to 15 read replicas\nSupports up to billions of relations\n\n\n\n\n\nCassandra compatible\nFully managed\nAutomatically scale tables based on traffic\ntables replicated across 3 times across multiple AZs\nondemand, provisioned\n\n\n\n\n\nLedger database\nFully managed\nimmutable, transparent, cryptographically verifiable transaction log\nhigh performance, low latency\nserverless, pay as you go\nno decentralized consensus, no blockchain\n\n\n\n\n\nTime series database\nFully managed\nstore and analyze trillions of events per day",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "database choice in aws"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/12_database.html#database-types",
    "href": "posts/04_archives/aws_saa/notes/12_database.html#database-types",
    "title": "database choice in aws",
    "section": "",
    "text": "RDBMS(RDS, aurora): SQL, OLTP\nNoSQL: DynamoDB(JSON), ElasticCache(key / value), Neptune(graphs), DocumentDB(MongoDB), Keyspaces(Cassandra)\nObject storage: S3(for big), Glacier(for backup, archive)\nData warehouse: SQL analytics, Redshift(OLAP), athena, EMR\nSearch: openSearch(JSON)\nGraphs: Amazon Neptune\nLedger: QLDB\nTime series: Timestream\n\n\n\n\nMongoDB compatible\nFully managed\nhighly available with replication across 3 AZs\nAutomatically scales up to 10GB storage, millions of requests per seconds workloads\n\n\n\n\n\nGraph database\nFully managed\nHighl available with replication across 3 AZs, up to 15 read replicas\nSupports up to billions of relations\n\n\n\n\n\nCassandra compatible\nFully managed\nAutomatically scale tables based on traffic\ntables replicated across 3 times across multiple AZs\nondemand, provisioned\n\n\n\n\n\nLedger database\nFully managed\nimmutable, transparent, cryptographically verifiable transaction log\nhigh performance, low latency\nserverless, pay as you go\nno decentralized consensus, no blockchain\n\n\n\n\n\nTime series database\nFully managed\nstore and analyze trillions of events per day",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "database choice in aws"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "managed service to create and control encryption keys\nAble to audit key usage with CloudTrail\nattached to region =&gt; can replicate across regions\n\n\n\n\nsymmetric key: same key for encryption and decryption\nasymmetric key: public and private key\n\n\n\n\n\nAWS owned key: managed by AWS\nAWS Managed key: managed by AWS but you have control over the key policy\nCustomer managed key: managed by you, but AWS manages the underlying infrastructure, not free\n\n\n\n\n\nkey policy is attached to the key\nDefault key policy: complete access to the key\ncustom key policy: define who can use the key and roles and who can administer the key",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#kmskey-management-service",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#kmskey-management-service",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "managed service to create and control encryption keys\nAble to audit key usage with CloudTrail\nattached to region =&gt; can replicate across regions\n\n\n\n\nsymmetric key: same key for encryption and decryption\nasymmetric key: public and private key\n\n\n\n\n\nAWS owned key: managed by AWS\nAWS Managed key: managed by AWS but you have control over the key policy\nCustomer managed key: managed by you, but AWS manages the underlying infrastructure, not free\n\n\n\n\n\nkey policy is attached to the key\nDefault key policy: complete access to the key\ncustom key policy: define who can use the key and roles and who can administer the key",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#aws-wafweb-application-firewall",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#aws-wafweb-application-firewall",
    "title": "김형훈의 학습 블로그",
    "section": "AWS WAF(Web Application Firewall)",
    "text": "AWS WAF(Web Application Firewall)\n\ndeploy on\n\nCloudFront (global)\nApplication Load Balancer (regional)\nAPI Gateway (regional)\nAppSync GraphQL API (regional)\ncognito (regional)\n\n\n\nfeatures\n\nprotect from SQL injection, cross-site scripting, and other web attacks\nIP blacklisting and whitelisting\nfilter HTTP headers / body / URI\nlimit the size of requests\ngeo-blocking\nrate limiting (DDoS protection)",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#aws-shield",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#aws-shield",
    "title": "김형훈의 학습 블로그",
    "section": "AWS Shield",
    "text": "AWS Shield\n\nDDoS protection service\nStandard and Advanced plan",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#aws-firewall-manager",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#aws-firewall-manager",
    "title": "김형훈의 학습 블로그",
    "section": "AWS Firewall Manager",
    "text": "AWS Firewall Manager\n\ncentral management service to configure and manage WAF rules across accounts and applications",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#amazon-guardduty",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#amazon-guardduty",
    "title": "김형훈의 학습 블로그",
    "section": "Amazon GuardDuty",
    "text": "Amazon GuardDuty\n\nthreat detection service\ngood for detect crypto currency mining",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#amazon-inspector",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#amazon-inspector",
    "title": "김형훈의 학습 블로그",
    "section": "Amazon Inspector",
    "text": "Amazon Inspector\n\nsecurity assessment service\ncontinuous assessment of applications for vulnerabilities and deviations from best practices",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#amazon-macie",
    "href": "posts/04_archives/aws_saa/notes/17_AWS_secure.html#amazon-macie",
    "title": "김형훈의 학습 블로그",
    "section": "Amazon Macie",
    "text": "Amazon Macie\n\ndata security and data privacy service\ndetect and protect sensitive data",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "KMS(Key Management Service)"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/08_cloudfront.html",
    "href": "posts/04_archives/aws_saa/notes/08_cloudfront.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "CDN: Content Delivery Network\nedge location: cache content\nTTL: Time To Live. Cache Invalidation\norigin: source of the file the CDN will distribute\n\nS3 bucket: also used as ingress\nEC2 instance\nELB\nany HTTP server\n\ndistribution: the name given to the CDN which consists of a collection of edge locations  ### price class\nprice class: the number of edge locations used\n\nall: all edge locations\n200: all edge locations except the most expensive\n100: only the least expensive edge locations\n\n\n\n\n\nAWS Global Accelerator: improve the availability and performance of your applications with local or global users\nAnycast IP: route user traffic to the nearest edge location\nstatic IP: anycast IP",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "CloudFront"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/08_cloudfront.html#cloudfront",
    "href": "posts/04_archives/aws_saa/notes/08_cloudfront.html#cloudfront",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "CDN: Content Delivery Network\nedge location: cache content\nTTL: Time To Live. Cache Invalidation\norigin: source of the file the CDN will distribute\n\nS3 bucket: also used as ingress\nEC2 instance\nELB\nany HTTP server\n\ndistribution: the name given to the CDN which consists of a collection of edge locations  ### price class\nprice class: the number of edge locations used\n\nall: all edge locations\n200: all edge locations except the most expensive\n100: only the least expensive edge locations\n\n\n\n\n\nAWS Global Accelerator: improve the availability and performance of your applications with local or global users\nAnycast IP: route user traffic to the nearest edge location\nstatic IP: anycast IP",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "CloudFront"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/16_IAM.html",
    "href": "posts/04_archives/aws_saa/notes/16_IAM.html",
    "title": "AWS Organization",
    "section": "",
    "text": "global service\ncontrol over multiple AWS accounts\nconsolidated billing\nshared reserved instances and savings plans across accounts ## service control policies (SCPs)\nIAM policy applied to OU or account except management account\n\n\n\n\ncloudwatch agent\n\n\n\n\n\ncloudwatch agent\n\n\n\n\n\nIAM role: cross-account access\nResource-based policy: cross-service access \n\n\n\n\n\nsupported for users and roles(not groups)\nmaximum permissions that an entity can have\nIAM policy + permission boundary = effective permissions \n\n\n\n\n\n\n\n\nAD Connector: on-premises AD, redirect to on-premises AD (proxy)\nSimple AD: standalone AD\nAWS Managed Microsoft AD: managed AD, trust relationship",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Organization"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/16_IAM.html#iam-role-vs-resource-based-policy",
    "href": "posts/04_archives/aws_saa/notes/16_IAM.html#iam-role-vs-resource-based-policy",
    "title": "AWS Organization",
    "section": "",
    "text": "IAM role: cross-account access\nResource-based policy: cross-service access",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Organization"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/16_IAM.html#iam-permission-boundaries",
    "href": "posts/04_archives/aws_saa/notes/16_IAM.html#iam-permission-boundaries",
    "title": "AWS Organization",
    "section": "",
    "text": "supported for users and roles(not groups)\nmaximum permissions that an entity can have\nIAM policy + permission boundary = effective permissions",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Organization"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/16_IAM.html#aws-directory-service",
    "href": "posts/04_archives/aws_saa/notes/16_IAM.html#aws-directory-service",
    "title": "AWS Organization",
    "section": "",
    "text": "AD Connector: on-premises AD, redirect to on-premises AD (proxy)\nSimple AD: standalone AD\nAWS Managed Microsoft AD: managed AD, trust relationship",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "AWS Organization"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html",
    "title": "VPC",
    "section": "",
    "text": ": AWS managed NAT instance, use specific AZ, elastic IP only for another subnet\n\n\n\n: stateless, allow/deny traffic in/out of subnet default, it allows all traffic \n\n\n\n\n\n\nVPC\n\n\n\n\n\n: private connection between VPC and AWS services - Gateway endpoint: S3, DynamoDB. taget of route table - Interface endpoint: API Gateway, CloudWatch, KMS, SSM, S3, DynamoDB, etc.\n\n\n\n: VPC flow logs, capture information about IP traffic going to and from network interfaces in your VPC\n\n\n\n: connect on-premises network to AWS VPC \n\n\n\n: dedicated network connection between on-premises and AWS\n\n\n\n: IPv6 only, allow outbound traffic to the internet",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#nat-gateway",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#nat-gateway",
    "title": "VPC",
    "section": "",
    "text": ": AWS managed NAT instance, use specific AZ, elastic IP only for another subnet",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#nacls",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#nacls",
    "title": "VPC",
    "section": "",
    "text": ": stateless, allow/deny traffic in/out of subnet default, it allows all traffic",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#vpc-peering",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#vpc-peering",
    "title": "VPC",
    "section": "",
    "text": "VPC",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#vpc-endpoint",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#vpc-endpoint",
    "title": "VPC",
    "section": "",
    "text": ": private connection between VPC and AWS services - Gateway endpoint: S3, DynamoDB. taget of route table - Interface endpoint: API Gateway, CloudWatch, KMS, SSM, S3, DynamoDB, etc.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#vpc-flow-logs",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#vpc-flow-logs",
    "title": "VPC",
    "section": "",
    "text": ": VPC flow logs, capture information about IP traffic going to and from network interfaces in your VPC",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#site-to-site-vpn",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#site-to-site-vpn",
    "title": "VPC",
    "section": "",
    "text": ": connect on-premises network to AWS VPC",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#direct-connectdx",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#direct-connectdx",
    "title": "VPC",
    "section": "",
    "text": ": dedicated network connection between on-premises and AWS",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/18_VPC.html#egress-only-internet-gateway",
    "href": "posts/04_archives/aws_saa/notes/18_VPC.html#egress-only-internet-gateway",
    "title": "VPC",
    "section": "",
    "text": ": IPv6 only, allow outbound traffic to the internet",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "VPC"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/04_elb_asg.html",
    "href": "posts/04_archives/aws_saa/notes/04_elb_asg.html",
    "title": "ELB",
    "section": "",
    "text": "HTTP, HTTPS, WebSockets\n\nLayer 7\nfixed hostname in every AZ\nclient IP address preservation in the X-Forwarded-For header\ncan use sticky sessions through cookies #### target group\nEC2 instances\nECS tasks\nLambda functions\nIP addresses (private) #### routing routing to diffrent target or same machine different application based on:\nrouting based on URL\nrouting based on hostname\nrouting based on path\nrouting based on query string\nrouting based on HTTP header\nrouting based on port\n\n\n\n\n\nTCP, TLS, UDP\n\nLayer 4\nfixed IP address per AZ and support assigning Elastic IP address\nhigh throughput and low latency #### target group\nEC2 instances\nIP addresses (private)\nLambda functions\nALB\n\n\n\n\n\nip\nLayer 3\nDeploy, scale, and manage third-party virtual appliances\nexample: firewall, intrusion detection and prevention, deep packet inspection, and security analytics\nTransparent Network Gateway: single endpoint for all traffic\nLoad Balancer Gateway: distribute traffic across multiple virtual appliances\nUse GENEVE tunneling protocol on port 6081 #### target group\nEC2 instances\nIP addresses (private)\n\n\n\n\n\n\ndistribute traffic evenly across all registered instances in all enabled AZs\nenabled by default for ALB and no charge for inter AZ data transfer (can be disabled in target group)\ndisabled by default for NLB, GWLB and charge for inter AZ data transfer\n\n\n\n\n\n\n\nServer Name Indication\nALB and NLB and cloudFront support SNI\n\n\n\n\n\n\nALB and NLB support connection draining (deregestration delay)\n\n\n\n\n\n\n\nTarget tracking scaling policy\nSimple / Step scaling policy\nScheduled scaling policy\nPredictive scaling policy",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "ELB"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/04_elb_asg.html#types-of-elb",
    "href": "posts/04_archives/aws_saa/notes/04_elb_asg.html#types-of-elb",
    "title": "ELB",
    "section": "",
    "text": "HTTP, HTTPS, WebSockets\n\nLayer 7\nfixed hostname in every AZ\nclient IP address preservation in the X-Forwarded-For header\ncan use sticky sessions through cookies #### target group\nEC2 instances\nECS tasks\nLambda functions\nIP addresses (private) #### routing routing to diffrent target or same machine different application based on:\nrouting based on URL\nrouting based on hostname\nrouting based on path\nrouting based on query string\nrouting based on HTTP header\nrouting based on port\n\n\n\n\n\nTCP, TLS, UDP\n\nLayer 4\nfixed IP address per AZ and support assigning Elastic IP address\nhigh throughput and low latency #### target group\nEC2 instances\nIP addresses (private)\nLambda functions\nALB\n\n\n\n\n\nip\nLayer 3\nDeploy, scale, and manage third-party virtual appliances\nexample: firewall, intrusion detection and prevention, deep packet inspection, and security analytics\nTransparent Network Gateway: single endpoint for all traffic\nLoad Balancer Gateway: distribute traffic across multiple virtual appliances\nUse GENEVE tunneling protocol on port 6081 #### target group\nEC2 instances\nIP addresses (private)",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "ELB"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/04_elb_asg.html#cross-zone-load-balancing",
    "href": "posts/04_archives/aws_saa/notes/04_elb_asg.html#cross-zone-load-balancing",
    "title": "ELB",
    "section": "",
    "text": "distribute traffic evenly across all registered instances in all enabled AZs\nenabled by default for ALB and no charge for inter AZ data transfer (can be disabled in target group)\ndisabled by default for NLB, GWLB and charge for inter AZ data transfer",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "ELB"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/04_elb_asg.html#ssltls",
    "href": "posts/04_archives/aws_saa/notes/04_elb_asg.html#ssltls",
    "title": "ELB",
    "section": "",
    "text": "Server Name Indication\nALB and NLB and cloudFront support SNI",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "ELB"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/04_elb_asg.html#connection-draining",
    "href": "posts/04_archives/aws_saa/notes/04_elb_asg.html#connection-draining",
    "title": "ELB",
    "section": "",
    "text": "ALB and NLB support connection draining (deregestration delay)",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "ELB"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/04_elb_asg.html#asg",
    "href": "posts/04_archives/aws_saa/notes/04_elb_asg.html#asg",
    "title": "ELB",
    "section": "",
    "text": "Target tracking scaling policy\nSimple / Step scaling policy\nScheduled scaling policy\nPredictive scaling policy",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "ELB"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html",
    "href": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html",
    "title": "Amazon RDS",
    "section": "",
    "text": "Amazon RDS is a managed relational database service that provides a highly available, scalable, and secure database.\nAmazon RDS supports multiple database engines:\n\nAmazon Aurora\nMySQL\nMariaDB\nPostgreSQL\nOracle\nMicrosoft SQL Server\n\nAmazon RDS provides the following features:\n\nAutomated backups\nMulti-AZ deployments\nRead replicas\nMonitoring\nSecurity\nScalability\nHigh availability ### auto scaling\n\nmust set maximum storage threshold\n\n\nfree storage is less then 10% of allocated storage\nlow-storage lasts at least 5 minutes\n6 hours have passed since last modification\n\n\n\n\nup to 15 read replicas\nwithin AZ, cross AZ, cross region (dont pay for data transfer across AZ, not across region)\nread replicas can be promoted to a standalone database\n\n\n\n\nused for disaster recovery(not used for scaling)\nsynchronous replication\nfailover to standby in case of primary failure\nno manual intervention ### from single AZ to multi AZ\nzero downtime\njust modify for the database instance\n\n\n\n\n\n\nMySQL and PostgreSQL compatible\ncloud optimized (5 times faster than MySQL, 3 times faster than PostgreSQL)\nstorage auto scaling\n15 read replicas (cross region)\nfailover instantaneously (less than 30 seconds through master node)\ncost more but effective ### High Availability and Read Scalability\n6 copies of data across 3 AZs (4 copies is needed for write, 3 copies is needed for read)\nself-healing storage\nstorage is striped across 100s of volumes\n\n\n\n\n1 primary region\n5 read-only secondary regions\nreplication lag is less than 1 second\nup to 16 read replicas per secondary region\nfailover to secondary region\ncross-region replication takes less than 1 second\n\n\n\n\n\n\n\n\nAutomated backup (can disable, 5 minutes backup window)\nManual snapshot (retention as log as you want)\nsnapshot restore =&gt; new database\ns3 restore\n\n\n\n\n\nAutomated backup (cannot disable, point-in-time recovery)\nManual snapshot (retention as log as you want)\nsnapshot restore =&gt; new database\nPercona XtraBackup, s3 restore\n\n\n\n\n\n\n\n\n\nin-memory caching service\nRedis or Memcached (no high availability and backup)\nheavy application code change",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon RDS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#rds-read-replicas-for-read-scalibity",
    "href": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#rds-read-replicas-for-read-scalibity",
    "title": "Amazon RDS",
    "section": "",
    "text": "up to 15 read replicas\nwithin AZ, cross AZ, cross region (dont pay for data transfer across AZ, not across region)\nread replicas can be promoted to a standalone database\n\n\n\n\nused for disaster recovery(not used for scaling)\nsynchronous replication\nfailover to standby in case of primary failure\nno manual intervention ### from single AZ to multi AZ\nzero downtime\njust modify for the database instance",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon RDS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#amazon-aurora",
    "href": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#amazon-aurora",
    "title": "Amazon RDS",
    "section": "",
    "text": "MySQL and PostgreSQL compatible\ncloud optimized (5 times faster than MySQL, 3 times faster than PostgreSQL)\nstorage auto scaling\n15 read replicas (cross region)\nfailover instantaneously (less than 30 seconds through master node)\ncost more but effective ### High Availability and Read Scalability\n6 copies of data across 3 AZs (4 copies is needed for write, 3 copies is needed for read)\nself-healing storage\nstorage is striped across 100s of volumes\n\n\n\n\n1 primary region\n5 read-only secondary regions\nreplication lag is less than 1 second\nup to 16 read replicas per secondary region\nfailover to secondary region\ncross-region replication takes less than 1 second",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon RDS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#backup",
    "href": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#backup",
    "title": "Amazon RDS",
    "section": "",
    "text": "Automated backup (can disable, 5 minutes backup window)\nManual snapshot (retention as log as you want)\nsnapshot restore =&gt; new database\ns3 restore\n\n\n\n\n\nAutomated backup (cannot disable, point-in-time recovery)\nManual snapshot (retention as log as you want)\nsnapshot restore =&gt; new database\nPercona XtraBackup, s3 restore",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon RDS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#elasticcache",
    "href": "posts/04_archives/aws_saa/notes/05_RDS_aurora_elasticCache.html#elasticcache",
    "title": "Amazon RDS",
    "section": "",
    "text": "in-memory caching service\nRedis or Memcached (no high availability and backup)\nheavy application code change",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon RDS"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/01_IAM.html",
    "href": "posts/04_archives/aws_saa/notes/01_IAM.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": ": identity access management (Global service)\n\n\n\ngroup by users (not group itself)\n\n\n\nroot account created by default each users can have multi groups",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Define IAM"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/01_IAM.html#define-iam",
    "href": "posts/04_archives/aws_saa/notes/01_IAM.html#define-iam",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": ": identity access management (Global service)\n\n\n\ngroup by users (not group itself)\n\n\n\nroot account created by default each users can have multi groups",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Define IAM"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/01_IAM.html#iampolicies",
    "href": "posts/04_archives/aws_saa/notes/01_IAM.html#iampolicies",
    "title": "김형훈의 학습 블로그",
    "section": "IAM:Policies",
    "text": "IAM:Policies\n\nUsers or Groups can be assigned JSON documents called policies\npolicies define permissions of the users(inline) or groups\nAWS apply the least privilege principle\n\n\nJSON exe\n{\n    {\n        \"Version\": \"2012-10-17\",\n        // optional: \"id\": \"...\",\n        \"Statement\": [\n            {\n                // optional: \"Sid\": \"...\",\n                \"Effect\": \"Allow\",\n                \"Action\": \"s3:ListBucket\",\n                \"Resource\": \"arn:aws:s3:::example-bucket\"\n            },\n            {\n                \"Effect\": \"Allow\",\n                \"Action\": [\n                    \"s3:GetObject\",\n                    \"s3:PutObject\"\n                ],\n                \"Resource\": \"arn:aws:s3:::example-bucket/*\"\n            }\n        ]\n    }\n}\n\nEffect: Allow/Deny\nPrinciple: who can perform the action (account, user, role)\nAction: list of actions that are allowed or denied\nResource: list of resources that are allowed or denied\nCondition: when the policy is in effect (optional)",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Define IAM"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/01_IAM.html#iamroles-for-services",
    "href": "posts/04_archives/aws_saa/notes/01_IAM.html#iamroles-for-services",
    "title": "김형훈의 학습 블로그",
    "section": "IAM:Roles for Services",
    "text": "IAM:Roles for Services\n\nRoles are used to delegate permissions to entities that you trust\n\n\ntrusted entities\n\nAWS account\n\nAWS services\n\nEC2, Lambda, CodeBuild, CodePipeline, etc.",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Define IAM"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/01_IAM.html#iamsecurity-tools",
    "href": "posts/04_archives/aws_saa/notes/01_IAM.html#iamsecurity-tools",
    "title": "김형훈의 학습 블로그",
    "section": "IAM:Security Tools",
    "text": "IAM:Security Tools\n\nIAM Credentials Report (account level):\nlist of all users and their various credentials\nIAM Access Advisor (user level):\nhow long each service has been active and when it was last used",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Define IAM"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/00_region.html",
    "href": "posts/04_archives/aws_saa/notes/00_region.html",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "regions:\ncluster of data center\navailability zone (AZ)\n\n\nusually 3, min 3, max 6\none or more discrete data center\nseparate from each others, so that isolated from disasters\n\n\nData center\n\n\nrack\nhost\ninstance\n\n\n\naws edge locations / points of presence\n\n400+ points of presence(400+ edge locations, 10+ regional cathes) in 90+ cities across 40+ contries\n\n\n\n\n\n\n\nglobal\n\n\nIAM\nDNS services\nCDN\nWAF\n\n\nregion\n\n\nec2\nlambda\nrekognition\n\n\n\n\n\ncompliance with data governance and legal requirements\nproximity to customers\navailable services within a region\npricing",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "aws global infrastructure"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/00_region.html#aws-global-infrastructure",
    "href": "posts/04_archives/aws_saa/notes/00_region.html#aws-global-infrastructure",
    "title": "김형훈의 학습 블로그",
    "section": "",
    "text": "regions:\ncluster of data center\navailability zone (AZ)\n\n\nusually 3, min 3, max 6\none or more discrete data center\nseparate from each others, so that isolated from disasters\n\n\nData center\n\n\nrack\nhost\ninstance\n\n\n\naws edge locations / points of presence\n\n400+ points of presence(400+ edge locations, 10+ regional cathes) in 90+ cities across 40+ contries\n\n\n\n\n\n\n\nglobal\n\n\nIAM\nDNS services\nCDN\nWAF\n\n\nregion\n\n\nec2\nlambda\nrekognition\n\n\n\n\n\ncompliance with data governance and legal requirements\nproximity to customers\navailable services within a region\npricing",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "aws global infrastructure"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html",
    "title": "Amazon CloudWatch",
    "section": "",
    "text": "every service sends metrics to CloudWatch\nnamespace is a container for metrics\nmetric is a variable to monitor\ndimension is a name/value pair that is attributed to a metric\nup to 30 dimensions per metric\ntimestamp is the time of the data point\nstream data to destination near real-time\n\n\n\n\n\nlog data is stored indefinitely\nlog group is a container for logs\nlog stream is a sequence of log events\nlog event is a record of some activity\nSDK, Elastic Beanstalk, ECS, Lambda, CloudTrail, VPC Flow Logs, Route 53, API Gateway, CloudWatch Unified Agent can send logs to CloudWatch Logs\nlog subscription: send logs to Lambda, Kinesis, ElasticSearch, S3\n\n\n\n\n\ncollect more system-level metrics \n\n\n\n\n\nalarm is a notification that is sent when a metric is in breach of the threshold\nstate: OK, ALARM, INSUFFICIENT_DATA\ntarget: stop, terminate, reboot, recover, start, or snapshot an instance / trigger an Auto Scaling action / send a notification to an SNS topic\nsingle metric alarm, composite alarm, anomaly detection alarm\n\n\n\n\n\ncron jobs\nevent is a change in state\nrule is a description of an event pattern\ntarget is a resource that is invoked when a rule is triggered\nevent bus is a container for events\nevent pattern is a JSON object that describes a set of events to match",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html#matrics",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html#matrics",
    "title": "Amazon CloudWatch",
    "section": "",
    "text": "every service sends metrics to CloudWatch\nnamespace is a container for metrics\nmetric is a variable to monitor\ndimension is a name/value pair that is attributed to a metric\nup to 30 dimensions per metric\ntimestamp is the time of the data point\nstream data to destination near real-time",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html#logs",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html#logs",
    "title": "Amazon CloudWatch",
    "section": "",
    "text": "log data is stored indefinitely\nlog group is a container for logs\nlog stream is a sequence of log events\nlog event is a record of some activity\nSDK, Elastic Beanstalk, ECS, Lambda, CloudTrail, VPC Flow Logs, Route 53, API Gateway, CloudWatch Unified Agent can send logs to CloudWatch Logs\nlog subscription: send logs to Lambda, Kinesis, ElasticSearch, S3",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html#cloudwatch-agent",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html#cloudwatch-agent",
    "title": "Amazon CloudWatch",
    "section": "",
    "text": "collect more system-level metrics",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html#cloudwatch-alarms",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html#cloudwatch-alarms",
    "title": "Amazon CloudWatch",
    "section": "",
    "text": "alarm is a notification that is sent when a metric is in breach of the threshold\nstate: OK, ALARM, INSUFFICIENT_DATA\ntarget: stop, terminate, reboot, recover, start, or snapshot an instance / trigger an Auto Scaling action / send a notification to an SNS topic\nsingle metric alarm, composite alarm, anomaly detection alarm",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html#cloudwatch-events-eventbridge",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html#cloudwatch-events-eventbridge",
    "title": "Amazon CloudWatch",
    "section": "",
    "text": "cron jobs\nevent is a change in state\nrule is a description of an event pattern\ntarget is a resource that is invoked when a rule is triggered\nevent bus is a container for events\nevent pattern is a JSON object that describes a set of events to match",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/aws_saa/notes/15_monitoring.html#insights-events",
    "href": "posts/04_archives/aws_saa/notes/15_monitoring.html#insights-events",
    "title": "Amazon CloudWatch",
    "section": "Insights Events",
    "text": "Insights Events\n\ninsights events provide insights into the performance and availability of your AWS Account",
    "crumbs": [
      "PARA",
      "Archives",
      "AWS SAA 준비",
      "Notes",
      "Amazon CloudWatch"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/0_intro.html#what-is-human-factors",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/0_intro.html#what-is-human-factors",
    "title": "Introduction to Human Factors",
    "section": "what is human factors",
    "text": "what is human factors\n\nhuman factors = Ergonomics\na human-centered design philosophy &lt;-&gt; technology-centered design",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Introduction to Human Factors"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/0_intro.html#component-of-human-factors",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/0_intro.html#component-of-human-factors",
    "title": "Introduction to Human Factors",
    "section": "component of human factors",
    "text": "component of human factors\n\nhuman: physical, cognitive, group\ntask: physical + cognitive + group\nenvirnment: working environment, systems",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Introduction to Human Factors"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/0_intro.html#goal-of-human-factors",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/0_intro.html#goal-of-human-factors",
    "title": "Introduction to Human Factors",
    "section": "Goal of human factors",
    "text": "Goal of human factors\n\nReduce errors\nIncrease productivity\nEnhance safety\nEnhance comfort",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Introduction to Human Factors"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/1_reaserch_method.html#reaserch-meathods",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/1_reaserch_method.html#reaserch-meathods",
    "title": "Research Method in Human Factors",
    "section": "reaserch meathods",
    "text": "reaserch meathods\n\ndescriptive Research\n관찰을 통해 데이터 묘사\n\n무엇을 측정할지\n어떻게 숫자로 표현할지\n\n\n대부분 평균, 표준편차를 대푯값으로 사용\n변수들 간의 관계를 파악하기 위해 상관분석, 회귀분석을 사용\n\n\ntypes of descriptive research\n\nobservational research\n\n\n관찰 연구를 계획할 때, 측정할 변수, 각 변수를 기록할 방법, 관찰이 이루어지는 조건, 관찰 기간 등을 식별\n\n\nsurvey research\n\n\n설문조사를 통해 데이터 수집\n\n\nincident and accident analysis\n\n\n사고나 오류를 분석하여 원인을 찾음\n사고나 오류를 줄이기 위한 대책을 마련\n\n\n\n\nexperimanetal Research\n하나 이상의 독립변수에 의도적인 변화를 주고, 그 변화가 하나 이상의 종속변수에 미치는 인과관계를 측정\n이때 다른 변수들은 통제한다\n\n예시\n\n휴대전화를 사용하는 것이 운전에 미치는 영향\n인센티브를 미리 주고 잘못 할 때마다 차감하는 것과, 잘할 때마다 인센티브를 주는 것의 차이\n\n\n\ntype of variables\n\nindependent(predictor, stratification) variable\ndependent(descriptive, criterion) variable\ncontrol variable: 이 값은 고정시키고 실험을 진행한다. 일반화하기 어렵게 한다.\nrandom variable (sigma): 통제할 수 없는 변수. 일반화하기 용이하다.\nconfounding variable: 수식에는 포함되지 않지만 주의해야하는 변수.\n\n\ndecide variables\noperational definition: 변수를 관찰 가능하고 측정 가능한 형태로 정의\n\nindependent variable\n\nRange: realistic / select a range taht will show the effect / pilot experiment\n\ndependent variable\n\nreliability: consistent. solution: increase the number of observations\nvalidity: measure what was intended\n\n\n\n\n\n\nwhy use experimental research?\n\nhumans are variable\n\n\nintra individual variability\ninter individual variability\n\n\nways to handle variability\n\n\nuse statistical techniques\ncontrol variability as much as possible\n\n\n\ntypes of experimental design\n\nsingle variable experiment\n\n\ntwo levels\nmulti levels\n\n\nfactorial design: 두개 이상의 독립변수를 조합하여 실험군을 만든다.\n\n\n변수 간 interaction effect을 확인할 수 있다.\nmore difficult to analyze\n2 x 2, 3 x 3, 2 x 2 x 2 등으로 설계한다.\nbetween-subject, within-subject를 모두 사용하는 mixed designs를 사용할 수 있음.\n\n\nbetween-subjects design: 각각의 실험군에 다른 사람들을 넣는다.\n\n\ngeneralibility 높다, intra person variability를 제거할 수 있다.\n\n\nwithin-subjects design: 같은 사람들을 다른 실험군에 넣는다.\n\n\ncost-effective, less variability, inter person variability를 제거할 수 있다.\n\n\n\n\nevaluation research\n시스템이나 제품이 목적을 충족하는지 평가\n\nusability testing: 사용자가 제품을 실제로 사용하면서 발생하는 문제점 파악\n\n태스크 완료 시간, 오류율, 사용자 만족도 등을 측정\n\ncost-benefit analysis: 제품 또는 시스템 도입의 경제성 평가\n\n직접 비용(하드웨어, 소프트웨어 구입비, training cost 등)\n예상되는 이익(생산성 향상, 오류 감소 등)을 비교 분석",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Research Method in Human Factors"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/1_reaserch_method.html#research-design",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/1_reaserch_method.html#research-design",
    "title": "Research Method in Human Factors",
    "section": "research design",
    "text": "research design\n\nqualitative research\n\n보통 마케팅에서 진행.\n\n\n\nquantitative research\n\nexperiments\ncorrelational observation\nsurveys and questionnaires\n\nsample: 랜덤하게 샘플링하는게 중요\nrating\nbias: 질문의 순서, 질문의 내용, 질문의 방향\n\narchival research\n\n\nfield study\n\nuncontrolled\nresults may be more generalizable to real-world situations\nhigher cost\ndifficult to replicate\ndifficult to control extraneous variables\n\n\n\nlab experiment\n\ncontrolled\nprecise replication\nlower cost\nmore flexibility\nreal-world generalizability may be limited",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Research Method in Human Factors"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#attention의-정의",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#attention의-정의",
    "title": "Attention",
    "section": "Attention의 정의",
    "text": "Attention의 정의\n\nAttention acts as a means of focusing limited mental resources on the information and cognitive processes that are most salient at a given moment\nFocusing most salient at a given moment:\n\n주의는 Search light로 비유됨\n한 영역에 집중하면 다른 부분은 배제.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Attention"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#attention의-네-가지-주요-측면",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#attention의-네-가지-주요-측면",
    "title": "Attention",
    "section": "Attention의 네 가지 주요 측면",
    "text": "Attention의 네 가지 주요 측면\n\nSelective, Focused, Divided, Sustained Attention은 독립적이지 않으며, 상호작용하여 주의 과정 형성.\n\n\nFocused Attention (집중적 주의)\n\n특정 과업에 집중하고, 외부 방해 요인을 배제하는 능력.\n방해 요소(Distraction)를 최소화하여 현재 작업에 주의 집중.\n예시:\n\n냉장고에서 음식을 꺼내려는 도중 질문을 받으면 집중력이 분산되어 원래 작업을 잊어버릴 수 있음.\n\n\n\n\nDivided Attention (분할 주의)\n\n여러 작업을 동시에 수행하며 주의를 분배.\nSelective Attention과의 차이:\n\nSelective Attention: 특정 자극을 선택적으로 받아들임.\nDivided Attention: 여러 작업 간 우선순위를 메기고 주의 자원 분배.\n\n예시:\n\n운전 중 대화하며 라디오 듣기.\n각 작업에 필요한 시간과 노력을 어떻게 배분할지를 결정.\n\n\n\n\nSustained Attention (지속적 주의)\n\n주의가 높거나 낮거나보다는, 장시간 동안 주의를 유지하는 능력.\n높은 주의 레벨 필요 시:\n\n정보를 놓치는 경우가 발생할 가능성이 높음.\n여러 정보와 자극을 동시에 처리.\n예: 주식 거래에서 여러 종목을 모니터링.\n\n낮은 주의 레벨 시:\n\n자극 부족으로 주의 산만 발생.\n예: CCTV 감시 업무.\n\n\n\n\nSelective Attention (선택적 주의)\n\n여러 감각 자극 중 중요한 정보를 선택적으로 처리.\n시각, 청각, 촉각 등 다양한 감각 경로를 통해 들어오는 자극에서 의미 있는 정보 선별.\n예시:\n\n운전 중:\n\n표지판, 신호등, 앞차의 움직임 → 중요한 정보.\n옆 보행자의 얼굴이나 주변 불필요한 자극 → 중요하지 않은 정보.\n\n\n\n\n\nMental Workload (정신적 작업 부하)\n\n동시에 수행할 수 있는 과업이 몇 개인지 혹은 이 과업이 수행하기에 attention scale을 넘어가는 것인지 분석 용도\n측정 방법:\n\n주관적 설문:\n\n작업자가 느끼는 주관적 부담을 평가.\n\n생체 반응 분석:\n\n심박수, 뇌파 등 생리적 데이터를 활용.\n\n부과 과업(parallel tasking):\n\n추가 과업을 부여하여 작업 부하 평가.\n예시:\n\n운전 중 숫자 거꾸로 세기.\n특정 숫자를 기억하고 응답(예: N-back 테스트).\n\n\n\n워크로드 증가의 결과 특정 작업의 실패 확률 증가한다.\n\n\n\nAttention의 결정 요인\n\n의지\n\n개인의 목표와 필요에 따라 주의 집중.\n예: 차선 변경 시 후방 차량 확인.\n\ncaptured by salience and grouping\n\n공간, 강도, 색상, 크기, 음조 등 외부 요인.\n강렬한 자극이 주의를 끌 가능성 높음.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Attention"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#selective-attention",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#selective-attention",
    "title": "Attention",
    "section": "Selective Attention",
    "text": "Selective Attention\n\n특정한 자극(예: 시각적 또는 청각적 정보)에 주의를 집중하며, 다른 자극을 배제하는 과정.\n중요도에 따라 특정 정보를 선택적으로 처리하며 불필요한 정보는 억제.\nattention이 sensory memory로 부터 들어온 정보의 filter나 gateway나 bottle neck으로 작용한다고 봄\n\n\n작동 원리\n\nTop-down Processing (Mental model):\n\n개인의 경험과 목표에 기반하여 주의 집중 전략을 개발.\n예: 초보 운전때 앞만 보고 가다가 숙련이 되면 사이드미러 같은 주변도 보게 됨.\n\nBottom-up Processing (자극 기반 처리):\n\n강렬하거나 눈에 띄는 자극에 주의가 끌림.\n예: 갑작스러운 소리나 반짝이는 신호등.\n결정 요인\n\nSalience Source: 자극의 강도(밝기, 소리 크기 등).\n\nInformation Access Trade-offs: 특정 정보를 처리함으로써 얻는 이득.\n\n\n\n\nBottleneck Model\nEarly Selection Theory\n- sensory memory까지는 잘 오지만, Attention filter에 선택이 된게 처리가 되고 나머지는 처리가 안 된다.\n- 감각 단계에서 물리적 특성(의미가 아닌)을 기준으로 정보 필터링.\n- 폐기된 정보는 행동에 미치는 영향 없음.\n- 한계: 칵테일 파티 현상(의미 정보 처리 설명 불가).\n\nLate Selection Theory\n- 모든 정보가 cognition / working memory까지 전달 후 선택.\n- 식별되지 않은 정보는 작업 기억의 제한된 용량으로 인해 빠르게 잊혀짐.\n- 선택되지 않은 정보도 행동에 영향을 미침.\n- 광고 실험 - 인지하지 못하는 정보(빠르게 잊어버려서)에 의해서도 행동의 변화가 있을 것이다.\n\n\nTask\nGeneral orientation and scene scanning\n- 그림을 보거나 웹 브라우징\n감독 제어 (Supervisory Control)\n- 자동화된 시스템에서 이상 징후를 탐지.\n- 주로 AOI(Area of Interests)를 스캐닝 함.\nAOI는 여러개가 있음. 시간, 중요도, 과업의 컨텍스트에 따라서 다르게 설정됨\nspecific task-related information이 있는 물리적 위치\nAOI를 몇개를 만들고, 이들에 대한 시선의 이동을 어떻게 만들것인가가 중요한 issue - 예시:\n자율주행 차량 또는 산업 기계 감독.\n제어 패널에서 비정상적인 지표 확인 (예: 전력 공급 문제, 자원 부족).\n탐지 (Noticing)\n- 예상치 못한 사건이나 환경 변화 감지.\n- 예시:\n- CCTV로 비정상적인 활동 탐지.\n- 주요 시스템 성능의 갑작스러운 변화 인식.\n탐색 (Searching)\n- 방해 요소 속에서 특정 목표를 찾는 활동.\n- 예시:\n- 공항에서 수하물의 X-ray 검색.\n읽기 (Reading)\n- 책이나 디스플레이에서 정보를 읽고 이해.\n- 예시:\n- 계기판의 게이지 읽기.\n확인 (Confirming)\n- 작업이나 과정의 결과를 확인.\n- 예시:\n- 비행기 바퀴가 잘 내려왔는지 확인\n선택적 주의 과업 실패는 중요 정보를 놓치거나 잘못 해석하는 경우 발생할 수 있다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Attention"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#seev-model",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#seev-model",
    "title": "Attention",
    "section": "SEEV Model",
    "text": "SEEV Model\nvisual attention에 영향을 주는 요소들을 설명\n\nBottom-up factors\n\nSalience: cue의 특징\nEffort: AOI로 이동하는데 드는 비용\n선형적으로 증가하는건 아니고, 그룹핑 할 수 있음.\n(Within foveal vision) 중심시에서 초점 변화. 멀리있는거에서 가까이 있는거 보는거 &lt; Eye movement &lt; Head movement &lt; Body\n중요한 정보는 cost가 작은 쪽에 배치를 해야함.\n\n\n\nTop-down factors\n\nExpectancy: 일어날 것 같은거에 주의를 더 많이 집중. mental model에 의해 예측 능력이 생길 수 있음.\nValue: 이것에 집중했을 때 얻는 이득, 보지 않았을 때 지불하는 비용\n\n\n\nGuidline\n\n중요한 AOI는 salience가 높아야함\n사용 빈도가 높은 AOI 사이의 거리는 가까워야함\n순차적인 디스플레이도 서로 가깝게 배치해야함.\n\n\n\nChange Blindness\n\n발생 원인\n\n멘탈 워크로드가 높은 경우\n눈에 띄는 변화(Slient change)는 발견하기 쉬움\n중심시에서 멀리 떨어진 곳에서 변화가 발생하면 탐지하기 어렵다.\n시야 밖에서 일어나는 변화는 인지하기 어려움(화면이 깜빡이면서 변하면 animation 효과가 안나타남)\n예상치 못한 변화는 탐지하기 어려움.(top-down processing)\n특정 위치를 응시(fixation)하고 있어도 집중(attention)이 부족하면 변화를 인지하지 못함.\n\n\n\n\nSearch Task의 유형\n\nSerial Search\n\n하나씩 순차적으로 탐색, 탐색 시간이 항목 수에 비례.\n\n예: 긴 텍스트 리스트에서 특정 단어 찾기. 같은 그림 2개 찾기\n\nParallel Search\n\n눈에 띄는 단서(pop-out effect)를 이용해 한 번에 탐색.\n\n5 search items is the same for 50 search items\n\npreattentive process로 유발됨\n\nParallel Search를 유도하는 방법\n\n색상, 크기, 대비(contrast), 회전\n\nmotion\n\nfeature를 adding하는건 찾기 쉬운데 missing하는건 찾기 어려움\n\nO안에서 Q 찾기 vs Q안에서 O 찾기\n\n깜빡이는 곳에서 안깜빡이는거 찾기 vs 안깜빡이는거에서 깜빡이는거 찾기",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Attention"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#divided-attention",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/6_attention.html#divided-attention",
    "title": "Attention",
    "section": "Divided Attention",
    "text": "Divided Attention\n\n개념\n\n일반적으로 단순 작업보다는 멀티 태스킹이 많이 일어남.\n\n단순 작업: 라면 끓일 때 진짜 라면만 순서대로 끓임. (멀티테스킹 x)\n\n복잡 작업: 라면을 끓이면서 설거지도 하고, 반찬도 만들고, 카톡도 하고, … (멀티테스킹 o)\n\n여러 작업을 동시에 수행하면서 주의를 분배.\nAttention을 한계가 있는 자원으로 바라봄\n\n\n\nResource Model\n\nCentral Resource Theory:\n주의 자원을 단일 통으로 간주. 예: 교차로 진입 시 운전에만 집중, 라디오 듣기같은 다른 작업은 집중을 못함.\nMultiple Resource Theory:\n주의 자원이 감각기관의 특성, 과업의 특성에 따라 별개로 존재\n예: 시각(도로), 청각(라디오) 자원을 분리 사용.\n작업 간 유사성이 높을수록 분배 어려움.\n예: 운전 중 영화 감상(둘 다 시각 자원 사용).\n\n\n\n주의 자원과 훈련의 문제\n주의 자원은 고정인가, 훈련으로 확장 가능한가?\n\n리소스 차이는 명확히 증명되지 않았음.\n전략을 통한 과업 배분 및 우선순위 설정 → 성능 향상.\n반복적 학습과 자동화 → 개별 과업 및 주의 배분이 자연스럽게 효율화.\n\n\n\nAttention as capacity\n\n어떤 정보를 얼마나 주의 깊게 받아들일지 결정\n어떤 정보를 선택할 것인지는 disposition(형태), intentions, arousal, evaluation에 의존\n받아들이는 정보의 특성(visual, auditory), 반응(manual, vocal)에 따라 리소스 풀을 나눌 수 있다.\ntasks interfere to the degree that they tap into the same pool of resources\n\n\n\nUnitary Resource Model (단일 자원 모델)\n\n\n주의(attention)를 제한된 자원으로 봄\n과업 수행에 필요한 자원의 양이 가용 자원을 초과하면 성능 저하\n\n\n\nMultiple Resource Model (다중 자원 모델)\n\n서로 다른 유형의 과업은 다른 자원을 사용\n하지만 한쪽의 workload가 높으면 다른쪽에 영향을 미칠 수 있음.\n비주얼 테스트 두 개를 수행하는 것이 비주얼-청각 테스트보다 더 어려움\n한 객체의 두 가지 특징에 주의를 기울이는 것이 두 객체의 한 가지 특징에 주의를 기울이는 것보다 쉬움\nEx) 특성을 여러 막대로 보여주는것보다 육각형으로 보여주는게 더 보기 쉬움\n\n\n\nPerceptual Modalities\n\nAuditory,Visual, and Tactile Perceptual modalities에 사용하는 resource가 전부 다름\nVisual은 Focal과 Ambient가 서로 다른 자원을 사용함\nCross-modality가 15%정도 더 효과가 있음\ntactile은 auditory랑 비슷함.\n\n\n\ncoding\n\nspatial, verbal\nauditory verbal verbal and visual spatial manual is efficient\nverbal은 단 너무 길면 좋지 않다.\n모든 채널에서 다 쓸 수는 없다. (tactile 같은 경우에는 verbal 코딩이 없음)\n\n\n\nAttentional Allocation during Time-sharing: Skill or Ability?\n\nIf skill:\nAttentional allocation should be trainable\nSkills developed in one task transfer to unrelated tasks.\nIf ability:\nNo evidence supports the existence of a universal “multitasking ability.”\nPeople excel at specific tasks due to familiarity and automation, not inherent multitasking talent.\n\n\nPractical Implications\n\nOperator training:\nTraining must develop automaticity in single-task skills to reduce resource demand\nTraining of attentional allocation and time-sharing will help dual-task performance\nOperator selection:\ntime-sharing ability가 좋은 사람을 선택하는 것보다는 single-task performance가 좋고 자동화가 잘 사람을 선택하는 것이 더 좋음\n\n\n\n\nSystem design이나 multi-task performance를 측정할 때 좋은 것\n\nTask analysis나 multiple resource model를 사용하는 것이 좋다.\nTask의 어떤 면이 효율적으로 time-shared 될 것인가?\nTask의 어떤 면이 interference를 일으킬 것인가?\ninterference를 최소화하기 위해 어떻게 디자인 해야하나?\nex) driving할 때 손과 발을 따로 사용하게 하기\nTime-sharing efficiency, task performance, and mental workload를 고려해야한다\n(멘탈 워크로드 측정은 아직도 쉽지 않다.)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Attention"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/8_control.html#basic-control-task-and-device",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/8_control.html#basic-control-task-and-device",
    "title": "Control",
    "section": "Basic Control Task and Device",
    "text": "Basic Control Task and Device\n\n\n\n상태를 체크할 때는 toggle switch, 눌렀다 떼는 건 push button\n레버도 상태를 체크할 때 사용. 그 중 큰 힘이 필요한 경우. continuous setting에서는 slider가 쓰임\nselector switch는 lever랑은 다르게 discrete한 상태가 있음 (선풍기 버튼)\n조이스틱은 보통 가속도(2D, 멀리 밀면 빨리 가는 애)를 제어하거나 속도(1D, 버튼 조이스틱)를 제어하는데 사용. 마우스는 위치를 제어.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Control"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/8_control.html#principles-to-design-of-control-device",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/8_control.html#principles-to-design-of-control-device",
    "title": "Control",
    "section": "15 principles to design of control device",
    "text": "15 principles to design of control device\n\nAttention principles\n\nProximity compatibility\n\n컨트롤 하고자 하는 대상과 컨트롤이 가까워야 한다.\n비상 스위치는 가까이 있어야 한다.\n\n\n\nAvoid resource competition\n\n같은 physical or cognitive resource를 사용하는 control은 피해야한다.\nex) 레버로 속도, 방향 모두 제어\n\n\n\n\nPerceptual principles\n\nMake accessible\n\nphysical accessibility: 손이 닿아야 한다.\ncognitive accessibility: 뭐 하는 control인지 이해하기 쉬워야 한다.\nex) 미는 손잡이는 flat하게 만든다.\n다양한 환경을 고려해야한다. (빛이나 소음이 많은 환경)\n\n\n\nMake discriminable\n\nvisual differentiation: 각각의 컨트롤 장비를 구분할 수 있게\nlogical grouping: 비슷한 기능을 하는 것끼리 묶어놓기\n\n\n\nExploit(활용) redundancy gain\n\n두개의 독립적인 정보를 제공하면 성능이 좋아진다.\n한 가지 정보가 없어도 다른 정보로 대체할 수 있다.\n\n\n\nAvoid absolute judgement limits\n\nworking memory limit(7)를 넘기지 말라.\ncontinuous vs with detents: 연속적인 조절에서 anchor point를 만들어주면 좋다.\n\n\n\n\nMemory Principles\n\nKnowledge in the world\n보편적으로 아는 표현을 사용\n\n\nBe consistent\n\n다른 상황에서도 예상 가능하고 일정한 방법으로 control이 가능해야한다.\n\n\n\nmake discriminable vs be consistent\n\n\n\n\nMental model principles\n\nLocation Compatibility\n\nSpatial Compatibility / physical similarity\n\n\n\nMovement Compatibility\n\n\n\n\nPopulation Stereotypes\n\nrotary controls: 시계방향으로 돌리면 커진다\nUp is on\nIncrease is right, Forward is faster\n\n\n\nResponse selection principles\n\nAvoid accidental activation\n\n사고로 눌리는 것을 방지해야한다.\n\n\n\nHick-Hyman Law\n\\(RT = a + b \\log_2(n+1)\\)\nN is the number of choices\n종류가 많아져도 그냥 몇개만 고민함\n\n\nDecision complexity advantage\n\n일반적으로 복잡한 선택을 적게 하는게 간단한 선택을 여러번 하는것보다 효율적이다\n\n\n\nFitt’s Law\n\n\nIndex of Difficulty: \\(ID = \\log_2(\\frac{2A}{W})\\)\nMovement Time: \\(MT = a + bID\\)\n\navoid accidental vs Fitt’s Law - target width가 구석에 있으면 width가 무한대가 된다.\n\n\nprovide feedback\ntouch screen은 haptic feedback이 없어서 불편함",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Control"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#overview",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#overview",
    "title": "Signal Detection Theory",
    "section": "Overview",
    "text": "Overview\n\n인간의 정보 처리 과정 중 perception에 관련된 것\nperception 단계에서 자극 뿐 아니라 노이즈도 같이 들어옴\n여러가지 신호 중 무엇이 중요한지 판단하는 것\nsiganal 탐지 과정을 정량적 모델로 분석하고 성능 평가가 목표\n인공지능 분야에서 중요성이 대두되고 있음",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#example",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#example",
    "title": "Signal Detection Theory",
    "section": "Example",
    "text": "Example\n\nQuality control inspector\n빵이나 과자가 찌그러졌는지 검사, 반도체 품질 검사. 요즘에는 기계가 대부분 담당\nDetection of a flashing warning light (or cctv)\n거수자 탐지\nAirport security guard\nDetecting peculiar patterns in medical imaging (x-ray)\n종양, 암세포 탐지\nMobile phone rings (sound)\nphantoms vibration\nMorning alarm is active or not (visual)\n\n주변의 제품, 서비스 문제 파악, 해결 디자인 제시, 검증",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#signal-detection-theory",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#signal-detection-theory",
    "title": "Signal Detection Theory",
    "section": "Signal Detection Theory",
    "text": "Signal Detection Theory\n\nTrials\n\nSignal case(signal + noise): target이 존재\nNoise case(noise only): target이 없음\n\nResponse\n\nYes\nNo\n\n\n\n\nHit rate: P(Hit) = Number of Hits / Number of Signal Trials\nFalse alarm rate: P(FA) = Number of False Alarms / Number of Noise Trials\nMiss rate: P(Miss) = 1 - P(Hit)\nCorrect rejection rate: P(CR) = 1 - P(FA)\n\n\nWhat does it mean to detect?\n\nsignal is digital (exist / not exist)\nAbsolute threshold is exist\n\n\n\nAssumptions\n\n관찰자가 관찰할 수 있는 signal은 숫자나 변수로 표현할 수 있어야함\nsignal이 random variation이 있다\n피험자가 signal이 있는지 없는지 단순하게 표시할 수 있다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#distribution-of-signal-and-noise",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#distribution-of-signal-and-noise",
    "title": "Signal Detection Theory",
    "section": "Distribution of signal and noise",
    "text": "Distribution of signal and noise\n\n\nsensitivity index (d')\n\n값이 작으면 분간 힘듦\n값이 크면 분간 쉬움\nsignal의 성격에 따라 결정됨\n\nresponse bias (β)\n\ncriterion에 따라 yes라고 대답하는 비중과 no라고 대답하는 비중\n평가자에 따라 결정됨\n\nd′이 0, β가 50%면 그냥 랜덤으로 대답한 것과 같음\n\n\nd′ 계산\n\nP(M), P(CR) 계산\n표준 정규분포를 그림\nM과 CR의 z값을 찾음\nd′ = (0 - z(M)) + (z(CR) - 0)\n\n\n\nβ 계산\n\nd′과 관계 없이 조절\n\n\\(β = \\frac{P(X/(S+N))}{P(X/N)}\\)\n\\(\\ln β = d′λ_{center}\\)\nβ ~ 1: neutral\n\n\n\n\\(λ_{center}\\) 계산\n\\(λ_{center} = -\\frac{1}{2}(Z(FA)+Z(H))\\)\n\n\\(λ_{center}\\) = 0: ideal observer\n\\(λ_{center}\\) &lt; 0: liberal. yes라고 대답하는 비중이 늘어, hit rate가 높아지지만 false alarm rate도 높아짐\nex) 용의자를 찾는 경찰, 암세포 탐지\n\\(λ_{center}\\) &gt; 0: conservative. no라고 대답하는 비중이 늘어, correct rejection rate가 높아지지만 miss rate도 높아짐\nex) 억울한 죄인을 만들지 않으려는 범원 판결",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#optimal-response-criterion",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#optimal-response-criterion",
    "title": "Signal Detection Theory",
    "section": "Optimal Response Criterion",
    "text": "Optimal Response Criterion\nsignal이 더 많은 환경, noise가 더 많은 환경이 있음. 즉, probability가 다를 수 있음\n또, Effects of payoffs가 있음\n\nsignal이 많은 환경 -&gt; criterion을 낮추는게 좋음. \\(β_{opt} &lt; 1\\)\nnoise가 많은 환경 -&gt; criterion을 높이는게 좋음. \\(β_{opt} &gt; 1\\)\n\\(β_{opt} = \\frac{P(N)}{P(S)} * \\frac{V(CR) + C(FA)}{V(H) + C(M)}\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#sluggish-β",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#sluggish-β",
    "title": "Signal Detection Theory",
    "section": "Sluggish β",
    "text": "Sluggish β\n\n\n\nprobability 혹은 payoffs의 변화에 따라 bias가 optimal이랑 다르게 나옴\n\n\n\n\\(β_{opt}\\)가 낮은 경우, ideal보다 덜 conservative함.\n\\(β_{opt}\\)가 높은 경우, ideal보다 덜 risky함.\n확률에 의해 b가 조정될 때 더 많이 발생함.\n\n확률에 대한 계산이 잘못되는 경우\n평가자가 반복되는 반응에 bored해지는 경우",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#roc-curve",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#roc-curve",
    "title": "Signal Detection Theory",
    "section": "ROC Curve",
    "text": "ROC Curve\n\n\n\nd′이 높아질 수록 false alarm 비중이 낮아지고, hit 비중이 높아짐",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#signal-detection-performance",
    "href": "posts/04_archives/bs_2_2/notes/bs_human/5_signal_detction.html#signal-detection-performance",
    "title": "Signal Detection Theory",
    "section": "Signal Detection Performance",
    "text": "Signal Detection Performance\n\nResponse Bias (β)\n\n잘 맞추면 보상을 준다\nfalse signals to raise signal rate\nFalse Alarm에서도 incentive를 준다.\n\n\n\nSensitivity (d′)\n\ngive feedback\nsignal을 조금 더 오래 보여줌\nsignal을 강조\nsignal을 움직이게\n휴식 시간을 충분히 줌\nsignal이 어떠넌지 잘 보여줌\n온갖 감각으로 signal을 보여줌",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Human",
      "Signal Detection Theory"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/8-central-limit-theorem.html#중심-극한-정리",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/8-central-limit-theorem.html#중심-극한-정리",
    "title": "중심 극한 정리",
    "section": "중심 극한 정리",
    "text": "중심 극한 정리\n평군이 μ이고, 분산이 \\(σ^2\\)인 모집단으로부터 추출한 확률표본 \\(X_1, X_2, ..., X_n\\)의 표본평균 \\(\\bar{X}\\)의 분포\n\n모집단의 분포와 상관 없이 \\(E(\\bar{X}) = μ\\), \\(Var(\\bar{X}) = \\frac{σ^2}{n}\\)\n정규 모집단일 경우 \\(\\bar{X}\\)가 정규분포를 따름\n정규 모집단이 아닐 경우\n\\(n \\geq 30\\) 이면 중심극한정리에 의해 \\(\\bar{X}\\)는 정규분포에 근사됨. (모집단의 skewed에 따라 더 큰 n이 필요할 수 있음)\n∴ \\(\\bar{X} \\sim N(μ, \\frac{σ^2}{n}), \\frac{\\bar{X} - μ}{σ/\\sqrt{n}} \\sim N(0, 1^2)\\)\n모집단의 분포가 이산, 연속 분포일 때 모두 적용 가능하다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "중심 극한 정리"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/8-central-limit-theorem.html#이항분포의-정규근사",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/8-central-limit-theorem.html#이항분포의-정규근사",
    "title": "중심 극한 정리",
    "section": "이항분포의 정규근사",
    "text": "이항분포의 정규근사",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "중심 극한 정리"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#확률변수",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#확률변수",
    "title": "확률변수와 확률분포",
    "section": "확률변수",
    "text": "확률변수\nsample space의 원소를 상호 배반인 event들로 분할하여 실수 값으로 대응시키는 함수\n\n이산확률변수: 확률변수가 취할 수 있는 값이 유한개 또는 무한개이지만 셀 수 있는 경우\n연속확률변수: 확률변수가 취할 수 있는 값이 실수의 구간이고 셀 수 없는 경우\n\n이산 표본공간 -&gt; 이산 확률변수\n연속 표본공간 -&gt; 연속 확률변수\n연속 표본공간 -&gt; 이산 확률변수",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#확률-분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#확률-분포",
    "title": "확률변수와 확률분포",
    "section": "확률 분포",
    "text": "확률 분포\n\n표본공간 S에 정의된 확률변수 X의 모든 함수값들이 발생할 확률. 모집단의 확률구조를 나타냄\n확률 실험 -&gt; 표본공간 -&gt; 확률변수 -&gt; 확률분포\n\n\n이산확률분포\n확률 질량 함수(pmf): P(X=x) = f(x) =&gt; X가 x일 확률\n- 기하분포: 성공확률 p인 베르누이 시행을 독립적으로 반복했을 때 첫 번째 성공이 나타날 때까지의 시행횟수\n\n\n연속확률분포\n\n확률 밀도 함수(pdf): \\(\\int{f(x)}dx = 1\\)\n\\(\\int_a^b {f(x)}dx = P(a ≤ x ≤ b)\\) =&gt; x가 a와 b사이에 있을 확률\nP(X=x) = 0 (연속형 데이터여서 특정값을 가질 확률은 0)\nf(x) ≠ P(X=x)\nf(x)는 1보다 큰 값을 가질 수 있음\n누적분포함수(cdf): \\(F(x) = P(X ≤ x)\\) =&gt; \\(\\int_{-∞}^x{f(y)}dy\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#결합-확률분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#결합-확률분포",
    "title": "확률변수와 확률분포",
    "section": "결합 확률분포",
    "text": "결합 확률분포\n\npmf: \\(P(X=x, Y=y) = f(x, y)\\)\npdf: \\(P(a ≤ X ≤ b, c ≤ Y ≤ d) = \\int_{a}^{b}\\int_{c}^{d}{f(x, y)}dydx\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#주변-확률분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#주변-확률분포",
    "title": "확률변수와 확률분포",
    "section": "주변 확률분포",
    "text": "주변 확률분포\n\npmf: \\(f_X(x) = \\sum_y{f(x,y)}\\)\npdf: \\(f_X(x) = \\int_{-∞}^{∞}{f(x, y)}dy\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#조건부-확률분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#조건부-확률분포",
    "title": "확률변수와 확률분포",
    "section": "조건부 확률분포",
    "text": "조건부 확률분포\n\n\\(f(x|y)\\) = \\(\\frac{joint}{marginal}\\) = \\(\\frac{f(x, y)}{f_Y(y)}\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#독립-확률변수",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#독립-확률변수",
    "title": "확률변수와 확률분포",
    "section": "독립 확률변수",
    "text": "독립 확률변수\n\n모든 \\(x, y\\)에 대해 \\(f(x, y) = f_X(x)f_Y(y)\\)\n\n\n\n\\(f(x, y) = g(x) * h(y)\\)\n\nx, y 의 구간이 서로 간섭받지 않는다.\nX,Y는 독립이다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#확률변수의-변환",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html#확률변수의-변환",
    "title": "확률변수와 확률분포",
    "section": "확률변수의 변환",
    "text": "확률변수의 변환\n\ncdf를 이용한 변환\ncdf를 미분해서 pdf\n\n\n역함수가 존재할 경우\n\\(g(y) = f(u^{-1}(y)) * |\\frac{du^{-1}}{dy}|\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "확률변수와 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html",
    "title": "이산형 확률분포",
    "section": "",
    "text": "확률분포 정의 단계",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행",
    "title": "이산형 확률분포",
    "section": "시행",
    "text": "시행\n각 시행의 결과는 성공(A) 또는 실패(B)\n성공 확률은 p, 실패 확률은 1-p\n각 시행은 서로 독립적 → 모집단의 크기가 충분히 크고, 표본의 크기가 충분히 작다면, 비복원 추출에서도 유효\n∴ S = {A,B}, f(1) = P(X=1) = p, f(0) = P(X=0) = 1-p\n\n\n\n베르누이 시행 예시",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포",
    "title": "이산형 확률분포",
    "section": "분포",
    "text": "분포\n표기: \\(B(1,p)\\)\n\\(f(x) = p^x(1-p)^{1-x}, x = 0, 1\\)\n\\(E(x) = p\\)\n\\(Var(x) = p(1-p)\\)\n\\(m(t) = 1 - p + pe^t\\)\np = 0.5일 때, 분산은 0.25로 가장 큰 값을 가짐",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-1",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-1",
    "title": "이산형 확률분포",
    "section": "시행",
    "text": "시행\nn번의 독립적인 베르누이 시행을 했을 때 성공 횟수 X\n서로 독립인 n개의 베르누이 분포의 합과 같다.",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-1",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-1",
    "title": "이산형 확률분포",
    "section": "분포",
    "text": "분포\n표기: \\(X \\sim B(n,p)\\)\n\\(f(x) = {_n}C_x\\) \\(p^x(1-p)^{n-x}, x = 0, 1, 2, ..., n\\)\n\\(E(x) = np\\)\n\\(Var(x) = np(1-p)\\)\n\\(m(t) = (1-p + pe^t)^n\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-2",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-2",
    "title": "이산형 확률분포",
    "section": "시행",
    "text": "시행\n성공 확률 p인 베르누이 시행을 반복하여 처음 성공할 때까지의 시행 횟수 X\n지수분포와 유사하다\n기하분포는 비기억 속성을 가진다",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-2",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-2",
    "title": "이산형 확률분포",
    "section": "분포",
    "text": "분포\n표기: \\(X \\sim G(p)\\)\n\\(f(x) = (1-p)^{x-1}p, x = 1, 2, 3, ...\\)\n\\(E(x) = \\frac{1}{p}\\)\n\\(Var(x) = \\frac{1-p}{p^2}\\)\n\\(m(t) = \\frac{pe^t}{1-qe^t}, (qe^t&lt;1), (q=1-p)\\)\n\\(P(X &gt; x + y | X &gt; x) = P(X &gt; y) = (1-p)^y\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-3",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-3",
    "title": "이산형 확률분포",
    "section": "시행",
    "text": "시행\n모집단의 크기에 비해 샘플의 크기가 작지 않은 경우, 비 복원 추출시 각각의 선택이 베르누이 시행이라 할 수 없다.\n\\(\\frac{r}{N} = p\\)로 일정할 때, N을 증가시키면, \\(HG(n, N, r)\\)은 \\(B(n, p)\\)로 수렴한다",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-3",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-3",
    "title": "이산형 확률분포",
    "section": "분포",
    "text": "분포\n표기: \\(X \\sim HG(n, N, r)\\)\n\\(f(x) = \\frac{\\binom{r}{x}\\binom{N-r}{n-x}}{\\binom{N}{n}}, x = 0, 1, 2, ..., n\\)\n\\(E(x) = \\frac{nr}{N}\\)\n\\(Var(x) = \\frac{nr(N-r)(N-n)}{N^2(N-1)}\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-4",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#시행-4",
    "title": "이산형 확률분포",
    "section": "시행",
    "text": "시행\n임의의 기간동안 어떤 사건이 간헐적으로 발생할 때, 사건이 발생하는 횟수 X\n임의의 기간을 n 등분하여 각 등분에서 사건이 발생할 확률이 p라고 할 때, 발생횟수 기댓값 λ를 고정시킨 채로 n을 무한히 증가시킴\nn이 매우 크고 p가 매우 작을 때 이항분포를 포아송분포로 근사할 수 있다\n포아송 분포 + 포아송 분포 = 포아송 분포: \\(P(λ) + P(λ) = P(2λ)\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-4",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html#분포-4",
    "title": "이산형 확률분포",
    "section": "분포",
    "text": "분포\n표기: \\(X \\sim P(\\lambda)\\)\n\\(f(x) = \\frac{e^{-\\lambda}\\lambda^x}{x!}, x = 0, 1, 2, ...\\)\n\\(E(x) = \\lambda\\)\n\\(Var(x) = \\lambda\\)\n\\(m(t) = e^{\\lambda(e^t-1)}\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "이산형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html#standard-normal-distribution",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html#standard-normal-distribution",
    "title": "연속형 확률분포",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\nμ = 0, σ = 1인 정규분포",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "연속형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html#chi-square-distribution",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html#chi-square-distribution",
    "title": "연속형 확률분포",
    "section": "Chi-square Distribution",
    "text": "Chi-square Distribution\nα = ν/2, θ = 2인 감마분포\n자유도 ν에 따라 모양이 변함: 커질수록 정규분포에 가까워짐\n표기: \\(X \\sim χ^2(ν)\\)\n\\(E(x) = ν\\)\n\\(Var(x) = 2ν\\)",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "연속형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html#exponential-distribution",
    "href": "posts/04_archives/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html#exponential-distribution",
    "title": "연속형 확률분포",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\nα = 1, \\(λ = \\frac{1}{\\theta}\\)인 감마분포\nPoisson 분포에서 사건 발생 사이의 시간을 나타낼 수 있음\n표기: \\(X \\sim Exp(λ)\\)\n\\(f(x) = λe^{-λx}, x \\geq 0\\)\n\\(E(x) = \\frac{1}{λ}\\)\n\\(Var(x) = \\frac{1}{λ^2}\\)\n\\(P(X &gt; x) = e^{-λx}\\)\n\\(P(X &gt; x + y | X &gt; x) = P(X &gt; y) = e^{-λy}\\)\n포아송분포에서의 \\(\\frac{1}{λ}\\)와 동일\n비기억 특성을 가짐\n독립적으로 동일한 지수분포의 합은 감마분포 \\(Γ(n, \\frac{1}{\\lambda})\\)를 따름",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Statistics",
      "연속형 확률분포"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/09.html",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/09.html",
    "title": "Database Design",
    "section": "",
    "text": "MS access is prototyping tool for mock-ups",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Design"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/09.html#purpose-of-a-database-design",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/09.html#purpose-of-a-database-design",
    "title": "Database Design",
    "section": "Purpose of a Database Design",
    "text": "Purpose of a Database Design\nset of database specifications that can be implemented as a database in a DBMS\n\nconceptual design: non-DBMS specific\nlogical design: DBMS specific\nphysical design: DBMS specific but not implemented directly by humans",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Design"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/09.html#logical-designrelational-design",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/09.html#logical-designrelational-design",
    "title": "Database Design",
    "section": "Logical Design(Relational Design)",
    "text": "Logical Design(Relational Design)\n\nCreate a table(relation) for each entity\n\nspecify primary key\nspecify properties for each column\n\ndata type\nconstraints\ndefault value\nnull status\n\nverify normalization: data structure의 complexity를 증가시킬 수도 있다 → denormalization: 조인 불필요, 조회 시 성능 향상 → datastructure complexity vs modification problems\n\nCreate relationships by placing foreign keys:\n\nStrong entity relationships\nID-dependent / non-ID-dependent weak entity relationships\nSubtypes\nRecursive",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Design"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/09.html#representing-relationships",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/09.html#representing-relationships",
    "title": "Database Design",
    "section": "Representing Relationships",
    "text": "Representing Relationships\nid-dependent의 경우 부모의 primary key로 composite key 생성\nMaximum cardinality의 유형에 따라 관계 표현 방법이 달라짐\n\n1:1: foreign key를 어디에 두어도 상관 없음\nCREATE UNIQUE INDEX idx_1_1 ON table(foriegn_key);\n1:N: many(child) 쪽에 foreign key를 두는 것이 일반적\n1 side is called parent, many side is called child\nM:N\nData Modeling에서만 쓰임. database design에서는 intersection table을 사용하여 표현. intersection table은 두 entity의 primary key를 포함하는 composite key를 가짐\n만약 두 primary key 외의 attribute를 가진다면, association entity로 표현\nSupertype / Subtype: Supertype의 primary key를 Subtype의 primary key로 사용\nRecursive Relationship: 방향 이거 다시 보자\nN:M의 경우 virtual table을 생성하여 표현\n\n설문조사는\ndescriptive statistics\n남녀 비율, 경험 비율 등등도 포함되어야 한다.\n가중 평균으로 보여준다\n도서관 예약 시스템\n\n퇴설 처리 미흡\n좌석 이용 정보 파악\n앱 알림\n\n좌석 배치도 감이 안온다. 잔여시간도 안뜬다",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Database Design"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/13.html#tier-layers-of-database-system",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/13.html#tier-layers-of-database-system",
    "title": "ASP.NET",
    "section": "3-Tier Layers of Database System",
    "text": "3-Tier Layers of Database System\n\npresentation layer: user interface\napplication layer: web server(IIS)\ndata layer: database server",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "ASP.NET"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/13.html#api-interface-standards-for-db-access",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/13.html#api-interface-standards-for-db-access",
    "title": "ASP.NET",
    "section": "API Interface Standards for DB Access",
    "text": "API Interface Standards for DB Access\nDBMS에 접근하기 위한 표준 API\n\nODBC Open Database Connectivity\nDBMS-independent API\nJDBC: Java Database Connectivity\n\n&lt;a target=\"_blank\"&gt;",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "ASP.NET"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/13.html#asp-active-server-pages",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/13.html#asp-active-server-pages",
    "title": "ASP.NET",
    "section": "ASP (Active Server Pages)",
    "text": "ASP (Active Server Pages)\nserver side scripting(VBScript) language\nCGI: &lt;% %&gt;는 server에서 실행되는 코드",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "ASP.NET"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/13.html#asp-데이터베이스-연동",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/13.html#asp-데이터베이스-연동",
    "title": "ASP.NET",
    "section": "ASP 데이터베이스 연동",
    "text": "ASP 데이터베이스 연동\n&lt;%\n  Dim conn, connCmd, rs\n  Set connCmd = \"DSN=dsn_name; Database=dbname; UID=user;PWD=password\"\n  Set conn = Server.CreateObject(\"ADODB.Connection\")\n  Set rs = Server.CreateObject(\"ADODB.Recordset\")\n  conn.Open connCmd\n  rs.Open \"SELECT * FROM table_name\", conn\n%&gt;\n\n&lt;%\n  rs.getRows()\n\n  conn.Execute SQL\n%&gt;",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "ASP.NET"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/13.html#오류-메세지-한글-설정",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/13.html#오류-메세지-한글-설정",
    "title": "ASP.NET",
    "section": "오류 메세지 한글 설정",
    "text": "오류 메세지 한글 설정\n&lt;meta charset=\"UTF-8\"&gt;\n&lt;%\n  Session.CodePage = 949\n  Response.CharSet = \"euc-kr\"\n  Response.AddHeader \"Pragma\",\"no-cache\"\n  Response.AddHeader \"cache-control\", \"no-staff\"\n  Response.Expires = -1\n%&gt;\n\nform tag 한글 깨짐 문제\n&lt;%\nSession.CodePage=\"65001\"\nResponse.CharSet=\"UTF-8\"\n%&gt;",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "ASP.NET"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#the-importance-of-dbs-today",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#the-importance-of-dbs-today",
    "title": "An Overview of Database",
    "section": "The Importance of DBs Today",
    "text": "The Importance of DBs Today\n\nDepend upon database: Internet, Web 2.0, IOT",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#why-and-how-databases-are-used",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#why-and-how-databases-are-used",
    "title": "An Overview of Database",
    "section": "Why and How Databases are Used?",
    "text": "Why and How Databases are Used?\n\nThe purpose of a database is to keep track of thing\ndb store information that is more complicated than a simple spread sheet",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#problems-with-lists-spread-sheet",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#problems-with-lists-spread-sheet",
    "title": "An Overview of Database",
    "section": "Problems with Lists (spread sheet)",
    "text": "Problems with Lists (spread sheet)\n\nRedundancy\n\n\n\n\n필요없는 column들이 중복됨\n\n\n\nMultiple Themes\n\n\n그 결과로, list에 나타날 때만 존재하는 informartion이 생김\n\n\nList Modification Issues\n\n\n\n\ndeletion problems, update problems, insertion problems",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#relational-databases",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#relational-databases",
    "title": "An Overview of Database",
    "section": "Relational Databases",
    "text": "Relational Databases\n\nRelationa Model is methodology used as a solution for database design\nA relational database stores information in tables\n\nEach informational topic is stored in its own table\n\nEach theme in the list can be stored in a table\n\nTable = file = relation\ncolumn = fields = attribute\nrow = record = tuple",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#sql-structured-query-language",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#sql-structured-query-language",
    "title": "An Overview of Database",
    "section": "SQL (Structured Query Language)",
    "text": "SQL (Structured Query Language)\n\ninternational standard for creating, processing, querying databases and their tables\ndb applications use SQL to retrieve, format, report, insert, delete, modify data for users\ncan combine table by join operation\n\nSELECT  CUSTOMER.CustomerLastName, \n        CUSTOMER.CustomerFirstName, \n        CUSTOMER.Phone,\n        COURSE.CourseDate, \n        ENROLLMENT.AmountPaid,\n        COURSE.Course, \n        COURSE.Fee\nFROM    CUSTOMER, ENROLLMENT, COURSE\nWHERE   CUSTOMER.CustomerNumber = ENROLLMENT.CustomerNumber -- join condition\n        AND  COURSE.CourseNumber = ENROLLMENT.CourseNumber; -- join condition",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#database-system-dbs",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#database-system-dbs",
    "title": "An Overview of Database",
    "section": "Database System (DBS)",
    "text": "Database System (DBS)\n\n\n\nThe four components of database system\n\n\n\nUser: Employ database application to keep track of things\nUse forms to read, enter, query data\nproduce reports\nDatabase Application: web/mobile database applications, Forms, Reports\nDBMS: used to create, process, administer the database\nDatabase: self-describing collection of related tables\nuser data, metadata, index and other overhead data, application metadata(form, reports) are stored in db\nmetadata = about the structure of the database. &lt;-&gt; user data\n\n\nFunction of DBMS\n\nDB administration\n\nControl concurrency\nProvide security\nPerform backup and recovery\n\n\n\n\nReferential Integrity Constraints",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#personal-vs-enterprise-class-database-systems",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#personal-vs-enterprise-class-database-systems",
    "title": "An Overview of Database",
    "section": "Personal vs Enterprise-class Database Systems",
    "text": "Personal vs Enterprise-class Database Systems\n\nPersonal: Access\nEnterprise-class(Organizational): Microsoft SQL server",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#nosql-databases",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#nosql-databases",
    "title": "An Overview of Database",
    "section": "NoSQL databases",
    "text": "NoSQL databases\n\nNoSQL database = non-relational database",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#cloud-databases",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/01-2.html#cloud-databases",
    "title": "An Overview of Database",
    "section": "Cloud databases",
    "text": "Cloud databases\nMain frame -&gt; Client/server -&gt; Cloud",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "An Overview of Database"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/07.html#data-and-information",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/07.html#data-and-information",
    "title": "Data Modeling and the Entity-Relationship Model",
    "section": "Data and information",
    "text": "Data and information\n\nData: raw facts. recorded facts\nInformation: meaningful context\nKnowledge: information + 가치",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Data Modeling and the Entity-Relationship Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/07.html#what-is-information-system",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/07.html#what-is-information-system",
    "title": "Data Modeling and the Entity-Relationship Model",
    "section": "What is information system?",
    "text": "What is information system?\n\nSystem: a set of components that interact to achieve some purpose or goal\nInformation System: composed of hardware, software, data, procedures, people",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Data Modeling and the Entity-Relationship Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/07.html#system-analysis-and-design",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/07.html#system-analysis-and-design",
    "title": "Data Modeling and the Entity-Relationship Model",
    "section": "System Analysis and Design",
    "text": "System Analysis and Design\n\nSystem analysis and design: process of creating and maintaining information systems\nclassic methodology: SDLC\n\n\nSDLC (System Development Life Cycle)\n\n\n\nSDLC\n\n\n\nSystem definitions: 예산 편상, 위험 분석, …\nRequirements analysis\nComponent design\nImplementation\nSystem maintenance\n\n\ndatabase development process\n\nRequirements analysis\ninput: the project plan\noutput: a set of approved requirements -&gt; data model (ER model로 conceptual design)\nsource: Use cases, Business rules\nComponent Design: Relational Database Design (상세 설계)\nImplementation",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Data Modeling and the Entity-Relationship Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/07.html#er-model",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/07.html#er-model",
    "title": "Data Modeling and the Entity-Relationship Model",
    "section": "ER model",
    "text": "ER model\n\nEntities\n\nEntity class\nEntity instance\n\nAttributes: Data type, Properties(default, constraints)\nIdentifiers\n\nunique\nNonunique: identifies a set of instances\n\nRelationships\n\nbinary relationship\n\nMaximum cardinality: 1:1(A has a B), 1:N(A has a set of B), M:N\nMinimum cardinality: 0, 1\n\nternary relationship",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Data Modeling and the Entity-Relationship Model"
    ]
  },
  {
    "objectID": "posts/04_archives/bs_2_2/notes/bs_database/07.html#entit-relationship-diagram",
    "href": "posts/04_archives/bs_2_2/notes/bs_database/07.html#entit-relationship-diagram",
    "title": "Data Modeling and the Entity-Relationship Model",
    "section": "Entit-Relationship Diagram",
    "text": "Entit-Relationship Diagram\n\nEntity classes: rectangle\nRelationships: diamond\nmaximum cardinality: inside the diamond\nminimum cardinality: oval or hash mark next to diamond\nstrong entity: 독자적으로 존재 가능. 강한개체 관계는 점선\nNon-ID-dependent: identifier에 다른 entity의 identifier가 포함되어 있지 않음. 점선으로 표기(non-identifying relationship)\nweak entity: 약, 강 관계는 실선. IS: rounded square, traditional: 2 layer square\nID-dependent: identifier에 다른 entity의 identifier가 포함되어 있음. 실선으로 표기(identifying relationship)\nassociative entity: relationship이 entity로 변환된 것.\nMany-to-many relationship을 2개의 1:N으로 변환\nsuper type, sub type: 상속관계. sub type is a super type\n\nexclusive: Discriminator attribute가 필요함\ninclusive\n\nrecursive relationship\nBusiness rule: build-in constraints, trigger, stored procedure, application code로 구현 가능\ndata model validation: form, report를 이용한 prototyping",
    "crumbs": [
      "PARA",
      "Archives",
      "2학년 2학기 학부 정리",
      "Notes",
      "Bs Database",
      "Data Modeling and the Entity-Relationship Model"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/11.html",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/11.html",
    "title": "4 - 정형 데이터 마이닝",
    "section": "",
    "text": "맨 위로",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/15.html",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/15.html",
    "title": "5 - 시각화 구현",
    "section": "",
    "text": "맨 위로",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "5 - 시각화 구현"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/12.html",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/12.html",
    "title": "4 - 비정형 데이터 마이닝",
    "section": "",
    "text": "맨 위로",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 비정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/13.html#시각화-인사이트-프로세스의-의미",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/13.html#시각화-인사이트-프로세스의-의미",
    "title": "5 - 시각화 인사이트 프로세스",
    "section": "시각화 인사이트 프로세스의 의미",
    "text": "시각화 인사이트 프로세스의 의미\n\n1. 인사이트란 무엇인가\n상위 개념을 발견하기 위해, 각 단계의 관계를 이해해야 한다.\n이를 위해 시각화 인사이트 방법이 필요하다.\n\n\n\nDIKW 피라미드와 시각화 관계\n\n\n\n\n2. 시각화와 인사이트",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "5 - 시각화 인사이트 프로세스"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/13.html#탐색",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/13.html#탐색",
    "title": "5 - 시각화 인사이트 프로세스",
    "section": "탐색",
    "text": "탐색\n\n상위 개념을 발견하기 위해, 각 단계의 관계를 이해하는 과정\n객관적인 패턴을 찾는 용도\n\n\n1. 사용 가능한 데이터 확인\n\n데이터 접근\n\n이벤트 기록으로서 접근: 데이터로부터 통찰을 이끌어 내기 위해서 데이터 생성 원리를 파악해야 한다고 간주\n객체지향 관점에서의 접근: 데이터로부터 통찰을 이끌어 내기 위해서 전체 구조를 파악해야 한다고 간주\n\n데이터 명세화\n\n모든 데이터는 하나 이상의 차원과 측정값을 가지고 있다.\n이는 분석 형태에 따라, 차원이 될 수도 있고, 측정값이 될 수도 있다.\n\n\n\n\n2. 연결 고리의 확인\n데이터 명세서를 이용해 2개 이상의 데이터간 연결 고리를 확인해 봄\n\n공통 요소 찾기\n공통 요소로 변환하기: 데이터 타입이 달라도 공통 요소로 묶을 수 있다 (더 자세한 데이터를 덜 자세한 데이터로 변환. 반대는 불가)\n\n시간 데이터의 변환\n공간 데이터의 변환(지오코딩, 코로플레스 지도, X-Ray Map 사용 가능)\n계층 관계 변환: 상위 수준(덜 자세한)이라는 공통 요소로 변환. replace, lookup, vlookup 함수 사용 가능\n\n탐색 범위 설정: 차원과 측정값의 전체 조합 종류가 탐색 범위가 됨. 데이터를 구성하는 항목이 늘어날 수록 탐색 범위가 늘어남\n\n여러 데이터를 보유한 경우, 개별 데이터 안에서 먼저 탐색\n측정값 하나의 차원만 연결해 탐색\n같은 데이터 안에서 차원과 측정값을 맞바꾸면 다른 통찰을 얻을 수 있음\n어떤 통찰을 얻기 위해 비주얼 인사이트 프로세스를 사용하는 것인지 살펴본 후, 목표와 관련 있을 법한 조합을 만듦\n상식적으로 의미나 연계성이 없는 조합은 배제\n\n\n\n\n3. 관계의 탐색\n상관관계와 인과관계를 탐색\n\n이상값 처리: 시각화 도구를 통해 전체 구조를 파악한 후 처리\n차원과 측정값 유형에 따른 관계 파악 시각화\n\n시각화 도구 선정\n시간 데이터에서의 관계 파악: 구글 모션차트 사용 가능\n공간 데이터에서의 관계 파악: Arc GIS, X-Ray Map, 파워 맵 사용 가능\n비정형 데이터에서의 관계 파악\n\n워들: 주어진 텍스트에서 형태소 단위를 추출(NLP)해 빈도에 따라 시각화\n\n\n잘라보고 달리보기: 둘 이상의 차원과 측정값으로 이루어진 데이터를 여러 관점으로 살펴본다.\n\n잘라보기(slice): ex) 연령별, 성별 평균 체중 데이터 → 20세 이상, 40세 미만 남성들의 체중 패턴\n달리보기(dice): ex) 연령별, 성별 평균 체중 데이터 → 남성의 연령별 체중 패턴, 여성의 연령별 체중 패턴\nMS excel의 pivot, powerview, spreadsheet의 pivot table report 사용 가능\n\n내려다보고 올려보기\n\n내려다보기(Drill Down): 데이터를 하위 계층으로 세분화한다.\n올려보기(Reverse Driil Down): 데이터를 상위 계층으로 통합한다.\nTree map, Hyperbolic Tree\n\n척도의 조정: 스파크라인 차트 사용 가능",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "5 - 시각화 인사이트 프로세스"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/13.html#분석",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/13.html#분석",
    "title": "5 - 시각화 인사이트 프로세스",
    "section": "분석",
    "text": "분석\n\n탐색을 통해 발견된 패턴을 분석하는 과정\n\n\n1. 분석 대상의 구체화\n\n2차 탐색: 관계들의 분석 우선순위 결정. 궁극적인 목표는 그냥 다시 한 번 더 검토하는 것\n분석 목표에 따른 분석 기법\n\n \n\n\n2. 분석 시각화 도구\n통계적 도구와 시각적 도구는 상호보완 관계\n\n\n3. 지표 설정과 분석\n\n지표: 어떤 현상의 강도를 평가하는 기준이 되는 수치\n\nex) KPI(Key Performance Indicator): 핵심 성과 지표. 목표 달성을 위한 세부적인 활동 결과물의 추진 정도나 수준을 측정하고 평가\n주로 함수식 구조를 가짐 (ex. 매출액 = 판매단가 * 판매량)\n요인 분석(factor analysis)를 통해 지표가 다른 요인과 설명력이 겹치는지 여부 확인할 수 있다.\n어떤 변화요인에 의해 지표의 흐름에 영향을 미쳤는지 파악하기 어렵다는 단점이 있다.",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "5 - 시각화 인사이트 프로세스"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/13.html#활용",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/13.html#활용",
    "title": "5 - 시각화 인사이트 프로세스",
    "section": "활용",
    "text": "활용\n\n도출한 인사이트를 활용하는 과정\n\n\n1. 내부에서 적용\n\n기존 문제 해결 방식이나 설명 모델의 수정\n새로운 문제 해결 방식의 도입\n새롭게 발견한 가능성에 대한 구체적인 탐색과 발전\n\n\n\n2. 외부에 대한 설명, 설득과 시각화 도구\n설득이 필요하기 때문에 스토리텔링이 감미된 시각화 자료나, 인터렉티브 인포그래픽 활용\n\n\n3. 인사이트의 발전과 확장\n계속 잘 검토해 나가야함",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "5 - 시각화 인사이트 프로세스"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/10.html#통계분석의-이해",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/10.html#통계분석의-이해",
    "title": "4 - 통계분석",
    "section": "통계분석의 이해",
    "text": "통계분석의 이해\n\n1. 표본 추출 방법\n\n단순랜덤 추출법\n계통추출법: k개씩 띄어서 랜덤으로 추출\n집락 추출법: 군집을 나눈 후, 군집 안에서 단순랜덤 추출\n층화 추출법: 이질적인 모집단에서, 비슷한 특성을 가진 층을 나눈 후, 각 층에서 단순랜덤 추출\n\n\n\n2. 척도\n\n명목척도\n순서척도\n구간척도: 더하기, 빼기 가능. 곱셈 나눗셈 불가능\n비율척도: 절대적 기준인 0이 존재, 사칙연산 가능\n\n\n\n3. 비모수 검정\n\n모집단에 대한 가정이 없이, 서열관계나 차이를 검정하는 방법\n분포의 형태가 동일하다, 동일하지 않다로 가정\n관측값들의 순위나 차이의 부호에 의존\n\n\n\n\n비모수 검정 예시",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 통계분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/10.html#기초-통계분석",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/10.html#기초-통계분석",
    "title": "4 - 통계분석",
    "section": "기초 통계분석",
    "text": "기초 통계분석\n\n\n\n상관 분석 유형",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 통계분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/10.html#통계분석의-방법론",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/10.html#통계분석의-방법론",
    "title": "4 - 통계분석",
    "section": "통계분석의 방법론",
    "text": "통계분석의 방법론\n\nt 검정\n\n일표본\n대응표본\n독립표본\n\nANOVA\n\n일원분산분석\n이원분산분석\n다원분산분석\n\n다변량분석\n실험계획법\n\n요인배치법\n분할법\n교락법\n난괴법\n\n교차분석\n\n적합성 검정: k개의 범주들에 대한 관측값 갯수가 기댓값과 일치하는지 검정\n\n자유도: k-1\n각 집단의 \\(\\frac{(관측도수 - 기대도수)^2}{기대도수}\\)의 합이 카이제곱 분포를 따름\n\n독립성 검정\n\n자유도: (r - 1)(c - 1)\n\n동질성 검정: 독립성 검정이랑 유사",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 통계분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/10.html#회귀분석",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/10.html#회귀분석",
    "title": "4 - 통계분석",
    "section": "회귀분석",
    "text": "회귀분석\n\n1. 가정\n\n선형성\n정규성: qq-plot, 대각선에 가까워야함\n등분산성: 수평선에 가까워야함\n독립성: 더빈 왓슨 검정(0~4), 2에 가까울수록 독립성이 있다.\n\n→ 가정을 충족하지 않을 경우, 회귀모델을 수정해야함\n\n이상치 → 관측값 제거\n선형성 → 독립변수 변환\n정규성, 등분산성 미충족 → 종속변수 변환\n\n변환: \\(x\\) → \\(x^λ\\)\n\n\n2. 회귀식\n\n\n\\(R^2 = \\frac{SSR}{SST}\\)\n\\(R^2_{adj} = 1 - \\frac{(1 - R^2)(n - 1)}{n - k - 1}\\)\n\n\n\n3. 다중공선성\n\n독립변수들 간에 강한 상관관계가 존재하는 경우\n\n상관계수: 변수간 상관계수를 직접 계산\n허용오차: 1 - \\(R^2\\). 0.1 이하면 다중공선성이 존재한다고 판단\nVIF: 허용 오차의 역수. 10 이상이면 다중공선성이 존재한다고 판단 → 변수 제거\n\n\n\n\n4. 최적화 회귀방정식\n\nAIC, BIC나 F-value를 크게 만드는 변수 제거\n\n\n전진 선택법: 상수항부터 시작해, 한번에 한개씩 독립변수 추가\n\n전체 변수 사용할 수 있지만 안정성이 낮음\n\n후진 선택법: 모든 독립변수를 포함한 후, 하나씩 제거. AIC가 더 이상 작아지지 않을 때까지\n\n안정성이 높지만 변수가 많을 때 시간이 오래 걸림\n\n단계 선택법: 전진, 후진 선택법을 혼합.\n\n이미 선택된 변수를 제거할 수 있음\n변수가 많으면 시간이 오래 걸림",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 통계분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/10.html#고급-회귀분석",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/10.html#고급-회귀분석",
    "title": "4 - 통계분석",
    "section": "고급 회귀분석",
    "text": "고급 회귀분석\n\n1. 패널티 회귀분석\n지나치게 많은 독립변수를 갖는 모델에 페널티를 부과하는 방식\n\n릿지: 모델의 설명력에 기여하지 못하는 독립변수의 계수 크기를 0에 근접하게 축소 (\\(l_2\\) 규제)\n\n회귀 계수가 비슷하고, 독립변수가 많을 때 효과가 좋다.\n\n라쏘: 모델의 설명력에 기여하지 못하는 독립변수의 계수 크기를 0으로 만듦 (\\(l_1\\) 규제)\n\n회귀 계수 차이가 클 때 효과가 좋다.\n\n엘라스틱넷: 릿지와 라쏘를 혼합한 방법 (\\(l_1\\) + \\(l_2\\) 규제)\n\n\n\n2. 일반화 회귀분석\n\n종속변수가 연속형이면서 정규분포를 따르지 않을 때 사용\n\n\nlogistic 회귀모형\npoisson 회귀모형",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 통계분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/10.html#시계열-분석",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/10.html#시계열-분석",
    "title": "4 - 통계분석",
    "section": "시계열 분석",
    "text": "시계열 분석\n\n시계열 데이터 생성\n탐색적 분석을 통해 데이터 이해\n\n시각화 작업으로 변통 패턴 관찰\n성분분해 작업으로 추세, 계절성분, 불규칙성분 분리\n\n추세\n계절\n불규칙\n\n\n미래 관측값에 대한 예측\n\n지수 모델링 기법\nARIMA 기법",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 통계분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/02.html#빅데이터-분석과-전략-인사이트",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/02.html#빅데이터-분석과-전략-인사이트",
    "title": "1 - 가치 창조를 위한 데이터 사이언스와 전략 인사이트",
    "section": "빅데이터 분석과 전략 인사이트",
    "text": "빅데이터 분석과 전략 인사이트\n빅테이터 분석은 분석을 통해 가치를 창출하는 것이 목적이다.\n\n일차원적인 분석: 해당 부서나 업무 영역에만 효과가 있다. 변화하는 환경에서 새로운 기회를 포착하기 어려움.\n전략도출 가치기반 분석: 일차원적인 분석을 통해 얻은 가치를 기반으로 활용 범위를 더 넓고 전략적으로 확장해야한다.",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "1 - 가치 창조를 위한 데이터 사이언스와 전략 인사이트"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/02.html#전략-인사이트-도출을-위한-필요-역량",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/02.html#전략-인사이트-도출을-위한-필요-역량",
    "title": "1 - 가치 창조를 위한 데이터 사이언스와 전략 인사이트",
    "section": "전략 인사이트 도출을 위한 필요 역량",
    "text": "전략 인사이트 도출을 위한 필요 역량\n\n\n\n데이터 사이언티스트의 요구 역량\n\n\n외부 환경이 다음과 같이 변화함에 따라 인사이트 도출을 위한 인문학적 역량이 요구됨.\n\n컨버전스 → 디버전스\n생산 → 서비스\n생산 → 시장창조",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "1 - 가치 창조를 위한 데이터 사이언스와 전략 인사이트"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/06.html#마스터-플랜-수립-프레임-워크",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/06.html#마스터-플랜-수립-프레임-워크",
    "title": "3 - 분석 마스터 플랜",
    "section": "마스터 플랜 수립 프레임 워크",
    "text": "마스터 플랜 수립 프레임 워크\n\n\n\n마스터 플랜 수립 개요\n\n\n\n2. 수행 과제 도출 및 우선순위 평가\n\n\n\n일반적인 IT 프로젝트 우선순위 평가\n\n\n\n\n\nROI 관점\n\n\n위 기준에 따라 시급성과 난이도를 평가한 후, 아래 그림에 맞게 우선순위를 정한다.\n\n우선순위 기준을 시급성에 둔다면, 3 → 4 → 2 순, 난이도에 둔다면 3 → 1 → 2 순으로 우선순위를 정한다.\n\n\n3. 이행계획 수립\n\n\n\n로드맵 수립\n\n\n\n세부 이행계획 수립",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "3 - 분석 마스터 플랜"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/06.html#분석-거버넌스-체계-수립",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/06.html#분석-거버넌스-체계-수립",
    "title": "3 - 분석 마스터 플랜",
    "section": "분석 거버넌스 체계 수립",
    "text": "분석 거버넌스 체계 수립\n\n1. 거버넌스 체계\n\n\n\n2. 데이터 분석 수준진단\n\n\n분석 준비도\n\n\n\n분석 성숙도\n\n\n\n\nCMMI(Capability Maturity Model Integration)\n\n\n분석 준비도와 성숙도를 통해 현재 분석 수준을 파악한다. 이후 아래의 그림에 맞춰 목표 방향을 설정한다.\n\n\n\n4. 데이터 거버넌스 체계 수립\n\n구성 요소:\n\n원칙\n조직\n프로세스\n\n\n\n\n\n체계\n\n\n\n데이터 표준화: 규칙같은거 통일하는거\n데이터 관리 체계: 라이프사이클 같은거 관리하는거\n레포지토리: 너가 아는 그거\n표준화 활동: 잘 지켜지는지 지속적으로 모니터링하는거\n\n\n\n5. 데이터 조직 및 인력방안 수립\n\n\n\n분석 조직 구조\n\n\n\n\n\n분석 조직 인력 구성\n\n\n\n\n6. 분석과제 관리 프로세스 수립\n\n\n\n분석 과제 관리 프로세스",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "3 - 분석 마스터 플랜"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/01.html#결정론적-vs-통계적-의사결정",
    "href": "posts/01_projects/adp_필기/notes/통계/01.html#결정론적-vs-통계적-의사결정",
    "title": "통계 기초",
    "section": "결정론적 vs 통계적 의사결정",
    "text": "결정론적 vs 통계적 의사결정\n우리가 일상생활에서 무의식적으로 사용하는 것은 결정론적 의사결정이다.\n변화의 원인을 결정론적으로 확신하는 것이 결정론적 의사결정이다.\n어떤 사건이 우연히 발생할 확률을 묻는 것으로 시작하는 것이 통계적 의사결정이다.",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "통계 기초"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/01.html#통계의-본질",
    "href": "posts/01_projects/adp_필기/notes/통계/01.html#통계의-본질",
    "title": "통계 기초",
    "section": "통계의 본질",
    "text": "통계의 본질\n데이터를 설명하는 대표적인 특징이 평균과 분산, 중앙값, 최빈값, … 이다.\n\n중심 경향성: 평균, 중앙값, 최빈값\n산포도: 분산, 표준편차, 사분위수, 변동계수\n\n이 중 평균, 분산이 계산하기 쉽고, 좋은 추정값이 된다.\n통계는 분산의 마법이다.",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "통계 기초"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/01.html#what-is-p-value",
    "href": "posts/01_projects/adp_필기/notes/통계/01.html#what-is-p-value",
    "title": "통계 기초",
    "section": "what is p-value",
    "text": "what is p-value\n어떤 사건이 우연히 발생할 확률\np-value가 0.05보다 작다 = 어떤 사건이 우연히 발생할 확률이 낮다 = 우연이 아니다.",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "통계 기초"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/01.html#통계적-가설검정",
    "href": "posts/01_projects/adp_필기/notes/통계/01.html#통계적-가설검정",
    "title": "통계 기초",
    "section": "통계적 가설검정",
    "text": "통계적 가설검정\n\n귀무가설(Null Hypothesis, \\(H_0\\)): 기존의 주장\n대립가설(Alternative Hypothesis, \\(H_1\\)): 새로운 주장\np-value가 0.05보다 작다: \\(H_1\\) 채택, \\(H_0\\)이 실제로 참일 경우: 1종 오류\np-value가 0.05보다 크다: \\(H_0\\) 채택, \\(H_1\\)이 실제로 참일 경우: 2종 오류",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "통계 기초"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/01.html#변수와-데이터",
    "href": "posts/01_projects/adp_필기/notes/통계/01.html#변수와-데이터",
    "title": "통계 기초",
    "section": "변수와 데이터",
    "text": "변수와 데이터\n\n이산/범주형 변수\n\n명목변수\n순위변수\n\n연속형 변수\n\n구간 변수\n비율 변수",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "통계 기초"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/01.html#상관관계와-상관계수",
    "href": "posts/01_projects/adp_필기/notes/통계/01.html#상관관계와-상관계수",
    "title": "통계 기초",
    "section": "상관관계와 상관계수",
    "text": "상관관계와 상관계수\n상관관계: 한 변수와 다른 변수가 공변하는 함수관계 - 상관계수는 힘(0~1), 방향(+,-)을 나타냄 - scatter plot에서 데이터가 모여있으면 상관계수가 높고, 흩어져 있으면 상관계수가 낮다(공 모양). - 상관계수의 힘은 점이 모여있는 정도를 나타내고, 각도(방향)와는 관련이 없다. - 단, 직선이 완벽히 수평이면 상관계수는 0이다. - 직선 관계만 알 수 있다.",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "통계 기초"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/02.html#t-test",
    "href": "posts/01_projects/adp_필기/notes/통계/02.html#t-test",
    "title": "t-test",
    "section": "t-test",
    "text": "t-test\n모집단의 표준편차가 알려지지 않았을 때, 정규분포의 모집단에서 추출된 표본의 평균값에 대한 가설검정 방법\n목적: 두개의 집단이 같은지 다른지 비교하기 위해 사용\n두 집단의 차이가 표준편차보다 작다 = 우연히 발생한 차이\n두 집단의 차이가 표준편차보다 크다 = 우연히 발생한 차이가 아님\n\n양측 검정: 단순히 다를 때\n\n\\(H_0\\): \\(\\bar{X}_a = \\bar{X}_b\\) → \\(D_{a-b} = 0\\)\n\\(H_1\\): \\(\\bar{X}_a ≠ \\bar{X}_b\\) → \\(\\bar{X}_a &gt; \\bar{X}_b\\) or \\(\\bar{X}_a &lt; \\bar{X}_b\\) → \\(D_{a-b} &gt; 0\\) or \\(D_{a-b} &lt; 0\\)\n\n단측 검정: 어느 한쪽이 더 큰지 작은지 알 때\n\n\\(H_0\\): \\(\\bar{X}_a = \\bar{X}_b\\) → \\(D_{a-b} = 0\\)\n\\(H_1\\): \\(\\bar{X}_a &gt; \\bar{X}_b\\) → \\(D_{a-b} &gt; 0\\)\n\n\n대립 가설을 하나만(lower, greater) 가져가냐, 둘 다 가져가냐 차이\n\nTwo sample t-test\n\n두 집단의 평균값을 비교\n두 집단의 분산이 같은지 다른지에 따라 equal variance t-test, unequal variance t-test로 나뉨\n\nPaired t-test\n\n동일한 집단의 평균값을 비교\n두 집단의 차이가 0인지 아닌지 검정",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "t-test"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/03.html",
    "href": "posts/01_projects/adp_필기/notes/통계/03.html",
    "title": "분산 분석",
    "section": "",
    "text": "비교 집단이 2개보다 많은 경우 단순히 t-test를 여러번 하면 1종 오류에 빠져서 안됨.",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "분산 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/03.html#one-way-anova",
    "href": "posts/01_projects/adp_필기/notes/통계/03.html#one-way-anova",
    "title": "분산 분석",
    "section": "One-way Anova",
    "text": "One-way Anova\n독립변수가 하나일 때, 3개 이상의 집단 간 평균 차이를 비교하는 방법 - 종속변수: 연속형만 가능 - 독립변수: 이산/범주형 변수만 가능",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "분산 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/03.html#f-value",
    "href": "posts/01_projects/adp_필기/notes/통계/03.html#f-value",
    "title": "분산 분석",
    "section": "F-value",
    "text": "F-value\n2개의 분산의 비율. 전체 평균과 그룹의 평균이 필요함\n\n그룹 간 변동(between variance, df1, treatment): 전체 평균과 그룹 내 데이터들의 평균과의 차이.\n\n자유도: 그룹의 수 - 1\n\n그룹 내 변동(within variance, df2, error): 그룹 내 데이터들의 평균과 그룹 내 데이터들의 차이\n\n자유도: 전체 데이터 수 - 그룹의 수\n\n\nbetween variance &gt; within variance = 적어도 어느 한 그룹이 통계적으로 유의미한 차이가 있다. → 어떤 그룹이 유의미한지는 알 수 없음 → 사후검정\n\n사후검정(Post Hoc Test)\n\nTukey HSD: 모든 집단을 두 개씩 비교하는 방법\nBonferroni: 모든 집단을 한 번씩 비교하는 방법\n\n등등..",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "분산 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/03.html#two-way-anova",
    "href": "posts/01_projects/adp_필기/notes/통계/03.html#two-way-anova",
    "title": "분산 분석",
    "section": "Two-way Anova",
    "text": "Two-way Anova\n독립변수가 2개일 때, 종속변수의 평균값이 독립변수의 수준에 따라 유의한 차이가 있는지 검정하는 방법이다.\n\nmain effect: 각 독립변수의 수준에 따른 종속변수의 평균값 차이\ninteraction effect: 한 독립변수의 종속변수에 대한 영향이 다른 독립변수의 수준에 따라 달라지는지\n\nmain effect f-value 2개, interaction effect f-value 1개를 구한다. df = \\(k_n - 1\\), interaction df = \\((k_1 - 1)(k_2 - 1)\\)\nbetween variance는 1개만 있으면 됨. df = \\((n-1)k_1k_2\\)",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "분산 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/03.html#공분산-분석",
    "href": "posts/01_projects/adp_필기/notes/통계/03.html#공분산-분석",
    "title": "분산 분석",
    "section": "공분산 분석",
    "text": "공분산 분석\n분산 분석에 공변량을 추가한것\n공변량: control 변수",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "분산 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/03.html#반복측정-분산분석",
    "href": "posts/01_projects/adp_필기/notes/통계/03.html#반복측정-분산분석",
    "title": "분산 분석",
    "section": "반복측정 분산분석",
    "text": "반복측정 분산분석\n동일한 대상에 대해 여러번 측정한 경우",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "분산 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/03.html#다변량-분산분석",
    "href": "posts/01_projects/adp_필기/notes/통계/03.html#다변량-분산분석",
    "title": "분산 분석",
    "section": "다변량 분산분석",
    "text": "다변량 분산분석\n2개 이상의 종속변수가 있을 경우 집단별 차이를 검정",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "분산 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/통계/03.html#카이제곱-검정",
    "href": "posts/01_projects/adp_필기/notes/통계/03.html#카이제곱-검정",
    "title": "분산 분석",
    "section": "카이제곱 검정",
    "text": "카이제곱 검정\n범주형 변수 간 관련성이 모집단에 존재하는지 검정\n\n\n관측빈도: 관측값\n기대빈도\n자유도: (r - 1)(c - 1)\n\\(X^2 = \\sum \\frac{(O - E)^2}{E}\\)\n독립성 검정: 두 범주형 변수가 서로 독립인지 검정\n적합성 검정: 범주형 변수가 하나일 때 범주별 비율 분포에 대한 가설 검정",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "통계",
      "분산 분석"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/3.html#nonlinear-programming-example",
    "href": "posts/01_projects/bs_3_1/notes/OR/3.html#nonlinear-programming-example",
    "title": "Nonlinear Programming",
    "section": "Nonlinear Programming Example",
    "text": "Nonlinear Programming Example\n\nPricing\nInventory\nPortfolio optimization (finance)\n→ Balance (margin vs price, ordering cost vs inventory cost, return vs risk, …)\n\nBecause trade off can only be modeled in a nonlinear way, the programs are by nature nonlinear\n\nAt least one of fumular is nonlinear, Nonlinear Program.\nBut some people says that NLP contents LP\n\n\nExample: Pricing a single good\n\nA retailer buys one product at a unit cost \\(c\\)\nIt chooses a unit retail price \\(p\\)\nThe demand is a function of \\(p\\): \\(D(p) = a - bp\\)\nFind profit-maximizing price\n\n\\[\\begin{aligned}\n\\underset{p}{max} \\quad  &(p-c)(a-bp) \\\\\ns.t. \\quad  &p ≥ 0 \\\\\n\\end{aligned}\\]\n\\[\n\\text{or}\n\\]\n\\[\\begin{aligned}\n\\underset{p\\ge0}{max} \\quad  &(p-c)(a-bp) \\\\\n\\end{aligned}\\]\n\\(p - c\\) is sales margin, \\(a-bp\\) is Demand (how many sales)\n\n\nExample: Folding a piece of paper\n\n\n\nExample: locating a hospital",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Nonlinear Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/3.html#eoq-model-economic-order-quantity",
    "href": "posts/01_projects/bs_3_1/notes/OR/3.html#eoq-model-economic-order-quantity",
    "title": "Nonlinear Programming",
    "section": "EOQ Model (Economic Order Quantity)",
    "text": "EOQ Model (Economic Order Quantity)\n \n\nParameters\n\n\\(D\\): annual demand\n\\(K\\): unit ordering cost\n\\(h\\): unit holding cost per year\n\\(p\\): unit purchasing cost\n\nDecision varaible\n\n\\(q\\): order quantity per order\n\nObjective: Minimizing annual total cost",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Nonlinear Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/3.html#portfolio-model",
    "href": "posts/01_projects/bs_3_1/notes/OR/3.html#portfolio-model",
    "title": "Nonlinear Programming",
    "section": "Portfolio Model",
    "text": "Portfolio Model",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Nonlinear Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/1.html#terminology",
    "href": "posts/01_projects/bs_3_1/notes/OR/1.html#terminology",
    "title": "Linear Programming",
    "section": "Terminology",
    "text": "Terminology\n\nprocess of fomulating and solving linear programs\nmathematical program with some special properties\n\nobjective function\nconstraints (\\(b_1, b_2, ..., b_m\\))\ndecision variables (\\(x_1, x_2, ..., x_n, x_i ∈ ℝ\\))\n→ also expressed as a \\(x\\) that means vector of \\(n\\) variables\n\n\n\nconstraints\n\nSign constraints: single variable\n\nnonnegative: \\(x_i ≥ 0\\)\nnonpositive: \\(x_i ≤ 0\\)\nunrestricted in sign or free: no sign constraints\n\nFunctional constraints: other cases\nequality constraints: \\(a_1x_1 + a_2x_2 + ... + a_nx_n = b\\)\ninequality constraints: \\(a_1x_1 + a_2x_2 + ... + a_nx_n ≤ b\\)\nbinding constraints (or active constraints)\nno matter \\(g(x)\\) is equality or not, if \\(g(a) = b, a\\) is binding\nstrict constraints: \\(a_1x_1 + a_2x_2 + ... + a_nx_n &lt; b\\)\nweak constraints: \\(a_1x_1 + a_2x_2 + ... + a_nx_n ≤ b\\)\n→ practical mathematical program’s inequalities are all weak\n\n\n\nsolution\n\nfeasible solution: satisfies all constraints\n\nfeasible region: set of all feasible solutions\n\noptimal solution: maximizes or minimizes the objective function\nthere may be multiple or no optimal solutions",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Linear Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/OR/1.html#three-types-of-lps",
    "href": "posts/01_projects/bs_3_1/notes/OR/1.html#three-types-of-lps",
    "title": "Linear Programming",
    "section": "Three types of LPs",
    "text": "Three types of LPs\n\nInfeasible\nUnbounded: unbounded feasible region does not imply an unbounded LP\nFinitely optimal\n\nUnique optimal solutions\nMultiple optimal solutions\n\n\n\nParameter: we know. \\(C_1, C_2, ...\\)\nVariables: do not know. \\(x_1, x_2, ...\\)",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "OR",
      "Linear Programming"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/notes/scholarships/2.html",
    "href": "posts/01_projects/bs_3_1/notes/scholarships/2.html",
    "title": "성적 장학금",
    "section": "",
    "text": "오~예~ (남은 등록금 300만원을 대출 받으며)\n\n\n\n 맨 위로",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기",
      "Notes",
      "Scholarships",
      "성적 장학금"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/index.html",
    "href": "posts/01_projects/bs_3_1/index.html",
    "title": "학부 3학년 1학기",
    "section": "",
    "text": "ON-GOING\n    \n    \n        시작일: 2024-12-21\n        종료일: 2025-06-20\n    \n    \n        \n            \n        \n        계산 중...\n    \n    \n    \n        산업공학 학부",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/index.html#details",
    "href": "posts/01_projects/bs_3_1/index.html#details",
    "title": "학부 3학년 1학기",
    "section": "Details",
    "text": "Details\n산업정보시스템공학과 3학년 1학기 개념 정리, 과제, 할 일 등을 총 정리한 노트 모음입니다.",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/index.html#tasks",
    "href": "posts/01_projects/bs_3_1/index.html#tasks",
    "title": "학부 3학년 1학기",
    "section": "Tasks",
    "text": "Tasks\n\n\n\n    \n    \n    \n            \n                \n                    \n                    OR 예습\n                \n                \n            \n\n            \n            \n                \n                \n                    푸른등대 기부장학금 - 두나무UDC 신청 (~2025-01-20 18:00)\n                \n                신청 완료. 결과 4월 중순\n            \n            \n            \n                \n                \n                    2025 DB 드림리더 장학생 신청 (~2025-01-10)\n                \n                잘할 자신이 없다\n            \n            \n            \n                \n                \n                    경기도 학자금대출 이자 지원 신청 (~2025.02.14 18:00)\n                \n                신청 완료\n            \n            \n            \n                \n                    \n                    학과 근로 신청\n                \n                신청 완료\n            \n\n            \n            \n                \n                \n                    연재장학재단 지원금 신청 (~2025-02-06 15:00)\n                \n                1명만 뽑는 장학금에 학과장님 추천서 받기 망설여진다\n            \n            \n            \n                \n                    \n                    KMOOC 학점 인정 신청 (2025-03-10~)",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/index.html#필요한-자료",
    "href": "posts/01_projects/bs_3_1/index.html#필요한-자료",
    "title": "학부 3학년 1학기",
    "section": "필요한 자료",
    "text": "필요한 자료\n\n자기소개서 작성 1\n교육 이수 증빙자료\nPortfolio: 큰일 났다. 진짜 못만들었다.",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/index.html#참고-자료",
    "href": "posts/01_projects/bs_3_1/index.html#참고-자료",
    "title": "학부 3학년 1학기",
    "section": "참고 자료",
    "text": "참고 자료\n\nOR 강의",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기"
    ]
  },
  {
    "objectID": "posts/01_projects/bs_3_1/index.html#related-posts",
    "href": "posts/01_projects/bs_3_1/index.html#related-posts",
    "title": "학부 3학년 1학기",
    "section": "Related Posts",
    "text": "Related Posts",
    "crumbs": [
      "PARA",
      "Projects",
      "학부 3학년 1학기"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/2.html#intro",
    "href": "posts/02_areas/42_seoul/notes/2.html#intro",
    "title": "ft_transcendence - JWT",
    "section": "intro",
    "text": "intro\n\n\n\n42 seoul 공통과정 6서클 과제\n\n\n1편 github action에 이어서 JWT 파트에 대해 설명하겠습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "ft_transcendence - JWT"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/2.html#프로젝트-및-구현-설명",
    "href": "posts/02_areas/42_seoul/notes/2.html#프로젝트-및-구현-설명",
    "title": "ft_transcendence - JWT",
    "section": "프로젝트 및 구현 설명",
    "text": "프로젝트 및 구현 설명\n\nJWT\n\n\n\nsecurity 요구사항\n\n\n\n\n\nJWT 요구사항\n\n\n비밀번호를 저장할 때는 암호화를 해야 한다는 요구사항이 있습니다. 이번 포스팅에서는 다루지 않지만, 우리의 구현에서는 비밀번호 없이 OAuth만으로 로그인이 가능하도록 설계했습니다. 따라서 사용자가 직접 비밀번호를 설정하지는 않습니다.\n다만, JWT 구현 과정에서 비밀번호로 간주될 수 있는 부분이 있다고 판단하여 해시 처리를 추가했습니다. 이는 명세서의 해당 요구사항을 반영한 것입니다.\n\n개념\n구현에 대해 설명하기 전에, 먼저 JWT(JSON Web Token)가 무엇인지 이해해야 합니다. JWT는 토큰 기반 암호화 방식의 표준화된 형식으로, 다음과 같은 형태를 가지고 있습니다.\n\nHeader: 토큰의 유형(예: JWT)과 사용된 암호화 알고리즘(예: HMAC SHA256)을 지정합니다.\nPayload: 토큰에 담을 정보를 포함합니다. 여기에는 클레임(Claim)이라고 불리는 키-값 쌍이 포함됩니다.\nSignature: 헤더와 페이로드를 합친 후, 지정된 알고리즘과 비밀 키를 사용해 서명한 값입니다. 이 서명은 토큰의 무결성을 보장합니다.\n\n각 부분은 점(.)으로 구분되며, Base64Url로 인코딩되어 있습니다.\n토큰 암호화 방식은 왜 등장했을까요? 우리가 일반적으로 알고 있는 세션-쿠키 방식과는 어떤 차이가 있을까요?\n\n세션-쿠키 방식: 사용자가 로그인하면 서버는 세션 ID를 생성하고 이를 사용자의 정보와 함께 데이터베이스나 메모리에 저장합니다. 이후 클라이언트는 쿠키에 세션 ID를 저장하고, 요청마다 이를 서버로 전송합니다. 서버는 세션 ID를 검증하여 사용자를 인증합니다. 이 방식은 사용자가 증가할수록 서버의 메모리나 데이터베이스에 부담이 커집니다.\n토큰 암호화 방식: 인증에 필요한 정보와 사용자의 정보(클레임)가 토큰 자체에 포함되어 있습니다. 서버는 토큰의 서명만 검증하면 되기 때문에 별도의 저장 공간이 필요하지 않습니다. 따라서 서버의 부하를 줄일 수 있습니다.\n\n즉, 기존의 세션-쿠키에서는 서버에 저장하던 정보를 토큰에 담아서 사용자한테 전달하는게 토큰 인증방식입니다. 언뜻 보기에는 토큰 암호화 방식이 세션-쿠키 방식의 상위호환처럼 보이지만, 토큰 방식에는 몇 가지 보안상의 위협이 존재합니다. 주요 위협과 그에 대한 대응 방법은 다음과 같습니다.\n\n토큰 탈취: 토큰이 노출되면 공격자가 이를 악용할 수 있습니다.\n대응 방법: HTTPS를 사용하여 통신을 암호화하고, 토큰의 유효 기간을 짧게 설정합니다. 또한, Refresh Token을 사용하여 Access Token의 유효 기간을 더욱 단축할 수 있습니다.\nXSS(Cross-Site Scripting) 공격: 악성 스크립트를 통해 토큰을 탈취할 수 있습니다.\n대응 방법: HttpOnly와 Secure 플래그를 사용해 쿠키에 토큰을 저장합니다.\nCSRF(Cross-Site Request Forgery) 공격: 사용자의 권한을 도용해 악의적인 요청을 보낼 수 있습니다.\n대응 방법: CSRF 토큰을 사용하거나, SameSite 속성을 설정해 쿠키를 보호합니다.\n토큰 재생 공격: 탈취한 토큰을 재사용하는 공격입니다.\n대응 방법: 토큰에 일회용 nonce 값을 포함시키거나, 토큰 블랙리스트를 관리합니다.\n\n\n\n\n\n\n\n토큰 탈취의 대응방법이 조금 허술하다고 느껴질 수 있습니다.\n더 많은 정보는 이 포스팅이 도움이 될것 같습니다.\n\n\n\n인증 방식은 상황에 맞게 알맞은 선택을 하는게 중요합니다. 서버 확장성이나 경량화 측면에서는 토큰 인증 방식이 매력적인 이점을 가져다 줍니다. 하지만, 보안이 중요한 서비스의 경우 session-cookie 방식이 더 유리할 수 있습니다.\n\n\n구현\n그럼 이제 구현 내용을 보도록 하겠습니다.\n\n\nmiddleware.py\n\nclass JWTMiddleware:\n    def __init__(self, get_response):\n        self.get_response = get_response\n\n    def __call__(self, request):\n        access = request.COOKIES.get('access')\n        if access and request.path != '/auth/ft' and request.path != '/auth/refresh':\n            request.META['HTTP_AUTHORIZATION'] = f'Bearer {access}'\n        response = self.get_response(request)\n        return responseclass JWTMiddleware:\n    def __init__(self, get_response):\n        self.get_response = get_response\n\n    def __call__(self, request):\n        access = request.COOKIES.get('access')\n        if access and request.path != '/auth/ft' and request.path != '/auth/refresh':\n            request.META['HTTP_AUTHORIZATION'] = f'Bearer {access}'\n        response = self.get_response(request)\n        return response\n\n\n\nsettings.py\n\nSIMPLE_JWT = {\n    \"AUTH_HEADER_TYPES\": (\"Bearer\",),\n    \n    ...\n}\n\n\n\n아_정리하기_귀찮아\n\ndef get_info_from_token(token, key):\n    try:\n        payload = jwt.decode(\n            token,\n            settings.SECRET_KEY,\n            algorithms=[settings.SIMPLE_JWT['ALGORITHM']],\n            options={\"verify_signature\": False, \"verify_exp\": False}\n        )\n    except jwt.InvalidTokenError:\n        pass\n    ret = payload.get(key)\n    return ret\n\nclass CustomTokenRefresh(APIView):\n    permission_classes = []\n\n    def post(self, request):\n        try:\n            refresh_token = request.COOKIES.get('refresh')\n            access_token = request.COOKIES.get('access')\n            if refresh_token is None:\n                raise TokenError\n            user_id = get_info_from_token(refresh_token, 'user_id')\n            if user_id is None:\n                raise TokenError\n            user = User.objects.get(id=user_id)\n            if access_token is not None:\n                ret = get_info_from_token(access_token, '2FA')\n                is_weak = ret is not None and ret == 'F'\n            else:\n                is_weak = user.two_factor == True\n            if user.refresh_token is None or not check_password(refresh_token, user.refresh_token):\n                raise TokenError\n            validate_token = RefreshToken(refresh_token)\n            validate_token.check_exp()\n        except (TokenError, User.DoesNotExist) as e:\n            if isinstance(e, TokenError):\n                user.refresh_token = None\n                user.save()\n            res = Response({'detail': 'Given token not valid for any token type'}, status=401)\n            res.delete_cookie('access')\n            res.delete_cookie('refresh')\n            return res\n        refresh = RefreshToken.for_user(user)\n        user.last_login = timezone.now()\n        user.refresh_token = make_password(str(refresh), None, 'md5')\n        user.save()\n        access = refresh.access_token\n        if is_weak:\n            access['2FA'] = 'F'\n        response = Response(status=204)\n        response.set_cookie(\n            'access', \n            str(access), \n            httponly=True, \n            secure=True,\n            samesite='Lax')\n        response.set_cookie(\n            'refresh', \n            str(refresh), \n            httponly=True, \n            path=f\"/auth/refresh;\",\n            secure=True,\n            samesite='Strict')\n        return response\n\nclass AuthProvider(APIView):\n    permission_classes = []\n\n    def get(self, request, auth_name):\n        if auth_name == 'ft':\n            ret = get_ft_user(request)\n        else:\n            raise Http404\n        if isinstance(ret, HttpResponse) or isinstance(ret, Response):\n            return ret\n        try:\n            user = User.objects.get(oauth__id=ret[\"id\"], oauth__provider=ret[\"provider\"])\n        except User.DoesNotExist:\n            user_list = User.objects.all()\n            for num in range(1, 100):\n                if num == 1:\n                    username = ret['default_username']\n                else:\n                    username = ret[\"default_username\"] + '-' + f\"{num:03d}\"\n                if not user_list.filter(username=username).exists():\n                    break\n            random_str = ''.join(random.choices(string.ascii_letters, k=10)) \n            user = User(\n                username = username, \n                email = ret[\"email\"],\n                oauth = {\n                    \"id\": ret[\"id\"],\n                    \"provider\": ret[\"provider\"],\n                },\n                password = make_password(random_str, None, 'md5'),\n            )\n            user.save()\n            user = User.objects.get(username=username)\n            sync_user_to_game_db(user.id, user.username)\n        user.last_login = timezone.now()\n        refresh = RefreshToken.for_user(user)\n        user.refresh_token = make_password(str(refresh), None, 'md5')\n        user.save()\n        if user.two_factor:\n            res = HttpResponseRedirect(f'{settings.BASE_URL}/two-factor')\n            access = refresh.access_token\n            access['2FA'] = 'F'\n        else:\n            res = HttpResponseRedirect(f'{settings.BASE_URL}/home')\n            access = refresh.access_token\n        res.status_code = 303\n        res.set_cookie(\n            'access', \n            str(access), \n            httponly=True, \n            secure=True,\n            samesite='Lax')\n        res.set_cookie(\n            'refresh', \n            str(refresh), \n            httponly=True, \n            path=f\"/auth/refresh;\",\n            secure=True,\n            samesite='Strict')\n        return res\n\ndef get_ft_user(request):\n    code = request.GET.get('code', '')\n    if code == '':\n        response = HttpResponseRedirect(getattr(settings, 'AUTH_42_CLIENT_URL', ''))\n        response.status_code = 303\n        return response\n    try:\n        response = requests.post(f'https://api.intra.42.fr/oauth/token?{urlencode({\n            'grant_type': 'authorization_code',\n            'client_id': getattr(settings, 'AUTH_42_CLIENT_ID', ''),\n            'client_secret': getattr(settings, 'AUTH_42_CLIENT_SECRET', ''),\n            'code': code,\n            'redirect_uri': f'{settings.BASE_URL}/auth/ft',\n            'scope': 'public',\n        })}')\n        response.raise_for_status()\n        response = requests.get('https://api.intra.42.fr/v2/me', headers={\n            'Authorization': f'Bearer {response.json()['access_token']}'\n        })\n        response.raise_for_status()\n        user = response.json()\n        return {\n            \"default_username\": user[\"login\"],\n            \"provider\": \"42\",\n            \"id\": user[\"id\"],\n            \"email\": user[\"email\"],\n        }\n    except (requests.exceptions.RequestException, JSONDecodeError, KeyError) as e:\n        if response.status_code == 401:\n            return Response({\"detail\": \"잘못된 권한입니다\"}, status=401)\n        logger.error(f'{e}: response code: {response.status_code} and response body: {response.text}')\n        return Response({\"detail\": \"Internal Server Error\"}, status=500)\n\n@api_view(['POST'])\n@permission_classes([IsAuthenticated])\ndef logOut(request):\n    user = request.user\n    user.last_logout=timezone.now()\n    user.refresh_token = None\n    user.save()\n    res = Response(status=204)\n    res.delete_cookie('access')\n    res.delete_cookie('refresh')\n    return res",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "ft_transcendence - JWT"
    ]
  },
  {
    "objectID": "posts/02_areas/42_seoul/notes/2.html#outro",
    "href": "posts/02_areas/42_seoul/notes/2.html#outro",
    "title": "ft_transcendence - JWT",
    "section": "outro",
    "text": "outro\n3편에 block chain 관련 설명으로 이어서 진행하겠습니다.",
    "crumbs": [
      "PARA",
      "Areas",
      "42 Seoul",
      "Notes",
      "ft_transcendence - JWT"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/11.html#데이터-마이닝-개요",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/11.html#데이터-마이닝-개요",
    "title": "4 - 정형 데이터 마이닝",
    "section": "데이터 마이닝 개요",
    "text": "데이터 마이닝 개요",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/11.html#분류-분석",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/11.html#분류-분석",
    "title": "4 - 정형 데이터 마이닝",
    "section": "분류 분석",
    "text": "분류 분석",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/11.html#앙상블-분석",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/11.html#앙상블-분석",
    "title": "4 - 정형 데이터 마이닝",
    "section": "앙상블 분석",
    "text": "앙상블 분석",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/11.html#인공신경망-분석",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/11.html#인공신경망-분석",
    "title": "4 - 정형 데이터 마이닝",
    "section": "인공신경망 분석",
    "text": "인공신경망 분석",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/11.html#군집-분석",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/11.html#군집-분석",
    "title": "4 - 정형 데이터 마이닝",
    "section": "군집 분석",
    "text": "군집 분석",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/11.html#연관-분석",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/11.html#연관-분석",
    "title": "4 - 정형 데이터 마이닝",
    "section": "연관 분석",
    "text": "연관 분석",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/12.html#텍스트-마이닝",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/12.html#텍스트-마이닝",
    "title": "4 - 비정형 데이터 마이닝",
    "section": "텍스트 마이닝",
    "text": "텍스트 마이닝\n\n비정형 데이터를 구조화해서 패턴을 도출한 후 결과를 평가 및 해석하는 일련의 과정\n\n\n기능\n\n목표 기능: 문서 분류, 군집, 정보 추출, 문서 요약\n사용 기술: 자연어 처리, 컴퓨터 언어학\n\n\n\n과정\n\n\n텍스트 수집\n텍스트 전처리\n\ntm 패키지: 문서를 Corpus 객체로 변환해서 관리\n\nVCorpus: 문서를 Corpus로 변환해서 메모리에 저장\nPCorpus: 문서를 Corpus로 변환해서 디스크에 저장\nDirSource, DataframeSource, VectorSource: 데이터 소스 지정\ntm_map(x, FUN): x에 FUN을 적용\nDocumentTermMatrix: 문서-단어 빈도표 생성\nTermDocumentMatrix: 단어-문서 빈도표 생성\n\n전처리\n\n정제: 노이즈 제거\n토큰화\n\n단어 토큰화\n어절 토큰화\n형태소 토큰화\n품사 태깅\n\n불용어 처리: 불필요한 토큰 제거\n정제 / 정규화\n\n표기가 다른 같은 단어 통일\n대소문자 통일\n불필요한 단어 제거\n정규표현식으로 특수문자 제거\n\n어간 / 어근 추출\n텍스트 인코딩\n\none hot 인코딩\n말뭉치(BoW): 단어의 빈도수를 벡터로 표현\nTF-IDF: 문서 내 단어의 빈도 수 / 단어가 등장한 문서 수\n워드 임베딩\n\n\n텍스트 분석\n\n토픽 모델링\n감성 분석\n텍스트 분류\n텍스트 군집화\n\n텍스트 시각화\n\n워드 클라우드\n의미 연결망 분석\n\n\n\n\n\n정보 검색의 적절성",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 비정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/12.html#사회연결망-분석",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/12.html#사회연결망-분석",
    "title": "4 - 비정형 데이터 마이닝",
    "section": "사회연결망 분석",
    "text": "사회연결망 분석\n\n2. 기법\n\n개인을 노드, 관계를 엣지로 해서 그래프 생성\n아래의 기준에 따라 구조 파악",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "4 - 비정형 데이터 마이닝"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/15.html#시각화-구현-개요",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/15.html#시각화-구현-개요",
    "title": "5 - 시각화 구현",
    "section": "시각화 구현 개요",
    "text": "시각화 구현 개요",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "5 - 시각화 구현"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/15.html#분석-도구를-이용한-시각화-구현-r",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/15.html#분석-도구를-이용한-시각화-구현-r",
    "title": "5 - 시각화 구현",
    "section": "분석 도구를 이용한 시각화 구현: R",
    "text": "분석 도구를 이용한 시각화 구현: R",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "5 - 시각화 구현"
    ]
  },
  {
    "objectID": "posts/01_projects/adp_필기/notes/adp_자습서/15.html#라이브러리-기반-시각화-구현-d3.js",
    "href": "posts/01_projects/adp_필기/notes/adp_자습서/15.html#라이브러리-기반-시각화-구현-d3.js",
    "title": "5 - 시각화 구현",
    "section": "라이브러리 기반 시각화 구현: D3.js",
    "text": "라이브러리 기반 시각화 구현: D3.js",
    "crumbs": [
      "PARA",
      "Projects",
      "ADP 필기 준비",
      "Notes",
      "Adp 자습서",
      "5 - 시각화 구현"
    ]
  }
]