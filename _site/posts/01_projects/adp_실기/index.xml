<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>김형훈의 학습 블로그</title>
<link>https://cryscham123.github.io/posts/01_projects/adp_실기/</link>
<atom:link href="https://cryscham123.github.io/posts/01_projects/adp_실기/index.xml" rel="self" type="application/rss+xml"/>
<description>ADP 실기를 준비해 봅시다.</description>
<image>
<url>https://cryscham123.github.io/profile.jpg</url>
<title>김형훈의 학습 블로그</title>
<link>https://cryscham123.github.io/posts/01_projects/adp_실기/</link>
</image>
<generator>quarto-1.5.56</generator>
<lastBuildDate>Sat, 27 Sep 2025 03:12:51 GMT</lastBuildDate>
<item>
  <title></title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/00.pdf</link>
  <description><![CDATA[ undefined ]]></description>
  <category>자격증</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/00.pdf</guid>
  <pubDate>Sat, 27 Sep 2025 03:12:51 GMT</pubDate>
</item>
<item>
  <title>pandas data 구조</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/01.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<p>pandas: numpy를 라벨링한거</p>
<section id="series" class="level1">
<h1>Series</h1>
<p>1차원 배열 구조, 이름과 형식을 가지고 모든 값에 고유한 인덱스를 가짐</p>
<div id="6272c162" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"></span>
<span id="cb1-3">data1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.Series({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ulala'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'haha'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>}, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'class'</span>)</span>
<span id="cb1-4">data1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>ulala    1
haha     2
Name: class, dtype: int64</code></pre>
</div>
</div>
<div id="ad44486d" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">data1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.Series({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ulala'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ulala'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>}, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'class'</span>)</span>
<span id="cb3-2">data1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>ulala    2
Name: class, dtype: int64</code></pre>
</div>
</div>
<div id="0b0b7f8f" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">data2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.Series([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'class'</span>)</span>
<span id="cb5-2">data2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>0    1
1    2
Name: class, dtype: int64</code></pre>
</div>
</div>
</section>
<section id="dataframe" class="level1">
<h1>DataFrame</h1>
<p>2차원 배열 구조, 각 행은 인덱스를 가지고, 각 열은 이름과 형식을 가짐</p>
<section id="before" class="level2">
<h2 class="anchored" data-anchor-id="before">Before</h2>
<p>데이터를 호출하고, 데이터 내용과 요약 / 통계 정보를 확인해야함</p>
<p>칼럼명이 칼럼 타입을 변경해야할 때도 있음</p>
<section id="pandas-사용-준비" class="level3">
<h3 class="anchored" data-anchor-id="pandas-사용-준비">Pandas 사용 준비</h3>
<ol type="1">
<li>라이브러리 설치</li>
<li>라이브러리 호출</li>
</ol>
<div id="b20fb1ea" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb7-2"></span>
<span id="cb7-3">pd.set_option(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'display.max_rows'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span></code></pre></div>
</div>
</section>
<section id="dataframe-선언" class="level3">
<h3 class="anchored" data-anchor-id="dataframe-선언">DataFrame 선언</h3>
<div id="29f91ddf" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb8-2">dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'kor'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span>], [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'math'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80</span>]])</span>
<span id="cb8-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># declare df 1</span></span>
<span id="cb8-4">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(dataset, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'class'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>])</span>
<span id="cb8-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># declare df 2</span></span>
<span id="cb8-6">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame([[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'kor'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span>], [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'math'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80</span>]], columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'class'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>])</span>
<span id="cb8-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># declare df 3</span></span>
<span id="cb8-8">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'class'</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'kor'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'math'</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80</span>]})</span>
<span id="cb8-9">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">class</th>
<th data-quarto-table-cell-role="th">score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>kor</td>
<td>70</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>math</td>
<td>80</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="dataframe-읽고-저장" class="level3">
<h3 class="anchored" data-anchor-id="dataframe-읽고-저장">DataFrame 읽고 저장</h3>
<div id="dd1a332a" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># filepath = '../book/data/data.csv'</span></span>
<span id="cb9-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># data = pd.read_csv(filepath, na_values='NA', encoding='utf8')</span></span>
<span id="cb9-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># data.to_csv('result.csv', header=True, index=True, encoding='utf8')</span></span></code></pre></div>
</div>
</section>
<section id="dataframe-출력" class="level3">
<h3 class="anchored" data-anchor-id="dataframe-출력">DataFrame 출력</h3>
<div id="3d24f7a5" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_iris</span>
<span id="cb10-2"></span>
<span id="cb10-3">iris <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_iris()</span>
<span id="cb10-4">iris</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>{'data': array([[5.1, 3.5, 1.4, 0.2],
        [4.9, 3. , 1.4, 0.2],
        [4.7, 3.2, 1.3, 0.2],
        [4.6, 3.1, 1.5, 0.2],
        [5. , 3.6, 1.4, 0.2],
        [5.4, 3.9, 1.7, 0.4],
        [4.6, 3.4, 1.4, 0.3],
        [5. , 3.4, 1.5, 0.2],
        [4.4, 2.9, 1.4, 0.2],
        [4.9, 3.1, 1.5, 0.1],
        [5.4, 3.7, 1.5, 0.2],
        [4.8, 3.4, 1.6, 0.2],
        [4.8, 3. , 1.4, 0.1],
        [4.3, 3. , 1.1, 0.1],
        [5.8, 4. , 1.2, 0.2],
        [5.7, 4.4, 1.5, 0.4],
        [5.4, 3.9, 1.3, 0.4],
        [5.1, 3.5, 1.4, 0.3],
        [5.7, 3.8, 1.7, 0.3],
        [5.1, 3.8, 1.5, 0.3],
        [5.4, 3.4, 1.7, 0.2],
        [5.1, 3.7, 1.5, 0.4],
        [4.6, 3.6, 1. , 0.2],
        [5.1, 3.3, 1.7, 0.5],
        [4.8, 3.4, 1.9, 0.2],
        [5. , 3. , 1.6, 0.2],
        [5. , 3.4, 1.6, 0.4],
        [5.2, 3.5, 1.5, 0.2],
        [5.2, 3.4, 1.4, 0.2],
        [4.7, 3.2, 1.6, 0.2],
        [4.8, 3.1, 1.6, 0.2],
        [5.4, 3.4, 1.5, 0.4],
        [5.2, 4.1, 1.5, 0.1],
        [5.5, 4.2, 1.4, 0.2],
        [4.9, 3.1, 1.5, 0.2],
        [5. , 3.2, 1.2, 0.2],
        [5.5, 3.5, 1.3, 0.2],
        [4.9, 3.6, 1.4, 0.1],
        [4.4, 3. , 1.3, 0.2],
        [5.1, 3.4, 1.5, 0.2],
        [5. , 3.5, 1.3, 0.3],
        [4.5, 2.3, 1.3, 0.3],
        [4.4, 3.2, 1.3, 0.2],
        [5. , 3.5, 1.6, 0.6],
        [5.1, 3.8, 1.9, 0.4],
        [4.8, 3. , 1.4, 0.3],
        [5.1, 3.8, 1.6, 0.2],
        [4.6, 3.2, 1.4, 0.2],
        [5.3, 3.7, 1.5, 0.2],
        [5. , 3.3, 1.4, 0.2],
        [7. , 3.2, 4.7, 1.4],
        [6.4, 3.2, 4.5, 1.5],
        [6.9, 3.1, 4.9, 1.5],
        [5.5, 2.3, 4. , 1.3],
        [6.5, 2.8, 4.6, 1.5],
        [5.7, 2.8, 4.5, 1.3],
        [6.3, 3.3, 4.7, 1.6],
        [4.9, 2.4, 3.3, 1. ],
        [6.6, 2.9, 4.6, 1.3],
        [5.2, 2.7, 3.9, 1.4],
        [5. , 2. , 3.5, 1. ],
        [5.9, 3. , 4.2, 1.5],
        [6. , 2.2, 4. , 1. ],
        [6.1, 2.9, 4.7, 1.4],
        [5.6, 2.9, 3.6, 1.3],
        [6.7, 3.1, 4.4, 1.4],
        [5.6, 3. , 4.5, 1.5],
        [5.8, 2.7, 4.1, 1. ],
        [6.2, 2.2, 4.5, 1.5],
        [5.6, 2.5, 3.9, 1.1],
        [5.9, 3.2, 4.8, 1.8],
        [6.1, 2.8, 4. , 1.3],
        [6.3, 2.5, 4.9, 1.5],
        [6.1, 2.8, 4.7, 1.2],
        [6.4, 2.9, 4.3, 1.3],
        [6.6, 3. , 4.4, 1.4],
        [6.8, 2.8, 4.8, 1.4],
        [6.7, 3. , 5. , 1.7],
        [6. , 2.9, 4.5, 1.5],
        [5.7, 2.6, 3.5, 1. ],
        [5.5, 2.4, 3.8, 1.1],
        [5.5, 2.4, 3.7, 1. ],
        [5.8, 2.7, 3.9, 1.2],
        [6. , 2.7, 5.1, 1.6],
        [5.4, 3. , 4.5, 1.5],
        [6. , 3.4, 4.5, 1.6],
        [6.7, 3.1, 4.7, 1.5],
        [6.3, 2.3, 4.4, 1.3],
        [5.6, 3. , 4.1, 1.3],
        [5.5, 2.5, 4. , 1.3],
        [5.5, 2.6, 4.4, 1.2],
        [6.1, 3. , 4.6, 1.4],
        [5.8, 2.6, 4. , 1.2],
        [5. , 2.3, 3.3, 1. ],
        [5.6, 2.7, 4.2, 1.3],
        [5.7, 3. , 4.2, 1.2],
        [5.7, 2.9, 4.2, 1.3],
        [6.2, 2.9, 4.3, 1.3],
        [5.1, 2.5, 3. , 1.1],
        [5.7, 2.8, 4.1, 1.3],
        [6.3, 3.3, 6. , 2.5],
        [5.8, 2.7, 5.1, 1.9],
        [7.1, 3. , 5.9, 2.1],
        [6.3, 2.9, 5.6, 1.8],
        [6.5, 3. , 5.8, 2.2],
        [7.6, 3. , 6.6, 2.1],
        [4.9, 2.5, 4.5, 1.7],
        [7.3, 2.9, 6.3, 1.8],
        [6.7, 2.5, 5.8, 1.8],
        [7.2, 3.6, 6.1, 2.5],
        [6.5, 3.2, 5.1, 2. ],
        [6.4, 2.7, 5.3, 1.9],
        [6.8, 3. , 5.5, 2.1],
        [5.7, 2.5, 5. , 2. ],
        [5.8, 2.8, 5.1, 2.4],
        [6.4, 3.2, 5.3, 2.3],
        [6.5, 3. , 5.5, 1.8],
        [7.7, 3.8, 6.7, 2.2],
        [7.7, 2.6, 6.9, 2.3],
        [6. , 2.2, 5. , 1.5],
        [6.9, 3.2, 5.7, 2.3],
        [5.6, 2.8, 4.9, 2. ],
        [7.7, 2.8, 6.7, 2. ],
        [6.3, 2.7, 4.9, 1.8],
        [6.7, 3.3, 5.7, 2.1],
        [7.2, 3.2, 6. , 1.8],
        [6.2, 2.8, 4.8, 1.8],
        [6.1, 3. , 4.9, 1.8],
        [6.4, 2.8, 5.6, 2.1],
        [7.2, 3. , 5.8, 1.6],
        [7.4, 2.8, 6.1, 1.9],
        [7.9, 3.8, 6.4, 2. ],
        [6.4, 2.8, 5.6, 2.2],
        [6.3, 2.8, 5.1, 1.5],
        [6.1, 2.6, 5.6, 1.4],
        [7.7, 3. , 6.1, 2.3],
        [6.3, 3.4, 5.6, 2.4],
        [6.4, 3.1, 5.5, 1.8],
        [6. , 3. , 4.8, 1.8],
        [6.9, 3.1, 5.4, 2.1],
        [6.7, 3.1, 5.6, 2.4],
        [6.9, 3.1, 5.1, 2.3],
        [5.8, 2.7, 5.1, 1.9],
        [6.8, 3.2, 5.9, 2.3],
        [6.7, 3.3, 5.7, 2.5],
        [6.7, 3. , 5.2, 2.3],
        [6.3, 2.5, 5. , 1.9],
        [6.5, 3. , 5.2, 2. ],
        [6.2, 3.4, 5.4, 2.3],
        [5.9, 3. , 5.1, 1.8]]),
 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),
 'frame': None,
 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='&lt;U10'),
 'DESCR': '.. _iris_dataset:\n\nIris plants dataset\n--------------------\n\n**Data Set Characteristics:**\n\n:Number of Instances: 150 (50 in each of three classes)\n:Number of Attributes: 4 numeric, predictive attributes and the class\n:Attribute Information:\n    - sepal length in cm\n    - sepal width in cm\n    - petal length in cm\n    - petal width in cm\n    - class:\n            - Iris-Setosa\n            - Iris-Versicolour\n            - Iris-Virginica\n\n:Summary Statistics:\n\n============== ==== ==== ======= ===== ====================\n                Min  Max   Mean    SD   Class Correlation\n============== ==== ==== ======= ===== ====================\nsepal length:   4.3  7.9   5.84   0.83    0.7826\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n============== ==== ==== ======= ===== ====================\n\n:Missing Attribute Values: None\n:Class Distribution: 33.3% for each of 3 classes.\n:Creator: R.A. Fisher\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n:Date: July, 1988\n\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\nfrom Fisher\'s paper. Note that it\'s the same as in R, but not as in the UCI\nMachine Learning Repository, which has two wrong data points.\n\nThis is perhaps the best known database to be found in the\npattern recognition literature.  Fisher\'s paper is a classic in the field and\nis referenced frequently to this day.  (See Duda &amp; Hart, for example.)  The\ndata set contains 3 classes of 50 instances each, where each class refers to a\ntype of iris plant.  One class is linearly separable from the other 2; the\nlatter are NOT linearly separable from each other.\n\n.. dropdown:: References\n\n  - Fisher, R.A. "The use of multiple measurements in taxonomic problems"\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in "Contributions to\n    Mathematical Statistics" (John Wiley, NY, 1950).\n  - Duda, R.O., &amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n    (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.\n  - Dasarathy, B.V. (1980) "Nosing Around the Neighborhood: A New System\n    Structure and Classification Rule for Recognition in Partially Exposed\n    Environments".  IEEE Transactions on Pattern Analysis and Machine\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\n  - Gates, G.W. (1972) "The Reduced Nearest Neighbor Rule".  IEEE Transactions\n    on Information Theory, May 1972, 431-433.\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al"s AUTOCLASS II\n    conceptual clustering system finds 3 classes in the data.\n  - Many, many more ...\n',
 'feature_names': ['sepal length (cm)',
  'sepal width (cm)',
  'petal length (cm)',
  'petal width (cm)'],
 'filename': 'iris.csv',
 'data_module': 'sklearn.datasets.data'}</code></pre>
</div>
</div>
<div id="a3ff6655" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">iris <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(iris.data, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.feature_names)</span>
<span id="cb12-2">iris</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal length (cm)</th>
<th data-quarto-table-cell-role="th">sepal width (cm)</th>
<th data-quarto-table-cell-role="th">petal length (cm)</th>
<th data-quarto-table-cell-role="th">petal width (cm)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5.1</td>
<td>3.5</td>
<td>1.4</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4.9</td>
<td>3.0</td>
<td>1.4</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4.7</td>
<td>3.2</td>
<td>1.3</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4.6</td>
<td>3.1</td>
<td>1.5</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5.0</td>
<td>3.6</td>
<td>1.4</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">145</td>
<td>6.7</td>
<td>3.0</td>
<td>5.2</td>
<td>2.3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">146</td>
<td>6.3</td>
<td>2.5</td>
<td>5.0</td>
<td>1.9</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">147</td>
<td>6.5</td>
<td>3.0</td>
<td>5.2</td>
<td>2.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">148</td>
<td>6.2</td>
<td>3.4</td>
<td>5.4</td>
<td>2.3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">149</td>
<td>5.9</td>
<td>3.0</td>
<td>5.1</td>
<td>1.8</td>
</tr>
</tbody>
</table>

<p>150 rows × 4 columns</p>
</div>
</div>
</div>
<div id="3f909627" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">iris.info()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 150 entries, 0 to 149
Data columns (total 4 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   sepal length (cm)  150 non-null    float64
 1   sepal width (cm)   150 non-null    float64
 2   petal length (cm)  150 non-null    float64
 3   petal width (cm)   150 non-null    float64
dtypes: float64(4)
memory usage: 4.8 KB</code></pre>
</div>
</div>
<div id="5786b73e" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">iris.describe()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal length (cm)</th>
<th data-quarto-table-cell-role="th">sepal width (cm)</th>
<th data-quarto-table-cell-role="th">petal length (cm)</th>
<th data-quarto-table-cell-role="th">petal width (cm)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>150.000000</td>
<td>150.000000</td>
<td>150.000000</td>
<td>150.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>5.843333</td>
<td>3.057333</td>
<td>3.758000</td>
<td>1.199333</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>0.828066</td>
<td>0.435866</td>
<td>1.765298</td>
<td>0.762238</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>4.300000</td>
<td>2.000000</td>
<td>1.000000</td>
<td>0.100000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>5.100000</td>
<td>2.800000</td>
<td>1.600000</td>
<td>0.300000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>5.800000</td>
<td>3.000000</td>
<td>4.350000</td>
<td>1.300000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>6.400000</td>
<td>3.300000</td>
<td>5.100000</td>
<td>1.800000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>7.900000</td>
<td>4.400000</td>
<td>6.900000</td>
<td>2.500000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>sepal length와 petal width의 값의 차이가 크다.</p>
<p>전처리 과정에서 변수 정규화 수행의 근거가 된다.</p>
</section>
<section id="index-column-명-변경" class="level3">
<h3 class="anchored" data-anchor-id="index-column-명-변경">index / column 명 변경</h3>
<div id="ac723533" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">df.index</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>RangeIndex(start=0, stop=2, step=1)</code></pre>
</div>
</div>
<div id="71f2bd87" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(df.index)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>[0, 1]</code></pre>
</div>
</div>
<div id="adfb5ad1" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">df.index <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'A'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'B'</span>]</span>
<span id="cb20-2">df.index</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>Index(['A', 'B'], dtype='object')</code></pre>
</div>
</div>
<div id="e82e85d6" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">class</th>
<th data-quarto-table-cell-role="th">score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">A</td>
<td>kor</td>
<td>70</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">B</td>
<td>math</td>
<td>80</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="6017c0c1" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">df.set_index(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'class'</span>, drop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, append<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb23-2">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">score</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">class</th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">kor</td>
<td>70</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">math</td>
<td>80</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="35ed08bd" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">df.reset_index(drop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb24-2">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">class</th>
<th data-quarto-table-cell-role="th">score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>kor</td>
<td>70</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>math</td>
<td>80</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="0292c0cf" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">iris.columns</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',
       'petal width (cm)'],
      dtype='object')</code></pre>
</div>
</div>
<div id="d04428a6" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">iris.columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal length'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal width'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'petal length'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'petal width'</span>]</span>
<span id="cb27-2">iris</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal length</th>
<th data-quarto-table-cell-role="th">sepal width</th>
<th data-quarto-table-cell-role="th">petal length</th>
<th data-quarto-table-cell-role="th">petal width</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5.1</td>
<td>3.5</td>
<td>1.4</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4.9</td>
<td>3.0</td>
<td>1.4</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4.7</td>
<td>3.2</td>
<td>1.3</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4.6</td>
<td>3.1</td>
<td>1.5</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5.0</td>
<td>3.6</td>
<td>1.4</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">145</td>
<td>6.7</td>
<td>3.0</td>
<td>5.2</td>
<td>2.3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">146</td>
<td>6.3</td>
<td>2.5</td>
<td>5.0</td>
<td>1.9</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">147</td>
<td>6.5</td>
<td>3.0</td>
<td>5.2</td>
<td>2.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">148</td>
<td>6.2</td>
<td>3.4</td>
<td>5.4</td>
<td>2.3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">149</td>
<td>5.9</td>
<td>3.0</td>
<td>5.1</td>
<td>1.8</td>
</tr>
</tbody>
</table>

<p>150 rows × 4 columns</p>
</div>
</div>
</div>
<div id="4b4600e2" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">iris.columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.columns.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>.replace(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">' '</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_'</span>)</span>
<span id="cb28-2">iris</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal_length</th>
<th data-quarto-table-cell-role="th">sepal_width</th>
<th data-quarto-table-cell-role="th">petal_length</th>
<th data-quarto-table-cell-role="th">petal_width</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5.1</td>
<td>3.5</td>
<td>1.4</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4.9</td>
<td>3.0</td>
<td>1.4</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4.7</td>
<td>3.2</td>
<td>1.3</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4.6</td>
<td>3.1</td>
<td>1.5</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5.0</td>
<td>3.6</td>
<td>1.4</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">145</td>
<td>6.7</td>
<td>3.0</td>
<td>5.2</td>
<td>2.3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">146</td>
<td>6.3</td>
<td>2.5</td>
<td>5.0</td>
<td>1.9</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">147</td>
<td>6.5</td>
<td>3.0</td>
<td>5.2</td>
<td>2.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">148</td>
<td>6.2</td>
<td>3.4</td>
<td>5.4</td>
<td>2.3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">149</td>
<td>5.9</td>
<td>3.0</td>
<td>5.1</td>
<td>1.8</td>
</tr>
</tbody>
</table>

<p>150 rows × 4 columns</p>
</div>
</div>
</div>
</section>
<section id="데이터-타입-변경" class="level3">
<h3 class="anchored" data-anchor-id="데이터-타입-변경">데이터 타입 변경</h3>
<p>사용 가능한 타입</p>
<ul>
<li>int</li>
<li>float</li>
<li>bool</li>
<li>datetime</li>
<li>category</li>
<li>object</li>
</ul>
<div id="12b5f4f5" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">iris.dtypes</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>sepal_length    float64
sepal_width     float64
petal_length    float64
petal_width     float64
dtype: object</code></pre>
</div>
</div>
<div id="55ef10f6" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">iris[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_length'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_length'</span>].astype(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'int'</span>)</span>
<span id="cb31-2">iris[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_width'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'petal_length'</span>]] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb31-3">iris[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_width'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'petal_length'</span>]].astype(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'int'</span>)</span>
<span id="cb31-4">iris</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal_length</th>
<th data-quarto-table-cell-role="th">sepal_width</th>
<th data-quarto-table-cell-role="th">petal_length</th>
<th data-quarto-table-cell-role="th">petal_width</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5</td>
<td>3</td>
<td>1</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4</td>
<td>3</td>
<td>1</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4</td>
<td>3</td>
<td>1</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>3</td>
<td>1</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>3</td>
<td>1</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">145</td>
<td>6</td>
<td>3</td>
<td>5</td>
<td>2.3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">146</td>
<td>6</td>
<td>2</td>
<td>5</td>
<td>1.9</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">147</td>
<td>6</td>
<td>3</td>
<td>5</td>
<td>2.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">148</td>
<td>6</td>
<td>3</td>
<td>5</td>
<td>2.3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">149</td>
<td>5</td>
<td>3</td>
<td>5</td>
<td>1.8</td>
</tr>
</tbody>
</table>

<p>150 rows × 4 columns</p>
</div>
</div>
</div>
</section>
</section>
<section id="row-coumn-선택-추가-삭제" class="level2">
<h2 class="anchored" data-anchor-id="row-coumn-선택-추가-삭제">row / coumn 선택 추가 삭제</h2>
<section id="row-선택" class="level3">
<h3 class="anchored" data-anchor-id="row-선택">row 선택</h3>
<div id="f302c291" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">iris[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal_length</th>
<th data-quarto-table-cell-role="th">sepal_width</th>
<th data-quarto-table-cell-role="th">petal_length</th>
<th data-quarto-table-cell-role="th">petal_width</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5</td>
<td>3</td>
<td>1</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4</td>
<td>3</td>
<td>1</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4</td>
<td>3</td>
<td>1</td>
<td>0.2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>3</td>
<td>1</td>
<td>0.2</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="column-선택" class="level3">
<h3 class="anchored" data-anchor-id="column-선택">column 선택</h3>
<p>Series 형식으로 출력</p>
<div id="120e90b4" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">iris[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_length'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>0      5
1      4
2      4
3      4
4      5
      ..
145    6
146    6
147    6
148    6
149    5
Name: sepal_length, Length: 150, dtype: int64</code></pre>
</div>
</div>
<p>DataFrame 형식으로 출력</p>
<div id="f48d69b4" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">iris[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_length'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_width'</span>]]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal_length</th>
<th data-quarto-table-cell-role="th">sepal_width</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">145</td>
<td>6</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">146</td>
<td>6</td>
<td>2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">147</td>
<td>6</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">148</td>
<td>6</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">149</td>
<td>5</td>
<td>3</td>
</tr>
</tbody>
</table>

<p>150 rows × 2 columns</p>
</div>
</div>
</div>
</section>
<section id="column-row-선택" class="level3">
<h3 class="anchored" data-anchor-id="column-row-선택">column, row 선택</h3>
<div id="99f447c1" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">iris.loc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_length'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_width'</span>]]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal_length</th>
<th data-quarto-table-cell-role="th">sepal_width</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>5</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>4</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4</td>
<td>3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>3</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="dced888b" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">iris.iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal_width</th>
<th data-quarto-table-cell-role="th">petal_length</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>3</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="row-추가" class="level3">
<h3 class="anchored" data-anchor-id="row-추가">row 추가</h3>
<div id="e1ff00a2" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 방법 1: concat 사용</span></span>
<span id="cb38-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># df = pd.concat([df, pd.DataFrame([{'class': 'eng', 'score': 90}])], ignore_index=True)</span></span>
<span id="cb38-3"></span>
<span id="cb38-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 방법 2: loc 사용 </span></span>
<span id="cb38-5">df.loc[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(df)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'class'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'eng'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">90</span>}</span>
<span id="cb38-6">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">class</th>
<th data-quarto-table-cell-role="th">score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>kor</td>
<td>70</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>math</td>
<td>80</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>eng</td>
<td>90</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="column-추가" class="level3">
<h3 class="anchored" data-anchor-id="column-추가">column 추가</h3>
<div id="4ccbe3be" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'yo'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb39-2">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">class</th>
<th data-quarto-table-cell-role="th">score</th>
<th data-quarto-table-cell-role="th">yo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>kor</td>
<td>70</td>
<td>80</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>math</td>
<td>80</td>
<td>90</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>eng</td>
<td>90</td>
<td>100</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="row-삭제" class="level3">
<h3 class="anchored" data-anchor-id="row-삭제">row 삭제</h3>
<div id="225929fd" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">df.drop(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb40-2">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">class</th>
<th data-quarto-table-cell-role="th">score</th>
<th data-quarto-table-cell-role="th">yo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>kor</td>
<td>70</td>
<td>80</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>math</td>
<td>80</td>
<td>90</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="column-삭제" class="level3">
<h3 class="anchored" data-anchor-id="column-삭제">column 삭제</h3>
<div id="7a7a9991" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">df.drop(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'yo'</span>], inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb41-2">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">class</th>
<th data-quarto-table-cell-role="th">score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>kor</td>
<td>70</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>math</td>
<td>80</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
<section id="조건-선택" class="level2">
<h2 class="anchored" data-anchor-id="조건-선택">조건 선택</h2>
<div id="f1891b9d" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">iris[(iris[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_length'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (iris[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_width'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">sepal_length</th>
<th data-quarto-table-cell-role="th">sepal_width</th>
<th data-quarto-table-cell-role="th">petal_length</th>
<th data-quarto-table-cell-role="th">petal_width</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">54</td>
<td>6</td>
<td>2</td>
<td>4</td>
<td>1.5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">58</td>
<td>6</td>
<td>2</td>
<td>4</td>
<td>1.3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">62</td>
<td>6</td>
<td>2</td>
<td>4</td>
<td>1.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">63</td>
<td>6</td>
<td>2</td>
<td>4</td>
<td>1.4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">68</td>
<td>6</td>
<td>2</td>
<td>4</td>
<td>1.5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">130</td>
<td>7</td>
<td>2</td>
<td>6</td>
<td>1.9</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">132</td>
<td>6</td>
<td>2</td>
<td>5</td>
<td>2.2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">133</td>
<td>6</td>
<td>2</td>
<td>5</td>
<td>1.5</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">134</td>
<td>6</td>
<td>2</td>
<td>5</td>
<td>1.4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">146</td>
<td>6</td>
<td>2</td>
<td>5</td>
<td>1.9</td>
</tr>
</tbody>
</table>

<p>29 rows × 4 columns</p>
</div>
</div>
</div>
<div id="be8c4f64" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">df.loc[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'합격'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Pass'</span></span>
<span id="cb43-2">df.loc[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'합격'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Pass'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'합격'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Fail'</span></span>
<span id="cb43-3">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">class</th>
<th data-quarto-table-cell-role="th">score</th>
<th data-quarto-table-cell-role="th">합격</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>kor</td>
<td>70</td>
<td>Fail</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>math</td>
<td>80</td>
<td>Pass</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="9f0874d8" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb44-2"></span>
<span id="cb44-3">condition_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span>), </span>
<span id="cb44-4">                  (df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>),</span>
<span id="cb44-5">                  (df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>)]</span>
<span id="cb44-6">grade_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'A'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'B'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'C'</span>]</span>
<span id="cb44-7">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'grade'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.select(condition_list, grade_list, default<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'F'</span>)</span>
<span id="cb44-8">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">class</th>
<th data-quarto-table-cell-role="th">score</th>
<th data-quarto-table-cell-role="th">합격</th>
<th data-quarto-table-cell-role="th">grade</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>kor</td>
<td>70</td>
<td>Fail</td>
<td>A</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>math</td>
<td>80</td>
<td>Pass</td>
<td>A</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<section id="결측치-탐색" class="level3">
<h3 class="anchored" data-anchor-id="결측치-탐색">결측치 탐색</h3>
<div id="e68561ed" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1">df.isna().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>class    0
score    0
합격       0
grade    0
dtype: int64</code></pre>
</div>
</div>
<div id="6c3f43d2" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1">df.notna().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 행 기준</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>0    4
1    4
dtype: int64</code></pre>
</div>
</div>
</section>
<section id="결측치-제거" class="level3">
<h3 class="anchored" data-anchor-id="결측치-제거">결측치 제거</h3>
<div id="ec9e100e" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># dropna(axis=0, how='any' or 'all', thresh=None, subset=None, inplace=False)</span></span>
<span id="cb49-2">df.dropna()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">class</th>
<th data-quarto-table-cell-role="th">score</th>
<th data-quarto-table-cell-role="th">합격</th>
<th data-quarto-table-cell-role="th">grade</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>kor</td>
<td>70</td>
<td>Fail</td>
<td>A</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>math</td>
<td>80</td>
<td>Pass</td>
<td>A</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="결측치-대체" class="level3">
<h3 class="anchored" data-anchor-id="결측치-대체">결측치 대체</h3>
<div id="3f9eab98" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># fillna(value=None, method=None ('pad', 'ffill', 'backfill', 'bfill'), axis=None, inplace=False, limit=None)</span></span></code></pre></div>
</div>


</section>
</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>데이터 분석</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/01.html</guid>
  <pubDate>Sat, 20 Sep 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>전처리</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/core/01.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="결측치-처리" class="level2">
<h2 class="anchored" data-anchor-id="결측치-처리">결측치 처리</h2>
<ul>
<li>대푯값으로 대체</li>
<li>단순확률대치법</li>
<li>다른 모델로 예측</li>
<li>보간법: 시계열에서 주로 사용.</li>
</ul>
</section>
<section id="이상치-처리" class="level2">
<h2 class="anchored" data-anchor-id="이상치-처리">이상치 처리</h2>
<ul>
<li>ESD</li>
<li>IQR</li>
<li>DBSCAN</li>
</ul>
</section>
<section id="클래스-불균형" class="level2">
<h2 class="anchored" data-anchor-id="클래스-불균형">클래스 불균형</h2>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>확률 통계</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/core/01.html</guid>
  <pubDate>Fri, 15 Aug 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>EDA</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/core/00.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="질적-변수" class="level2">
<h2 class="anchored" data-anchor-id="질적-변수">질적 변수</h2>
<section id="상관분석" class="level3">
<h3 class="anchored" data-anchor-id="상관분석">상관분석</h3>
<div id="0c85a918" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.stats <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> spearmanr, kendalltau</span>
<span id="cb1-2"></span>
<span id="cb1-3">corr, p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> spearmanr(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'var1'</span>], df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'var2'</span>])</span>
<span id="cb1-4"></span>
<span id="cb1-5">corr, p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kendalltau(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'var1'</span>], df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'var2'</span>])</span>
<span id="cb1-6"></span>
<span id="cb1-7">df.corr(method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'kendall'</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># kendal, spearman</span></span></code></pre></div>
</div>
<div id="91a526a6" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.stats.contingeny <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> association</span>
<span id="cb2-2"></span>
<span id="cb2-3">v2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> association(table.values, method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tschuprow"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># phi 계수</span></span>
<span id="cb2-4">v2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> association(table.values, method<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cramer'</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 크래머 v</span></span>
<span id="cb2-5">v2</span></code></pre></div>
</div>
<ul>
<li>상관계수: 공분산을 각 변수의 표준편차로 나눈 것</li>
<li>스피어만 상관계수: 서열척도 vs 서열척도. 확률분포에 대한 가정 필요 없음.</li>
<li>켄달의 타우: 서열척도 vs 서열척도.
<ul>
<li>둘 중 하나가 연속형이여도 스피어만, 켄달의 타우 중 하나를 사용.</li>
<li>샘플이 적거나, 이상치, 동점이 많은 경우 켄달의 타우를 주로 사용.</li>
<li>두 변수의 크기는 같아야함.</li>
</ul></li>
<li>phi 계수: 명목척도 vs 명목척도
<ul>
<li>두 변인 모두 level이 2개일 때 사용</li>
<li>두 변수를 0과 1로 바꾼 후 pearson 상관계수 계산</li>
</ul></li>
<li>크래머 v: 명목척도 vs 명목척도.
<ul>
<li>적어도 하나의 변수가 3개 이상의 level을 가지면 사용</li>
<li>범위는 0~1. 0.2 이하면 서로 연관성이 약하고, 0.6 이상이면 서로 연관성이 높음.</li>
</ul></li>
<li>Point-biserial correlation: 명목척도 vs 연속형
<ul>
<li>명목척도의 level이 2개일 때</li>
</ul></li>
<li>Polyserial correlation: 명목척도 vs 연속형
<ul>
<li>명목척도의 level이 3개 이상일 때</li>
</ul></li>
<li>명목과 순서의 경우
<ul>
<li>level이 2개: Mann-Whitney U검정</li>
<li>3개 이상: Kruskal-Wallis H test</li>
</ul></li>
</ul>
</section>
<section id="시각화" class="level3">
<h3 class="anchored" data-anchor-id="시각화">시각화</h3>
<div id="331bf90e" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb3-2"></span>
<span id="cb3-3">cols <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'your'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'target'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cols'</span>, ...]</span>
<span id="cb3-4">freq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(df[cols].value_counts()) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 도수분포표</span></span>
<span id="cb3-5">freq[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'proportion'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[cols].value_counts(normalize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 상대도수분포표</span></span></code></pre></div>
</div>
<div id="14b5320c" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">freq[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'count'</span>].plot.bar(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>), subplots<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, layout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))</span>
<span id="cb4-2">plt.tight_layout()</span>
<span id="cb4-3">plt.show()</span></code></pre></div>
</div>
<div id="35130288" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">plt.pie(freq[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'count'</span>].values, </span>
<span id="cb5-2">        labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>freq.index, </span>
<span id="cb5-3">        autopct<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%1.1f%%</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, </span>
<span id="cb5-4">        colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sns.color_palette(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pastel'</span>, n_colors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(freq)))</span>
<span id="cb5-5">plt.show()</span></code></pre></div>
</div>
</section>
</section>
<section id="양적-변수" class="level2">
<h2 class="anchored" data-anchor-id="양적-변수">양적 변수</h2>
<section id="기술통계" class="level3">
<h3 class="anchored" data-anchor-id="기술통계">기술통계</h3>
<div id="eabaed26" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.stats.mstats <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> gmean, hmean, tmean</span>
<span id="cb6-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb6-3"></span>
<span id="cb6-4">np.mean(example) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 산술평균</span></span>
<span id="cb6-5">gmean(example) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 기하평균</span></span>
<span id="cb6-6">hmean(example) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 조화평균</span></span>
<span id="cb6-7">tmean(example, (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 절사평균</span></span>
<span id="cb6-8">np.sqrt(np.mean(np.array(example) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 평방평균</span></span></code></pre></div>
</div>
<ul>
<li>기하평균: 비율의 평균에 주로 사용됨. 한 값이라도 0이면 전체가 0이 됨</li>
<li>조화평균: 속도, 밀도 등의 평균에 주로 사용됨.</li>
<li>절사평균: 극단값의 영향을 줄이기 위해 상위, 하위 몇 %를 제외한 평균</li>
<li>평방평균: 신호, 파동 등에서 자주 사용</li>
</ul>
<div id="a848a5fa" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">df.median()</span>
<span id="cb7-2">df.mode()[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb7-3">df.quantile(q<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>)</span></code></pre></div>
</div>
<ul>
<li>상관계수: 피어슨</li>
</ul>
</section>
<section id="시각화-1" class="level3">
<h3 class="anchored" data-anchor-id="시각화-1">시각화</h3>
<ul>
<li>도수분포표</li>
<li>상대도수분포표</li>
<li>줄기잎그림</li>
<li>히스토그램</li>
<li>상자그림</li>
<li>산점도</li>
</ul>


</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>확률 통계</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/core/00.html</guid>
  <pubDate>Mon, 04 Aug 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>분류 - 신용 카드 사기 검출</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/04.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="under-over-sampling" class="level2">
<h2 class="anchored" data-anchor-id="under-over-sampling">under, over sampling</h2>
<ul>
<li>under sampling: 많은 비중을 차지하는 레이블을 작은 비중의 레이블에 맞추는것</li>
<li>over sampling: 반대
<ul>
<li>smote: k 최근접 이웃 진행 후, 이웃 간 간격을 맞추는 record를 새로 생성하는 방식</li>
</ul></li>
</ul>
<div id="05f6e255" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span></code></pre></div>
</div>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>머신 러닝</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/04.html</guid>
  <pubDate>Fri, 01 Aug 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>텍스트 분석 - 감성 분석</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/09.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>머신 러닝</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/09.html</guid>
  <pubDate>Tue, 29 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>텍스트 분석 - 20 뉴스그룹 분류</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/08.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="전처리" class="level2">
<h2 class="anchored" data-anchor-id="전처리">전처리</h2>
<div id="e4db7dfd" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> fetch_20newsgroups</span>
<span id="cb1-2"></span>
<span id="cb1-3">train_news <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fetch_20newsgroups(subset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'train'</span>, remove<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'headers'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'footers'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'quates'</span>))</span>
<span id="cb1-4">X_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_news.data</span>
<span id="cb1-5">y_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_news.target</span>
<span id="cb1-6"></span>
<span id="cb1-7">test_news <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fetch_20newsgroups(subset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'test'</span>, remove<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'headers'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'footers'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'quates'</span>))</span>
<span id="cb1-8">X_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> test_news.data</span>
<span id="cb1-9">y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> test_news.target</span></code></pre></div>
</div>
</section>
<section id="학습" class="level2">
<h2 class="anchored" data-anchor-id="학습">학습</h2>
<section id="count-vector" class="level3">
<h3 class="anchored" data-anchor-id="count-vector">Count Vector</h3>
<div id="232c2224" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.feature_extraction.text <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> CountVectorizer</span>
<span id="cb2-2"></span>
<span id="cb2-3">cnt_vect <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CountVectorizer()</span>
<span id="cb2-4">X_train_cnt_vect <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cnt_vect.fit_transform(X_train)</span>
<span id="cb2-5">X_test_cnt_vect <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cnt_vect.transform(X_test)</span></code></pre></div>
</div>
<div id="0069beaf" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LogisticRegression</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> accuracy_score</span>
<span id="cb3-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> warnings</span>
<span id="cb3-4"></span>
<span id="cb3-5">warnings.filterwarnings(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ignore'</span>)</span>
<span id="cb3-6"></span>
<span id="cb3-7">lr_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LogisticRegression(solver<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'liblinear'</span>)</span>
<span id="cb3-8">lr_clf.fit(X_train_cnt_vect, y_train)</span>
<span id="cb3-9">pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lr_clf.predict(X_test_cnt_vect)</span>
<span id="cb3-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>accuracy_score(y_test, pred)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> '</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.731 </code></pre>
</div>
</div>
</section>
<section id="tf-idf" class="level3">
<h3 class="anchored" data-anchor-id="tf-idf">TF-IDF</h3>
<div id="dcfcfa23" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.feature_extraction.text <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> TfidfVectorizer</span>
<span id="cb5-2"></span>
<span id="cb5-3">tfidf_vect <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TfidfVectorizer()</span>
<span id="cb5-4">X_train_tfidf_vect <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tfidf_vect.fit_transform(X_train)</span>
<span id="cb5-5">X_test_tfidf_vect <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tfidf_vect.transform(X_test)</span>
<span id="cb5-6"></span>
<span id="cb5-7">lr_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LogisticRegression(solver<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'liblinear'</span>)</span>
<span id="cb5-8">lr_clf.fit(X_train_tfidf_vect, y_train)</span>
<span id="cb5-9">pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lr_clf.predict(X_test_tfidf_vect)</span>
<span id="cb5-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>accuracy_score(y_test, pred)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> '</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.778 </code></pre>
</div>
</div>


</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>머신 러닝</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/08.html</guid>
  <pubDate>Tue, 29 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>텍스트 분석</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/07.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">overview</h2>
<section id="nlp-vs-텍스트-분석" class="level3">
<h3 class="anchored" data-anchor-id="nlp-vs-텍스트-분석">NLP vs 텍스트 분석</h3>
<ul>
<li>NLP(자연어 처리)는 컴퓨터가 인간의 언어를 이해하고 처리하는 기술을 의미</li>
<li>텍스트 분석은 주로 비정형 텍스트 데이터를 머신러닝, 통계 등의 방법으로 예측 분석이나 유용한 정보를 추출하는 데 중점을 둔다.</li>
</ul>
</section>
<section id="종류" class="level3">
<h3 class="anchored" data-anchor-id="종류">종류</h3>
<ul>
<li>텍스트 분류: 문서가 특정 분류 또는 카테고리에 속하는 것을 예측 (연예 / 정치 / 스포츠 같은 카테고리 분류 혹은 스팸 메일 검출). 지도 학습</li>
<li>감성 분석: 텍스트에서 주관적 요소를 분석하는 기법. 지도 혹은 비지도.</li>
<li>텍스트 요약: 텍스트 내에서 주제나 중심 사상을 추출</li>
<li>텍스트 군집화: 비슷한 유형의 문서를 군집화 하는 것. 비지도 학습</li>
</ul>
</section>
</section>
<section id="프로세스" class="level2">
<h2 class="anchored" data-anchor-id="프로세스">프로세스</h2>
<ol type="1">
<li>텍스트 전처리: 대 / 소문자 변경, 특수 문자 제거, 토큰화, 불용어 제거, 어근 추출 등의 정규화 작업</li>
<li>피처 벡터화 / 추출: 텍스트에서 피처를 추출하고 벡터 값을 할당. BOW와 Word2Vec이 대표적</li>
<li>ML 모델 수립 및 학습 / 예측 / 평가</li>
</ol>
</section>
<section id="전처리" class="level2">
<h2 class="anchored" data-anchor-id="전처리">전처리</h2>
<ul>
<li>클렌징: 문자, 기호 등을 사전에 제거</li>
<li>토큰화
<ul>
<li>문장 토큰화: 마침표, 개행문자 등을 기준으로 문장을 분리. 각 문장이 가지는 의미가 중요한 경우 사용.</li>
<li>단어 토큰화: 공백, 콤마, 마침표, 개행문자 등으로 단어를 분리.
<ul>
<li>n-gram: 단어의 연속된 n개를 묶어서 하나의 단위로 처리하는 방법. 문장이 가지는 의미를 조금이라도 보존할 수 있다.</li>
</ul></li>
</ul></li>
</ul>
<div id="63c1ee71" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> nltk <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> sent_tokenize</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> nltk</span>
<span id="cb1-3">nltk.download(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'punkt'</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 문장을 분리하는 마침표, 개행문자 등의 데이터 셋 다운로드</span></span>
<span id="cb1-4">nltk.download(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'punkt_tab'</span>)</span>
<span id="cb1-5"></span>
<span id="cb1-6">text_sample <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The Matrix is everywhere its all around us, here even in this room. You can see it when you look out your window or when you turn on your television. You can feel it when you go to work, when you go to church, when you pay your taxes."</span></span>
<span id="cb1-7">sentences <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sent_tokenize(text_sample)</span>
<span id="cb1-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(sentences)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['The Matrix is everywhere its all around us, here even in this room.', 'You can see it when you look out your window or when you turn on your television.', 'You can feel it when you go to work, when you go to church, when you pay your taxes.']</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package punkt to
[nltk_data]     /home/cryscham123/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt_tab to
[nltk_data]     /home/cryscham123/nltk_data...
[nltk_data]   Package punkt_tab is already up-to-date!</code></pre>
</div>
</div>
<div id="6b8b73f5" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> nltk <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> word_tokenize</span>
<span id="cb4-2"></span>
<span id="cb4-3">sentence <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The Matrix is everywhere its all around us, here even in this room."</span></span>
<span id="cb4-4">words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> word_tokenize(sentence)</span>
<span id="cb4-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(words)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']</code></pre>
</div>
</div>
<div id="7f605e1a" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> tokenize_text(text):</span>
<span id="cb6-2">    sentences <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sent_tokenize(text)</span>
<span id="cb6-3">    words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [word_tokenize(sentence) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> sentence <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> sentences]</span>
<span id="cb6-4"></span>
<span id="cb6-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> words</span>
<span id="cb6-6"></span>
<span id="cb6-7">word_tokens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenize_text(text_sample)</span>
<span id="cb6-8">word_tokens</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>[['The',
  'Matrix',
  'is',
  'everywhere',
  'its',
  'all',
  'around',
  'us',
  ',',
  'here',
  'even',
  'in',
  'this',
  'room',
  '.'],
 ['You',
  'can',
  'see',
  'it',
  'when',
  'you',
  'look',
  'out',
  'your',
  'window',
  'or',
  'when',
  'you',
  'turn',
  'on',
  'your',
  'television',
  '.'],
 ['You',
  'can',
  'feel',
  'it',
  'when',
  'you',
  'go',
  'to',
  'work',
  ',',
  'when',
  'you',
  'go',
  'to',
  'church',
  ',',
  'when',
  'you',
  'pay',
  'your',
  'taxes',
  '.']]</code></pre>
</div>
</div>
<ul>
<li>stopword 제거: 분석에 필요하지 않은 단어를 제거하는 작업. 예) 관사, 전치사, 접속사 등</li>
</ul>
<div id="198f8e8c" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> nltk.corpus <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> stopwords</span>
<span id="cb8-2">nltk.download(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'stopwords'</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># stopwords 데이터 셋 다운로드</span></span>
<span id="cb8-3"></span>
<span id="cb8-4">stopwords.words(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'english'</span>)[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>]</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package stopwords to
[nltk_data]     /home/cryscham123/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>['a',
 'about',
 'above',
 'after',
 'again',
 'against',
 'ain',
 'all',
 'am',
 'an',
 'and',
 'any',
 'are',
 'aren',
 "aren't",
 'as',
 'at',
 'be',
 'because',
 'been']</code></pre>
</div>
</div>
<div id="88ec22e1" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">sw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> stopwords.words(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'english'</span>)</span>
<span id="cb11-2">all_tokens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb11-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> sentence <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> word_tokens:</span>
<span id="cb11-4">    filtered_words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb11-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> word <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> sentence:</span>
<span id="cb11-6">        word <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> word.lower()</span>
<span id="cb11-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> word <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> sw:</span>
<span id="cb11-8">            filtered_words.append(word)</span>
<span id="cb11-9">    all_tokens.append(filtered_words)</span>
<span id="cb11-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(all_tokens)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'], ['see', 'look', 'window', 'turn', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', ',', 'pay', 'taxes', '.']]</code></pre>
</div>
</div>
<ul>
<li>stemming, lemmatization: 문법적 또는 의미적으로 변화하는 단어의 원형을 찾는 것
<ul>
<li>stemming이 더 단순하고 빠르지만 lemmatization 이 더 저오학함</li>
</ul></li>
</ul>
<div id="dab74859" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> nltk.stem <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LancasterStemmer</span>
<span id="cb13-2"></span>
<span id="cb13-3">stemmer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LancasterStemmer()</span>
<span id="cb13-4"></span>
<span id="cb13-5"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(stemmer.stem(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'working'</span>), stemmer.stem(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'works'</span>), stemmer.stem(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'worked'</span>))</span>
<span id="cb13-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(stemmer.stem(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'amusing'</span>), stemmer.stem(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'amuses'</span>), stemmer.stem(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'amused'</span>))</span>
<span id="cb13-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(stemmer.stem(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'happier'</span>), stemmer.stem(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'happiest'</span>))</span>
<span id="cb13-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(stemmer.stem(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'fancier'</span>), stemmer.stem(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'fanciest'</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>work work work
amus amus amus
happy happiest
fant fanciest</code></pre>
</div>
</div>
<div id="96465f65" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> nltk.stem <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> WordNetLemmatizer</span>
<span id="cb15-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> nltk</span>
<span id="cb15-3">nltk.download(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'wordnet'</span>)</span>
<span id="cb15-4"></span>
<span id="cb15-5">lemma <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> WordNetLemmatizer()</span>
<span id="cb15-6"></span>
<span id="cb15-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(lemma.lemmatize(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'amusing'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'v'</span>), lemma.lemmatize(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'amuses'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'v'</span>), lemma.lemmatize(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'amused'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'v'</span>))</span>
<span id="cb15-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(lemma.lemmatize(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'happier'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'a'</span>), lemma.lemmatize(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'happiest'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'a'</span>))</span>
<span id="cb15-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(lemma.lemmatize(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'fancier'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'a'</span>), lemma.lemmatize(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'fanciest'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'a'</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>amuse amuse amuse
happy happy
fancy fancy</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package wordnet to
[nltk_data]     /home/cryscham123/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!</code></pre>
</div>
</div>
</section>
<section id="bow" class="level2">
<h2 class="anchored" data-anchor-id="bow">BOW</h2>
<ul>
<li>문서가 가지는 모든 단어를 문맥이나 순서를 무시하고 빈도 값을 부여해 피처 값을 추출하는 모델</li>
<li>count 기반 벡터화: 빈도가 높을수록 중요한 단어로 인식</li>
<li>TF-IDF(term frequency - inverse document frequency) 기반 벡터화: 빈도가 높을수록 좋으나, 모든 문서에서 전반적으로 나타나는 단어에 대해서는 패털티를 줌
<ul>
<li><img src="https://latex.codecogs.com/png.latex?TF_i%20*%20log%5Cfrac%7BN%7D%7BDF_i%7D">
<ul>
<li><img src="https://latex.codecogs.com/png.latex?TF_i">: 개별 문서에서의 단어 i 빈도</li>
<li><img src="https://latex.codecogs.com/png.latex?DF_i">: 단어 i를 가지고 있는 문서 개수</li>
<li>N: 전체 문서 개수</li>
</ul></li>
</ul></li>
<li>희소행렬 문제: 불필요한 0 값이 많아지는 문제
<ul>
<li>COO</li>
<li>CSR</li>
<li>혹은 희소행렬을 잘 처리하는 알고리즘: 로지스틱 회귀, 선형 svm, 나이브 베이즈 등</li>
</ul></li>
</ul>
<section id="coo" class="level3">
<h3 class="anchored" data-anchor-id="coo">COO</h3>
<ul>
<li>0이 아닌 데이터만 별도의 array에 저장.</li>
</ul>
<div id="aab7eb13" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb18-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> sparse</span>
<span id="cb18-3"></span>
<span id="cb18-4">dense <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]])</span>
<span id="cb18-5">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>])</span>
<span id="cb18-6">row_pos <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb18-7">col_pos <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb18-8">sparse_coo <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sparse.coo_matrix((data, (row_pos, col_pos)))</span>
<span id="cb18-9">sparse_coo</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>&lt;COOrdinate sparse matrix of dtype 'int64'
    with 3 stored elements and shape (2, 3)&gt;</code></pre>
</div>
</div>
<div id="920b655f" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">sparse_coo.toarray()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>array([[3, 0, 1],
       [0, 2, 0]])</code></pre>
</div>
</div>
</section>
<section id="csr" class="level3">
<h3 class="anchored" data-anchor-id="csr">CSR</h3>
<ul>
<li>COO + 시작위치만 기록하는 방법</li>
</ul>
<div id="29fe3804" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> sparse</span>
<span id="cb22-2"></span>
<span id="cb22-3">dense2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>],</span>
<span id="cb22-4">                   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>],</span>
<span id="cb22-5">                   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb22-6">                   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb22-7">                   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>],</span>
<span id="cb22-8">                   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]])</span>
<span id="cb22-9">data2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb22-10">row_pos <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>])</span>
<span id="cb22-11">col_pos <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb22-12">row_pos_ind <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>])</span>
<span id="cb22-13"></span>
<span id="cb22-14">sparse_csr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sparse.csr_matrix((data2, col_pos, row_pos_ind))</span>
<span id="cb22-15">sparse_csr.toarray()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>array([[0, 0, 1, 0, 0, 5],
       [1, 4, 0, 3, 2, 5],
       [0, 6, 0, 3, 0, 0],
       [2, 0, 0, 0, 0, 0],
       [0, 0, 0, 7, 0, 8],
       [1, 0, 0, 0, 0, 0]])</code></pre>
</div>
</div>
<div id="e6d22228" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">sparse_csr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sparse.csr_matrix(dense2)</span>
<span id="cb24-2">sparse_csr.toarray()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>array([[0, 0, 1, 0, 0, 5],
       [1, 4, 0, 3, 2, 5],
       [0, 6, 0, 3, 0, 0],
       [2, 0, 0, 0, 0, 0],
       [0, 0, 0, 7, 0, 8],
       [1, 0, 0, 0, 0, 0]])</code></pre>
</div>
</div>


</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>머신 러닝</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/07.html</guid>
  <pubDate>Tue, 29 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>차원 축소</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/06.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="pca" class="level2">
<h2 class="anchored" data-anchor-id="pca">PCA</h2>
<div id="cb1d936b" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_iris</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-4"></span>
<span id="cb1-5">iris <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_iris()</span>
<span id="cb1-6">columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_length'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_width'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'petal_length'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'petal_width'</span>]</span>
<span id="cb1-7">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(iris.data, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>columns)</span>
<span id="cb1-8">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'target'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.target</span>
<span id="cb1-9">markers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'^'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'s'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>]</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, marker <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(markers):</span>
<span id="cb1-12">    x_axis_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'target'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_length'</span>]</span>
<span id="cb1-13">    y_axis_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'target'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal_width'</span>]</span>
<span id="cb1-14">    plt.scatter(x_axis_data, y_axis_data, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>marker, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.target_names[i])</span>
<span id="cb1-15">plt.legend()</span>
<span id="cb1-16">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal length'</span>)</span>
<span id="cb1-17">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sepal width'</span>)</span>
<span id="cb1-18">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/06_files/figure-html/cell-2-output-1.png" width="589" height="432" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>PCA는 scaling의 영향을 받음.</li>
</ul>
<div id="5cda3239" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.decomposition <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PCA</span>
<span id="cb2-3"></span>
<span id="cb2-4">scaled_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler().fit_transform(df.iloc[:, :<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb2-5"></span>
<span id="cb2-6">pca <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PCA(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb2-7">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pca.fit_transform(scaled_df)</span></code></pre></div>
</div>
<div id="2991346c" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">pca_columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca_component_1'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca_component_2'</span>]</span>
<span id="cb3-2">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(df, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pca_columns)</span>
<span id="cb3-3">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'target'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.target</span></code></pre></div>
</div>
<div id="26863b93" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">markers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'^'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'s'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>]</span>
<span id="cb4-2"></span>
<span id="cb4-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, marker <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(markers):</span>
<span id="cb4-4">    x_axis_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'target'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca_component_1'</span>]</span>
<span id="cb4-5">    y_axis_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'target'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca_component_2'</span>]</span>
<span id="cb4-6">    plt.scatter(x_axis_data, y_axis_data, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>marker, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.target_names[i])</span>
<span id="cb4-7">plt.legend()</span>
<span id="cb4-8">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca_component_1'</span>)</span>
<span id="cb4-9">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pca_component_2'</span>)</span>
<span id="cb4-10">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/06_files/figure-html/cell-5-output-1.png" width="587" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="신용카드-고객-데이터" class="level2">
<h2 class="anchored" data-anchor-id="신용카드-고객-데이터">신용카드 고객 데이터</h2>
<div id="7ddc060a" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_excel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/creadit_card.xls'</span>, header<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, sheet_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Data'</span>).iloc[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:]</span>
<span id="cb5-2">df.rename(columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PAY_0'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PAY_1'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'default payment next month'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'default'</span>}, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb5-3">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'default'</span>]</span>
<span id="cb5-4">features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'default'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
</div>
<div id="689f1e58" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb6-2"></span>
<span id="cb6-3">corr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> features.corr()</span>
<span id="cb6-4">sns.heatmap(corr, annot<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, fmt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.1g'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/06_files/figure-html/cell-7-output-1.png" width="610" height="482" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>BILL_AMT1~6, PAY_1~6의 상관도가 높다.</li>
</ul>
<div id="d35a5afa" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">cols_bill <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'BILL_AMT'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(i) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>)]</span>
<span id="cb7-2">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb7-3">df_cols_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(features[cols_bill])</span>
<span id="cb7-4">pca <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PCA(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb7-5">pca.fit(df_cols_scaled)</span>
<span id="cb7-6">pca.explained_variance_ratio_</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>array([0.90555253, 0.0509867 ])</code></pre>
</div>
</div>
<ul>
<li>PCA 할 때 column 전부 다 안 넣어도 되나?</li>
<li>다 넣어야 하는 듯</li>
</ul>
</section>
<section id="lda" class="level2">
<h2 class="anchored" data-anchor-id="lda">LDA</h2>
<ul>
<li>클래스 분리를 최대화하는 축을 찾음</li>
<li>PCA와 다르게 지도 학습임.</li>
</ul>
<div id="7ca579cb" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.discriminant_analysis <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearDiscriminantAnalysis</span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler</span>
<span id="cb9-3"></span>
<span id="cb9-4">iris <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_iris()</span>
<span id="cb9-5">iris_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler().fit_transform(iris.data)</span></code></pre></div>
</div>
<div id="4f389cb7" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">lda <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearDiscriminantAnalysis(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb10-2">iris_lda <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lda.fit_transform(iris_scaled, iris.target)</span></code></pre></div>
</div>
<div id="1fdd19bc" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">lda_columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lda_components_1'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lda_components_2'</span>]</span>
<span id="cb11-2">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(iris_lda, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lda_columns)</span>
<span id="cb11-3">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'target'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> iris.target</span>
<span id="cb11-4"></span>
<span id="cb11-5">markers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'^'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'s'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>]</span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, marker <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(markers):</span>
<span id="cb11-8">    x_axis_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'target'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lda_components_1'</span>]</span>
<span id="cb11-9">    y_axis_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'target'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lda_components_2'</span>]</span>
<span id="cb11-10">    plt.scatter(x_axis_data, y_axis_data, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>marker, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris.target_names[i])</span>
<span id="cb11-11">plt.legend()</span>
<span id="cb11-12">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lda_components_1'</span>)</span>
<span id="cb11-13">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'lda_components_2'</span>)</span>
<span id="cb11-14">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/06_files/figure-html/cell-11-output-1.png" width="587" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>머신 러닝</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/06.html</guid>
  <pubDate>Mon, 28 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>회귀</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/05.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="경사하강법" class="level2">
<h2 class="anchored" data-anchor-id="경사하강법">경사하강법</h2>
<div id="72757eac" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"></span>
<span id="cb1-4">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.random.rand(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-5">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-6">plt.scatter(X, y)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/05_files/figure-html/cell-2-output-1.png" width="566" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="679facc8" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_cost(y, y_pred):</span>
<span id="cb2-2">    N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y)</span>
<span id="cb2-3">    cost <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(np.square(y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y_pred)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> N</span>
<span id="cb2-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> cost</span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_weight_updates(w1, w0, X, y, learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>):</span>
<span id="cb2-7">    N <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(y)</span>
<span id="cb2-8">    w1_update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros_like(w1)</span>
<span id="cb2-9">    w0_update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros_like(w0)</span>
<span id="cb2-10">    y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.dot(X, w1.T) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> w0</span>
<span id="cb2-11">    diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> y_pred</span>
<span id="cb2-12"></span>
<span id="cb2-13">    w1_update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>N) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.dot(X.T, diff)</span>
<span id="cb2-14">    w0_update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>N) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> learning_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(diff)</span>
<span id="cb2-15"></span>
<span id="cb2-16">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> w1_update, w0_update</span>
<span id="cb2-17"></span>
<span id="cb2-18"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> gradient_descent_steps(X, y, iters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>):</span>
<span id="cb2-19">    w0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb2-20">    w1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb2-21"></span>
<span id="cb2-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(iters):</span>
<span id="cb2-23">        w1_update, w0_update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_weight_updates(w1, w0, X, y, learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>)</span>
<span id="cb2-24">        w1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> w1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> w1_update</span>
<span id="cb2-25">        w0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> w0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> w0_update</span>
<span id="cb2-26"></span>
<span id="cb2-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> w1, w0</span></code></pre></div>
</div>
<div id="b9d1775e" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">w1, w0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gradient_descent_steps(X, y, iters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb3-2">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> w1[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> w0</span>
<span id="cb3-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'w0: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>w0[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> w1: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>w1[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, total cost: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>get_cost(y, y_pred)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb3-4">plt.scatter(X, y)</span>
<span id="cb3-5">plt.plot(X, y_pred)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>w0: 5.955 w1: 3.940, total cost: 1.018</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/05_files/figure-html/cell-4-output-2.png" width="566" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>일반 경사하강법은 시간이 오래걸려서 잘 안씀</li>
</ul>
</section>
<section id="미니-배치-확률적-경사-하강법" class="level2">
<h2 class="anchored" data-anchor-id="미니-배치-확률적-경사-하강법">미니 배치 확률적 경사 하강법</h2>
<div id="81b437bc" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> stochastic_gradient_descent_steps(X, y, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, iters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>):</span>
<span id="cb5-2">    w0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb5-3">    w1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb5-4"></span>
<span id="cb5-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> ind <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(iters):</span>
<span id="cb5-6">        stochastic_random_index <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.permutation(X.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb5-7">        sample_X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[stochastic_random_index[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:batch_size]]</span>
<span id="cb5-8">        sample_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y[stochastic_random_index[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:batch_size]]</span>
<span id="cb5-9"></span>
<span id="cb5-10">        w1_update, w0_update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_weight_updates(w1, w0, sample_X, sample_y, learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>)</span>
<span id="cb5-11">        w1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> w1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> w1_update</span>
<span id="cb5-12">        w0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> w0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> w0_update</span>
<span id="cb5-13"></span>
<span id="cb5-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> w1, w0</span></code></pre></div>
</div>
<div id="7ce5cf77" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">w1, w0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> stochastic_gradient_descent_steps(X, y, iters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb6-2">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> w1[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> w0</span>
<span id="cb6-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'w0: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>w0[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> w1: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>w1[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, total cost: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>get_cost(y, y_pred)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb6-4">plt.scatter(X, y)</span>
<span id="cb6-5">plt.plot(X, y_pred)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>w0: 5.931 w1: 3.978, total cost: 1.021</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/05_files/figure-html/cell-6-output-2.png" width="566" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="선형-회귀" class="level2">
<h2 class="anchored" data-anchor-id="선형-회귀">선형 회귀</h2>
<div id="6c4fd569" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb8-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb8-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> stats</span>
<span id="cb8-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_boston</span>
<span id="cb8-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> warnings</span>
<span id="cb8-6"></span>
<span id="cb8-7">warnings.filterwarnings(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ignore'</span>)</span>
<span id="cb8-8"></span>
<span id="cb8-9">boston <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_boston()</span>
<span id="cb8-10"></span>
<span id="cb8-11">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(boston.data, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>boston.feature_names)</span>
<span id="cb8-12">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'price'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> boston.target</span>
<span id="cb8-13">df.head()</span></code></pre></div>
</div>
<div id="a9d30dd9" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">lm_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RM'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ZN'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'INDUS'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'NOX'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'AGE'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PTRAIO'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LSTAT'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'RAD'</span>]</span>
<span id="cb9-2"></span>
<span id="cb9-3">fig, axs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>), ncols<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(lm_features) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, nrows<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb9-4"></span>
<span id="cb9-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, feature <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(lm_features):</span>
<span id="cb9-6">    row <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb9-7">    col <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb9-8"></span>
<span id="cb9-9">    sns.regplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>feature, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'price'</span>, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axs[row][col])</span></code></pre></div>
</div>
<p>boston 데이터가 윤리적 문제로 사용 불가능하다고 한다.</p>
<div id="a3b571cf" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb10-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> cross_val_score</span>
<span id="cb10-3"></span>
<span id="cb10-4">y_target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'price'</span>]</span>
<span id="cb10-5">X_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.drop([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'price'</span>], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb10-6">lr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb10-7"></span>
<span id="cb10-8">neg_mse_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cross_val_score(lr, X_data, y_target, scoring<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"neg_mean_squared_error"</span>, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb10-9">rmse_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.sqrt(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> neg_mse_scores)</span>
<span id="cb10-10">avg_rmse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(rmse_scores)</span></code></pre></div>
</div>
<p>cross_val_score는 값이 큰걸 좋게 평가해서 neg를 기준으로 넣어줘야함</p>
</section>
<section id="다항-회귀" class="level2">
<h2 class="anchored" data-anchor-id="다항-회귀">다항 회귀</h2>
<div id="6e15120c" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PolynomialFeatures</span>
<span id="cb11-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb11-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.pipeline <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Pipeline</span>
<span id="cb11-4"></span>
<span id="cb11-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> polynominal_func(X):</span>
<span id="cb11-6">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb11-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> y</span>
<span id="cb11-8"></span>
<span id="cb11-9">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Pipeline([(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'poly'</span>, PolynomialFeatures(degree<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)),</span>
<span id="cb11-10">                  (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'linear'</span>, LinearRegression())])</span>
<span id="cb11-11">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>).reshape(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb11-12">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> polynominal_func(X)</span>
<span id="cb11-13"></span>
<span id="cb11-14">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.fit(X, y)</span>
<span id="cb11-15"></span>
<span id="cb11-16">np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(model.named_steps[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'linear'</span>].coef_, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>array([0.  , 0.18, 0.18, 0.36, 0.54, 0.72, 0.72, 1.08, 1.62, 2.34])</code></pre>
</div>
</div>
</section>
<section id="규제" class="level2">
<h2 class="anchored" data-anchor-id="규제">규제</h2>
<ul>
<li><p>L2 규제(Ridge): <img src="https://latex.codecogs.com/png.latex?min(RSS(W)%20+%20%5Clambda%20%7C%7CW%7C%7C%5E2)"></p></li>
<li><p>L1 규제(Lasso): <img src="https://latex.codecogs.com/png.latex?min(RSS(W)%20+%20%5Clambda%20%7C%7CW%7C%7C_1)"></p></li>
<li><p>λ가 크면, 회귀계수의 크기가 작아지고, λ가 0이 되면 일반 선형회귀와 같아짐</p></li>
<li><p>L1 규제는 영향력이 작은 피처의 계수를 0으로 만들어서 피처 선택 효과가 있음. L2는 0으로 만들지는 않음</p></li>
</ul>
<section id="릿지" class="level3">
<h3 class="anchored" data-anchor-id="릿지">릿지</h3>
<div id="b3d47d18" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Ridge</span>
<span id="cb13-2"></span>
<span id="cb13-3">ridge <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Ridge(alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb13-4">neg_mse_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cross_val_score(ridge, X_data, y_target, scoring<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"neg_mean_squared_error"</span>, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb13-5">rmse_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.sqrt(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> neg_mse_scores)</span>
<span id="cb13-6">avg_rmse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(rmse_scores)</span></code></pre></div>
</div>
</section>
<section id="라쏘-엘라스틱넷" class="level3">
<h3 class="anchored" data-anchor-id="라쏘-엘라스틱넷">라쏘 엘라스틱넷</h3>
<div id="5e7600e7" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb14-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Ridge, Lasso, ElasticNet</span>
<span id="cb14-3"></span>
<span id="cb14-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_linear_reg_eval(model_name, params<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, X_data_n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, y_target_n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb14-5">    coeff_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame()</span>
<span id="cb14-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> param <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> params:</span>
<span id="cb14-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Ridge'</span>:</span>
<span id="cb14-8">            model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Ridge(alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>param)</span>
<span id="cb14-9">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Lasso'</span>:</span>
<span id="cb14-10">            model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Lasso(alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>param)</span>
<span id="cb14-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ElasticNet'</span>:</span>
<span id="cb14-12">            model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ElasticNet(alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>param, l1_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>)</span>
<span id="cb14-13">        neg_mse_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cross_val_score(model, X_data_n, y_target_n, scoring<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"neg_mean_squared_error"</span>, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb14-14">        rmse_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.sqrt(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> neg_mse_scores)</span>
<span id="cb14-15">        avg_rmse <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(rmse_scores)</span>
<span id="cb14-16">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>param<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>avg_rmse<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb14-17"></span>
<span id="cb14-18">        model.fit(X_data_n, y_target_n)</span>
<span id="cb14-19">        coeff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.Series(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model.coef_, index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>X_data_n.columns)</span>
<span id="cb14-20">        colname <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'alpha:'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(param)</span>
<span id="cb14-21">        coeff_df[colname] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> coeff</span>
<span id="cb14-22"></span>
<span id="cb14-23">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> coeff_df</span></code></pre></div>
</div>
</section>
</section>
<section id="선형-회귀-모델을-위한-데이터-변환" class="level2">
<h2 class="anchored" data-anchor-id="선형-회귀-모델을-위한-데이터-변환">선형 회귀 모델을 위한 데이터 변환</h2>
<ul>
<li>로그 변환: 언더플로우를 고려해서 logp 보다는 log1p를 사용한다.</li>
</ul>
<div id="b210089d" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">np.log1p(data)</span></code></pre></div>
</div>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>머신 러닝</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/05.html</guid>
  <pubDate>Sun, 27 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>분류 - 산탄데르 고객 만족 예측</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/03.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="preprocessing">Preprocessing</h2>
<div id="d5947441" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> warnings</span>
<span id="cb1-5"></span>
<span id="cb1-6">plt.rcParams[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'font.family'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Noto Sans KR'</span></span>
<span id="cb1-7">warnings.filterwarnings(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ignore'</span>)</span>
<span id="cb1-8"></span>
<span id="cb1-9">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/santander/train.csv'</span>, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'latin-1'</span>)</span>
<span id="cb1-10">df.info()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 76020 entries, 0 to 76019
Columns: 371 entries, ID to TARGET
dtypes: float64(111), int64(260)
memory usage: 215.2 MB</code></pre>
</div>
</div>
<div id="64745c05" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">df.describe()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ID</th>
<th data-quarto-table-cell-role="th">var3</th>
<th data-quarto-table-cell-role="th">var15</th>
<th data-quarto-table-cell-role="th">imp_ent_var16_ult1</th>
<th data-quarto-table-cell-role="th">imp_op_var39_comer_ult1</th>
<th data-quarto-table-cell-role="th">imp_op_var39_comer_ult3</th>
<th data-quarto-table-cell-role="th">imp_op_var40_comer_ult1</th>
<th data-quarto-table-cell-role="th">imp_op_var40_comer_ult3</th>
<th data-quarto-table-cell-role="th">imp_op_var40_efect_ult1</th>
<th data-quarto-table-cell-role="th">imp_op_var40_efect_ult3</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">saldo_medio_var33_hace2</th>
<th data-quarto-table-cell-role="th">saldo_medio_var33_hace3</th>
<th data-quarto-table-cell-role="th">saldo_medio_var33_ult1</th>
<th data-quarto-table-cell-role="th">saldo_medio_var33_ult3</th>
<th data-quarto-table-cell-role="th">saldo_medio_var44_hace2</th>
<th data-quarto-table-cell-role="th">saldo_medio_var44_hace3</th>
<th data-quarto-table-cell-role="th">saldo_medio_var44_ult1</th>
<th data-quarto-table-cell-role="th">saldo_medio_var44_ult3</th>
<th data-quarto-table-cell-role="th">var38</th>
<th data-quarto-table-cell-role="th">TARGET</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>...</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>7.602000e+04</td>
<td>76020.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>75964.050723</td>
<td>-1523.199277</td>
<td>33.212865</td>
<td>86.208265</td>
<td>72.363067</td>
<td>119.529632</td>
<td>3.559130</td>
<td>6.472698</td>
<td>0.412946</td>
<td>0.567352</td>
<td>...</td>
<td>7.935824</td>
<td>1.365146</td>
<td>12.215580</td>
<td>8.784074</td>
<td>31.505324</td>
<td>1.858575</td>
<td>76.026165</td>
<td>56.614351</td>
<td>1.172358e+05</td>
<td>0.039569</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>43781.947379</td>
<td>39033.462364</td>
<td>12.956486</td>
<td>1614.757313</td>
<td>339.315831</td>
<td>546.266294</td>
<td>93.155749</td>
<td>153.737066</td>
<td>30.604864</td>
<td>36.513513</td>
<td>...</td>
<td>455.887218</td>
<td>113.959637</td>
<td>783.207399</td>
<td>538.439211</td>
<td>2013.125393</td>
<td>147.786584</td>
<td>4040.337842</td>
<td>2852.579397</td>
<td>1.826646e+05</td>
<td>0.194945</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>1.000000</td>
<td>-999999.000000</td>
<td>5.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>5.163750e+03</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>38104.750000</td>
<td>2.000000</td>
<td>23.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>6.787061e+04</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>76043.000000</td>
<td>2.000000</td>
<td>28.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.064092e+05</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>113748.750000</td>
<td>2.000000</td>
<td>40.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.187563e+05</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>151838.000000</td>
<td>238.000000</td>
<td>105.000000</td>
<td>210000.000000</td>
<td>12888.030000</td>
<td>21024.810000</td>
<td>8237.820000</td>
<td>11073.570000</td>
<td>6600.000000</td>
<td>6600.000000</td>
<td>...</td>
<td>50003.880000</td>
<td>20385.720000</td>
<td>138831.630000</td>
<td>91778.730000</td>
<td>438329.220000</td>
<td>24650.010000</td>
<td>681462.900000</td>
<td>397884.300000</td>
<td>2.203474e+07</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

<p>8 rows × 371 columns</p>
</div>
</div>
</div>
<div id="e314ea19" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'var3'</span>].replace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">999999</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb4-2">df.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ID'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb4-3"></span>
<span id="cb4-4">X_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.iloc[:, :<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb4-5">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.iloc[:, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
</div>
<div id="f9cec085" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">test_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/santander/test.csv'</span>, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'latin-1'</span>)</span>
<span id="cb5-2">test_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'var3'</span>].replace(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">999999</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb5-3">test_df.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ID'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
</div>
<div id="05d26bff" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb6-2"></span>
<span id="cb6-3">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X_features, labels, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>)</span></code></pre></div>
</div>
<ul>
<li>train, test의 label의 비율이 동일한게 좋은걸까</li>
</ul>
</section>
<section id="xgboost" class="level2">
<h2 class="anchored" data-anchor-id="xgboost">XGBoost</h2>
<div id="8340b7d0" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">X_tr, X_val, y_tr, y_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X_train, y_train, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span></code></pre></div>
</div>
<div id="43b1a238" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> xgboost <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> XGBClassifier</span>
<span id="cb8-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> roc_auc_score</span>
<span id="cb8-3"></span>
<span id="cb8-4">evals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb8-5">xgb_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> XGBClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, </span>
<span id="cb8-6">                    learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, </span>
<span id="cb8-7">                    early_stopping_rounds<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,</span>
<span id="cb8-8">                    eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'auc'</span>])</span>
<span id="cb8-9">xgb_clf.fit(X_tr, y_tr, eval_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>evals, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb8-10">xgb_roc_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb8-11"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>xgb_roc_score<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
</div>
<section id="베이지안-최적화" class="level3">
<h3 class="anchored" data-anchor-id="베이지안-최적화">베이지안 최적화</h3>
<div id="ffd62d7c" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KFold</span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> roc_auc_score</span>
<span id="cb9-3"></span>
<span id="cb9-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> objective_func(search_space):</span>
<span id="cb9-5">    xgb_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> XGBClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, </span>
<span id="cb9-6">                            early_stopping_rounds<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>,</span>
<span id="cb9-7">                            eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'auc'</span>,</span>
<span id="cb9-8">                            max_depth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>]),</span>
<span id="cb9-9">                            min_child_weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_weight'</span>]),</span>
<span id="cb9-10">                            colsample_bytree<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colsample_bytree'</span>],</span>
<span id="cb9-11">                            learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>])</span>
<span id="cb9-12">    roc_auc_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb9-13">    kf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KFold(n_splits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb9-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> tr_index, val_index <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> kf.split(X_train):</span>
<span id="cb9-15">        X_tr, y_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train.iloc[tr_index], y_train.iloc[tr_index]</span>
<span id="cb9-16">        X_val, y_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>  X_train.iloc[val_index], y_train.iloc[val_index]</span>
<span id="cb9-17"></span>
<span id="cb9-18">        xgb_clf.fit(X_tr, y_tr, eval_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[(X_tr, y_tr), (X_val, y_val)])</span>
<span id="cb9-19">        score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb9-20">        roc_auc_list.append(score)</span>
<span id="cb9-21"></span>
<span id="cb9-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.mean(roc_auc_list)</span></code></pre></div>
</div>
<div id="c5c43e8f" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> hyperopt <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> hp, fmin, tpe, Trials</span>
<span id="cb10-2"></span>
<span id="cb10-3">xgb_search_space <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb10-4">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>: hp.quniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb10-5">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_weight'</span>: hp.quniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_weight'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb10-6">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colsample_bytree'</span>: hp.uniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colsample_bytree'</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span>),</span>
<span id="cb10-7">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>: hp.uniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>)</span>
<span id="cb10-8">}</span>
<span id="cb10-9"></span>
<span id="cb10-10">trials <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Trials()</span>
<span id="cb10-11">best <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fmin(fn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>objective_func,</span>
<span id="cb10-12">            space<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>xgb_search_space,</span>
<span id="cb10-13">            algo<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tpe.suggest,</span>
<span id="cb10-14">            max_evals<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>,</span>
<span id="cb10-15">            trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>trials)</span>
<span id="cb10-16"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(best)</span></code></pre></div>
</div>
</section>
<section id="재-학습" class="level3">
<h3 class="anchored" data-anchor-id="재-학습">재 학습</h3>
<div id="84dbf898" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> xgboost <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> XGBClassifier</span>
<span id="cb11-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> roc_auc_score</span>
<span id="cb11-3"></span>
<span id="cb11-4">evals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb11-5">xgb_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> XGBClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, </span>
<span id="cb11-6">                    learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(best[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>),</span>
<span id="cb11-7">                    max_depth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(best[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>]),</span>
<span id="cb11-8">                    min_child_weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(best[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_weight'</span>]),</span>
<span id="cb11-9">                    colsample_bytree<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(best[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colsample_bytree'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>),</span>
<span id="cb11-10">                    early_stopping_rounds<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,</span>
<span id="cb11-11">                    eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'auc'</span>])</span>
<span id="cb11-12">xgb_clf.fit(X_tr, y_tr, eval_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>evals, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb11-13">xgb_roc_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb11-14"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>xgb_roc_score<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
</div>
</section>
<section id="plot-importance" class="level3">
<h3 class="anchored" data-anchor-id="plot-importance">plot importance</h3>
<div id="7efd1ad9" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> xgboost <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plot_importance</span>
<span id="cb12-2"></span>
<span id="cb12-3">plot_importance(xgb_clf, max_num_features<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>)</span></code></pre></div>
</div>
</section>
</section>
<section id="lightgbm" class="level2">
<h2 class="anchored" data-anchor-id="lightgbm">LightGBM</h2>
<div id="58532da1" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> roc_auc_score</span>
<span id="cb13-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> lightgbm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LGBMClassifier</span>
<span id="cb13-3"></span>
<span id="cb13-4">lgbm_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LGBMClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, early_stopping_rounds<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'auc'</span>)</span>
<span id="cb13-5"></span>
<span id="cb13-6">eval_set <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb13-7">lgbm_clf.fit(X_tr, y_tr, eval_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>eval_set)</span>
<span id="cb13-8"></span>
<span id="cb13-9">lgbm_roc_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb13-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>lgbm_roc_score<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100
[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Info] Number of positive: 1653, number of negative: 40918
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007850 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 13447
[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 251
[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038829 -&gt; initscore=-3.208978
[LightGBM] [Info] Start training from score -3.208978
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[28]    training's binary_logloss: 0.117279 valid_1's binary_logloss: 0.137813
[LightGBM] [Warning] Unknown parameter: eval_metric
0.834</code></pre>
</div>
</div>
<section id="베이지안-최적화-1" class="level3">
<h3 class="anchored" data-anchor-id="베이지안-최적화-1">베이지안 최적화</h3>
<div id="d3b3256c" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KFold</span>
<span id="cb15-2"></span>
<span id="cb15-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> objective_func(search_space):</span>
<span id="cb15-4">    lgbm_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LGBMClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, </span>
<span id="cb15-5">                            early_stopping_rounds<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>,</span>
<span id="cb15-6">                            eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'auc'</span>,</span>
<span id="cb15-7">                            num_leaves<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'num_leaves'</span>]),</span>
<span id="cb15-8">                            max_depth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>]),</span>
<span id="cb15-9">                            min_child_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_samples'</span>]),</span>
<span id="cb15-10">                            subsample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'subsample'</span>],</span>
<span id="cb15-11">                            learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>])</span>
<span id="cb15-12">    roc_auc_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb15-13">    kf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KFold(n_splits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb15-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> tr_index, val_index <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> kf.split(X_train):</span>
<span id="cb15-15">        X_tr, y_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train.iloc[tr_index], y_train.iloc[tr_index]</span>
<span id="cb15-16">        X_val, y_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>  X_train.iloc[val_index], y_train.iloc[val_index]</span>
<span id="cb15-17"></span>
<span id="cb15-18">        lgbm_clf.fit(X_tr, y_tr, eval_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[(X_tr, y_tr), (X_val, y_val)])</span>
<span id="cb15-19">        score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb15-20">        roc_auc_list.append(score)</span>
<span id="cb15-21"></span>
<span id="cb15-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.mean(roc_auc_list)</span></code></pre></div>
</div>
<div id="b6d8769a" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> hyperopt <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> hp, fmin, tpe, Trials</span>
<span id="cb16-2"></span>
<span id="cb16-3">lgbm_search_space <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb16-4">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'num_leaves'</span>: hp.quniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'num_leaves'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb16-5">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>: hp.quniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">160</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb16-6">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_samples'</span>: hp.quniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_samples'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb16-7">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'subsample'</span>: hp.uniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'subsample'</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb16-8">  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>: hp.uniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>)</span>
<span id="cb16-9">}</span>
<span id="cb16-10"></span>
<span id="cb16-11">trials <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Trials()</span>
<span id="cb16-12">best <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fmin(fn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>objective_func,</span>
<span id="cb16-13">            space<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>lgbm_search_space,</span>
<span id="cb16-14">            algo<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tpe.suggest,</span>
<span id="cb16-15">            max_evals<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>,</span>
<span id="cb16-16">            trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>trials)</span>
<span id="cb16-17"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(best)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009804 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Total Bins 12809
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Start training from score -3.168309
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      Training until validation scores don't improve for 30 rounds
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      Early stopping, best iteration is:
[36]    training's binary_logloss: 0.121676 valid_1's binary_logloss: 0.127049
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011714 seconds.
You can set `force_col_wise=true` to remove the overhead.
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Total Bins 12874
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Start training from score -3.194075
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      Training until validation scores don't improve for 30 rounds
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      Early stopping, best iteration is:
[44]    training's binary_logloss: 0.115084 valid_1's binary_logloss: 0.135595
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007309 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Total Bins 12874
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Start training from score -3.233233
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      Training until validation scores don't improve for 30 rounds
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      Early stopping, best iteration is:
[50]    training's binary_logloss: 0.110571 valid_1's binary_logloss: 0.140209
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006776 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Total Bins 12809
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Start training from score -3.168309
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 Training until validation scores don't improve for 30 rounds
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 Early stopping, best iteration is:
[68]    training's binary_logloss: 0.119949 valid_1's binary_logloss: 0.127337
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:02&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008185 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Total Bins 12874
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Start training from score -3.194075
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 Training until validation scores don't improve for 30 rounds
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 Did not meet early stopping. Best iteration is:
[74]    training's binary_logloss: 0.114945 valid_1's binary_logloss: 0.135003
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005666 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Total Bins 12865
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Info] Start training from score -3.233233
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 Training until validation scores don't improve for 30 rounds
  2%|▏         | 1/50 [00:03&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 Did not meet early stopping. Best iteration is:
[75]    training's binary_logloss: 0.111732 valid_1's binary_logloss: 0.140191
  2%|▏         | 1/50 [00:04&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:04&lt;01:41,  2.08s/trial, best loss: -0.8354243542379886]  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006637 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12907
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.168309
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[21]    training's binary_logloss: 0.121998 valid_1's binary_logloss: 0.127349
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:04&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006521 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12970
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.194075
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[26]    training's binary_logloss: 0.115056 valid_1's binary_logloss: 0.136143
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008614 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 13049
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.233233
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[30]    training's binary_logloss: 0.110308 valid_1's binary_logloss: 0.140967
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:05&lt;01:41,  2.12s/trial, best loss: -0.8361046999787884]  6%|▌         | 3/50 [00:05&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006389 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12809
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.168309
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[20]    training's binary_logloss: 0.119702 valid_1's binary_logloss: 0.127682
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005965 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12874
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.194075
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[21]    training's binary_logloss: 0.11491  valid_1's binary_logloss: 0.13632
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:06&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006447 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12865
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.233233
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[19]    training's binary_logloss: 0.113764 valid_1's binary_logloss: 0.141398
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:07&lt;01:31,  1.95s/trial, best loss: -0.8361046999787884]  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006690 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12809
  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.168309
  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
  8%|▊         | 4/50 [00:07&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 Did not meet early stopping. Best iteration is:
[71]    training's binary_logloss: 0.114179 valid_1's binary_logloss: 0.127237
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006128 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12874
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.194075
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
  8%|▊         | 4/50 [00:08&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[57]    training's binary_logloss: 0.113751 valid_1's binary_logloss: 0.136174
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007084 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12865
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.233233
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[58]    training's binary_logloss: 0.11113  valid_1's binary_logloss: 0.140897
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:09&lt;01:24,  1.83s/trial, best loss: -0.8361046999787884] 10%|█         | 5/50 [00:09&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:09&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:09&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006562 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12809
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.168309
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[23]    training's binary_logloss: 0.120721 valid_1's binary_logloss: 0.127623
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005976 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12874
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.194075
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[21]    training's binary_logloss: 0.117914 valid_1's binary_logloss: 0.135692
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:10&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006221 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12865
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.233233
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[18]    training's binary_logloss: 0.117142 valid_1's binary_logloss: 0.141073
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:11&lt;01:28,  1.98s/trial, best loss: -0.8361046999787884] 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005795 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12809
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.168309
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[23]    training's binary_logloss: 0.122492 valid_1's binary_logloss: 0.127389
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:11&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005857 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12882
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.194075
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[20]    training's binary_logloss: 0.119931 valid_1's binary_logloss: 0.13599
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007378 seconds.
You can set `force_col_wise=true` to remove the overhead.
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12883
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.233233
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[21]    training's binary_logloss: 0.116742 valid_1's binary_logloss: 0.14122
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:12&lt;01:20,  1.83s/trial, best loss: -0.8361046999787884] 14%|█▍        | 7/50 [00:12&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:12&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:12&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:12&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 14%|█▍        | 7/50 [00:12&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006486 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12809
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.168309
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[37]    training's binary_logloss: 0.118076 valid_1's binary_logloss: 0.12711
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008708 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12874
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.194075
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 14%|█▍        | 7/50 [00:13&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[27]    training's binary_logloss: 0.118244 valid_1's binary_logloss: 0.135768
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007417 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12865
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.233233
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[34]    training's binary_logloss: 0.11261  valid_1's binary_logloss: 0.140798
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:14&lt;01:12,  1.69s/trial, best loss: -0.8361046999787884] 16%|█▌        | 8/50 [00:14&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:14&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:14&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:14&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 16%|█▌        | 8/50 [00:14&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007634 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 16%|█▌        | 8/50 [00:14&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12907
 16%|█▌        | 8/50 [00:14&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 16%|█▌        | 8/50 [00:14&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:14&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:14&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.168309
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 Did not meet early stopping. Best iteration is:
[93]    training's binary_logloss: 0.113871 valid_1's binary_logloss: 0.127108
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007168 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12934
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.194075
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 16%|█▌        | 8/50 [00:15&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 Did not meet early stopping. Best iteration is:
[75]    training's binary_logloss: 0.113106 valid_1's binary_logloss: 0.135792
 16%|█▌        | 8/50 [00:16&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:16&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:16&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:16&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:16&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 16%|█▌        | 8/50 [00:16&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008788 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 16%|█▌        | 8/50 [00:16&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12989
 16%|█▌        | 8/50 [00:16&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 16%|█▌        | 8/50 [00:16&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:16&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:16&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 16%|█▌        | 8/50 [00:17&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.233233
 16%|█▌        | 8/50 [00:17&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 16%|█▌        | 8/50 [00:17&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 Did not meet early stopping. Best iteration is:
[82]    training's binary_logloss: 0.109277 valid_1's binary_logloss: 0.140921
 16%|█▌        | 8/50 [00:17&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:17&lt;01:14,  1.76s/trial, best loss: -0.8361046999787884] 18%|█▊        | 9/50 [00:17&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:17&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:17&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:17&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 18%|█▊        | 9/50 [00:17&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007124 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 18%|█▊        | 9/50 [00:17&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12809
 18%|█▊        | 9/50 [00:17&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 18%|█▊        | 9/50 [00:17&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.168309
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[57]    training's binary_logloss: 0.120677 valid_1's binary_logloss: 0.127111
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009349 seconds.
You can set `force_col_wise=true` to remove the overhead.
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12874
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.194075
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 18%|█▊        | 9/50 [00:18&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[50]    training's binary_logloss: 0.118347 valid_1's binary_logloss: 0.135488
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013450 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Total Bins 12865
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Info] Start training from score -3.233233
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 Training until validation scores don't improve for 30 rounds
 18%|█▊        | 9/50 [00:19&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 Early stopping, best iteration is:
[54]    training's binary_logloss: 0.114424 valid_1's binary_logloss: 0.140196
 18%|█▊        | 9/50 [00:20&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:20&lt;01:27,  2.14s/trial, best loss: -0.8361046999787884] 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006974 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12907
 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 20%|██        | 10/50 [00:20&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  Did not meet early stopping. Best iteration is:
[78]    training's binary_logloss: 0.111459 valid_1's binary_logloss: 0.12715
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006741 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12943
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[58]    training's binary_logloss: 0.112371 valid_1's binary_logloss: 0.13579
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:21&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:22&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:22&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:22&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 20%|██        | 10/50 [00:22&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007176 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 20%|██        | 10/50 [00:22&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 13017
 20%|██        | 10/50 [00:22&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 20%|██        | 10/50 [00:22&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:22&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:22&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 20%|██        | 10/50 [00:25&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 20%|██        | 10/50 [00:25&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 20%|██        | 10/50 [00:25&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  Did not meet early stopping. Best iteration is:
[76]    training's binary_logloss: 0.105423 valid_1's binary_logloss: 0.141018
 20%|██        | 10/50 [00:25&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:25&lt;01:30,  2.26s/trial, best loss: -0.8361046999787884] 22%|██▏       | 11/50 [00:25&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006851 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12809
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[19]    training's binary_logloss: 0.123258 valid_1's binary_logloss: 0.127671
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008232 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12874
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 22%|██▏       | 11/50 [00:26&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[19]    training's binary_logloss: 0.118847 valid_1's binary_logloss: 0.135735
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006765 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12865
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[20]    training's binary_logloss: 0.115967 valid_1's binary_logloss: 0.140884
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:27&lt;02:09,  3.33s/trial, best loss: -0.8361046999787884] 24%|██▍       | 12/50 [00:27&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:27&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:27&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007459 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12809
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[17]    training's binary_logloss: 0.118279 valid_1's binary_logloss: 0.128419
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010830 seconds.
You can set `force_col_wise=true` to remove the overhead.
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12882
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 24%|██▍       | 12/50 [00:28&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[16]    training's binary_logloss: 0.114963 valid_1's binary_logloss: 0.136964
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008271 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12935
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[18]    training's binary_logloss: 0.111041 valid_1's binary_logloss: 0.141811
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:29&lt;01:49,  2.88s/trial, best loss: -0.8361046999787884] 26%|██▌       | 13/50 [00:29&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:29&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:29&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:29&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006716 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12911
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[25]    training's binary_logloss: 0.117911 valid_1's binary_logloss: 0.127609
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007818 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12970
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 26%|██▌       | 13/50 [00:30&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[26]    training's binary_logloss: 0.112846 valid_1's binary_logloss: 0.135945
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007760 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 13049
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[21]    training's binary_logloss: 0.11335  valid_1's binary_logloss: 0.141758
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:31&lt;01:36,  2.60s/trial, best loss: -0.8361046999787884] 28%|██▊       | 14/50 [00:31&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011169 seconds.
You can set `force_col_wise=true` to remove the overhead.
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12809
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[15]    training's binary_logloss: 0.123793 valid_1's binary_logloss: 0.127794
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006417 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12874
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 28%|██▊       | 14/50 [00:32&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[17]    training's binary_logloss: 0.117509 valid_1's binary_logloss: 0.136341
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012417 seconds.
You can set `force_col_wise=true` to remove the overhead.
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12874
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[14]    training's binary_logloss: 0.118131 valid_1's binary_logloss: 0.141827
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:33&lt;01:29,  2.48s/trial, best loss: -0.8361046999787884] 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006221 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12809
 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 30%|███       | 15/50 [00:33&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[30]    training's binary_logloss: 0.116669 valid_1's binary_logloss: 0.127316
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008685 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12874
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 30%|███       | 15/50 [00:34&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[30]    training's binary_logloss: 0.112195 valid_1's binary_logloss: 0.13634
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008114 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12865
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.110627 valid_1's binary_logloss: 0.141491
 30%|███       | 15/50 [00:35&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:36&lt;01:18,  2.23s/trial, best loss: -0.8361046999787884] 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006910 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12809
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[44]    training's binary_logloss: 0.11468  valid_1's binary_logloss: 0.127009
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:36&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008679 seconds.
You can set `force_col_wise=true` to remove the overhead.
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12874
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[30]    training's binary_logloss: 0.116699 valid_1's binary_logloss: 0.136132
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009082 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12865
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 32%|███▏      | 16/50 [00:37&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:38&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:38&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 32%|███▏      | 16/50 [00:38&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 32%|███▏      | 16/50 [00:38&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 32%|███▏      | 16/50 [00:38&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[37]    training's binary_logloss: 0.110851 valid_1's binary_logloss: 0.140914
 32%|███▏      | 16/50 [00:38&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:38&lt;01:17,  2.28s/trial, best loss: -0.8361046999787884] 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009004 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12809
 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 34%|███▍      | 17/50 [00:38&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.133099 valid_1's binary_logloss: 0.130118
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010889 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12874
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 34%|███▍      | 17/50 [00:39&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.128591 valid_1's binary_logloss: 0.138373
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006967 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12874
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 34%|███▍      | 17/50 [00:40&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.125837 valid_1's binary_logloss: 0.144181
 34%|███▍      | 17/50 [00:41&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:41&lt;01:17,  2.35s/trial, best loss: -0.8361046999787884] 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007196 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12809
 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 36%|███▌      | 18/50 [00:41&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[35]    training's binary_logloss: 0.117838 valid_1's binary_logloss: 0.127509
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009471 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12882
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[34]    training's binary_logloss: 0.114266 valid_1's binary_logloss: 0.136132
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:42&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007509 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12935
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[44]    training's binary_logloss: 0.107097 valid_1's binary_logloss: 0.141644
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:43&lt;01:18,  2.47s/trial, best loss: -0.8361046999787884] 38%|███▊      | 19/50 [00:43&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:43&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:43&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006872 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12911
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[32]    training's binary_logloss: 0.120651 valid_1's binary_logloss: 0.12748
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007690 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12970
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 38%|███▊      | 19/50 [00:44&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.117806 valid_1's binary_logloss: 0.135748
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007569 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 13049
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  Early stopping, best iteration is:
[39]    training's binary_logloss: 0.111183 valid_1's binary_logloss: 0.140593
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:45&lt;01:17,  2.49s/trial, best loss: -0.8361046999787884] 40%|████      | 20/50 [00:45&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:45&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:45&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:46&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 40%|████      | 20/50 [00:46&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010567 seconds.
You can set `force_col_wise=true` to remove the overhead.
 40%|████      | 20/50 [00:46&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12809
 40%|████      | 20/50 [00:46&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 40%|████      | 20/50 [00:46&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:46&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:46&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 40%|████      | 20/50 [00:46&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 40%|████      | 20/50 [00:46&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 40%|████      | 20/50 [00:46&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.127621 valid_1's binary_logloss: 0.127975
 40%|████      | 20/50 [00:46&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:46&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028233 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12874
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.123117 valid_1's binary_logloss: 0.136484
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:47&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007220 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12865
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.120407 valid_1's binary_logloss: 0.141888
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:48&lt;01:10,  2.36s/trial, best loss: -0.8361046999787884] 42%|████▏     | 21/50 [00:48&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:48&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:48&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008396 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12809
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  Did not meet early stopping. Best iteration is:
[94]    training's binary_logloss: 0.120321 valid_1's binary_logloss: 0.12706
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007023 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12874
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 42%|████▏     | 21/50 [00:49&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  Did not meet early stopping. Best iteration is:
[95]    training's binary_logloss: 0.116042 valid_1's binary_logloss: 0.135298
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007237 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Total Bins 12865
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  Training until validation scores don't improve for 30 rounds
 42%|████▏     | 21/50 [00:50&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.112382 valid_1's binary_logloss: 0.140103
 42%|████▏     | 21/50 [00:51&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:51&lt;01:13,  2.53s/trial, best loss: -0.8361046999787884] 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007562 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 44%|████▍     | 22/50 [00:51&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.120691 valid_1's binary_logloss: 0.127296
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009653 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 44%|████▍     | 22/50 [00:52&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[99]    training's binary_logloss: 0.116561 valid_1's binary_logloss: 0.135521
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007650 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 44%|████▍     | 22/50 [00:53&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.113883 valid_1's binary_logloss: 0.140482
 44%|████▍     | 22/50 [00:54&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:54&lt;01:11,  2.56s/trial, best loss: -0.8361206531552328] 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009103 seconds.
You can set `force_col_wise=true` to remove the overhead.
 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 46%|████▌     | 23/50 [00:54&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.12506  valid_1's binary_logloss: 0.127517
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007298 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 46%|████▌     | 23/50 [00:55&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.120784 valid_1's binary_logloss: 0.135909
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006853 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 46%|████▌     | 23/50 [00:56&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.11795  valid_1's binary_logloss: 0.141026
 46%|████▌     | 23/50 [00:57&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [00:57&lt;01:11,  2.65s/trial, best loss: -0.8361206531552328] 48%|████▊     | 24/50 [00:57&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [00:57&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [00:57&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [00:57&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 48%|████▊     | 24/50 [00:57&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006418 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 48%|████▊     | 24/50 [00:57&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 48%|████▊     | 24/50 [00:57&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 48%|████▊     | 24/50 [00:57&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [00:57&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [00:57&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 48%|████▊     | 24/50 [01:00&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 48%|████▊     | 24/50 [01:00&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 48%|████▊     | 24/50 [01:00&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[49]    training's binary_logloss: 0.120728 valid_1's binary_logloss: 0.12726
 48%|████▊     | 24/50 [01:00&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:00&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:00&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:00&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007255 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[51]    training's binary_logloss: 0.116085 valid_1's binary_logloss: 0.13534
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006430 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 48%|████▊     | 24/50 [01:01&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[60]    training's binary_logloss: 0.11095  valid_1's binary_logloss: 0.140369
 48%|████▊     | 24/50 [01:02&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:02&lt;01:10,  2.71s/trial, best loss: -0.8361206531552328] 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007186 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 50%|█████     | 25/50 [01:02&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[97]    training's binary_logloss: 0.118162 valid_1's binary_logloss: 0.127362
 50%|█████     | 25/50 [01:03&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:03&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006679 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[93]    training's binary_logloss: 0.114804 valid_1's binary_logloss: 0.135408
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:04&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:05&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 50%|█████     | 25/50 [01:05&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007134 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 50%|█████     | 25/50 [01:05&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 50%|█████     | 25/50 [01:05&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 50%|█████     | 25/50 [01:05&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:05&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:05&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 50%|█████     | 25/50 [01:05&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 50%|█████     | 25/50 [01:05&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 50%|█████     | 25/50 [01:05&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[98]    training's binary_logloss: 0.111333 valid_1's binary_logloss: 0.140214
 50%|█████     | 25/50 [01:05&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:05&lt;01:28,  3.53s/trial, best loss: -0.8361206531552328] 52%|█████▏    | 26/50 [01:05&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006927 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[35]    training's binary_logloss: 0.11927  valid_1's binary_logloss: 0.127628
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007967 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:06&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[33]    training's binary_logloss: 0.11608  valid_1's binary_logloss: 0.136215
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007403 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 52%|█████▏    | 26/50 [01:07&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[37]    training's binary_logloss: 0.111732 valid_1's binary_logloss: 0.141059
 52%|█████▏    | 26/50 [01:08&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:08&lt;01:23,  3.49s/trial, best loss: -0.8361206531552328] 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011520 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 54%|█████▍    | 27/50 [01:08&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[65]    training's binary_logloss: 0.11962  valid_1's binary_logloss: 0.127063
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007475 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 54%|█████▍    | 27/50 [01:09&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[72]    training's binary_logloss: 0.114002 valid_1's binary_logloss: 0.135602
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008925 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 54%|█████▍    | 27/50 [01:10&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[71]    training's binary_logloss: 0.111386 valid_1's binary_logloss: 0.140329
 54%|█████▍    | 27/50 [01:11&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:11&lt;01:11,  3.11s/trial, best loss: -0.8361206531552328] 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006519 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[26]    training's binary_logloss: 0.123961 valid_1's binary_logloss: 0.127545
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010127 seconds.
You can set `force_col_wise=true` to remove the overhead.
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 56%|█████▌    | 28/50 [01:11&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[32]    training's binary_logloss: 0.117126 valid_1's binary_logloss: 0.13534
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007890 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 56%|█████▌    | 28/50 [01:12&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[41]    training's binary_logloss: 0.111145 valid_1's binary_logloss: 0.140511
 56%|█████▌    | 28/50 [01:13&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:13&lt;01:06,  3.03s/trial, best loss: -0.8361206531552328] 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010351 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 58%|█████▊    | 29/50 [01:13&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.135256 valid_1's binary_logloss: 0.131344
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007594 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.130846 valid_1's binary_logloss: 0.139185
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:14&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006775 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.127867 valid_1's binary_logloss: 0.14514
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:15&lt;00:57,  2.75s/trial, best loss: -0.8361206531552328] 60%|██████    | 30/50 [01:15&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:15&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:15&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:15&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 60%|██████    | 30/50 [01:15&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006594 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 60%|██████    | 30/50 [01:15&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 60%|██████    | 30/50 [01:15&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 60%|██████    | 30/50 [01:15&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:15&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:15&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.127239 valid_1's binary_logloss: 0.127384
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006879 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 60%|██████    | 30/50 [01:16&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.12288  valid_1's binary_logloss: 0.135571
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007380 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.120284 valid_1's binary_logloss: 0.140863
 60%|██████    | 30/50 [01:17&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:18&lt;00:54,  2.70s/trial, best loss: -0.8361206531552328] 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008255 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 62%|██████▏   | 31/50 [01:18&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[76]    training's binary_logloss: 0.119732 valid_1's binary_logloss: 0.127276
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007609 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[70]    training's binary_logloss: 0.116807 valid_1's binary_logloss: 0.135585
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:19&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008248 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[80]    training's binary_logloss: 0.112368 valid_1's binary_logloss: 0.14032
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:20&lt;00:49,  2.59s/trial, best loss: -0.8361206531552328] 64%|██████▍   | 32/50 [01:20&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:20&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:20&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007186 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[50]    training's binary_logloss: 0.120657 valid_1's binary_logloss: 0.126949
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006888 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 64%|██████▍   | 32/50 [01:21&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[42]    training's binary_logloss: 0.118801 valid_1's binary_logloss: 0.135645
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006469 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[51]    training's binary_logloss: 0.113559 valid_1's binary_logloss: 0.140513
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:22&lt;00:47,  2.66s/trial, best loss: -0.8361206531552328] 66%|██████▌   | 33/50 [01:22&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012104 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[36]    training's binary_logloss: 0.121629 valid_1's binary_logloss: 0.127166
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008693 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 66%|██████▌   | 33/50 [01:23&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[34]    training's binary_logloss: 0.117903 valid_1's binary_logloss: 0.13587
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011244 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[34]    training's binary_logloss: 0.115553 valid_1's binary_logloss: 0.140845
 66%|██████▌   | 33/50 [01:24&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:25&lt;00:42,  2.48s/trial, best loss: -0.8361206531552328] 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007149 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[16]    training's binary_logloss: 0.118882 valid_1's binary_logloss: 0.128522
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008471 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 68%|██████▊   | 34/50 [01:25&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[11]    training's binary_logloss: 0.12009  valid_1's binary_logloss: 0.136809
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012520 seconds.
You can set `force_col_wise=true` to remove the overhead.
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 68%|██████▊   | 34/50 [01:26&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[14]    training's binary_logloss: 0.114296 valid_1's binary_logloss: 0.141912
 68%|██████▊   | 34/50 [01:27&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:27&lt;00:37,  2.36s/trial, best loss: -0.8361206531552328] 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009374 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12870
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[67]    training's binary_logloss: 0.117834 valid_1's binary_logloss: 0.127248
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:27&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008813 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12934
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[55]    training's binary_logloss: 0.116506 valid_1's binary_logloss: 0.135743
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008382 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12939
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200
 70%|███████   | 35/50 [01:28&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:29&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:29&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 70%|███████   | 35/50 [01:29&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 70%|███████   | 35/50 [01:29&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 70%|███████   | 35/50 [01:29&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[62]    training's binary_logloss: 0.112207 valid_1's binary_logloss: 0.140686
 70%|███████   | 35/50 [01:29&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:29&lt;00:33,  2.26s/trial, best loss: -0.8361206531552328] 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008790 seconds.
You can set `force_col_wise=true` to remove the overhead.
 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 72%|███████▏  | 36/50 [01:29&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[72]    training's binary_logloss: 0.116081 valid_1's binary_logloss: 0.12713
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008642 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 72%|███████▏  | 36/50 [01:30&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[49]    training's binary_logloss: 0.117446 valid_1's binary_logloss: 0.135845
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006554 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 72%|███████▏  | 36/50 [01:31&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  Early stopping, best iteration is:
[54]    training's binary_logloss: 0.113495 valid_1's binary_logloss: 0.140635
 72%|███████▏  | 36/50 [01:32&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:32&lt;00:32,  2.33s/trial, best loss: -0.8361206531552328] 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008911 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12809
 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 74%|███████▍  | 37/50 [01:32&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[97]    training's binary_logloss: 0.11803  valid_1's binary_logloss: 0.126746
 74%|███████▍  | 37/50 [01:35&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:35&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008127 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12874
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[85]    training's binary_logloss: 0.115626 valid_1's binary_logloss: 0.135332
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:36&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:37&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 74%|███████▍  | 37/50 [01:37&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013095 seconds.
You can set `force_col_wise=true` to remove the overhead.
 74%|███████▍  | 37/50 [01:37&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Total Bins 12865
 74%|███████▍  | 37/50 [01:37&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 74%|███████▍  | 37/50 [01:37&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:37&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:37&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 74%|███████▍  | 37/50 [01:37&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 74%|███████▍  | 37/50 [01:37&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  Training until validation scores don't improve for 30 rounds
 74%|███████▍  | 37/50 [01:37&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  Did not meet early stopping. Best iteration is:
[89]    training's binary_logloss: 0.112365 valid_1's binary_logloss: 0.140135
 74%|███████▍  | 37/50 [01:37&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:37&lt;00:31,  2.40s/trial, best loss: -0.8361206531552328] 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007640 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12870
 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 76%|███████▌  | 38/50 [01:37&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  Did not meet early stopping. Best iteration is:
[98]    training's binary_logloss: 0.123399 valid_1's binary_logloss: 0.126912
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12934
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 76%|███████▌  | 38/50 [01:38&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.119208 valid_1's binary_logloss: 0.135189
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011345 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12939
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 76%|███████▌  | 38/50 [01:39&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.116397 valid_1's binary_logloss: 0.140343
 76%|███████▌  | 38/50 [01:40&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:40&lt;00:40,  3.35s/trial, best loss: -0.8368093643173017] 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006904 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12870
 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 78%|███████▊  | 39/50 [01:40&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.13496  valid_1's binary_logloss: 0.13089
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006719 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12934
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.130487 valid_1's binary_logloss: 0.138913
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:41&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:42&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 78%|███████▊  | 39/50 [01:42&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009924 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 78%|███████▊  | 39/50 [01:42&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12939
 78%|███████▊  | 39/50 [01:42&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200
 78%|███████▊  | 39/50 [01:42&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:42&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:42&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 78%|███████▊  | 39/50 [01:42&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 78%|███████▊  | 39/50 [01:42&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 78%|███████▊  | 39/50 [01:42&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.12765  valid_1's binary_logloss: 0.144942
 78%|███████▊  | 39/50 [01:42&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:42&lt;00:34,  3.12s/trial, best loss: -0.8368093643173017] 80%|████████  | 40/50 [01:42&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:42&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:42&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008446 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12907
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  Did not meet early stopping. Best iteration is:
[91]    training's binary_logloss: 0.119162 valid_1's binary_logloss: 0.126781
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010092 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12943
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 80%|████████  | 40/50 [01:43&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  Did not meet early stopping. Best iteration is:
[76]    training's binary_logloss: 0.117526 valid_1's binary_logloss: 0.135504
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018761 seconds.
You can set `force_col_wise=true` to remove the overhead.
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 13017
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 80%|████████  | 40/50 [01:44&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  Did not meet early stopping. Best iteration is:
[84]    training's binary_logloss: 0.113084 valid_1's binary_logloss: 0.140427
 80%|████████  | 40/50 [01:45&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:45&lt;00:29,  2.92s/trial, best loss: -0.8368093643173017] 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007948 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12870
 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 82%|████████▏ | 41/50 [01:45&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.124667 valid_1's binary_logloss: 0.127059
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006578 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12934
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 82%|████████▏ | 41/50 [01:46&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.120428 valid_1's binary_logloss: 0.135621
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006144 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12935
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.117733 valid_1's binary_logloss: 0.140661
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:47&lt;00:25,  2.86s/trial, best loss: -0.8368093643173017] 84%|████████▍ | 42/50 [01:47&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008411 seconds.
You can set `force_col_wise=true` to remove the overhead.
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12809
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[28]    training's binary_logloss: 0.120438 valid_1's binary_logloss: 0.127484
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006109 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12874
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 84%|████████▍ | 42/50 [01:48&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[25]    training's binary_logloss: 0.118015 valid_1's binary_logloss: 0.13605
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006744 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12865
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[25]    training's binary_logloss: 0.115064 valid_1's binary_logloss: 0.14127
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:49&lt;00:22,  2.76s/trial, best loss: -0.8368093643173017] 86%|████████▌ | 43/50 [01:49&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008998 seconds.
You can set `force_col_wise=true` to remove the overhead.
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12907
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[16]    training's binary_logloss: 0.117532 valid_1's binary_logloss: 0.128445
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009310 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12970
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 86%|████████▌ | 43/50 [01:50&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[13]    training's binary_logloss: 0.116506 valid_1's binary_logloss: 0.136088
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007065 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 13049
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[18]    training's binary_logloss: 0.10854  valid_1's binary_logloss: 0.14215
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:51&lt;00:17,  2.51s/trial, best loss: -0.8368093643173017] 88%|████████▊ | 44/50 [01:51&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009960 seconds.
You can set `force_col_wise=true` to remove the overhead.
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12907
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[31]    training's binary_logloss: 0.120736 valid_1's binary_logloss: 0.127726
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007563 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12934
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 88%|████████▊ | 44/50 [01:52&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[28]    training's binary_logloss: 0.117682 valid_1's binary_logloss: 0.135689
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010431 seconds.
You can set `force_col_wise=true` to remove the overhead.
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12989
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[35]    training's binary_logloss: 0.112434 valid_1's binary_logloss: 0.141034
 88%|████████▊ | 44/50 [01:53&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:54&lt;00:14,  2.37s/trial, best loss: -0.8368093643173017] 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007370 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12907
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[25]    training's binary_logloss: 0.114951 valid_1's binary_logloss: 0.127139
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:54&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007464 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12970
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[20]    training's binary_logloss: 0.114337 valid_1's binary_logloss: 0.136683
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007329 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 13017
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 90%|█████████ | 45/50 [01:55&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[22]    training's binary_logloss: 0.110257 valid_1's binary_logloss: 0.141881
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:56&lt;00:11,  2.29s/trial, best loss: -0.8368093643173017] 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011444 seconds.
You can set `force_col_wise=true` to remove the overhead.
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12809
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[45]    training's binary_logloss: 0.120473 valid_1's binary_logloss: 0.127224
 92%|█████████▏| 46/50 [01:56&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007092 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12874
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[47]    training's binary_logloss: 0.115765 valid_1's binary_logloss: 0.135738
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 92%|█████████▏| 46/50 [01:57&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006695 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12865
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[43]    training's binary_logloss: 0.114087 valid_1's binary_logloss: 0.140748
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [01:58&lt;00:09,  2.26s/trial, best loss: -0.8368093643173017] 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007464 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12870
 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 94%|█████████▍| 47/50 [01:58&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[50]    training's binary_logloss: 0.117042 valid_1's binary_logloss: 0.127461
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006729 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12934
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 94%|█████████▍| 47/50 [01:59&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[58]    training's binary_logloss: 0.110513 valid_1's binary_logloss: 0.135839
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011866 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12989
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 94%|█████████▍| 47/50 [02:00&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[61]    training's binary_logloss: 0.107023 valid_1's binary_logloss: 0.140678
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:01&lt;00:06,  2.26s/trial, best loss: -0.8368093643173017] 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008940 seconds.
You can set `force_col_wise=true` to remove the overhead.
 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12818
 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195
 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 96%|█████████▌| 48/50 [02:01&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[50]    training's binary_logloss: 0.116856 valid_1's binary_logloss: 0.127122
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009554 seconds.
You can set `force_col_wise=true` to remove the overhead.
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12934
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 96%|█████████▌| 48/50 [02:02&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[36]    training's binary_logloss: 0.117447 valid_1's binary_logloss: 0.13599
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006844 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12935
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[48]    training's binary_logloss: 0.110674 valid_1's binary_logloss: 0.140834
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:03&lt;00:04,  2.44s/trial, best loss: -0.8368093643173017] 98%|█████████▊| 49/50 [02:03&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1637, number of negative: 38907
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007160 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12809
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040376 -&gt; initscore=-3.168309
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.168309
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[28]    training's binary_logloss: 0.117901 valid_1's binary_logloss: 0.128002
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:04&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1597, number of negative: 38947
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008421 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12874
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039389 -&gt; initscore=-3.194075
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.194075
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.11285  valid_1's binary_logloss: 0.135927
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of positive: 1538, number of negative: 39006
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007163 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Total Bins 12874
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.037934 -&gt; initscore=-3.233233
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Info] Start training from score -3.233233
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  Training until validation scores don't improve for 30 rounds
 98%|█████████▊| 49/50 [02:05&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  Early stopping, best iteration is:
[30]    training's binary_logloss: 0.110102 valid_1's binary_logloss: 0.141424
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:06&lt;00:02,  2.50s/trial, best loss: -0.8368093643173017]100%|██████████| 50/50 [02:06&lt;00:00,  2.48s/trial, best loss: -0.8368093643173017]100%|██████████| 50/50 [02:06&lt;00:00,  2.53s/trial, best loss: -0.8368093643173017]
{'learning_rate': 0.043324531254078945, 'max_depth': 133.0, 'min_child_samples': 85.0, 'num_leaves': 36.0, 'subsample': 0.7305792288105732}</code></pre>
</div>
</div>
</section>
<section id="재학습" class="level3">
<h3 class="anchored" data-anchor-id="재학습">재학습</h3>
<div id="05fb8493" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">lgbm_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LGBMClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, </span>
<span id="cb18-2">                          num_leaves<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(best[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'num_leaves'</span>]),</span>
<span id="cb18-3">                          max_depth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(best[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>]),</span>
<span id="cb18-4">                          min_child_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(best[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_samples'</span>]),</span>
<span id="cb18-5">                          subsample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(best[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'subsample'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>),</span>
<span id="cb18-6">                          learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>(best[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>),</span>
<span id="cb18-7">                          early_stopping_rounds<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, </span>
<span id="cb18-8">                          eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'auc'</span>)</span>
<span id="cb18-9"></span>
<span id="cb18-10">eval_set <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb18-11">lgbm_clf.fit(X_tr, y_tr, eval_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>eval_set)</span>
<span id="cb18-12"></span>
<span id="cb18-13">lgbm_roc_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb18-14"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>lgbm_roc_score<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100
[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Info] Number of positive: 1653, number of negative: 40918
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009941 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 12969
[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 192
[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038829 -&gt; initscore=-3.208978
[LightGBM] [Info] Start training from score -3.208978
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[62]    training's binary_logloss: 0.119449 valid_1's binary_logloss: 0.137449
[LightGBM] [Warning] Unknown parameter: eval_metric
0.838</code></pre>
</div>
</div>
</section>
</section>
<section id="제출" class="level2">
<h2 class="anchored" data-anchor-id="제출">제출</h2>
<div id="7af1ef06" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lgbm_clf.predict(test_df)</span>
<span id="cb20-2"></span>
<span id="cb20-3">submit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/santander/sample_submission.csv'</span>, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'latin-1'</span>)</span>
<span id="cb20-4">submit[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'TARGET'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> target</span>
<span id="cb20-5">submit.to_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/santander/submission.csv'</span>, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'latin-1'</span>, index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Warning] Unknown parameter: eval_metric</code></pre>
</div>
</div>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>머신 러닝</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/03.html</guid>
  <pubDate>Sat, 26 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>분류 - 앙상블</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/02.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="voting" class="level2">
<h2 class="anchored" data-anchor-id="voting">voting</h2>
<ul>
<li>서로 다른 알고리즘이 결합. 분류에서는 voting<sup>1</sup>으로 결정</li>
</ul>
<section id="example" class="level3">
<h3 class="anchored" data-anchor-id="example">Example</h3>
<div id="676b41f6" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> VotingClassifier</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LogisticRegression</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.neighbors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KNeighborsClassifier</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_breast_cancer</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> accuracy_score</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> warnings</span>
<span id="cb1-10"></span>
<span id="cb1-11">warnings.filterwarnings(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ignore'</span>)</span>
<span id="cb1-12"></span>
<span id="cb1-13">cancer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_breast_cancer()</span>
<span id="cb1-14"></span>
<span id="cb1-15">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(cancer.data, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cancer.feature_names)</span>
<span id="cb1-16">df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean radius</th>
<th data-quarto-table-cell-role="th">mean texture</th>
<th data-quarto-table-cell-role="th">mean perimeter</th>
<th data-quarto-table-cell-role="th">mean area</th>
<th data-quarto-table-cell-role="th">mean smoothness</th>
<th data-quarto-table-cell-role="th">mean compactness</th>
<th data-quarto-table-cell-role="th">mean concavity</th>
<th data-quarto-table-cell-role="th">mean concave points</th>
<th data-quarto-table-cell-role="th">mean symmetry</th>
<th data-quarto-table-cell-role="th">mean fractal dimension</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">worst radius</th>
<th data-quarto-table-cell-role="th">worst texture</th>
<th data-quarto-table-cell-role="th">worst perimeter</th>
<th data-quarto-table-cell-role="th">worst area</th>
<th data-quarto-table-cell-role="th">worst smoothness</th>
<th data-quarto-table-cell-role="th">worst compactness</th>
<th data-quarto-table-cell-role="th">worst concavity</th>
<th data-quarto-table-cell-role="th">worst concave points</th>
<th data-quarto-table-cell-role="th">worst symmetry</th>
<th data-quarto-table-cell-role="th">worst fractal dimension</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>17.99</td>
<td>10.38</td>
<td>122.80</td>
<td>1001.0</td>
<td>0.11840</td>
<td>0.27760</td>
<td>0.30010</td>
<td>0.14710</td>
<td>0.2419</td>
<td>0.07871</td>
<td>...</td>
<td>25.380</td>
<td>17.33</td>
<td>184.60</td>
<td>2019.0</td>
<td>0.16220</td>
<td>0.66560</td>
<td>0.7119</td>
<td>0.2654</td>
<td>0.4601</td>
<td>0.11890</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>20.57</td>
<td>17.77</td>
<td>132.90</td>
<td>1326.0</td>
<td>0.08474</td>
<td>0.07864</td>
<td>0.08690</td>
<td>0.07017</td>
<td>0.1812</td>
<td>0.05667</td>
<td>...</td>
<td>24.990</td>
<td>23.41</td>
<td>158.80</td>
<td>1956.0</td>
<td>0.12380</td>
<td>0.18660</td>
<td>0.2416</td>
<td>0.1860</td>
<td>0.2750</td>
<td>0.08902</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>19.69</td>
<td>21.25</td>
<td>130.00</td>
<td>1203.0</td>
<td>0.10960</td>
<td>0.15990</td>
<td>0.19740</td>
<td>0.12790</td>
<td>0.2069</td>
<td>0.05999</td>
<td>...</td>
<td>23.570</td>
<td>25.53</td>
<td>152.50</td>
<td>1709.0</td>
<td>0.14440</td>
<td>0.42450</td>
<td>0.4504</td>
<td>0.2430</td>
<td>0.3613</td>
<td>0.08758</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>11.42</td>
<td>20.38</td>
<td>77.58</td>
<td>386.1</td>
<td>0.14250</td>
<td>0.28390</td>
<td>0.24140</td>
<td>0.10520</td>
<td>0.2597</td>
<td>0.09744</td>
<td>...</td>
<td>14.910</td>
<td>26.50</td>
<td>98.87</td>
<td>567.7</td>
<td>0.20980</td>
<td>0.86630</td>
<td>0.6869</td>
<td>0.2575</td>
<td>0.6638</td>
<td>0.17300</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>20.29</td>
<td>14.34</td>
<td>135.10</td>
<td>1297.0</td>
<td>0.10030</td>
<td>0.13280</td>
<td>0.19800</td>
<td>0.10430</td>
<td>0.1809</td>
<td>0.05883</td>
<td>...</td>
<td>22.540</td>
<td>16.67</td>
<td>152.20</td>
<td>1575.0</td>
<td>0.13740</td>
<td>0.20500</td>
<td>0.4000</td>
<td>0.1625</td>
<td>0.2364</td>
<td>0.07678</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">564</td>
<td>21.56</td>
<td>22.39</td>
<td>142.00</td>
<td>1479.0</td>
<td>0.11100</td>
<td>0.11590</td>
<td>0.24390</td>
<td>0.13890</td>
<td>0.1726</td>
<td>0.05623</td>
<td>...</td>
<td>25.450</td>
<td>26.40</td>
<td>166.10</td>
<td>2027.0</td>
<td>0.14100</td>
<td>0.21130</td>
<td>0.4107</td>
<td>0.2216</td>
<td>0.2060</td>
<td>0.07115</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">565</td>
<td>20.13</td>
<td>28.25</td>
<td>131.20</td>
<td>1261.0</td>
<td>0.09780</td>
<td>0.10340</td>
<td>0.14400</td>
<td>0.09791</td>
<td>0.1752</td>
<td>0.05533</td>
<td>...</td>
<td>23.690</td>
<td>38.25</td>
<td>155.00</td>
<td>1731.0</td>
<td>0.11660</td>
<td>0.19220</td>
<td>0.3215</td>
<td>0.1628</td>
<td>0.2572</td>
<td>0.06637</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">566</td>
<td>16.60</td>
<td>28.08</td>
<td>108.30</td>
<td>858.1</td>
<td>0.08455</td>
<td>0.10230</td>
<td>0.09251</td>
<td>0.05302</td>
<td>0.1590</td>
<td>0.05648</td>
<td>...</td>
<td>18.980</td>
<td>34.12</td>
<td>126.70</td>
<td>1124.0</td>
<td>0.11390</td>
<td>0.30940</td>
<td>0.3403</td>
<td>0.1418</td>
<td>0.2218</td>
<td>0.07820</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">567</td>
<td>20.60</td>
<td>29.33</td>
<td>140.10</td>
<td>1265.0</td>
<td>0.11780</td>
<td>0.27700</td>
<td>0.35140</td>
<td>0.15200</td>
<td>0.2397</td>
<td>0.07016</td>
<td>...</td>
<td>25.740</td>
<td>39.42</td>
<td>184.60</td>
<td>1821.0</td>
<td>0.16500</td>
<td>0.86810</td>
<td>0.9387</td>
<td>0.2650</td>
<td>0.4087</td>
<td>0.12400</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">568</td>
<td>7.76</td>
<td>24.54</td>
<td>47.92</td>
<td>181.0</td>
<td>0.05263</td>
<td>0.04362</td>
<td>0.00000</td>
<td>0.00000</td>
<td>0.1587</td>
<td>0.05884</td>
<td>...</td>
<td>9.456</td>
<td>30.37</td>
<td>59.16</td>
<td>268.6</td>
<td>0.08996</td>
<td>0.06444</td>
<td>0.0000</td>
<td>0.0000</td>
<td>0.2871</td>
<td>0.07039</td>
</tr>
</tbody>
</table>

<p>569 rows × 30 columns</p>
</div>
</div>
</div>
<div id="73591d13" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">lr_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LogisticRegression(solver<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'liblinear'</span>)</span>
<span id="cb2-2">knn_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KNeighborsClassifier(n_neighbors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>)</span>
<span id="cb2-3"></span>
<span id="cb2-4">vo_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> VotingClassifier(estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'LR'</span>, lr_clf), (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'KNN'</span>, knn_clf)],</span>
<span id="cb2-5">                          voting<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'soft'</span>)</span>
<span id="cb2-6">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(cancer.data, cancer.target, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>)</span>
<span id="cb2-7">vo_clf.fit(X_train, y_train)</span>
<span id="cb2-8">pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vo_clf.predict(X_test)</span>
<span id="cb2-9">accuracy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> accuracy_score(y_test, pred)</span>
<span id="cb2-10">accuracy</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>0.9210526315789473</code></pre>
</div>
</div>
<div id="9d408271" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> classifier <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [lr_clf, knn_clf]:</span>
<span id="cb4-2">    classifier.fit(X_train, y_train)</span>
<span id="cb4-3">    pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> classifier.predict(X_test)</span>
<span id="cb4-4">    class_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> classifier.__class__.<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span></span>
<span id="cb4-5">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>class_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> 정확도: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>accuracy_score(y_test, pred)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>LogisticRegression 정확도: 0.9298
KNeighborsClassifier 정확도: 0.9211</code></pre>
</div>
</div>
<ul>
<li>반드시 voting이 제일 좋은 모델을 선택하는 것보다 좋은건 아님</li>
</ul>
</section>
</section>
<section id="bagging" class="level2">
<h2 class="anchored" data-anchor-id="bagging">bagging</h2>
<ul>
<li>같은 유형의 알고리즘의 분류기가 boostrap 해가서 예측. random forest가 대표적. 분류에서는 voting<sup>2</sup>으로 결정</li>
</ul>
<section id="randomforest" class="level3">
<h3 class="anchored" data-anchor-id="randomforest">RandomForest</h3>
<div id="86ae3c9a" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomForestClassifier</span>
<span id="cb6-2"></span>
<span id="cb6-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_new_feature_name_df(old):</span>
<span id="cb6-4">    df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>old.groupby(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'column_name'</span>).cumcount(), columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dup_cnt'</span>])</span>
<span id="cb6-5">    df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.reset_index()</span>
<span id="cb6-6">    new_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.merge(old.reset_index(), df, how<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'outer'</span>)</span>
<span id="cb6-7">    new_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'column_name'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_df[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'column_name'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dup_cnt'</span>]].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> x: x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb6-8">    new_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_df.drop([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb6-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> new_df</span>
<span id="cb6-10"></span>
<span id="cb6-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_human_dataset():</span>
<span id="cb6-12">    feature_name_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/human_activity/features.txt'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'\s+'</span>, header<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'column_index'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'column_name'</span>])</span>
<span id="cb6-13">    new_feature_name_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_new_feature_name_df(feature_name_df)</span>
<span id="cb6-14">    feature_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_feature_name_df.iloc[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].values.tolist()</span>
<span id="cb6-15"></span>
<span id="cb6-16">    X_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/human_activity/train/X_train.txt'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'\s+'</span>, names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>feature_name)</span>
<span id="cb6-17">    X_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/human_activity/test/X_test.txt'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'\s+'</span>, names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>feature_name)</span>
<span id="cb6-18"></span>
<span id="cb6-19">    y_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/human_activity/train/y_train.txt'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'\s+'</span>, header<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'action'</span>])</span>
<span id="cb6-20">    y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/human_activity/test/y_test.txt'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'\s+'</span>, header<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'action'</span>])</span>
<span id="cb6-21"></span>
<span id="cb6-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> X_train, X_test, y_train, y_test</span>
<span id="cb6-23"></span>
<span id="cb6-24">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_human_dataset()</span></code></pre></div>
</div>
<div id="879b9f9b" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">rf_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier(max_depth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>)</span>
<span id="cb7-2">rf_clf.fit(X_train, y_train)</span>
<span id="cb7-3">pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rf_clf.predict(X_test)</span>
<span id="cb7-4">accuracy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> accuracy_score(y_test, pred)</span>
<span id="cb7-5">accuracy</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>0.9178825924669155</code></pre>
</div>
</div>
</section>
</section>
<section id="boosting" class="level2">
<h2 class="anchored" data-anchor-id="boosting">boosting</h2>
<section id="gbm" class="level3">
<h3 class="anchored" data-anchor-id="gbm">GBM</h3>
<div id="7d4d016f" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># from sklearn.ensemble import GradientBoostingClassifier</span></span>
<span id="cb9-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># import time</span></span>
<span id="cb9-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># </span></span>
<span id="cb9-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># X_train, X_test, y_train, y_test = get_human_dataset()</span></span>
<span id="cb9-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># start_time = time.time()</span></span>
<span id="cb9-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># </span></span>
<span id="cb9-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># gb_clf = GradientBoostingClassifier()</span></span>
<span id="cb9-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># gb_clf.fit(X_train, y_train)</span></span>
<span id="cb9-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># gb_pred = gb_clf.predict(X_test)</span></span>
<span id="cb9-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># gb_accuracy = accuracy_score(y_test, gb_pred)</span></span>
<span id="cb9-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#</span></span>
<span id="cb9-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># end_time = time.time()</span></span>
<span id="cb9-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#</span></span>
<span id="cb9-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># print(f'{gb_accuracy:.3f}, {end_time - start_time}초')</span></span></code></pre></div>
</div>
<p>0.939, 701.6343066692352초</p>
<ul>
<li>아주 오래 걸림.</li>
</ul>
</section>
<section id="xgboost" class="level3">
<h3 class="anchored" data-anchor-id="xgboost">XGBoost</h3>
<ul>
<li><p>결손값을 자체 처리할 수 있다.</p></li>
<li><p>조기 종료 기능이 있다.</p></li>
<li><p>자체적으로 교차 검증, 성능 평가, 피처 중요도 시각화 기능이 있다.</p></li>
<li><p>python xgboost</p></li>
</ul>
<div id="a5e0c29a" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> xgboost <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> xgb</span>
<span id="cb10-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> xgboost <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plot_importance</span>
<span id="cb10-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb10-4"></span>
<span id="cb10-5">dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_breast_cancer()</span>
<span id="cb10-6"></span>
<span id="cb10-7">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(dataset.data, dataset.target, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>)</span>
<span id="cb10-8">X_tr, X_val, y_tr, y_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X_train, y_train, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span></code></pre></div>
</div>
<div id="b61f8977" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">dtr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xgb.DMatrix(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>X_tr, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_tr)</span>
<span id="cb11-2">dval <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xgb.DMatrix(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>X_val, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_val)</span>
<span id="cb11-3">dtest <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xgb.DMatrix(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>X_test, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_test)</span></code></pre></div>
</div>
<div id="fe3df619" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb12-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,</span>
<span id="cb12-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'eta'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>,</span>
<span id="cb12-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'objective'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'binary:logistic'</span>,</span>
<span id="cb12-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'eval_metric'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'logloss'</span></span>
<span id="cb12-6">}</span>
<span id="cb12-7">num_rounds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span></span></code></pre></div>
</div>
<div id="08be87e7" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">eval_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [(dtr, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'train'</span>), (dval, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'eval'</span>)]</span>
<span id="cb13-2"></span>
<span id="cb13-3">xgb_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xgb.train(params<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>params, dtrain<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dtr, num_boost_round<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>num_rounds, early_stopping_rounds<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, evals<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>eval_list)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0] train-logloss:0.61277   eval-logloss:0.58601
[1] train-logloss:0.57664   eval-logloss:0.55582
[2] train-logloss:0.54304   eval-logloss:0.52806
[3] train-logloss:0.51255   eval-logloss:0.50298
[4] train-logloss:0.48471   eval-logloss:0.47989
[5] train-logloss:0.45884   eval-logloss:0.45674
[6] train-logloss:0.43517   eval-logloss:0.43736
[7] train-logloss:0.41363   eval-logloss:0.42013
[8] train-logloss:0.39341   eval-logloss:0.40354
[9] train-logloss:0.37494   eval-logloss:0.38841
[10]    train-logloss:0.35744   eval-logloss:0.37480
[11]    train-logloss:0.34054   eval-logloss:0.35955
[12]    train-logloss:0.32442   eval-logloss:0.34527
[13]    train-logloss:0.30963   eval-logloss:0.32976
[14]    train-logloss:0.29638   eval-logloss:0.32018
[15]    train-logloss:0.28306   eval-logloss:0.30855
[16]    train-logloss:0.27060   eval-logloss:0.29773
[17]    train-logloss:0.25894   eval-logloss:0.28763
[18]    train-logloss:0.24842   eval-logloss:0.27760
[19]    train-logloss:0.23861   eval-logloss:0.27116
[20]    train-logloss:0.22890   eval-logloss:0.26281
[21]    train-logloss:0.21995   eval-logloss:0.25627
[22]    train-logloss:0.21183   eval-logloss:0.25092
[23]    train-logloss:0.20363   eval-logloss:0.24393
[24]    train-logloss:0.19606   eval-logloss:0.23852
[25]    train-logloss:0.18881   eval-logloss:0.23108
[26]    train-logloss:0.18165   eval-logloss:0.22460
[27]    train-logloss:0.17502   eval-logloss:0.21895
[28]    train-logloss:0.16889   eval-logloss:0.21248
[29]    train-logloss:0.16323   eval-logloss:0.20904
[30]    train-logloss:0.15760   eval-logloss:0.20456
[31]    train-logloss:0.15228   eval-logloss:0.20042
[32]    train-logloss:0.14728   eval-logloss:0.19496
[33]    train-logloss:0.14254   eval-logloss:0.19157
[34]    train-logloss:0.13775   eval-logloss:0.18653
[35]    train-logloss:0.13340   eval-logloss:0.18317
[36]    train-logloss:0.12934   eval-logloss:0.17926
[37]    train-logloss:0.12562   eval-logloss:0.17500
[38]    train-logloss:0.12162   eval-logloss:0.17143
[39]    train-logloss:0.11812   eval-logloss:0.16801
[40]    train-logloss:0.11493   eval-logloss:0.16522
[41]    train-logloss:0.11171   eval-logloss:0.16259
[42]    train-logloss:0.10874   eval-logloss:0.16035
[43]    train-logloss:0.10593   eval-logloss:0.15740
[44]    train-logloss:0.10316   eval-logloss:0.15462
[45]    train-logloss:0.10017   eval-logloss:0.15140
[46]    train-logloss:0.09748   eval-logloss:0.14985
[47]    train-logloss:0.09515   eval-logloss:0.14732
[48]    train-logloss:0.09280   eval-logloss:0.14613
[49]    train-logloss:0.09039   eval-logloss:0.14424
[50]    train-logloss:0.08814   eval-logloss:0.14301
[51]    train-logloss:0.08583   eval-logloss:0.14055
[52]    train-logloss:0.08369   eval-logloss:0.13767
[53]    train-logloss:0.08167   eval-logloss:0.13494
[54]    train-logloss:0.07971   eval-logloss:0.13295
[55]    train-logloss:0.07782   eval-logloss:0.13025
[56]    train-logloss:0.07603   eval-logloss:0.12777
[57]    train-logloss:0.07431   eval-logloss:0.12528
[58]    train-logloss:0.07265   eval-logloss:0.12285
[59]    train-logloss:0.07107   eval-logloss:0.12062
[60]    train-logloss:0.06952   eval-logloss:0.11986
[61]    train-logloss:0.06804   eval-logloss:0.11877
[62]    train-logloss:0.06626   eval-logloss:0.11728
[63]    train-logloss:0.06490   eval-logloss:0.11527
[64]    train-logloss:0.06361   eval-logloss:0.11325
[65]    train-logloss:0.06205   eval-logloss:0.11093
[66]    train-logloss:0.06085   eval-logloss:0.10911
[67]    train-logloss:0.05957   eval-logloss:0.10839
[68]    train-logloss:0.05846   eval-logloss:0.10659
[69]    train-logloss:0.05701   eval-logloss:0.10541
[70]    train-logloss:0.05598   eval-logloss:0.10382
[71]    train-logloss:0.05487   eval-logloss:0.10325
[72]    train-logloss:0.05390   eval-logloss:0.10238
[73]    train-logloss:0.05262   eval-logloss:0.10137
[74]    train-logloss:0.05173   eval-logloss:0.09989
[75]    train-logloss:0.05078   eval-logloss:0.09905
[76]    train-logloss:0.04998   eval-logloss:0.09774
[77]    train-logloss:0.04902   eval-logloss:0.09725
[78]    train-logloss:0.04813   eval-logloss:0.09723
[79]    train-logloss:0.04728   eval-logloss:0.09558
[80]    train-logloss:0.04655   eval-logloss:0.09499
[81]    train-logloss:0.04558   eval-logloss:0.09360
[82]    train-logloss:0.04481   eval-logloss:0.09289
[83]    train-logloss:0.04411   eval-logloss:0.09233
[84]    train-logloss:0.04323   eval-logloss:0.09104
[85]    train-logloss:0.04244   eval-logloss:0.09051
[86]    train-logloss:0.04163   eval-logloss:0.08929
[87]    train-logloss:0.04105   eval-logloss:0.08824
[88]    train-logloss:0.04029   eval-logloss:0.08709
[89]    train-logloss:0.03970   eval-logloss:0.08667
[90]    train-logloss:0.03908   eval-logloss:0.08651
[91]    train-logloss:0.03840   eval-logloss:0.08554
[92]    train-logloss:0.03790   eval-logloss:0.08459
[93]    train-logloss:0.03717   eval-logloss:0.08382
[94]    train-logloss:0.03655   eval-logloss:0.08279
[95]    train-logloss:0.03609   eval-logloss:0.08246
[96]    train-logloss:0.03551   eval-logloss:0.08162
[97]    train-logloss:0.03503   eval-logloss:0.08062
[98]    train-logloss:0.03438   eval-logloss:0.07993
[99]    train-logloss:0.03390   eval-logloss:0.07963
[100]   train-logloss:0.03329   eval-logloss:0.07899
[101]   train-logloss:0.03284   eval-logloss:0.07873
[102]   train-logloss:0.03245   eval-logloss:0.07871
[103]   train-logloss:0.03202   eval-logloss:0.07846
[104]   train-logloss:0.03158   eval-logloss:0.07822
[105]   train-logloss:0.03122   eval-logloss:0.07799
[106]   train-logloss:0.03076   eval-logloss:0.07690
[107]   train-logloss:0.03032   eval-logloss:0.07710
[108]   train-logloss:0.02993   eval-logloss:0.07759
[109]   train-logloss:0.02950   eval-logloss:0.07750
[110]   train-logloss:0.02908   eval-logloss:0.07647
[111]   train-logloss:0.02867   eval-logloss:0.07550
[112]   train-logloss:0.02831   eval-logloss:0.07529
[113]   train-logloss:0.02787   eval-logloss:0.07401
[114]   train-logloss:0.02750   eval-logloss:0.07395
[115]   train-logloss:0.02712   eval-logloss:0.07300
[116]   train-logloss:0.02674   eval-logloss:0.07235
[117]   train-logloss:0.02635   eval-logloss:0.07196
[118]   train-logloss:0.02599   eval-logloss:0.07107
[119]   train-logloss:0.02565   eval-logloss:0.07043
[120]   train-logloss:0.02536   eval-logloss:0.07095
[121]   train-logloss:0.02505   eval-logloss:0.07092
[122]   train-logloss:0.02473   eval-logloss:0.07007
[123]   train-logloss:0.02444   eval-logloss:0.07007
[124]   train-logloss:0.02418   eval-logloss:0.07058
[125]   train-logloss:0.02393   eval-logloss:0.07069
[126]   train-logloss:0.02363   eval-logloss:0.07066
[127]   train-logloss:0.02333   eval-logloss:0.06986
[128]   train-logloss:0.02305   eval-logloss:0.06984
[129]   train-logloss:0.02277   eval-logloss:0.06906
[130]   train-logloss:0.02252   eval-logloss:0.06911
[131]   train-logloss:0.02224   eval-logloss:0.06825
[132]   train-logloss:0.02198   eval-logloss:0.06751
[133]   train-logloss:0.02175   eval-logloss:0.06699
[134]   train-logloss:0.02155   eval-logloss:0.06748
[135]   train-logloss:0.02138   eval-logloss:0.06752
[136]   train-logloss:0.02114   eval-logloss:0.06747
[137]   train-logloss:0.02096   eval-logloss:0.06682
[138]   train-logloss:0.02075   eval-logloss:0.06686
[139]   train-logloss:0.02057   eval-logloss:0.06663
[140]   train-logloss:0.02032   eval-logloss:0.06654
[141]   train-logloss:0.02013   eval-logloss:0.06599
[142]   train-logloss:0.01995   eval-logloss:0.06647
[143]   train-logloss:0.01972   eval-logloss:0.06640
[144]   train-logloss:0.01950   eval-logloss:0.06636
[145]   train-logloss:0.01925   eval-logloss:0.06568
[146]   train-logloss:0.01910   eval-logloss:0.06597
[147]   train-logloss:0.01891   eval-logloss:0.06518
[148]   train-logloss:0.01876   eval-logloss:0.06547
[149]   train-logloss:0.01854   eval-logloss:0.06481
[150]   train-logloss:0.01838   eval-logloss:0.06530
[151]   train-logloss:0.01824   eval-logloss:0.06490
[152]   train-logloss:0.01806   eval-logloss:0.06506
[153]   train-logloss:0.01789   eval-logloss:0.06519
[154]   train-logloss:0.01771   eval-logloss:0.06496
[155]   train-logloss:0.01762   eval-logloss:0.06516
[156]   train-logloss:0.01742   eval-logloss:0.06457
[157]   train-logloss:0.01729   eval-logloss:0.06484
[158]   train-logloss:0.01716   eval-logloss:0.06408
[159]   train-logloss:0.01698   eval-logloss:0.06389
[160]   train-logloss:0.01679   eval-logloss:0.06333
[161]   train-logloss:0.01671   eval-logloss:0.06355
[162]   train-logloss:0.01657   eval-logloss:0.06357
[163]   train-logloss:0.01645   eval-logloss:0.06321
[164]   train-logloss:0.01631   eval-logloss:0.06317
[165]   train-logloss:0.01621   eval-logloss:0.06322
[166]   train-logloss:0.01604   eval-logloss:0.06270
[167]   train-logloss:0.01594   eval-logloss:0.06232
[168]   train-logloss:0.01587   eval-logloss:0.06253
[169]   train-logloss:0.01572   eval-logloss:0.06206
[170]   train-logloss:0.01564   eval-logloss:0.06167
[171]   train-logloss:0.01554   eval-logloss:0.06097
[172]   train-logloss:0.01547   eval-logloss:0.06117
[173]   train-logloss:0.01534   eval-logloss:0.06110
[174]   train-logloss:0.01526   eval-logloss:0.06115
[175]   train-logloss:0.01516   eval-logloss:0.06047
[176]   train-logloss:0.01502   eval-logloss:0.06018
[177]   train-logloss:0.01493   eval-logloss:0.06022
[178]   train-logloss:0.01482   eval-logloss:0.06012
[179]   train-logloss:0.01475   eval-logloss:0.05975
[180]   train-logloss:0.01468   eval-logloss:0.05968
[181]   train-logloss:0.01461   eval-logloss:0.05988
[182]   train-logloss:0.01454   eval-logloss:0.05952
[183]   train-logloss:0.01447   eval-logloss:0.05945
[184]   train-logloss:0.01437   eval-logloss:0.05952
[185]   train-logloss:0.01428   eval-logloss:0.05933
[186]   train-logloss:0.01420   eval-logloss:0.05926
[187]   train-logloss:0.01410   eval-logloss:0.05917
[188]   train-logloss:0.01404   eval-logloss:0.05883
[189]   train-logloss:0.01397   eval-logloss:0.05843
[190]   train-logloss:0.01389   eval-logloss:0.05825
[191]   train-logloss:0.01382   eval-logloss:0.05821
[192]   train-logloss:0.01372   eval-logloss:0.05829
[193]   train-logloss:0.01364   eval-logloss:0.05811
[194]   train-logloss:0.01358   eval-logloss:0.05808
[195]   train-logloss:0.01352   eval-logloss:0.05823
[196]   train-logloss:0.01346   eval-logloss:0.05829
[197]   train-logloss:0.01340   eval-logloss:0.05823
[198]   train-logloss:0.01331   eval-logloss:0.05832
[199]   train-logloss:0.01324   eval-logloss:0.05813
[200]   train-logloss:0.01317   eval-logloss:0.05811
[201]   train-logloss:0.01312   eval-logloss:0.05769
[202]   train-logloss:0.01305   eval-logloss:0.05754
[203]   train-logloss:0.01296   eval-logloss:0.05764
[204]   train-logloss:0.01289   eval-logloss:0.05749
[205]   train-logloss:0.01284   eval-logloss:0.05756
[206]   train-logloss:0.01279   eval-logloss:0.05772
[207]   train-logloss:0.01273   eval-logloss:0.05768
[208]   train-logloss:0.01268   eval-logloss:0.05783
[209]   train-logloss:0.01263   eval-logloss:0.05752
[210]   train-logloss:0.01258   eval-logloss:0.05711
[211]   train-logloss:0.01251   eval-logloss:0.05697
[212]   train-logloss:0.01243   eval-logloss:0.05662
[213]   train-logloss:0.01237   eval-logloss:0.05671
[214]   train-logloss:0.01231   eval-logloss:0.05659
[215]   train-logloss:0.01226   eval-logloss:0.05629
[216]   train-logloss:0.01219   eval-logloss:0.05595
[217]   train-logloss:0.01214   eval-logloss:0.05591
[218]   train-logloss:0.01208   eval-logloss:0.05580
[219]   train-logloss:0.01201   eval-logloss:0.05606
[220]   train-logloss:0.01196   eval-logloss:0.05592
[221]   train-logloss:0.01190   eval-logloss:0.05601
[222]   train-logloss:0.01185   eval-logloss:0.05608
[223]   train-logloss:0.01181   eval-logloss:0.05569
[224]   train-logloss:0.01176   eval-logloss:0.05559
[225]   train-logloss:0.01169   eval-logloss:0.05585
[226]   train-logloss:0.01164   eval-logloss:0.05576
[227]   train-logloss:0.01158   eval-logloss:0.05549
[228]   train-logloss:0.01153   eval-logloss:0.05521
[229]   train-logloss:0.01149   eval-logloss:0.05509
[230]   train-logloss:0.01145   eval-logloss:0.05493
[231]   train-logloss:0.01140   eval-logloss:0.05507
[232]   train-logloss:0.01136   eval-logloss:0.05469
[233]   train-logloss:0.01132   eval-logloss:0.05500
[234]   train-logloss:0.01128   eval-logloss:0.05474
[235]   train-logloss:0.01124   eval-logloss:0.05472
[236]   train-logloss:0.01120   eval-logloss:0.05490
[237]   train-logloss:0.01115   eval-logloss:0.05503
[238]   train-logloss:0.01111   eval-logloss:0.05516
[239]   train-logloss:0.01107   eval-logloss:0.05524
[240]   train-logloss:0.01103   eval-logloss:0.05537
[241]   train-logloss:0.01099   eval-logloss:0.05536
[242]   train-logloss:0.01096   eval-logloss:0.05568
[243]   train-logloss:0.01090   eval-logloss:0.05543
[244]   train-logloss:0.01087   eval-logloss:0.05556
[245]   train-logloss:0.01083   eval-logloss:0.05519
[246]   train-logloss:0.01081   eval-logloss:0.05537
[247]   train-logloss:0.01077   eval-logloss:0.05536
[248]   train-logloss:0.01072   eval-logloss:0.05549
[249]   train-logloss:0.01068   eval-logloss:0.05562
[250]   train-logloss:0.01064   eval-logloss:0.05537
[251]   train-logloss:0.01061   eval-logloss:0.05555
[252]   train-logloss:0.01058   eval-logloss:0.05568
[253]   train-logloss:0.01054   eval-logloss:0.05532
[254]   train-logloss:0.01051   eval-logloss:0.05508
[255]   train-logloss:0.01049   eval-logloss:0.05525
[256]   train-logloss:0.01045   eval-logloss:0.05524
[257]   train-logloss:0.01042   eval-logloss:0.05537
[258]   train-logloss:0.01037   eval-logloss:0.05554
[259]   train-logloss:0.01033   eval-logloss:0.05563
[260]   train-logloss:0.01030   eval-logloss:0.05528
[261]   train-logloss:0.01028   eval-logloss:0.05546
[262]   train-logloss:0.01025   eval-logloss:0.05559
[263]   train-logloss:0.01022   eval-logloss:0.05558
[264]   train-logloss:0.01017   eval-logloss:0.05576
[265]   train-logloss:0.01014   eval-logloss:0.05593
[266]   train-logloss:0.01011   eval-logloss:0.05558
[267]   train-logloss:0.01008   eval-logloss:0.05571
[268]   train-logloss:0.01005   eval-logloss:0.05584
[269]   train-logloss:0.01002   eval-logloss:0.05561
[270]   train-logloss:0.00998   eval-logloss:0.05560
[271]   train-logloss:0.00997   eval-logloss:0.05577
[272]   train-logloss:0.00992   eval-logloss:0.05574
[273]   train-logloss:0.00989   eval-logloss:0.05540
[274]   train-logloss:0.00987   eval-logloss:0.05557
[275]   train-logloss:0.00984   eval-logloss:0.05570
[276]   train-logloss:0.00981   eval-logloss:0.05547
[277]   train-logloss:0.00978   eval-logloss:0.05546
[278]   train-logloss:0.00973   eval-logloss:0.05543
[279]   train-logloss:0.00970   eval-logloss:0.05556
[280]   train-logloss:0.00969   eval-logloss:0.05562
[281]   train-logloss:0.00966   eval-logloss:0.05528</code></pre>
</div>
</div>
<div id="8b810501" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">pred_probs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xgb_model.predict(dtest)</span>
<span id="cb15-2">preds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> pred_probs]</span></code></pre></div>
</div>
<ul>
<li>sklearn xgboost</li>
</ul>
<div id="82293978" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> xgboost <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> XGBClassifier</span>
<span id="cb16-2"></span>
<span id="cb16-3">evals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb16-4">xgb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> XGBClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, </span>
<span id="cb16-5">                    learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, </span>
<span id="cb16-6">                    max_depth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, </span>
<span id="cb16-7">                    early_stopping_rounds<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>,</span>
<span id="cb16-8">                    eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'logloss'</span>])</span>
<span id="cb16-9">xgb.fit(X_tr, y_tr, eval_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>evals)</span>
<span id="cb16-10">preds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xgb.predict(X_test)</span>
<span id="cb16-11">pred_probs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> xgb.predict_proba(X_test)[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0] validation_0-logloss:0.61277    validation_1-logloss:0.58601
[1] validation_0-logloss:0.57664    validation_1-logloss:0.55582
[2] validation_0-logloss:0.54304    validation_1-logloss:0.52806
[3] validation_0-logloss:0.51255    validation_1-logloss:0.50298
[4] validation_0-logloss:0.48471    validation_1-logloss:0.47989
[5] validation_0-logloss:0.45884    validation_1-logloss:0.45674
[6] validation_0-logloss:0.43517    validation_1-logloss:0.43736
[7] validation_0-logloss:0.41363    validation_1-logloss:0.42013
[8] validation_0-logloss:0.39341    validation_1-logloss:0.40354
[9] validation_0-logloss:0.37494    validation_1-logloss:0.38841
[10]    validation_0-logloss:0.35744    validation_1-logloss:0.37480
[11]    validation_0-logloss:0.34054    validation_1-logloss:0.35955
[12]    validation_0-logloss:0.32442    validation_1-logloss:0.34527
[13]    validation_0-logloss:0.30963    validation_1-logloss:0.32976
[14]    validation_0-logloss:0.29638    validation_1-logloss:0.32018
[15]    validation_0-logloss:0.28306    validation_1-logloss:0.30855
[16]    validation_0-logloss:0.27060    validation_1-logloss:0.29773
[17]    validation_0-logloss:0.25894    validation_1-logloss:0.28763
[18]    validation_0-logloss:0.24842    validation_1-logloss:0.27760
[19]    validation_0-logloss:0.23861    validation_1-logloss:0.27116
[20]    validation_0-logloss:0.22890    validation_1-logloss:0.26281
[21]    validation_0-logloss:0.21995    validation_1-logloss:0.25627
[22]    validation_0-logloss:0.21183    validation_1-logloss:0.25092
[23]    validation_0-logloss:0.20363    validation_1-logloss:0.24393
[24]    validation_0-logloss:0.19606    validation_1-logloss:0.23852
[25]    validation_0-logloss:0.18881    validation_1-logloss:0.23108
[26]    validation_0-logloss:0.18165    validation_1-logloss:0.22460
[27]    validation_0-logloss:0.17502    validation_1-logloss:0.21895
[28]    validation_0-logloss:0.16889    validation_1-logloss:0.21248
[29]    validation_0-logloss:0.16323    validation_1-logloss:0.20904
[30]    validation_0-logloss:0.15760    validation_1-logloss:0.20456
[31]    validation_0-logloss:0.15228    validation_1-logloss:0.20042
[32]    validation_0-logloss:0.14728    validation_1-logloss:0.19496
[33]    validation_0-logloss:0.14254    validation_1-logloss:0.19157
[34]    validation_0-logloss:0.13775    validation_1-logloss:0.18653
[35]    validation_0-logloss:0.13340    validation_1-logloss:0.18317
[36]    validation_0-logloss:0.12934    validation_1-logloss:0.17926
[37]    validation_0-logloss:0.12562    validation_1-logloss:0.17500
[38]    validation_0-logloss:0.12162    validation_1-logloss:0.17143
[39]    validation_0-logloss:0.11812    validation_1-logloss:0.16801
[40]    validation_0-logloss:0.11493    validation_1-logloss:0.16522
[41]    validation_0-logloss:0.11171    validation_1-logloss:0.16259
[42]    validation_0-logloss:0.10874    validation_1-logloss:0.16035
[43]    validation_0-logloss:0.10593    validation_1-logloss:0.15740
[44]    validation_0-logloss:0.10316    validation_1-logloss:0.15462
[45]    validation_0-logloss:0.10017    validation_1-logloss:0.15140
[46]    validation_0-logloss:0.09748    validation_1-logloss:0.14985
[47]    validation_0-logloss:0.09515    validation_1-logloss:0.14732
[48]    validation_0-logloss:0.09280    validation_1-logloss:0.14613
[49]    validation_0-logloss:0.09039    validation_1-logloss:0.14424
[50]    validation_0-logloss:0.08814    validation_1-logloss:0.14301
[51]    validation_0-logloss:0.08583    validation_1-logloss:0.14055
[52]    validation_0-logloss:0.08369    validation_1-logloss:0.13767
[53]    validation_0-logloss:0.08167    validation_1-logloss:0.13494
[54]    validation_0-logloss:0.07971    validation_1-logloss:0.13295
[55]    validation_0-logloss:0.07782    validation_1-logloss:0.13025
[56]    validation_0-logloss:0.07603    validation_1-logloss:0.12777
[57]    validation_0-logloss:0.07431    validation_1-logloss:0.12528
[58]    validation_0-logloss:0.07265    validation_1-logloss:0.12285
[59]    validation_0-logloss:0.07107    validation_1-logloss:0.12062
[60]    validation_0-logloss:0.06952    validation_1-logloss:0.11986
[61]    validation_0-logloss:0.06804    validation_1-logloss:0.11877
[62]    validation_0-logloss:0.06626    validation_1-logloss:0.11728
[63]    validation_0-logloss:0.06490    validation_1-logloss:0.11527
[64]    validation_0-logloss:0.06361    validation_1-logloss:0.11325
[65]    validation_0-logloss:0.06205    validation_1-logloss:0.11093
[66]    validation_0-logloss:0.06085    validation_1-logloss:0.10911
[67]    validation_0-logloss:0.05957    validation_1-logloss:0.10839
[68]    validation_0-logloss:0.05846    validation_1-logloss:0.10659
[69]    validation_0-logloss:0.05701    validation_1-logloss:0.10541
[70]    validation_0-logloss:0.05598    validation_1-logloss:0.10382
[71]    validation_0-logloss:0.05487    validation_1-logloss:0.10325
[72]    validation_0-logloss:0.05390    validation_1-logloss:0.10238
[73]    validation_0-logloss:0.05262    validation_1-logloss:0.10137
[74]    validation_0-logloss:0.05173    validation_1-logloss:0.09989
[75]    validation_0-logloss:0.05078    validation_1-logloss:0.09905
[76]    validation_0-logloss:0.04998    validation_1-logloss:0.09774
[77]    validation_0-logloss:0.04902    validation_1-logloss:0.09725
[78]    validation_0-logloss:0.04813    validation_1-logloss:0.09723
[79]    validation_0-logloss:0.04728    validation_1-logloss:0.09558
[80]    validation_0-logloss:0.04655    validation_1-logloss:0.09499
[81]    validation_0-logloss:0.04558    validation_1-logloss:0.09360
[82]    validation_0-logloss:0.04481    validation_1-logloss:0.09289
[83]    validation_0-logloss:0.04411    validation_1-logloss:0.09233
[84]    validation_0-logloss:0.04323    validation_1-logloss:0.09104
[85]    validation_0-logloss:0.04244    validation_1-logloss:0.09051
[86]    validation_0-logloss:0.04163    validation_1-logloss:0.08929
[87]    validation_0-logloss:0.04105    validation_1-logloss:0.08824
[88]    validation_0-logloss:0.04029    validation_1-logloss:0.08709
[89]    validation_0-logloss:0.03970    validation_1-logloss:0.08667
[90]    validation_0-logloss:0.03908    validation_1-logloss:0.08651
[91]    validation_0-logloss:0.03840    validation_1-logloss:0.08554
[92]    validation_0-logloss:0.03790    validation_1-logloss:0.08459
[93]    validation_0-logloss:0.03717    validation_1-logloss:0.08382
[94]    validation_0-logloss:0.03655    validation_1-logloss:0.08279
[95]    validation_0-logloss:0.03609    validation_1-logloss:0.08246
[96]    validation_0-logloss:0.03551    validation_1-logloss:0.08162
[97]    validation_0-logloss:0.03503    validation_1-logloss:0.08062
[98]    validation_0-logloss:0.03438    validation_1-logloss:0.07993
[99]    validation_0-logloss:0.03390    validation_1-logloss:0.07963
[100]   validation_0-logloss:0.03329    validation_1-logloss:0.07899
[101]   validation_0-logloss:0.03284    validation_1-logloss:0.07873
[102]   validation_0-logloss:0.03245    validation_1-logloss:0.07871
[103]   validation_0-logloss:0.03202    validation_1-logloss:0.07846
[104]   validation_0-logloss:0.03158    validation_1-logloss:0.07822
[105]   validation_0-logloss:0.03122    validation_1-logloss:0.07799
[106]   validation_0-logloss:0.03076    validation_1-logloss:0.07690
[107]   validation_0-logloss:0.03032    validation_1-logloss:0.07710
[108]   validation_0-logloss:0.02993    validation_1-logloss:0.07759
[109]   validation_0-logloss:0.02950    validation_1-logloss:0.07750
[110]   validation_0-logloss:0.02908    validation_1-logloss:0.07647
[111]   validation_0-logloss:0.02867    validation_1-logloss:0.07550
[112]   validation_0-logloss:0.02831    validation_1-logloss:0.07529
[113]   validation_0-logloss:0.02787    validation_1-logloss:0.07401
[114]   validation_0-logloss:0.02750    validation_1-logloss:0.07395
[115]   validation_0-logloss:0.02712    validation_1-logloss:0.07300
[116]   validation_0-logloss:0.02674    validation_1-logloss:0.07235
[117]   validation_0-logloss:0.02635    validation_1-logloss:0.07196
[118]   validation_0-logloss:0.02599    validation_1-logloss:0.07107
[119]   validation_0-logloss:0.02565    validation_1-logloss:0.07043
[120]   validation_0-logloss:0.02536    validation_1-logloss:0.07095
[121]   validation_0-logloss:0.02505    validation_1-logloss:0.07092
[122]   validation_0-logloss:0.02473    validation_1-logloss:0.07007
[123]   validation_0-logloss:0.02444    validation_1-logloss:0.07007
[124]   validation_0-logloss:0.02418    validation_1-logloss:0.07058
[125]   validation_0-logloss:0.02393    validation_1-logloss:0.07069
[126]   validation_0-logloss:0.02363    validation_1-logloss:0.07066
[127]   validation_0-logloss:0.02333    validation_1-logloss:0.06986
[128]   validation_0-logloss:0.02305    validation_1-logloss:0.06984
[129]   validation_0-logloss:0.02277    validation_1-logloss:0.06906
[130]   validation_0-logloss:0.02252    validation_1-logloss:0.06911
[131]   validation_0-logloss:0.02224    validation_1-logloss:0.06825
[132]   validation_0-logloss:0.02198    validation_1-logloss:0.06751
[133]   validation_0-logloss:0.02175    validation_1-logloss:0.06699
[134]   validation_0-logloss:0.02155    validation_1-logloss:0.06748
[135]   validation_0-logloss:0.02138    validation_1-logloss:0.06752
[136]   validation_0-logloss:0.02114    validation_1-logloss:0.06747
[137]   validation_0-logloss:0.02096    validation_1-logloss:0.06682
[138]   validation_0-logloss:0.02075    validation_1-logloss:0.06686
[139]   validation_0-logloss:0.02057    validation_1-logloss:0.06663
[140]   validation_0-logloss:0.02032    validation_1-logloss:0.06654
[141]   validation_0-logloss:0.02013    validation_1-logloss:0.06599
[142]   validation_0-logloss:0.01995    validation_1-logloss:0.06647
[143]   validation_0-logloss:0.01972    validation_1-logloss:0.06640
[144]   validation_0-logloss:0.01950    validation_1-logloss:0.06636
[145]   validation_0-logloss:0.01925    validation_1-logloss:0.06568
[146]   validation_0-logloss:0.01910    validation_1-logloss:0.06597
[147]   validation_0-logloss:0.01891    validation_1-logloss:0.06518
[148]   validation_0-logloss:0.01876    validation_1-logloss:0.06547
[149]   validation_0-logloss:0.01854    validation_1-logloss:0.06481
[150]   validation_0-logloss:0.01838    validation_1-logloss:0.06530
[151]   validation_0-logloss:0.01824    validation_1-logloss:0.06490
[152]   validation_0-logloss:0.01806    validation_1-logloss:0.06506
[153]   validation_0-logloss:0.01789    validation_1-logloss:0.06519
[154]   validation_0-logloss:0.01771    validation_1-logloss:0.06496
[155]   validation_0-logloss:0.01762    validation_1-logloss:0.06516
[156]   validation_0-logloss:0.01742    validation_1-logloss:0.06457
[157]   validation_0-logloss:0.01729    validation_1-logloss:0.06484
[158]   validation_0-logloss:0.01716    validation_1-logloss:0.06408
[159]   validation_0-logloss:0.01698    validation_1-logloss:0.06389
[160]   validation_0-logloss:0.01679    validation_1-logloss:0.06333
[161]   validation_0-logloss:0.01671    validation_1-logloss:0.06355
[162]   validation_0-logloss:0.01657    validation_1-logloss:0.06357
[163]   validation_0-logloss:0.01645    validation_1-logloss:0.06321
[164]   validation_0-logloss:0.01631    validation_1-logloss:0.06317
[165]   validation_0-logloss:0.01621    validation_1-logloss:0.06322
[166]   validation_0-logloss:0.01604    validation_1-logloss:0.06270
[167]   validation_0-logloss:0.01594    validation_1-logloss:0.06232
[168]   validation_0-logloss:0.01587    validation_1-logloss:0.06253
[169]   validation_0-logloss:0.01572    validation_1-logloss:0.06206
[170]   validation_0-logloss:0.01564    validation_1-logloss:0.06167
[171]   validation_0-logloss:0.01554    validation_1-logloss:0.06097
[172]   validation_0-logloss:0.01547    validation_1-logloss:0.06117
[173]   validation_0-logloss:0.01534    validation_1-logloss:0.06110
[174]   validation_0-logloss:0.01526    validation_1-logloss:0.06115
[175]   validation_0-logloss:0.01516    validation_1-logloss:0.06047
[176]   validation_0-logloss:0.01502    validation_1-logloss:0.06018
[177]   validation_0-logloss:0.01493    validation_1-logloss:0.06022
[178]   validation_0-logloss:0.01482    validation_1-logloss:0.06012
[179]   validation_0-logloss:0.01475    validation_1-logloss:0.05975
[180]   validation_0-logloss:0.01468    validation_1-logloss:0.05968
[181]   validation_0-logloss:0.01461    validation_1-logloss:0.05988
[182]   validation_0-logloss:0.01454    validation_1-logloss:0.05952
[183]   validation_0-logloss:0.01447    validation_1-logloss:0.05945
[184]   validation_0-logloss:0.01437    validation_1-logloss:0.05952
[185]   validation_0-logloss:0.01428    validation_1-logloss:0.05933
[186]   validation_0-logloss:0.01420    validation_1-logloss:0.05926
[187]   validation_0-logloss:0.01410    validation_1-logloss:0.05917
[188]   validation_0-logloss:0.01404    validation_1-logloss:0.05883
[189]   validation_0-logloss:0.01397    validation_1-logloss:0.05843
[190]   validation_0-logloss:0.01389    validation_1-logloss:0.05825
[191]   validation_0-logloss:0.01382    validation_1-logloss:0.05821
[192]   validation_0-logloss:0.01372    validation_1-logloss:0.05829
[193]   validation_0-logloss:0.01364    validation_1-logloss:0.05811
[194]   validation_0-logloss:0.01358    validation_1-logloss:0.05808
[195]   validation_0-logloss:0.01352    validation_1-logloss:0.05823
[196]   validation_0-logloss:0.01346    validation_1-logloss:0.05829
[197]   validation_0-logloss:0.01340    validation_1-logloss:0.05823
[198]   validation_0-logloss:0.01331    validation_1-logloss:0.05832
[199]   validation_0-logloss:0.01324    validation_1-logloss:0.05813
[200]   validation_0-logloss:0.01317    validation_1-logloss:0.05811
[201]   validation_0-logloss:0.01312    validation_1-logloss:0.05769
[202]   validation_0-logloss:0.01305    validation_1-logloss:0.05754
[203]   validation_0-logloss:0.01296    validation_1-logloss:0.05764
[204]   validation_0-logloss:0.01289    validation_1-logloss:0.05749
[205]   validation_0-logloss:0.01284    validation_1-logloss:0.05756
[206]   validation_0-logloss:0.01279    validation_1-logloss:0.05772
[207]   validation_0-logloss:0.01273    validation_1-logloss:0.05768
[208]   validation_0-logloss:0.01268    validation_1-logloss:0.05783
[209]   validation_0-logloss:0.01263    validation_1-logloss:0.05752
[210]   validation_0-logloss:0.01258    validation_1-logloss:0.05711
[211]   validation_0-logloss:0.01251    validation_1-logloss:0.05697
[212]   validation_0-logloss:0.01243    validation_1-logloss:0.05662
[213]   validation_0-logloss:0.01237    validation_1-logloss:0.05671
[214]   validation_0-logloss:0.01231    validation_1-logloss:0.05659
[215]   validation_0-logloss:0.01226    validation_1-logloss:0.05629
[216]   validation_0-logloss:0.01219    validation_1-logloss:0.05595
[217]   validation_0-logloss:0.01214    validation_1-logloss:0.05591
[218]   validation_0-logloss:0.01208    validation_1-logloss:0.05580
[219]   validation_0-logloss:0.01201    validation_1-logloss:0.05606
[220]   validation_0-logloss:0.01196    validation_1-logloss:0.05592
[221]   validation_0-logloss:0.01190    validation_1-logloss:0.05601
[222]   validation_0-logloss:0.01185    validation_1-logloss:0.05608
[223]   validation_0-logloss:0.01181    validation_1-logloss:0.05569
[224]   validation_0-logloss:0.01176    validation_1-logloss:0.05559
[225]   validation_0-logloss:0.01169    validation_1-logloss:0.05585
[226]   validation_0-logloss:0.01164    validation_1-logloss:0.05576
[227]   validation_0-logloss:0.01158    validation_1-logloss:0.05549
[228]   validation_0-logloss:0.01153    validation_1-logloss:0.05521
[229]   validation_0-logloss:0.01149    validation_1-logloss:0.05509
[230]   validation_0-logloss:0.01145    validation_1-logloss:0.05493
[231]   validation_0-logloss:0.01140    validation_1-logloss:0.05507
[232]   validation_0-logloss:0.01136    validation_1-logloss:0.05469
[233]   validation_0-logloss:0.01132    validation_1-logloss:0.05500
[234]   validation_0-logloss:0.01128    validation_1-logloss:0.05474
[235]   validation_0-logloss:0.01124    validation_1-logloss:0.05472
[236]   validation_0-logloss:0.01120    validation_1-logloss:0.05490
[237]   validation_0-logloss:0.01115    validation_1-logloss:0.05503
[238]   validation_0-logloss:0.01111    validation_1-logloss:0.05516
[239]   validation_0-logloss:0.01107    validation_1-logloss:0.05524
[240]   validation_0-logloss:0.01103    validation_1-logloss:0.05537
[241]   validation_0-logloss:0.01099    validation_1-logloss:0.05536
[242]   validation_0-logloss:0.01096    validation_1-logloss:0.05568
[243]   validation_0-logloss:0.01090    validation_1-logloss:0.05543
[244]   validation_0-logloss:0.01087    validation_1-logloss:0.05556
[245]   validation_0-logloss:0.01083    validation_1-logloss:0.05519
[246]   validation_0-logloss:0.01081    validation_1-logloss:0.05537
[247]   validation_0-logloss:0.01077    validation_1-logloss:0.05536
[248]   validation_0-logloss:0.01072    validation_1-logloss:0.05549
[249]   validation_0-logloss:0.01068    validation_1-logloss:0.05562
[250]   validation_0-logloss:0.01064    validation_1-logloss:0.05537
[251]   validation_0-logloss:0.01061    validation_1-logloss:0.05555
[252]   validation_0-logloss:0.01058    validation_1-logloss:0.05568
[253]   validation_0-logloss:0.01054    validation_1-logloss:0.05532
[254]   validation_0-logloss:0.01051    validation_1-logloss:0.05508
[255]   validation_0-logloss:0.01049    validation_1-logloss:0.05525
[256]   validation_0-logloss:0.01045    validation_1-logloss:0.05524
[257]   validation_0-logloss:0.01042    validation_1-logloss:0.05537
[258]   validation_0-logloss:0.01037    validation_1-logloss:0.05554
[259]   validation_0-logloss:0.01033    validation_1-logloss:0.05563
[260]   validation_0-logloss:0.01030    validation_1-logloss:0.05528
[261]   validation_0-logloss:0.01028    validation_1-logloss:0.05546
[262]   validation_0-logloss:0.01025    validation_1-logloss:0.05559
[263]   validation_0-logloss:0.01022    validation_1-logloss:0.05558
[264]   validation_0-logloss:0.01017    validation_1-logloss:0.05576
[265]   validation_0-logloss:0.01014    validation_1-logloss:0.05593
[266]   validation_0-logloss:0.01011    validation_1-logloss:0.05558
[267]   validation_0-logloss:0.01008    validation_1-logloss:0.05571
[268]   validation_0-logloss:0.01005    validation_1-logloss:0.05584
[269]   validation_0-logloss:0.01002    validation_1-logloss:0.05561
[270]   validation_0-logloss:0.00998    validation_1-logloss:0.05560
[271]   validation_0-logloss:0.00997    validation_1-logloss:0.05577
[272]   validation_0-logloss:0.00992    validation_1-logloss:0.05574
[273]   validation_0-logloss:0.00989    validation_1-logloss:0.05540
[274]   validation_0-logloss:0.00987    validation_1-logloss:0.05557
[275]   validation_0-logloss:0.00984    validation_1-logloss:0.05570
[276]   validation_0-logloss:0.00981    validation_1-logloss:0.05547
[277]   validation_0-logloss:0.00978    validation_1-logloss:0.05546
[278]   validation_0-logloss:0.00973    validation_1-logloss:0.05543
[279]   validation_0-logloss:0.00970    validation_1-logloss:0.05556
[280]   validation_0-logloss:0.00969    validation_1-logloss:0.05562
[281]   validation_0-logloss:0.00966    validation_1-logloss:0.05528</code></pre>
</div>
</div>
</section>
<section id="lightgbm" class="level3">
<h3 class="anchored" data-anchor-id="lightgbm">LightGBM</h3>
<ul>
<li><p>성능은 xgboost랑 별로 차이가 없음.</p></li>
<li><p>1만건 이하의 데이터 세트에 대해 과적합이 발생할 가능성이 높다.</p></li>
<li><p>one hot 인코딩 필요 없음</p></li>
<li><p>python lightgbm</p></li>
</ul>
<div id="7232fa09" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> lightgbm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LGBMClassifier, early_stopping, plot_importance</span>
<span id="cb18-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb18-3"></span>
<span id="cb18-4">lgbm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LGBMClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>)</span>
<span id="cb18-5">evals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb18-6">lgbm.fit(X_tr, y_tr, </span>
<span id="cb18-7">         callbacks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [early_stopping(stopping_rounds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)],</span>
<span id="cb18-8">         eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'logloss'</span>, </span>
<span id="cb18-9">         eval_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>evals)</span>
<span id="cb18-10">preds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lgbm.predict(X_test)</span>
<span id="cb18-11">pred_proba <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lgbm.predict_proba(X_test)[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb18-12"></span>
<span id="cb18-13">plot_importance(lgbm)</span>
<span id="cb18-14">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Info] Number of positive: 262, number of negative: 147
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 4092
[LightGBM] [Info] Number of data points in the train set: 409, number of used features: 30
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.640587 -&gt; initscore=0.577912
[LightGBM] [Info] Start training from score 0.577912
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
Training until validation scores don't improve for 50 rounds
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
Early stopping, best iteration is:
[159]   training's binary_logloss: 0.00195741   valid_1's binary_logloss: 0.0442418</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/02_files/figure-html/cell-14-output-2.png" width="642" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="stacking" class="level2">
<h2 class="anchored" data-anchor-id="stacking">stacking</h2>
<div id="f9259961" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.neighbors <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KNeighborsClassifier</span>
<span id="cb20-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomForestClassifier</span>
<span id="cb20-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AdaBoostClassifier</span>
<span id="cb20-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.tree <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DecisionTreeClassifier</span>
<span id="cb20-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LogisticRegression</span>
<span id="cb20-6"></span>
<span id="cb20-7">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(cancer.data, cancer.target, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>)</span>
<span id="cb20-8"></span>
<span id="cb20-9">knn_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KNeighborsClassifier(n_neighbors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb20-10">rf_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb20-11">dt_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DecisionTreeClassifier()</span>
<span id="cb20-12">ada_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AdaBoostClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb20-13"></span>
<span id="cb20-14">lr_final <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LogisticRegression()</span></code></pre></div>
</div>
<div id="707b60f8" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">knn_clf.fit(X_train, y_train)</span>
<span id="cb21-2">rf_clf.fit(X_train, y_train)</span>
<span id="cb21-3">dt_clf.fit(X_train, y_train)</span>
<span id="cb21-4">ada_clf.fit(X_train, y_train)</span>
<span id="cb21-5"></span>
<span id="cb21-6">knn_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> knn_clf.predict(X_test)</span>
<span id="cb21-7">rf_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rf_clf.predict(X_test)</span>
<span id="cb21-8">dt_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dt_clf.predict(X_test)</span>
<span id="cb21-9">ada_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ada_clf.predict(X_test)</span>
<span id="cb21-10"></span>
<span id="cb21-11">pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([knn_pred, rf_pred, dt_pred, ada_pred])</span>
<span id="cb21-12">pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.transpose(pred)</span></code></pre></div>
</div>
<div id="7479cba6" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">lr_final.fit(pred, y_test)</span>
<span id="cb22-2">final <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lr_final.predict(pred)</span>
<span id="cb22-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>accuracy_score(y_test, final)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.991</code></pre>
</div>
</div>
<ul>
<li>test 셋으로 훈련을 하고 있는 부분이 문제 → cv 세트로 해야함</li>
</ul>
<section id="cv-세트-기반-stacking" class="level3">
<h3 class="anchored" data-anchor-id="cv-세트-기반-stacking">CV 세트 기반 stacking</h3>
<div id="49118349" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KFold</span>
<span id="cb24-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mean_absolute_error</span>
<span id="cb24-3"></span>
<span id="cb24-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):</span>
<span id="cb24-5">    kf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KFold(n_splits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_folds, shuffle<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb24-6">    train_fold_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((X_train_n.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb24-7">    test_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((X_test_n.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], n_folds))</span>
<span id="cb24-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> folder_counter, (train_index, valid_index) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(kf.split(X_train_n)):</span>
<span id="cb24-9">        X_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train_n[train_index]</span>
<span id="cb24-10">        y_tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_train_n[train_index]</span>
<span id="cb24-11">        X_te <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train_n[valid_index]</span>
<span id="cb24-12"></span>
<span id="cb24-13">        model.fit(X_tr, y_tr)</span>
<span id="cb24-14">        train_fold_pred[valid_index, :] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(X_te).reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb24-15">        test_pred[:, folder_counter] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(X_test_n)</span>
<span id="cb24-16"></span>
<span id="cb24-17">    test_pred_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(test_pred, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb24-18"></span>
<span id="cb24-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> train_fold_pred, test_pred_mean</span></code></pre></div>
</div>
<div id="ca76c460" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">knn_train, knn_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>)</span>
<span id="cb25-2">rf_train, rf_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>)</span>
<span id="cb25-3">dt_train, dt_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_stacking_base_datasets(dt_clf, X_train, y_train, X_test, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>)</span>
<span id="cb25-4">ada_train, ada_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>)</span></code></pre></div>
</div>
<div id="a8e87524" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">Stack_final_X_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.concatenate((knn_train, rf_train, dt_train, ada_train), axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb26-2">Stack_final_X_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.concatenate((knn_test, rf_test, dt_test, ada_test), axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb26-3"></span>
<span id="cb26-4">lr_final.fit(Stack_final_X_train, y_train)</span>
<span id="cb26-5">stack_final <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lr_final.predict(Stack_final_X_test)</span>
<span id="cb26-6"></span>
<span id="cb26-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>accuracy_score(y_test, stack_final)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.982</code></pre>
</div>
</div>
</section>
</section>
<section id="baysian-optimization" class="level2">
<h2 class="anchored" data-anchor-id="baysian-optimization">Baysian Optimization</h2>
<ul>
<li><p>Grid search로는 시간이 너무 오래 걸리는 경우</p></li>
<li><p>목표 함수: 하이퍼파라미터 입력 n개에 대한 모델 성능 출력 1개의 모델</p></li>
<li><p>Surrogate model: 목표 함수에 대한 예상 모델. 사전확률 분포에서 최적해 나감.</p></li>
<li><p>acquisition function: 불확실성이 가장 큰 point를 다음 관측 데이터로 결정.</p></li>
</ul>
<div id="450bc93c" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> hyperopt <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> hp, fmin, tpe, Trials, STATUS_OK</span>
<span id="cb28-2"></span>
<span id="cb28-3">search_space <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>: hp.quniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb28-4">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>: hp.quniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)}</span>
<span id="cb28-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> objective_func(search_space):</span>
<span id="cb28-6">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>]</span>
<span id="cb28-7">    y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y'</span>]</span>
<span id="cb28-8"></span>
<span id="cb28-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> y</span>
<span id="cb28-10"></span>
<span id="cb28-11">trial_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Trials()</span>
<span id="cb28-12">best <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fmin(fn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>objective_func,</span>
<span id="cb28-13">            space<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>search_space,</span>
<span id="cb28-14">            algo<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tpe.suggest,</span>
<span id="cb28-15">            max_evals<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>,</span>
<span id="cb28-16">            trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>trial_val)</span>
<span id="cb28-17">best</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  0%|          | 0/20 [00:00&lt;?, ?trial/s, best loss=?]100%|██████████| 20/20 [00:00&lt;00:00, 1705.00trial/s, best loss: -284.0]</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>{'x': 4.0, 'y': 15.0}</code></pre>
</div>
</div>
<section id="xgboost-하이퍼파라미터-최적화" class="level3">
<h3 class="anchored" data-anchor-id="xgboost-하이퍼파라미터-최적화">XGBoost 하이퍼파라미터 최적화</h3>
<div id="1177ac1f" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">dataset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_breast_cancer()</span>
<span id="cb31-2"></span>
<span id="cb31-3">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(dataset.data, dataset.target, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>)</span>
<span id="cb31-4">X_tr, X_val, y_tr, y_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X_train, y_train, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span>
<span id="cb31-5"></span>
<span id="cb31-6">xgb_search_space <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb31-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>: hp.quniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb31-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_weight'</span>: hp.quniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_weight'</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>),</span>
<span id="cb31-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>: hp.uniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>),</span>
<span id="cb31-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colsample_bytree'</span>: hp.uniform(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colsample_bytree'</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb31-11">}</span>
<span id="cb31-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># hp.choice('tree_criterion', ['gini', 'entropy']) 이런식으로도 가능</span></span></code></pre></div>
</div>
<div id="c7698d8f" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> cross_val_score</span>
<span id="cb32-2"></span>
<span id="cb32-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> objective_func(search_space):</span>
<span id="cb32-4">    xgb_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> XGBClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, </span>
<span id="cb32-5">                            max_depth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>]),</span>
<span id="cb32-6">                            min_child_weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_child_weight'</span>]),</span>
<span id="cb32-7">                            learning_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>],</span>
<span id="cb32-8">                            colsample_bytree<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>search_space[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colsample_bytree'</span>],</span>
<span id="cb32-9">                            eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'logloss'</span>)</span>
<span id="cb32-10">    accuracy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cross_val_score(xgb_clf, X_train, y_train, scoring<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'accuracy'</span>, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span>
<span id="cb32-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loss'</span>: <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> np.mean(accuracy), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'status'</span>: STATUS_OK}</span>
<span id="cb32-12"></span>
<span id="cb32-13">trial_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Trials()</span>
<span id="cb32-14">best <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fmin(fn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>objective_func,</span>
<span id="cb32-15">            space<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>xgb_search_space,</span>
<span id="cb32-16">            algo<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tpe.suggest,</span>
<span id="cb32-17">            max_evals<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>,</span>
<span id="cb32-18">            trials<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>trial_val)</span>
<span id="cb32-19">best</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]  2%|▏         | 1/50 [00:00&lt;00:15,  3.22trial/s, best loss: -0.9582752410828395]  4%|▍         | 2/50 [00:00&lt;00:14,  3.38trial/s, best loss: -0.9714186127570582]  6%|▌         | 3/50 [00:00&lt;00:15,  3.13trial/s, best loss: -0.9714186127570582]  8%|▊         | 4/50 [00:01&lt;00:16,  2.82trial/s, best loss: -0.9714186127570582] 10%|█         | 5/50 [00:01&lt;00:13,  3.43trial/s, best loss: -0.9714186127570582] 12%|█▏        | 6/50 [00:01&lt;00:10,  4.12trial/s, best loss: -0.9714186127570582] 14%|█▍        | 7/50 [00:01&lt;00:08,  4.92trial/s, best loss: -0.9714186127570582] 16%|█▌        | 8/50 [00:01&lt;00:07,  5.39trial/s, best loss: -0.9714186127570582] 18%|█▊        | 9/50 [00:02&lt;00:07,  5.79trial/s, best loss: -0.9714186127570582] 20%|██        | 10/50 [00:02&lt;00:06,  5.88trial/s, best loss: -0.9714186127570582] 22%|██▏       | 11/50 [00:02&lt;00:05,  6.59trial/s, best loss: -0.9714186127570582] 24%|██▍       | 12/50 [00:02&lt;00:05,  6.58trial/s, best loss: -0.9714186127570582] 26%|██▌       | 13/50 [00:02&lt;00:05,  7.31trial/s, best loss: -0.9714186127570582] 28%|██▊       | 14/50 [00:02&lt;00:04,  7.28trial/s, best loss: -0.9714186127570582] 30%|███       | 15/50 [00:02&lt;00:04,  7.17trial/s, best loss: -0.9714186127570582] 38%|███▊      | 19/50 [00:03&lt;00:02, 14.61trial/s, best loss: -0.9714186127570582] 42%|████▏     | 21/50 [00:03&lt;00:02, 10.53trial/s, best loss: -0.9714186127570582] 46%|████▌     | 23/50 [00:03&lt;00:02,  9.43trial/s, best loss: -0.9714186127570582] 50%|█████     | 25/50 [00:03&lt;00:02,  8.95trial/s, best loss: -0.9736261182758219] 54%|█████▍    | 27/50 [00:04&lt;00:02,  8.87trial/s, best loss: -0.9736261182758219] 56%|█████▌    | 28/50 [00:04&lt;00:02,  8.90trial/s, best loss: -0.9736261182758219] 60%|██████    | 30/50 [00:04&lt;00:02,  8.95trial/s, best loss: -0.9736261182758219] 62%|██████▏   | 31/50 [00:04&lt;00:02,  8.95trial/s, best loss: -0.9736261182758219] 64%|██████▍   | 32/50 [00:04&lt;00:02,  7.08trial/s, best loss: -0.9736261182758219] 66%|██████▌   | 33/50 [00:05&lt;00:02,  5.92trial/s, best loss: -0.9736261182758219] 68%|██████▊   | 34/50 [00:05&lt;00:03,  5.20trial/s, best loss: -0.9736261182758219] 70%|███████   | 35/50 [00:05&lt;00:03,  3.97trial/s, best loss: -0.9736261182758219] 72%|███████▏  | 36/50 [00:05&lt;00:03,  3.84trial/s, best loss: -0.9736261182758219] 74%|███████▍  | 37/50 [00:06&lt;00:03,  3.79trial/s, best loss: -0.9736261182758219] 76%|███████▌  | 38/50 [00:06&lt;00:02,  4.05trial/s, best loss: -0.9736261182758219] 78%|███████▊  | 39/50 [00:06&lt;00:02,  4.46trial/s, best loss: -0.9736261182758219] 80%|████████  | 40/50 [00:06&lt;00:01,  5.31trial/s, best loss: -0.9736261182758219] 82%|████████▏ | 41/50 [00:06&lt;00:01,  6.03trial/s, best loss: -0.9736261182758219] 84%|████████▍ | 42/50 [00:06&lt;00:01,  6.79trial/s, best loss: -0.9736261182758219] 86%|████████▌ | 43/50 [00:07&lt;00:01,  6.73trial/s, best loss: -0.9736261182758219] 88%|████████▊ | 44/50 [00:07&lt;00:00,  7.04trial/s, best loss: -0.9736261182758219] 90%|█████████ | 45/50 [00:07&lt;00:00,  7.43trial/s, best loss: -0.9736261182758219] 92%|█████████▏| 46/50 [00:07&lt;00:00,  7.02trial/s, best loss: -0.9736261182758219] 94%|█████████▍| 47/50 [00:07&lt;00:00,  7.14trial/s, best loss: -0.9736261182758219] 96%|█████████▌| 48/50 [00:07&lt;00:00,  6.67trial/s, best loss: -0.9736261182758219] 98%|█████████▊| 49/50 [00:07&lt;00:00,  7.19trial/s, best loss: -0.9736261182758219]100%|██████████| 50/50 [00:08&lt;00:00,  7.52trial/s, best loss: -0.9736261182758219]100%|██████████| 50/50 [00:08&lt;00:00,  6.22trial/s, best loss: -0.9736261182758219]</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>{'colsample_bytree': 0.8065561529248224,
 'learning_rate': 0.1128018538935688,
 'max_depth': 18.0,
 'min_child_weight': 2.0}</code></pre>
</div>
</div>


</section>
</section>


<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a><div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">각주</h2>

<ol>
<li id="fn1"><p>hard voting (단순 다수결), soft voting(label을 예측할 확률의 가중 평균으로 분류)으로 나뉨. 일반적으로 soft voting이 사용됨.↩︎</p></li>
<li id="fn2"><p>hard voting (단순 다수결), soft voting(label을 예측할 확률의 가중 평균으로 분류)으로 나뉨. 일반적으로 soft voting이 사용됨.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>머신 러닝</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/02.html</guid>
  <pubDate>Sat, 26 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>분류 - 결정 트리</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/01.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="개요" class="level2">
<h2 class="anchored" data-anchor-id="개요">개요</h2>
<ul>
<li>결정 노드가 많아지면 과적합이 발생할 수 있음</li>
<li>가능한 한 적은 결정 노드로 높은 예측 정확도를 가지려면 데이터를 분류할 때 최대한 많은 데이터 세트가 해당 분류에 속할 수 있도록 규칙을 정해야 함</li>
<li>균일하게 데이터 세트를 구성할 수 있도록 분할하는 것이 필요</li>
<li>균일도만 신경쓰면 되기 때문에 전처리 작업이 필요 없음</li>
</ul>
</section>
<section id="파라미터" class="level2">
<h2 class="anchored" data-anchor-id="파라미터">파라미터</h2>
<ul>
<li>min_samples_split: 노드를 분할하기 위한 최소한의 샘플 수.</li>
<li>min_samples_leaf: 말단 노드가 되기 위한 최소한의 샘플 수. 비대칭적 데이터의 경우 특정 클래스의 데이터가 극도로 작을 수 있으므로 작게 설정 필요</li>
<li>max_features: 분할을 고려할 feature의 수. default는 None으로 모든 feature를 고려함</li>
<li>max_depth</li>
<li>max_leaf_nodes</li>
</ul>
</section>
<section id="시각화" class="level2">
<h2 class="anchored" data-anchor-id="시각화">시각화</h2>
<div id="0f4f85b3" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.tree <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DecisionTreeClassifier, export_graphviz</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_iris</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> graphviz</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> warnings</span>
<span id="cb1-6"></span>
<span id="cb1-7">warnings.filterwarnings(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ignore'</span>)</span></code></pre></div>
</div>
<div id="a12b82c3" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">dt_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DecisionTreeClassifier()</span>
<span id="cb2-2"></span>
<span id="cb2-3">iris_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_iris()</span>
<span id="cb2-4">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(iris_data.data, iris_data.target, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>)</span>
<span id="cb2-5"></span>
<span id="cb2-6">dt_clf.fit(X_train, y_train)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked=""><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;DecisionTreeClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html">?<span>Documentation for DecisionTreeClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>
</div>
</div>
<div id="723f86fa" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">export_graphviz(dt_clf, out_file<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tree.dot"</span>, class_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris_data.target_names, feature_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris_data.feature_names, impurity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, filled<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tree.dot"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f:</span>
<span id="cb3-3">    dot_graph <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> f.read()</span>
<span id="cb3-4">graphviz.Source(dot_graph)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/01_files/figure-html/cell-4-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="3dc2a299" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> name, value <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(iris_data.feature_names, dt_clf.feature_importances_):</span>
<span id="cb4-5">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>value<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb4-6">sns.barplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dt_clf.feature_importances_, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>iris_data.feature_names)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>sepal length (cm): 0.000
sepal width (cm): 0.017
petal length (cm): 0.544
petal width (cm): 0.439</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/01_files/figure-html/cell-5-output-2.png" width="666" height="411" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="examples" class="level2">
<h2 class="anchored" data-anchor-id="examples">examples</h2>
<div id="522a15c6" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb6-2"></span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_new_feature_name_df(old):</span>
<span id="cb6-5">    df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>old.groupby(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'column_name'</span>).cumcount(), columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dup_cnt'</span>])</span>
<span id="cb6-6">    df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.reset_index()</span>
<span id="cb6-7">    new_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.merge(old.reset_index(), df, how<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'outer'</span>)</span>
<span id="cb6-8">    new_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'column_name'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_df[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'column_name'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dup_cnt'</span>]].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> x: x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb6-9">    new_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_df.drop([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb6-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> new_df</span>
<span id="cb6-11"></span>
<span id="cb6-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_human_dataset():</span>
<span id="cb6-13">    feature_name_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/human_activity/features.txt'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'\s+'</span>, header<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'column_index'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'column_name'</span>])</span>
<span id="cb6-14">    new_feature_name_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_new_feature_name_df(feature_name_df)</span>
<span id="cb6-15">    feature_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> new_feature_name_df.iloc[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].values.tolist()</span>
<span id="cb6-16"></span>
<span id="cb6-17">    X_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/human_activity/train/X_train.txt'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'\s+'</span>, names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>feature_name)</span>
<span id="cb6-18">    X_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/human_activity/test/X_test.txt'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'\s+'</span>, names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>feature_name)</span>
<span id="cb6-19"></span>
<span id="cb6-20">    y_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/human_activity/train/y_train.txt'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'\s+'</span>, header<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'action'</span>])</span>
<span id="cb6-21">    y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/human_activity/test/y_test.txt'</span>, sep<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'\s+'</span>, header<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'action'</span>])</span>
<span id="cb6-22"></span>
<span id="cb6-23">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> X_train, X_test, y_train, y_test</span>
<span id="cb6-24"></span>
<span id="cb6-25">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_human_dataset()</span>
<span id="cb6-26">X_train.info()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 7352 entries, 0 to 7351
Columns: 561 entries, tBodyAcc-mean()-X to angle(Z,gravityMean)
dtypes: float64(561)
memory usage: 31.5 MB</code></pre>
</div>
</div>
<div id="dd0fb5a8" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">y_train[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'action'</span>].value_counts()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>action
6    1407
5    1374
4    1286
1    1226
2    1073
3     986
Name: count, dtype: int64</code></pre>
</div>
</div>
<section id="default-파라미터-예측" class="level3">
<h3 class="anchored" data-anchor-id="default-파라미터-예측">default 파라미터 예측</h3>
<div id="b78d5bcd" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> accuracy_score</span>
<span id="cb10-2"></span>
<span id="cb10-3">dt_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DecisionTreeClassifier()</span>
<span id="cb10-4">dt_clf.fit(X_train, y_train)</span>
<span id="cb10-5">pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dt_clf.predict(X_test)</span>
<span id="cb10-6">accuracy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> accuracy_score(y_test, pred)</span>
<span id="cb10-7">accuracy</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>0.8608754665761792</code></pre>
</div>
</div>
</section>
<section id="하이퍼파라미터-최적화" class="level3">
<h3 class="anchored" data-anchor-id="하이퍼파라미터-최적화">하이퍼파라미터 최적화</h3>
<div id="92b35214" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> GridSearchCV</span>
<span id="cb12-2"></span>
<span id="cb12-3">params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb12-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_depth'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>],</span>
<span id="cb12-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'min_samples_split'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>]</span>
<span id="cb12-6">}</span>
<span id="cb12-7"></span>
<span id="cb12-8">grid_cv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GridSearchCV(dt_clf, param_grid<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>params, scoring<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'accuracy'</span>,cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb12-9">grid_cv.fit(X_train, y_train)</span>
<span id="cb12-10"></span>
<span id="cb12-11">cv_results_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(grid_cv.cv_results_)</span>
<span id="cb12-12">cv_results_df[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'param_max_depth'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mean_test_score'</span>]]</span>
<span id="cb12-13">cv_results_df</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 7 candidates, totalling 35 fits</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">mean_fit_time</th>
<th data-quarto-table-cell-role="th">std_fit_time</th>
<th data-quarto-table-cell-role="th">mean_score_time</th>
<th data-quarto-table-cell-role="th">std_score_time</th>
<th data-quarto-table-cell-role="th">param_max_depth</th>
<th data-quarto-table-cell-role="th">param_min_samples_split</th>
<th data-quarto-table-cell-role="th">params</th>
<th data-quarto-table-cell-role="th">split0_test_score</th>
<th data-quarto-table-cell-role="th">split1_test_score</th>
<th data-quarto-table-cell-role="th">split2_test_score</th>
<th data-quarto-table-cell-role="th">split3_test_score</th>
<th data-quarto-table-cell-role="th">split4_test_score</th>
<th data-quarto-table-cell-role="th">mean_test_score</th>
<th data-quarto-table-cell-role="th">std_test_score</th>
<th data-quarto-table-cell-role="th">rank_test_score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.730651</td>
<td>0.071066</td>
<td>0.004747</td>
<td>0.000612</td>
<td>6</td>
<td>16</td>
<td>{'max_depth': 6, 'min_samples_split': 16}</td>
<td>0.812373</td>
<td>0.870156</td>
<td>0.834694</td>
<td>0.865306</td>
<td>0.869388</td>
<td>0.850383</td>
<td>0.023090</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2.199078</td>
<td>0.058100</td>
<td>0.004974</td>
<td>0.000507</td>
<td>8</td>
<td>16</td>
<td>{'max_depth': 8, 'min_samples_split': 16}</td>
<td>0.812373</td>
<td>0.831407</td>
<td>0.842177</td>
<td>0.870068</td>
<td>0.890476</td>
<td>0.849300</td>
<td>0.027790</td>
<td>3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2.591271</td>
<td>0.101800</td>
<td>0.004741</td>
<td>0.000625</td>
<td>10</td>
<td>16</td>
<td>{'max_depth': 10, 'min_samples_split': 16}</td>
<td>0.813732</td>
<td>0.819850</td>
<td>0.837415</td>
<td>0.888435</td>
<td>0.896599</td>
<td>0.851206</td>
<td>0.034711</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2.873773</td>
<td>0.100605</td>
<td>0.005099</td>
<td>0.001333</td>
<td>12</td>
<td>16</td>
<td>{'max_depth': 12, 'min_samples_split': 16}</td>
<td>0.783821</td>
<td>0.817811</td>
<td>0.853741</td>
<td>0.885714</td>
<td>0.882313</td>
<td>0.844680</td>
<td>0.039008</td>
<td>5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>3.446341</td>
<td>0.244669</td>
<td>0.004722</td>
<td>0.000739</td>
<td>16</td>
<td>16</td>
<td>{'max_depth': 16, 'min_samples_split': 16}</td>
<td>0.803535</td>
<td>0.810333</td>
<td>0.842177</td>
<td>0.878231</td>
<td>0.887075</td>
<td>0.844270</td>
<td>0.034062</td>
<td>6</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>3.307252</td>
<td>0.254648</td>
<td>0.004365</td>
<td>0.000410</td>
<td>20</td>
<td>16</td>
<td>{'max_depth': 20, 'min_samples_split': 16}</td>
<td>0.794018</td>
<td>0.811693</td>
<td>0.831293</td>
<td>0.887075</td>
<td>0.891837</td>
<td>0.843183</td>
<td>0.039608</td>
<td>7</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>3.243996</td>
<td>0.227535</td>
<td>0.004434</td>
<td>0.000333</td>
<td>24</td>
<td>16</td>
<td>{'max_depth': 24, 'min_samples_split': 16}</td>
<td>0.796737</td>
<td>0.809653</td>
<td>0.846259</td>
<td>0.882313</td>
<td>0.895238</td>
<td>0.846040</td>
<td>0.038707</td>
<td>4</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="11706389" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">best_df_clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> grid_cv.best_estimator_</span>
<span id="cb14-2"></span>
<span id="cb14-3">ftr_importances_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> best_df_clf.feature_importances_</span>
<span id="cb14-4">ftr_importances <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.Series(ftr_importances_values, index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>X_train.columns)</span>
<span id="cb14-5">ftr_top20 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ftr_importances.sort_values(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>]</span>
<span id="cb14-6">sns.barplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ftr_top20, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ftr_top20.index)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/01_files/figure-html/cell-10-output-1.png" width="791" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>


</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>머신 러닝</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/machine_learning/01.html</guid>
  <pubDate>Sat, 26 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>다차원 척도법 (Multidimensional Scaling)</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="다차원-척도법mds이란" class="level2">
<h2 class="anchored" data-anchor-id="다차원-척도법mds이란">다차원 척도법(MDS)이란?</h2>
<p>다차원 척도법(Multidimensional Scaling, MDS)은 고차원 데이터를 저차원 공간에 시각화하는 차원 축소 기법입니다. 객체들 간의 거리나 유사도를 보존하면서 2차원 또는 3차원 공간에 데이터를 투영합니다.</p>
</section>
<section id="필요한-라이브러리-설치-및-임포트" class="level2">
<h2 class="anchored" data-anchor-id="필요한-라이브러리-설치-및-임포트">필요한 라이브러리 설치 및 임포트</h2>
<div id="966db7de" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.manifold <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MDS</span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pairwise_distances</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler, LabelEncoder</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> make_classification</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.spatial.distance <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pdist, squareform</span>
<span id="cb1-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> warnings</span>
<span id="cb1-11">warnings.filterwarnings(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ignore'</span>)</span>
<span id="cb1-12"></span>
<span id="cb1-13">plt.rcParams[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'font.family'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Noto Sans KR'</span></span></code></pre></div>
</div>
</section>
<section id="샘플-데이터-생성" class="level2">
<h2 class="anchored" data-anchor-id="샘플-데이터-생성">샘플 데이터 생성</h2>
<p>다양한 케이스를 위한 샘플 데이터를 생성합니다.</p>
<div id="9591b6dd" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 연속변수만 포함하는 데이터</span></span>
<span id="cb2-2">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb2-3">continuous_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_classification(</span>
<span id="cb2-4">    n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, </span>
<span id="cb2-5">    n_features<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, </span>
<span id="cb2-6">    n_classes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, </span>
<span id="cb2-7">    n_redundant<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, </span>
<span id="cb2-8">    n_informative<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,</span>
<span id="cb2-9">    random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span></span>
<span id="cb2-10">)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb2-11"></span>
<span id="cb2-12">continuous_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb2-13">    continuous_data, </span>
<span id="cb2-14">    columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'feature_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)]</span>
<span id="cb2-15">)</span>
<span id="cb2-16"></span>
<span id="cb2-17"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"연속변수 데이터셋 shape:"</span>, continuous_df.shape)</span>
<span id="cb2-18"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(continuous_df.head())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>연속변수 데이터셋 shape: (100, 5)
   feature_1  feature_2  feature_3  feature_4  feature_5
0   0.051936  -1.797511  -1.855638  -1.396449  -1.196204
1   0.403789   0.921306   3.200886   1.984403   0.106783
2   0.300321  -0.930015   0.162936  -0.576956   2.232421
3  -0.199444  -0.496488  -1.928236   0.929103  -1.480070
4   1.144153  -1.221289  -0.581620  -0.475414   1.675759</code></pre>
</div>
</div>
<div id="6e8588ab" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. 명목변수를 포함하는 혼합 데이터</span></span>
<span id="cb4-2">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 연속변수</span></span>
<span id="cb4-5">age <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">35</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb4-6">income <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb4-7">experience <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb4-8"></span>
<span id="cb4-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 명목변수</span></span>
<span id="cb4-10">education <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.choice([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'고등학교'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'대학교'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'대학원'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb4-11">department <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.choice([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'영업'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'마케팅'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'개발'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'HR'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb4-12">location <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.choice([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'서울'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'부산'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'대구'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'광주'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb4-13"></span>
<span id="cb4-14">mixed_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({</span>
<span id="cb4-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'age'</span>: age,</span>
<span id="cb4-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'income'</span>: income,</span>
<span id="cb4-17">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'experience'</span>: experience,</span>
<span id="cb4-18">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'education'</span>: education,</span>
<span id="cb4-19">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'department'</span>: department,</span>
<span id="cb4-20">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'location'</span>: location</span>
<span id="cb4-21">})</span>
<span id="cb4-22"></span>
<span id="cb4-23"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">혼합 데이터셋 shape:"</span>, mixed_df.shape)</span>
<span id="cb4-24"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(mixed_df.head())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
혼합 데이터셋 shape: (100, 6)
         age        income  experience education department location
0  39.967142  28769.438869    6.073362      고등학교         개발       서울
1  33.617357  43690.320159    6.682354       대학교        마케팅       서울
2  41.476885  44859.282252    8.249154      고등학교        마케팅       광주
3  50.230299  37965.840962    8.161406      고등학교         개발       서울
4  32.658466  47580.714325    0.866992       대학원         개발       광주</code></pre>
</div>
</div>
<div id="861d4607" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. 거리 행렬 데이터 (도시간 거리 예시)</span></span>
<span id="cb6-2">cities <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'서울'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'부산'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'대구'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'인천'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'광주'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'대전'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'울산'</span>]</span>
<span id="cb6-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 실제 도시간 거리 (km)</span></span>
<span id="cb6-4">distance_matrix <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([</span>
<span id="cb6-5">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">325</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">237</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">267</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">140</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">340</span>],      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 서울</span></span>
<span id="cb6-6">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">325</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">88</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">353</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">158</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">185</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">45</span>],       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 부산</span></span>
<span id="cb6-7">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">237</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">88</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">265</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">215</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">97</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">85</span>],        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 대구</span></span>
<span id="cb6-8">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">28</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">353</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">265</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">295</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">168</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">368</span>],      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 인천</span></span>
<span id="cb6-9">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">267</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">158</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">215</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">295</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">168</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>],     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 광주</span></span>
<span id="cb6-10">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">140</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">185</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">97</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">168</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">168</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">230</span>],      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 대전</span></span>
<span id="cb6-11">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">340</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">45</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">85</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">368</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">230</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 울산</span></span>
<span id="cb6-12">])</span>
<span id="cb6-13"></span>
<span id="cb6-14">distance_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(distance_matrix, </span>
<span id="cb6-15">                          index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cities, </span>
<span id="cb6-16">                          columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cities)</span>
<span id="cb6-17"></span>
<span id="cb6-18"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">도시간 거리 행렬:"</span>)</span>
<span id="cb6-19"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(distance_df)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
도시간 거리 행렬:
     서울   부산   대구   인천   광주   대전   울산
서울    0  325  237   28  267  140  340
부산  325    0   88  353  158  185   45
대구  237   88    0  265  215   97   85
인천   28  353  265    0  295  168  368
광주  267  158  215  295    0  168  200
대전  140  185   97  168  168    0  230
울산  340   45   85  368  200  230    0</code></pre>
</div>
</div>
</section>
<section id="연속변수만-포함하는-기본-mds-분석" class="level2">
<h2 class="anchored" data-anchor-id="연속변수만-포함하는-기본-mds-분석">1. 연속변수만 포함하는 기본 MDS 분석</h2>
<p>연속변수로만 구성된 데이터에 MDS를 적용하는 예시입니다.</p>
<div id="5bfe7e0b" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 데이터 표준화</span></span>
<span id="cb8-2">scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb8-3">continuous_scaled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(continuous_df)</span>
<span id="cb8-4"></span>
<span id="cb8-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 기본 MDS 적용 (2차원)</span></span>
<span id="cb8-6">mds <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MDS(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb8-7">mds_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mds.fit_transform(continuous_scaled)</span>
<span id="cb8-8"></span>
<span id="cb8-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 결과를 DataFrame으로 변환</span></span>
<span id="cb8-10">mds_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(mds_result, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS1'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS2'</span>])</span>
<span id="cb8-11"></span>
<span id="cb8-12"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"MDS 결과:"</span>)</span>
<span id="cb8-13"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(mds_df.head())</span>
<span id="cb8-14"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Stress 값: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stress_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MDS 결과:
       MDS1      MDS2
0  0.329495 -1.755421
1  0.049463  3.238964
2 -0.946161  0.369966
3  0.357709 -0.007320
4 -0.769899 -0.435848

Stress 값: 3208.7256</code></pre>
</div>
</div>
<div id="b7201053" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 시각화</span></span>
<span id="cb10-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb10-3">plt.scatter(mds_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS1'</span>], mds_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS2'</span>], alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)</span>
<span id="cb10-4">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 1'</span>)</span>
<span id="cb10-5">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 2'</span>)</span>
<span id="cb10-6">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS 결과 - 연속변수 데이터'</span>)</span>
<span id="cb10-7">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb10-8"></span>
<span id="cb10-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 각 점에 인덱스 번호 표시</span></span>
<span id="cb10-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, (x, y) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(mds_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS1'</span>], mds_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS2'</span>])):</span>
<span id="cb10-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 10개마다 번호 표시</span></span>
<span id="cb10-12">        plt.annotate(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(i), (x, y), xytext<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>), </span>
<span id="cb10-13">                    textcoords<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'offset points'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>)</span>
<span id="cb10-14"></span>
<span id="cb10-15">plt.tight_layout()</span>
<span id="cb10-16">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-7-output-1.png" width="950" height="757" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="29231f8d" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 클래스별로 색상을 다르게 하여 시각화 (원본 클래스 정보 사용)</span></span>
<span id="cb11-2">_, y_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_classification(</span>
<span id="cb11-3">    n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, </span>
<span id="cb11-4">    n_features<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, </span>
<span id="cb11-5">    n_classes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, </span>
<span id="cb11-6">    n_redundant<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, </span>
<span id="cb11-7">    n_informative<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,</span>
<span id="cb11-8">    random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span></span>
<span id="cb11-9">)</span>
<span id="cb11-10"></span>
<span id="cb11-11">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb11-12">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>]</span>
<span id="cb11-13"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>):</span>
<span id="cb11-14">    mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i</span>
<span id="cb11-15">    plt.scatter(mds_df.loc[mask, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS1'</span>], </span>
<span id="cb11-16">                mds_df.loc[mask, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS2'</span>], </span>
<span id="cb11-17">                c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors[i], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Class </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)</span>
<span id="cb11-18"></span>
<span id="cb11-19">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 1'</span>)</span>
<span id="cb11-20">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 2'</span>)</span>
<span id="cb11-21">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS 결과 - 클래스별 색상 구분'</span>)</span>
<span id="cb11-22">plt.legend()</span>
<span id="cb11-23">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb11-24">plt.tight_layout()</span>
<span id="cb11-25">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-8-output-1.png" width="950" height="757" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="884ed1d6" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 거리 보존 정도 확인</span></span>
<span id="cb12-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pairwise_distances</span>
<span id="cb12-3"></span>
<span id="cb12-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 원본 데이터의 거리 행렬</span></span>
<span id="cb12-5">original_distances <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pairwise_distances(continuous_scaled)</span>
<span id="cb12-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MDS 결과의 거리 행렬</span></span>
<span id="cb12-7">mds_distances <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pairwise_distances(mds_result)</span>
<span id="cb12-8"></span>
<span id="cb12-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 거리 상관계수 계산</span></span>
<span id="cb12-10">distance_correlation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.corrcoef(</span>
<span id="cb12-11">    original_distances.flatten(), </span>
<span id="cb12-12">    mds_distances.flatten()</span>
<span id="cb12-13">)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb12-14"></span>
<span id="cb12-15"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"원본 거리와 MDS 거리의 상관계수: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>distance_correlation<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb12-16"></span>
<span id="cb12-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shepard diagram 그리기</span></span>
<span id="cb12-18">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb12-19">plt.scatter(original_distances.flatten(), </span>
<span id="cb12-20">            mds_distances.flatten(), </span>
<span id="cb12-21">            alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb12-22">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Original Distances'</span>)</span>
<span id="cb12-23">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Distances'</span>)</span>
<span id="cb12-24">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Shepard Diagram - 거리 보존 정도'</span>)</span>
<span id="cb12-25">plt.plot([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, original_distances.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], </span>
<span id="cb12-26">         [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, original_distances.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], </span>
<span id="cb12-27">         <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r--'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>)</span>
<span id="cb12-28">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb12-29">plt.tight_layout()</span>
<span id="cb12-30">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>원본 거리와 MDS 거리의 상관계수: 0.8435</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-9-output-2.png" width="758" height="566" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="명목변수를-포함하는-혼합-데이터-mds-분석" class="level2">
<h2 class="anchored" data-anchor-id="명목변수를-포함하는-혼합-데이터-mds-분석">2. 명목변수를 포함하는 혼합 데이터 MDS 분석</h2>
<p>명목변수와 연속변수가 혼합된 데이터에 MDS를 적용하는 예시입니다.</p>
<div id="83cef539" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 혼합 데이터 전처리</span></span>
<span id="cb14-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> preprocess_mixed_data(df):</span>
<span id="cb14-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""혼합 데이터를 MDS에 적합하도록 전처리"""</span></span>
<span id="cb14-4">    processed_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.copy()</span>
<span id="cb14-5">    </span>
<span id="cb14-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 연속변수 표준화</span></span>
<span id="cb14-7">    continuous_cols <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'age'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'income'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'experience'</span>]</span>
<span id="cb14-8">    scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb14-9">    processed_df[continuous_cols] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(processed_df[continuous_cols])</span>
<span id="cb14-10">    </span>
<span id="cb14-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 명목변수 원핫 인코딩</span></span>
<span id="cb14-12">    categorical_cols <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'education'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'department'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'location'</span>]</span>
<span id="cb14-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> col <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> categorical_cols:</span>
<span id="cb14-14">        dummies <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.get_dummies(processed_df[col], prefix<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>col)</span>
<span id="cb14-15">        processed_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.concat([processed_df, dummies], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb14-16">        processed_df.drop(col, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb14-17">    </span>
<span id="cb14-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> processed_df</span>
<span id="cb14-19"></span>
<span id="cb14-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 데이터 전처리</span></span>
<span id="cb14-21">mixed_processed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> preprocess_mixed_data(mixed_df)</span>
<span id="cb14-22"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"전처리된 혼합 데이터 shape:"</span>, mixed_processed.shape)</span>
<span id="cb14-23"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">컬럼 목록:"</span>)</span>
<span id="cb14-24"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(mixed_processed.columns.tolist())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>전처리된 혼합 데이터 shape: (100, 14)

컬럼 목록:
['age', 'income', 'experience', 'education_고등학교', 'education_대학교', 'education_대학원', 'department_HR', 'department_개발', 'department_마케팅', 'department_영업', 'location_광주', 'location_대구', 'location_부산', 'location_서울']</code></pre>
</div>
</div>
<div id="da459f19" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 혼합 데이터에 MDS 적용</span></span>
<span id="cb16-2">mds_mixed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MDS(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb16-3">mds_mixed_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mds_mixed.fit_transform(mixed_processed)</span>
<span id="cb16-4"></span>
<span id="cb16-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 결과를 DataFrame으로 변환</span></span>
<span id="cb16-6">mds_mixed_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(mds_mixed_result, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS1'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS2'</span>])</span>
<span id="cb16-7"></span>
<span id="cb16-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"혼합 데이터 MDS 결과:"</span>)</span>
<span id="cb16-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(mds_mixed_df.head())</span>
<span id="cb16-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Stress 값: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds_mixed<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stress_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>혼합 데이터 MDS 결과:
       MDS1      MDS2
0  1.112396 -1.853207
1  0.199845 -1.172801
2 -0.073573 -1.903613
3 -0.293398 -2.665801
4  1.287388  1.284487

Stress 값: 3843.1912</code></pre>
</div>
</div>
<div id="d47091a4" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 부서별로 색상을 다르게 하여 시각화</span></span>
<span id="cb18-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb18-3">departments <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mixed_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'department'</span>].unique()</span>
<span id="cb18-4">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'orange'</span>]</span>
<span id="cb18-5"></span>
<span id="cb18-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, dept <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(departments):</span>
<span id="cb18-7">    mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mixed_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'department'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> dept</span>
<span id="cb18-8">    plt.scatter(mds_mixed_df.loc[mask, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS1'</span>], </span>
<span id="cb18-9">                mds_mixed_df.loc[mask, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS2'</span>], </span>
<span id="cb18-10">                c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors[i], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dept, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>)</span>
<span id="cb18-11"></span>
<span id="cb18-12">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 1'</span>)</span>
<span id="cb18-13">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 2'</span>)</span>
<span id="cb18-14">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS 결과 - 부서별 색상 구분 (혼합 데이터)'</span>)</span>
<span id="cb18-15">plt.legend()</span>
<span id="cb18-16">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb18-17">plt.tight_layout()</span>
<span id="cb18-18">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-12-output-1.png" width="1142" height="758" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="671aa270" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 학력별로 마커를 다르게 하여 시각화</span></span>
<span id="cb19-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb19-3">educations <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mixed_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'education'</span>].unique()</span>
<span id="cb19-4">markers <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'o'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'s'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'^'</span>]</span>
<span id="cb19-5"></span>
<span id="cb19-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, edu <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(educations):</span>
<span id="cb19-7">    mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mixed_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'education'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> edu</span>
<span id="cb19-8">    plt.scatter(mds_mixed_df.loc[mask, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS1'</span>], </span>
<span id="cb19-9">                mds_mixed_df.loc[mask, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS2'</span>], </span>
<span id="cb19-10">                marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>markers[i], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>edu, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>)</span>
<span id="cb19-11"></span>
<span id="cb19-12">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 1'</span>)</span>
<span id="cb19-13">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 2'</span>)</span>
<span id="cb19-14">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS 결과 - 학력별 마커 구분 (혼합 데이터)'</span>)</span>
<span id="cb19-15">plt.legend()</span>
<span id="cb19-16">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb19-17">plt.tight_layout()</span>
<span id="cb19-18">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-13-output-1.png" width="1142" height="758" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="9dfc1b8d" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 부서와 학력을 함께 시각화</span></span>
<span id="cb20-2">fig, (ax1, ax2) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb20-3"></span>
<span id="cb20-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 부서별 시각화</span></span>
<span id="cb20-5">departments <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mixed_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'department'</span>].unique()</span>
<span id="cb20-6">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'orange'</span>]</span>
<span id="cb20-7"></span>
<span id="cb20-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, dept <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(departments):</span>
<span id="cb20-9">    mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mixed_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'department'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> dept</span>
<span id="cb20-10">    ax1.scatter(mds_mixed_df.loc[mask, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS1'</span>], </span>
<span id="cb20-11">                mds_mixed_df.loc[mask, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS2'</span>], </span>
<span id="cb20-12">                c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors[i], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dept, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>)</span>
<span id="cb20-13"></span>
<span id="cb20-14">ax1.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 1'</span>)</span>
<span id="cb20-15">ax1.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 2'</span>)</span>
<span id="cb20-16">ax1.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'부서별 구분'</span>)</span>
<span id="cb20-17">ax1.legend()</span>
<span id="cb20-18">ax1.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb20-19"></span>
<span id="cb20-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 학력별 시각화</span></span>
<span id="cb20-21">educations <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mixed_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'education'</span>].unique()</span>
<span id="cb20-22">colors2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'purple'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'brown'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pink'</span>]</span>
<span id="cb20-23"></span>
<span id="cb20-24"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, edu <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(educations):</span>
<span id="cb20-25">    mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mixed_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'education'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> edu</span>
<span id="cb20-26">    ax2.scatter(mds_mixed_df.loc[mask, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS1'</span>], </span>
<span id="cb20-27">                mds_mixed_df.loc[mask, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS2'</span>], </span>
<span id="cb20-28">                c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors2[i], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>edu, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>)</span>
<span id="cb20-29"></span>
<span id="cb20-30">ax2.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 1'</span>)</span>
<span id="cb20-31">ax2.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 2'</span>)</span>
<span id="cb20-32">ax2.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'학력별 구분'</span>)</span>
<span id="cb20-33">ax2.legend()</span>
<span id="cb20-34">ax2.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb20-35"></span>
<span id="cb20-36">plt.tight_layout()</span>
<span id="cb20-37">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-14-output-1.png" width="1910" height="757" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="ea33eefa" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Gower 거리를 사용한 혼합 데이터 MDS</span></span>
<span id="cb21-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> gower_distance(X):</span>
<span id="cb21-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Gower 거리 계산 (연속변수와 명목변수 혼합용)"""</span></span>
<span id="cb21-4">    n_samples, n_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X.shape</span>
<span id="cb21-5">    distances <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((n_samples, n_samples))</span>
<span id="cb21-6">    </span>
<span id="cb21-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 각 피처가 연속변수인지 이진변수인지 판단</span></span>
<span id="cb21-8">    is_continuous <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb21-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n_features):</span>
<span id="cb21-10">        unique_vals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.unique(X[:, j])</span>
<span id="cb21-11">        is_continuous.append(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(unique_vals) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb21-12">    </span>
<span id="cb21-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n_samples):</span>
<span id="cb21-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, n_samples):</span>
<span id="cb21-15">            distance <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb21-16">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n_features):</span>
<span id="cb21-17">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> is_continuous[k]:</span>
<span id="cb21-18">                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 연속변수: 절대차이를 범위로 나눔</span></span>
<span id="cb21-19">                    range_k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(X[:, k]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(X[:, k])</span>
<span id="cb21-20">                    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> range_k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb21-21">                        distance <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>(X[i, k] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> X[j, k]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> range_k</span>
<span id="cb21-22">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb21-23">                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 명목변수: 같으면 0, 다르면 1</span></span>
<span id="cb21-24">                    distance <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> X[i, k] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> X[j, k] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb21-25">            </span>
<span id="cb21-26">            distances[i, j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> distances[j, i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> distance <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> n_features</span>
<span id="cb21-27">    </span>
<span id="cb21-28">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> distances</span>
<span id="cb21-29"></span>
<span id="cb21-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 원본 혼합 데이터로 Gower 거리 계산</span></span>
<span id="cb21-31">mixed_array <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mixed_processed.values</span>
<span id="cb21-32">gower_dist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gower_distance(mixed_array)</span>
<span id="cb21-33"></span>
<span id="cb21-34"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Gower 거리 기반 MDS</span></span>
<span id="cb21-35">mds_gower <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MDS(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, dissimilarity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'precomputed'</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb21-36">mds_gower_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mds_gower.fit_transform(gower_dist)</span>
<span id="cb21-37"></span>
<span id="cb21-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 결과 시각화</span></span>
<span id="cb21-39">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb21-40">departments <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mixed_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'department'</span>].unique()</span>
<span id="cb21-41">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'orange'</span>]</span>
<span id="cb21-42"></span>
<span id="cb21-43"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, dept <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(departments):</span>
<span id="cb21-44">    mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mixed_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'department'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> dept</span>
<span id="cb21-45">    plt.scatter(mds_gower_result[mask, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], </span>
<span id="cb21-46">                mds_gower_result[mask, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], </span>
<span id="cb21-47">                c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors[i], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dept, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>)</span>
<span id="cb21-48"></span>
<span id="cb21-49">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 1'</span>)</span>
<span id="cb21-50">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 2'</span>)</span>
<span id="cb21-51">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Gower 거리 기반 MDS 결과'</span>)</span>
<span id="cb21-52">plt.legend()</span>
<span id="cb21-53">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb21-54">plt.tight_layout()</span>
<span id="cb21-55">plt.show()</span>
<span id="cb21-56"></span>
<span id="cb21-57"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Gower 거리 기반 MDS Stress 값: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds_gower<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stress_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-15-output-1.png" width="950" height="757" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Gower 거리 기반 MDS Stress 값: 70.5540</code></pre>
</div>
</div>
</section>
<section id="거리-행렬-기반-mds-분석" class="level2">
<h2 class="anchored" data-anchor-id="거리-행렬-기반-mds-분석">3. 거리 행렬 기반 MDS 분석</h2>
<p>미리 계산된 거리 행렬을 사용하여 MDS를 적용하는 예시입니다.</p>
<div id="04c87ba6" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 도시간 거리 행렬로 MDS 수행</span></span>
<span id="cb23-2">mds_distance <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MDS(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, dissimilarity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'precomputed'</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb23-3">city_mds_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mds_distance.fit_transform(distance_matrix)</span>
<span id="cb23-4"></span>
<span id="cb23-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 결과를 DataFrame으로 변환</span></span>
<span id="cb23-6">city_mds_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(city_mds_result, </span>
<span id="cb23-7">                          columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS1'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS2'</span>], </span>
<span id="cb23-8">                          index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cities)</span>
<span id="cb23-9"></span>
<span id="cb23-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"도시 MDS 결과:"</span>)</span>
<span id="cb23-11"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(city_mds_df)</span>
<span id="cb23-12"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Stress 값: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds_distance<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stress_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>도시 MDS 결과:
          MDS1        MDS2
서울  -85.433007 -154.346568
부산   59.327174  130.031955
대구  -27.112189   81.647524
인천  -99.393194 -179.287057
광주  145.126739  -10.586077
대전  -24.860674  -32.769460
울산   32.345151  165.309682

Stress 값: 2023.2616</code></pre>
</div>
</div>
<div id="101f3de1" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 도시 위치 시각화</span></span>
<span id="cb25-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>))</span>
<span id="cb25-3">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'orange'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'purple'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'brown'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pink'</span>]</span>
<span id="cb25-4"></span>
<span id="cb25-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, city <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(cities):</span>
<span id="cb25-6">    plt.scatter(city_mds_df.loc[city, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS1'</span>], </span>
<span id="cb25-7">                city_mds_df.loc[city, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS2'</span>], </span>
<span id="cb25-8">                c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors[i], s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, </span>
<span id="cb25-9">                label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>city, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb25-10">    </span>
<span id="cb25-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 도시 이름 표시</span></span>
<span id="cb25-12">    plt.annotate(city, </span>
<span id="cb25-13">                (city_mds_df.loc[city, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS1'</span>], city_mds_df.loc[city, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS2'</span>]),</span>
<span id="cb25-14">                xytext<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>), textcoords<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'offset points'</span>, </span>
<span id="cb25-15">                fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, fontweight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bold'</span>)</span>
<span id="cb25-16"></span>
<span id="cb25-17">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 1'</span>)</span>
<span id="cb25-18">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 2'</span>)</span>
<span id="cb25-19">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'도시간 거리 기반 MDS 결과'</span>)</span>
<span id="cb25-20">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb25-21">plt.legend(bbox_to_anchor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.05</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'upper left'</span>)</span>
<span id="cb25-22">plt.tight_layout()</span>
<span id="cb25-23">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-17-output-1.png" width="1144" height="949" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="4fcc4885" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 실제 거리와 MDS 거리 비교</span></span>
<span id="cb26-2">mds_city_distances <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pairwise_distances(city_mds_result)</span>
<span id="cb26-3"></span>
<span id="cb26-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 거리 상관계수 계산</span></span>
<span id="cb26-5">city_distance_correlation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.corrcoef(</span>
<span id="cb26-6">    distance_matrix.flatten(), </span>
<span id="cb26-7">    mds_city_distances.flatten()</span>
<span id="cb26-8">)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb26-9"></span>
<span id="cb26-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"실제 거리와 MDS 거리의 상관계수: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>city_distance_correlation<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb26-11"></span>
<span id="cb26-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Shepard diagram for city distances</span></span>
<span id="cb26-13">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb26-14">plt.scatter(distance_matrix.flatten(), </span>
<span id="cb26-15">            mds_city_distances.flatten(), </span>
<span id="cb26-16">            alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>)</span>
<span id="cb26-17">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Original Distances (km)'</span>)</span>
<span id="cb26-18">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Distances'</span>)</span>
<span id="cb26-19">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Shepard Diagram - 도시간 거리 보존 정도'</span>)</span>
<span id="cb26-20">plt.plot([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, distance_matrix.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], </span>
<span id="cb26-21">         [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, distance_matrix.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()], </span>
<span id="cb26-22">         <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r--'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>)</span>
<span id="cb26-23">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb26-24">plt.tight_layout()</span>
<span id="cb26-25">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>실제 거리와 MDS 거리의 상관계수: 0.9970</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-18-output-2.png" width="758" height="566" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="6a960d30" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3차원 MDS 수행</span></span>
<span id="cb28-2">mds_3d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MDS(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, dissimilarity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'precomputed'</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb28-3">city_mds_3d_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mds_3d.fit_transform(distance_matrix)</span>
<span id="cb28-4"></span>
<span id="cb28-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3D 시각화</span></span>
<span id="cb28-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mpl_toolkits.mplot3d <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Axes3D</span>
<span id="cb28-7"></span>
<span id="cb28-8">fig <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>))</span>
<span id="cb28-9">ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fig.add_subplot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">111</span>, projection<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3d'</span>)</span>
<span id="cb28-10"></span>
<span id="cb28-11">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'orange'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'purple'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'brown'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pink'</span>]</span>
<span id="cb28-12"></span>
<span id="cb28-13"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, city <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(cities):</span>
<span id="cb28-14">    ax.scatter(city_mds_3d_result[i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], </span>
<span id="cb28-15">               city_mds_3d_result[i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], </span>
<span id="cb28-16">               city_mds_3d_result[i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>],</span>
<span id="cb28-17">               c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors[i], s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, </span>
<span id="cb28-18">               label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>city, edgecolors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb28-19">    </span>
<span id="cb28-20">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 도시 이름 표시</span></span>
<span id="cb28-21">    ax.text(city_mds_3d_result[i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], </span>
<span id="cb28-22">            city_mds_3d_result[i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], </span>
<span id="cb28-23">            city_mds_3d_result[i, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], </span>
<span id="cb28-24">            city, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, fontweight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bold'</span>)</span>
<span id="cb28-25"></span>
<span id="cb28-26">ax.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 1'</span>)</span>
<span id="cb28-27">ax.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 2'</span>)</span>
<span id="cb28-28">ax.set_zlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 3'</span>)</span>
<span id="cb28-29">ax.set_title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'3차원 MDS 결과 - 도시간 거리'</span>)</span>
<span id="cb28-30">ax.legend(bbox_to_anchor<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), loc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'upper left'</span>)</span>
<span id="cb28-31">plt.tight_layout()</span>
<span id="cb28-32">plt.show()</span>
<span id="cb28-33"></span>
<span id="cb28-34"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"3차원 MDS Stress 값: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds_3d<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stress_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-19-output-1.png" width="1100" height="950" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>3차원 MDS Stress 값: 1974.2860</code></pre>
</div>
</div>
<div id="2ba3c891" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 차원별 Stress 값 비교</span></span>
<span id="cb30-2">dimensions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>)</span>
<span id="cb30-3">stress_values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb30-4"></span>
<span id="cb30-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> dim <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> dimensions:</span>
<span id="cb30-6">    mds_temp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MDS(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dim, dissimilarity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'precomputed'</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb30-7">    mds_temp.fit(distance_matrix)</span>
<span id="cb30-8">    stress_values.append(mds_temp.stress_)</span>
<span id="cb30-9"></span>
<span id="cb30-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Stress plot (Scree plot)</span></span>
<span id="cb30-11">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb30-12">plt.plot(dimensions, stress_values, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bo-'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, markersize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>)</span>
<span id="cb30-13">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'차원 수'</span>)</span>
<span id="cb30-14">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Stress 값'</span>)</span>
<span id="cb30-15">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'차원 수에 따른 Stress 값 변화'</span>)</span>
<span id="cb30-16">plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb30-17">plt.xticks(dimensions)</span>
<span id="cb30-18"></span>
<span id="cb30-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 각 점에 stress 값 표시</span></span>
<span id="cb30-20"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, stress <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(stress_values):</span>
<span id="cb30-21">    plt.annotate(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>stress<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.3f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, </span>
<span id="cb30-22">                (dimensions[i], stress), </span>
<span id="cb30-23">                xytext<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>), textcoords<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'offset points'</span>, </span>
<span id="cb30-24">                ha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'center'</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb30-25"></span>
<span id="cb30-26">plt.tight_layout()</span>
<span id="cb30-27">plt.show()</span>
<span id="cb30-28"></span>
<span id="cb30-29"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"차원별 Stress 값:"</span>)</span>
<span id="cb30-30"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> dim, stress <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(dimensions, stress_values):</span>
<span id="cb30-31">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dim<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">차원: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>stress<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-20-output-1.png" width="950" height="565" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>차원별 Stress 값:
1차원: 340937.8571
2차원: 2023.2616
3차원: 1974.2860
4차원: 1980.2935
5차원: 1982.6011</code></pre>
</div>
</div>
</section>
<section id="다양한-mds-변형-기법" class="level2">
<h2 class="anchored" data-anchor-id="다양한-mds-변형-기법">4. 다양한 MDS 변형 기법</h2>
<p>다양한 MDS 알고리즘을 비교해보는 예시입니다.</p>
<div id="f361ef61" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 다양한 MDS 알고리즘 비교</span></span>
<span id="cb32-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.manifold <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MDS</span>
<span id="cb32-3"></span>
<span id="cb32-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 연속 데이터를 사용하여 다양한 MDS 알고리즘 비교</span></span>
<span id="cb32-5">algorithms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb32-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Classical MDS'</span>: MDS(metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>),</span>
<span id="cb32-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Non-metric MDS'</span>: MDS(metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>),</span>
<span id="cb32-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS with different init'</span>: MDS(metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, n_init<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb32-9">}</span>
<span id="cb32-10"></span>
<span id="cb32-11">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb32-12"></span>
<span id="cb32-13"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx, (name, mds_algo) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(algorithms.items()):</span>
<span id="cb32-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MDS 수행</span></span>
<span id="cb32-15">    result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mds_algo.fit_transform(continuous_scaled)</span>
<span id="cb32-16">    </span>
<span id="cb32-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 클래스별 색상으로 시각화</span></span>
<span id="cb32-18">    colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>]</span>
<span id="cb32-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>):</span>
<span id="cb32-20">        mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i</span>
<span id="cb32-21">        axes[idx].scatter(result[mask, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], result[mask, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], </span>
<span id="cb32-22">                         c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors[i], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Class </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>)</span>
<span id="cb32-23">    </span>
<span id="cb32-24">    axes[idx].set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 1'</span>)</span>
<span id="cb32-25">    axes[idx].set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 2'</span>)</span>
<span id="cb32-26">    axes[idx].set_title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Stress: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds_algo<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stress_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb32-27">    axes[idx].legend()</span>
<span id="cb32-28">    axes[idx].grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb32-29"></span>
<span id="cb32-30">plt.tight_layout()</span>
<span id="cb32-31">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-21-output-1.png" width="1718" height="564" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="4b1821d5" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 거리 메트릭 비교</span></span>
<span id="cb33-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics.pairwise <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> euclidean_distances, manhattan_distances, cosine_distances</span>
<span id="cb33-3"></span>
<span id="cb33-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 다양한 거리 메트릭으로 MDS 수행</span></span>
<span id="cb33-5">distance_metrics <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb33-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Euclidean'</span>: euclidean_distances(continuous_scaled),</span>
<span id="cb33-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Manhattan'</span>: manhattan_distances(continuous_scaled),</span>
<span id="cb33-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Cosine'</span>: cosine_distances(continuous_scaled)</span>
<span id="cb33-9">}</span>
<span id="cb33-10"></span>
<span id="cb33-11">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb33-12"></span>
<span id="cb33-13"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx, (metric_name, dist_matrix) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(distance_metrics.items()):</span>
<span id="cb33-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 거리 행렬을 사용한 MDS</span></span>
<span id="cb33-15">    mds_metric <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MDS(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, dissimilarity<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'precomputed'</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb33-16">    result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mds_metric.fit_transform(dist_matrix)</span>
<span id="cb33-17">    </span>
<span id="cb33-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 클래스별 색상으로 시각화</span></span>
<span id="cb33-19">    colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>]</span>
<span id="cb33-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>):</span>
<span id="cb33-21">        mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i</span>
<span id="cb33-22">        axes[idx].scatter(result[mask, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], result[mask, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], </span>
<span id="cb33-23">                         c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors[i], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Class </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>)</span>
<span id="cb33-24">    </span>
<span id="cb33-25">    axes[idx].set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 1'</span>)</span>
<span id="cb33-26">    axes[idx].set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 2'</span>)</span>
<span id="cb33-27">    axes[idx].set_title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>metric_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> Distance MDS</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Stress: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds_metric<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stress_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb33-28">    axes[idx].legend()</span>
<span id="cb33-29">    axes[idx].grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb33-30"></span>
<span id="cb33-31">plt.tight_layout()</span>
<span id="cb33-32">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-22-output-1.png" width="1718" height="564" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="mds-결과-해석-및-평가" class="level2">
<h2 class="anchored" data-anchor-id="mds-결과-해석-및-평가">5. MDS 결과 해석 및 평가</h2>
<p>MDS 결과를 해석하고 평가하는 방법들을 소개합니다.</p>
<div id="eac0116c" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Stress 값 해석 기준</span></span>
<span id="cb34-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> interpret_stress(stress_value):</span>
<span id="cb34-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Stress 값을 해석하는 함수"""</span></span>
<span id="cb34-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> stress_value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>:</span>
<span id="cb34-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"매우 좋음 (Excellent)"</span></span>
<span id="cb34-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> stress_value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>:</span>
<span id="cb34-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"좋음 (Good)"</span></span>
<span id="cb34-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> stress_value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>:</span>
<span id="cb34-9">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"보통 (Fair)"</span></span>
<span id="cb34-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb34-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나쁨 (Poor)"</span></span>
<span id="cb34-12"></span>
<span id="cb34-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 각 MDS 결과의 Stress 값 해석</span></span>
<span id="cb34-14"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"=== MDS 결과 평가 ==="</span>)</span>
<span id="cb34-15"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"연속변수 MDS Stress: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stress_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> - </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>interpret_stress(mds.stress_)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb34-16"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"혼합데이터 MDS Stress: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds_mixed<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stress_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> - </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>interpret_stress(mds_mixed.stress_)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb34-17"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Gower 거리 MDS Stress: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds_gower<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stress_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> - </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>interpret_stress(mds_gower.stress_)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb34-18"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"도시 거리 MDS Stress: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds_distance<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stress_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> - </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>interpret_stress(mds_distance.stress_)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>=== MDS 결과 평가 ===
연속변수 MDS Stress: 3208.7256 - 나쁨 (Poor)
혼합데이터 MDS Stress: 3843.1912 - 나쁨 (Poor)
Gower 거리 MDS Stress: 70.5540 - 나쁨 (Poor)
도시 거리 MDS Stress: 2023.2616 - 나쁨 (Poor)</code></pre>
</div>
</div>
<div id="9180be12" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 차원 축소 효과 비교</span></span>
<span id="cb36-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> calculate_explained_variance_ratio(original_data, mds_result):</span>
<span id="cb36-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""MDS로 설명되는 분산 비율 계산"""</span></span>
<span id="cb36-4">    original_var <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.var(original_data, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span>
<span id="cb36-5">    mds_var <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.var(mds_result, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span>
<span id="cb36-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> mds_var <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> original_var</span>
<span id="cb36-7"></span>
<span id="cb36-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 연속변수 데이터의 분산 설명 비율</span></span>
<span id="cb36-9">explained_ratio <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> calculate_explained_variance_ratio(continuous_scaled, mds_result)</span>
<span id="cb36-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">연속변수 MDS 분산 설명 비율: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>explained_ratio<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>explained_ratio<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">%)"</span>)</span>
<span id="cb36-11"></span>
<span id="cb36-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 원본 데이터 차원과 MDS 결과 비교</span></span>
<span id="cb36-13"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"원본 데이터 차원: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>continuous_scaled<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">차원"</span>)</span>
<span id="cb36-14"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"MDS 결과 차원: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds_result<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">차원"</span>)</span>
<span id="cb36-15"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"차원 축소율: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> mds_result.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>continuous_scaled.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.1f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">%"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
연속변수 MDS 분산 설명 비율: 0.9358 (93.58%)
원본 데이터 차원: 5차원
MDS 결과 차원: 2차원
차원 축소율: 60.0%</code></pre>
</div>
</div>
<div id="11367870" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MDS vs PCA 비교</span></span>
<span id="cb38-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.decomposition <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PCA</span>
<span id="cb38-3"></span>
<span id="cb38-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># PCA 수행</span></span>
<span id="cb38-5">pca <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PCA(n_components<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb38-6">pca_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pca.fit_transform(continuous_scaled)</span>
<span id="cb38-7"></span>
<span id="cb38-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 비교 시각화</span></span>
<span id="cb38-9">fig, (ax1, ax2) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb38-10"></span>
<span id="cb38-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MDS 결과</span></span>
<span id="cb38-12">colors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'blue'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span>]</span>
<span id="cb38-13"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>):</span>
<span id="cb38-14">    mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i</span>
<span id="cb38-15">    ax1.scatter(mds_result[mask, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], mds_result[mask, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], </span>
<span id="cb38-16">                c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors[i], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Class </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>)</span>
<span id="cb38-17"></span>
<span id="cb38-18">ax1.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 1'</span>)</span>
<span id="cb38-19">ax1.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MDS Dimension 2'</span>)</span>
<span id="cb38-20">ax1.set_title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'MDS 결과</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">Stress: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mds<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>stress_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb38-21">ax1.legend()</span>
<span id="cb38-22">ax1.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb38-23"></span>
<span id="cb38-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># PCA 결과</span></span>
<span id="cb38-25"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>):</span>
<span id="cb38-26">    mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> i</span>
<span id="cb38-27">    ax2.scatter(pca_result[mask, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], pca_result[mask, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], </span>
<span id="cb38-28">                c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>colors[i], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'Class </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>)</span>
<span id="cb38-29"></span>
<span id="cb38-30">ax2.set_xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PC1'</span>)</span>
<span id="cb38-31">ax2.set_ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PC2'</span>)</span>
<span id="cb38-32">ax2.set_title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'PCA 결과</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">설명분산비율: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>pca<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>explained_variance_ratio_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb38-33">ax2.legend()</span>
<span id="cb38-34">ax2.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)</span>
<span id="cb38-35"></span>
<span id="cb38-36">plt.tight_layout()</span>
<span id="cb38-37">plt.show()</span>
<span id="cb38-38"></span>
<span id="cb38-39"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"PCA 설명 분산 비율: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>pca<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>explained_variance_ratio_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>pca<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>explained_variance_ratio_<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">%)"</span>)</span>
<span id="cb38-40"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"각 주성분별 설명 분산 비율: PC1=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>pca<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>explained_variance_ratio_[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, PC2=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>pca<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>explained_variance_ratio_[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00_files/figure-html/cell-25-output-1.png" width="1526" height="564" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>PCA 설명 분산 비율: 0.5028 (50.28%)
각 주성분별 설명 분산 비율: PC1=0.2727, PC2=0.2301</code></pre>
</div>
</div>
</section>
<section id="결론" class="level2">
<h2 class="anchored" data-anchor-id="결론">결론</h2>
<p>다차원 척도법(MDS)은 다양한 유형의 데이터에 적용할 수 있는 강력한 차원 축소 기법입니다:</p>
<section id="주요-특징" class="level3">
<h3 class="anchored" data-anchor-id="주요-특징">주요 특징:</h3>
<ol type="1">
<li><strong>거리 보존</strong>: 원본 데이터의 거리 관계를 저차원에서 최대한 보존</li>
<li><strong>유연성</strong>: 연속변수, 명목변수, 거리 행렬 등 다양한 데이터 타입 지원</li>
<li><strong>직관적 해석</strong>: 2D/3D 시각화를 통한 직관적인 데이터 이해</li>
</ol>
</section>
<section id="적용-사례" class="level3">
<h3 class="anchored" data-anchor-id="적용-사례">적용 사례:</h3>
<ol type="1">
<li><strong>연속변수</strong>: 표준화 후 직접 적용</li>
<li><strong>혼합 데이터</strong>: 원핫 인코딩 또는 Gower 거리 사용</li>
<li><strong>거리 행렬</strong>: 미리 계산된 거리 정보 활용</li>
</ol>
</section>
<section id="평가-지표" class="level3">
<h3 class="anchored" data-anchor-id="평가-지표">평가 지표:</h3>
<ul>
<li><strong>Stress 값</strong>: 낮을수록 좋음 (&lt; 0.1이 권장)</li>
<li><strong>거리 상관계수</strong>: 원본과 MDS 거리의 상관관계</li>
<li><strong>Shepard diagram</strong>: 거리 보존 정도 시각화</li>
</ul>


</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>확률 통계</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/etc/00.html</guid>
  <pubDate>Sat, 12 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>외생 변수 추가하기</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/07.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<div id="84deb8a6" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> statsmodels.api <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sm</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-6"></span>
<span id="cb1-7">plt.rcParams[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'font.family'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Noto Sans KR'</span></span>
<span id="cb1-8"></span>
<span id="cb1-9">macro_econ_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sm.datasets.macrodata.load_pandas().data</span>
<span id="cb1-10">macro_econ_data</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">year</th>
<th data-quarto-table-cell-role="th">quarter</th>
<th data-quarto-table-cell-role="th">realgdp</th>
<th data-quarto-table-cell-role="th">realcons</th>
<th data-quarto-table-cell-role="th">realinv</th>
<th data-quarto-table-cell-role="th">realgovt</th>
<th data-quarto-table-cell-role="th">realdpi</th>
<th data-quarto-table-cell-role="th">cpi</th>
<th data-quarto-table-cell-role="th">m1</th>
<th data-quarto-table-cell-role="th">tbilrate</th>
<th data-quarto-table-cell-role="th">unemp</th>
<th data-quarto-table-cell-role="th">pop</th>
<th data-quarto-table-cell-role="th">infl</th>
<th data-quarto-table-cell-role="th">realint</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1959.0</td>
<td>1.0</td>
<td>2710.349</td>
<td>1707.4</td>
<td>286.898</td>
<td>470.045</td>
<td>1886.9</td>
<td>28.980</td>
<td>139.7</td>
<td>2.82</td>
<td>5.8</td>
<td>177.146</td>
<td>0.00</td>
<td>0.00</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1959.0</td>
<td>2.0</td>
<td>2778.801</td>
<td>1733.7</td>
<td>310.859</td>
<td>481.301</td>
<td>1919.7</td>
<td>29.150</td>
<td>141.7</td>
<td>3.08</td>
<td>5.1</td>
<td>177.830</td>
<td>2.34</td>
<td>0.74</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1959.0</td>
<td>3.0</td>
<td>2775.488</td>
<td>1751.8</td>
<td>289.226</td>
<td>491.260</td>
<td>1916.4</td>
<td>29.350</td>
<td>140.5</td>
<td>3.82</td>
<td>5.3</td>
<td>178.657</td>
<td>2.74</td>
<td>1.09</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1959.0</td>
<td>4.0</td>
<td>2785.204</td>
<td>1753.7</td>
<td>299.356</td>
<td>484.052</td>
<td>1931.3</td>
<td>29.370</td>
<td>140.0</td>
<td>4.33</td>
<td>5.6</td>
<td>179.386</td>
<td>0.27</td>
<td>4.06</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1960.0</td>
<td>1.0</td>
<td>2847.699</td>
<td>1770.5</td>
<td>331.722</td>
<td>462.199</td>
<td>1955.5</td>
<td>29.540</td>
<td>139.6</td>
<td>3.50</td>
<td>5.2</td>
<td>180.007</td>
<td>2.31</td>
<td>1.19</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">198</td>
<td>2008.0</td>
<td>3.0</td>
<td>13324.600</td>
<td>9267.7</td>
<td>1990.693</td>
<td>991.551</td>
<td>9838.3</td>
<td>216.889</td>
<td>1474.7</td>
<td>1.17</td>
<td>6.0</td>
<td>305.270</td>
<td>-3.16</td>
<td>4.33</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">199</td>
<td>2008.0</td>
<td>4.0</td>
<td>13141.920</td>
<td>9195.3</td>
<td>1857.661</td>
<td>1007.273</td>
<td>9920.4</td>
<td>212.174</td>
<td>1576.5</td>
<td>0.12</td>
<td>6.9</td>
<td>305.952</td>
<td>-8.79</td>
<td>8.91</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">200</td>
<td>2009.0</td>
<td>1.0</td>
<td>12925.410</td>
<td>9209.2</td>
<td>1558.494</td>
<td>996.287</td>
<td>9926.4</td>
<td>212.671</td>
<td>1592.8</td>
<td>0.22</td>
<td>8.1</td>
<td>306.547</td>
<td>0.94</td>
<td>-0.71</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">201</td>
<td>2009.0</td>
<td>2.0</td>
<td>12901.504</td>
<td>9189.0</td>
<td>1456.678</td>
<td>1023.528</td>
<td>10077.5</td>
<td>214.469</td>
<td>1653.6</td>
<td>0.18</td>
<td>9.2</td>
<td>307.226</td>
<td>3.37</td>
<td>-3.19</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">202</td>
<td>2009.0</td>
<td>3.0</td>
<td>12990.341</td>
<td>9256.0</td>
<td>1486.398</td>
<td>1044.088</td>
<td>10040.6</td>
<td>216.385</td>
<td>1673.9</td>
<td>0.12</td>
<td>9.6</td>
<td>308.013</td>
<td>3.56</td>
<td>-3.44</td>
</tr>
</tbody>
</table>

<p>203 rows × 14 columns</p>
</div>
</div>
</div>
<div id="1994673a" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">target <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> macro_econ_data[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'realgdp'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'realcons'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'realinv'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'realgovt'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'realdpi'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cpi'</span>]]</span>
<span id="cb2-2">target.plot(subplots<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>), layout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span>
<span id="cb2-3">plt.xticks(np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">208</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>), np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1959</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2010</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>))</span>
<span id="cb2-4">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/07_files/figure-html/cell-3-output-1.png" width="809" height="633" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>이 다음 부분은 오류인거 같음. 다른 책 보자.</li>
</ul>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>확률 통계</category>
  <category>시계열 분석</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/07.html</guid>
  <pubDate>Fri, 11 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>계절성 고려</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/06.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="sarima-모델" class="level2">
<h2 class="anchored" data-anchor-id="sarima-모델">SARIMA 모델</h2>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?SARIMA(p,%20d,%20q)(P,%20D,%20Q)_m"> 형태로 표현</li>
<li><img src="https://latex.codecogs.com/png.latex?m">: 계절성 주기</li>
<li><img src="https://latex.codecogs.com/png.latex?P,%20D,%20Q">: 계절성 AR, 차분, MA 차수</li>
</ul>
<div id="bc42b824" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-5"></span>
<span id="cb1-6">plt.rcParams[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'font.family'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Noto Sans KR'</span></span>
<span id="cb1-7"></span>
<span id="cb1-8">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/air.csv'</span>)</span></code></pre></div>
</div>
<div id="7284ce41" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.tsa.seasonal <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> STL</span>
<span id="cb2-2"></span>
<span id="cb2-3">decomposition <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> STL(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Passengers'</span>], period<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>).fit()</span></code></pre></div>
</div>
<div id="a83f52df" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.tsa.stattools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> adfuller</span>
<span id="cb3-2"></span>
<span id="cb3-3">df_diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.diff(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Passengers'</span>], n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-4"></span>
<span id="cb3-5">ADF_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(df_diff)</span>
<span id="cb3-6">ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>(-2.8292668241700025, 0.05421329028382508)</code></pre>
</div>
</div>
<div id="ee167ae9" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">df_diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.diff(df_diff, n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>)</span>
<span id="cb5-2"></span>
<span id="cb5-3">ADF_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(df_diff)</span>
<span id="cb5-4">ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>(-17.624862360208343, 3.823046855816035e-30)</code></pre>
</div>
</div>
<div id="cfb7c33f" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Union</span>
<span id="cb7-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.tsa.statespace.sarimax <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SARIMAX</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> optimize_SARIMA(endog: Union[pd.Series, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>], order_list: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>, d: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, D: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, s: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> pd.DataFrame:</span>
<span id="cb7-5">    results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb7-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> order <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> order_list:</span>
<span id="cb7-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb7-8">            model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SARIMAX(endog, </span>
<span id="cb7-9">                            order<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(order[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], d, order[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), </span>
<span id="cb7-10">                            seasonal_order<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(order[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>], D, order[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>], s),</span>
<span id="cb7-11">                            simple_differencing<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>).fit(disp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb7-12">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span>:</span>
<span id="cb7-13">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span></span>
<span id="cb7-14">        aic <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.aic</span>
<span id="cb7-15">        results.append([order, aic])</span>
<span id="cb7-16">    result_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(results)</span>
<span id="cb7-17">    result_df.columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(p, q, P, Q)'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'AIC'</span>]</span>
<span id="cb7-18">    result_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> result_df.sort_values(by<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"AIC"</span>).reset_index(drop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-19"></span>
<span id="cb7-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> result_df</span></code></pre></div>
</div>
<div id="ec034d5c" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> itertools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> product</span>
<span id="cb8-2"></span>
<span id="cb8-3">train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.iloc[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Passengers'</span>]</span>
<span id="cb8-4">test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.iloc[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>:]</span>
<span id="cb8-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  ps = range(0, 4, 1)</span></span>
<span id="cb8-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  qs = range(0, 4, 1)</span></span>
<span id="cb8-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  Ps = range(0, 4, 1)</span></span>
<span id="cb8-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  Qs = range(0, 4, 1)</span></span>
<span id="cb8-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># </span></span>
<span id="cb8-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  SARIMA_order_list = list(product(ps, qs, Ps, Qs))</span></span>
<span id="cb8-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># </span></span>
<span id="cb8-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># </span></span>
<span id="cb8-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  d = 1</span></span>
<span id="cb8-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  D = 1</span></span>
<span id="cb8-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  s = 12</span></span>
<span id="cb8-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  SARIMA_result_df = optimize_SARIMA(train, SARIMA_order_list, d, D, s)</span></span>
<span id="cb8-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  SARIMA_result_df</span></span></code></pre></div>
</div>
<div id="825f1f34" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">SARIMA_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SARIMAX(train, order<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), seasonal_order<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>), simple_differencing<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb9-2">SARIMA_model_fit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SARIMA_model.fit(disp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb9-3"></span>
<span id="cb9-4">SARIMA_model_fit.plot_diagnostics(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb9-5">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/06_files/figure-html/cell-8-output-1.png" width="806" height="673" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="e758f944" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.stats.diagnostic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> acorr_ljungbox</span>
<span id="cb10-2"></span>
<span id="cb10-3">tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> acorr_ljungbox(SARIMA_model_fit.resid, np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>))</span>
<span id="cb10-4">tr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">lb_stat</th>
<th data-quarto-table-cell-role="th">lb_pvalue</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>0.004785</td>
<td>0.944850</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>0.745422</td>
<td>0.688864</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>1.021040</td>
<td>0.796161</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>1.226086</td>
<td>0.873785</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5</td>
<td>1.436408</td>
<td>0.920290</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">6</td>
<td>1.711782</td>
<td>0.944208</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7</td>
<td>2.307234</td>
<td>0.940900</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">8</td>
<td>2.717276</td>
<td>0.950829</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9</td>
<td>2.733486</td>
<td>0.973931</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10</td>
<td>4.969176</td>
<td>0.893228</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="3b74ea29" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">SARIMA_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SARIMA_model_fit.get_prediction(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">132</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">143</span>).predicted_mean</span>
<span id="cb11-2"></span>
<span id="cb11-3">test[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SARIMA_pred'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SARIMA_pred</span>
<span id="cb11-4"></span>
<span id="cb11-5">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Passengers'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'실제 값'</span>)</span>
<span id="cb11-6">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SARIMA_pred'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'SARIMA 예측값'</span>)</span>
<span id="cb11-7">plt.xticks(np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">145</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>), np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1949</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1962</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb11-8">plt.xlim(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">120</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">143</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/06_files/figure-html/cell-10-output-1.png" width="590" height="430" class="figure-img"></p>
</figure>
</div>
</div>
</div>


</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>확률 통계</category>
  <category>시계열 분석</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/06.html</guid>
  <pubDate>Fri, 11 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>복잡한 시계열 모델</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/05.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<div id="ef521d9f" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.tsa.arima_process <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ArmaProcess</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-6"></span>
<span id="cb1-7">plt.rcParams[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'font.family'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Noto Sans KR'</span></span>
<span id="cb1-8"></span>
<span id="cb1-9">ar1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.33</span>])</span>
<span id="cb1-10">ma1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>])</span>
<span id="cb1-11"></span>
<span id="cb1-12">ARMA_1_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ArmaProcess(ar1, ma1).generate_sample(nsample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span></code></pre></div>
</div>
<div id="4c87d91a" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.tsa.stattools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> adfuller</span>
<span id="cb2-2"></span>
<span id="cb2-3">ADF_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(ARMA_1_1)</span>
<span id="cb2-4"></span>
<span id="cb2-5">ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>(-7.656346674014989, 1.7349289952389427e-11)</code></pre>
</div>
</div>
<div id="8f55bada" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.graphics.tsaplots <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plot_acf, plot_pacf</span>
<span id="cb4-2"></span>
<span id="cb4-3">plot_acf(ARMA_1_1, lags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb4-4">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/05_files/figure-html/cell-4-output-1.png" width="583" height="432" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>ARMA(1, 1) 모델인데 지연이 2.</li>
<li>ACF로는 차수를 추론할 수 없음.</li>
</ul>
<div id="43f2c2fa" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">plot_pacf(ARMA_1_1, lags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb5-2">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/05_files/figure-html/cell-5-output-1.png" width="583" height="432" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>마찬가지로 차수를 추론할 수 없음.</li>
</ul>
<section id="일반적-모델링-절차" class="level2">
<h2 class="anchored" data-anchor-id="일반적-모델링-절차">일반적 모델링 절차</h2>
<ul>
<li><img src="https://latex.codecogs.com/png.latex?AIC%20=%202k%20-%202ln(%5Chat%7BL%7D)"></li>
<li>k = p + q</li>
<li>L = max(likelihood)</li>
</ul>
<div id="73a3e2e2" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> itertools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> product</span>
<span id="cb6-2"></span>
<span id="cb6-3">ps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb6-4">qs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb6-5"></span>
<span id="cb6-6">order_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(product(ps, qs))</span></code></pre></div>
</div>
<div id="b748c778" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Union</span>
<span id="cb7-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.tsa.statespace.sarimax <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SARIMAX</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> optimize_ARMA(endog: Union[pd.Series, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>], order_list: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> pd.DataFrame:</span>
<span id="cb7-5">    results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb7-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> order <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> order_list:</span>
<span id="cb7-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb7-8">            model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SARIMAX(endog, order<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(order[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, order[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]), simple_differencing<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>).fit(disp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb7-9">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span>:</span>
<span id="cb7-10">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span></span>
<span id="cb7-11">        aic <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.aic</span>
<span id="cb7-12">        results.append([order, aic])</span>
<span id="cb7-13">    result_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(results)</span>
<span id="cb7-14">    result_df.columns <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'(p, q)'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'AIC'</span>]</span>
<span id="cb7-15">    result_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> result_df.sort_values(by<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"AIC"</span>).reset_index(drop<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-16"></span>
<span id="cb7-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> result_df</span>
<span id="cb7-18"></span>
<span id="cb7-19">result_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optimize_ARMA(ARMA_1_1, order_list)</span>
<span id="cb7-20">result_df</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/cryscham123/.local/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning:

Maximum Likelihood optimization failed to converge. Check mle_retvals
</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">(p, q)</th>
<th data-quarto-table-cell-role="th">AIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>(1, 2)</td>
<td>2880.745326</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>(2, 2)</td>
<td>2881.184850</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>(2, 1)</td>
<td>2881.215973</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>(0, 3)</td>
<td>2881.552804</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>(0, 2)</td>
<td>2881.934005</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>(1, 1)</td>
<td>2882.021239</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>(1, 3)</td>
<td>2882.411069</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>(3, 1)</td>
<td>2882.880564</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>(2, 3)</td>
<td>2883.178911</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>(3, 3)</td>
<td>2884.999545</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>(3, 2)</td>
<td>2885.215581</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>(0, 1)</td>
<td>2998.204843</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>(3, 0)</td>
<td>3059.234951</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>(2, 0)</td>
<td>3135.429791</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>(1, 0)</td>
<td>3326.498642</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15</td>
<td>(0, 0)</td>
<td>3894.252408</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<section id="잔차-분석" class="level3">
<h3 class="anchored" data-anchor-id="잔차-분석">잔차 분석</h3>
<div id="ad922785" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SARIMAX(ARMA_1_1, order<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), simple_differencing<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb9-2">model_fit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.fit(disp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb9-3"></span>
<span id="cb9-4">model_fit.plot_diagnostics(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span>
<span id="cb9-5">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/05_files/figure-html/cell-8-output-1.png" width="955" height="673" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="f24ed876" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.stats.diagnostic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> acorr_ljungbox</span>
<span id="cb10-2"></span>
<span id="cb10-3">tr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> acorr_ljungbox(model_fit.resid, np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>))</span>
<span id="cb10-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(tr)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     lb_stat  lb_pvalue
1   0.289153   0.590764
2   2.289623   0.318284
3   2.291207   0.514207
4   2.963817   0.563899
5   3.571527   0.612593
6   3.938499   0.684999
7   5.248137   0.629711
8   7.642936   0.469103
9   8.139031   0.520198
10  8.329570   0.596679</code></pre>
</div>
</div>
</section>
</section>
<section id="예시---대역폭-사용량-예측" class="level2">
<h2 class="anchored" data-anchor-id="예시---대역폭-사용량-예측">예시 - 대역폭 사용량 예측</h2>
<div id="6d9cd719" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/bandwidth.csv'</span>)</span>
<span id="cb12-2">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hourly_bandwidth'</span>)</span>
<span id="cb12-3"></span>
<span id="cb12-4">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'시간'</span>)</span>
<span id="cb12-5">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'시간당 대역폭 사용량(MBps)'</span>)</span>
<span id="cb12-6">plt.xticks(</span>
<span id="cb12-7">    np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">730</span>), </span>
<span id="cb12-8">    [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Jan'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feb'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Mar'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Apr'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'May'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Jun'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Jul'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Aug'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Sep'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Oct'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Nov'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Dec'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feb'</span>])</span>
<span id="cb12-9">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/05_files/figure-html/cell-10-output-1.png" width="598" height="434" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="dff2db6a" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">ADF_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hourly_bandwidth'</span>])</span>
<span id="cb13-2"></span>
<span id="cb13-3">ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(-0.8714653199452845, 0.7972240255014515)</code></pre>
</div>
</div>
<div id="a0ac94c2" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">bandwidth_diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.diff(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hourly_bandwidth'</span>], n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb15-2"></span>
<span id="cb15-3">ADF_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(bandwidth_diff)</span>
<span id="cb15-4"></span>
<span id="cb15-5">ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>(-20.694853863789028, 0.0)</code></pre>
</div>
</div>
<div id="24ea4779" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">df_diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bandwidth_diff'</span>: bandwidth_diff})</span>
<span id="cb17-2">train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df_diff.iloc[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">168</span>]</span>
<span id="cb17-3">test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df_diff.iloc[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">168</span>:]</span></code></pre></div>
</div>
<div id="f532852f" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">ps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb18-2">qs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb18-3">order_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(product(ps, qs))</span>
<span id="cb18-4">result_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optimize_ARMA(train[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bandwidth_diff'</span>], order_list)</span>
<span id="cb18-5">result_df</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">(p, q)</th>
<th data-quarto-table-cell-role="th">AIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>(3, 2)</td>
<td>27991.063879</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>(2, 3)</td>
<td>27991.287509</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>(2, 2)</td>
<td>27991.603598</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>(3, 3)</td>
<td>27993.416924</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>(1, 3)</td>
<td>28003.349550</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>(1, 2)</td>
<td>28051.351401</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>(3, 1)</td>
<td>28071.155496</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>(3, 0)</td>
<td>28095.618186</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>(2, 1)</td>
<td>28097.250766</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>(2, 0)</td>
<td>28098.407664</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">10</td>
<td>(1, 1)</td>
<td>28172.510044</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>(1, 0)</td>
<td>28941.056983</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>(0, 3)</td>
<td>31355.802141</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">13</td>
<td>(0, 2)</td>
<td>33531.179284</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>(0, 1)</td>
<td>39402.269523</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">15</td>
<td>(0, 0)</td>
<td>49035.184224</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="b66907b6" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SARIMAX(train[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bandwidth_diff'</span>], order<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), simple_differencing<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb19-2">model_fit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.fit(disp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb19-3">model_fit.plot_diagnostics(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/05_files/figure-html/cell-15-output-1.png" width="955" height="673" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/05_files/figure-html/cell-15-output-2.png" width="955" height="673" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="124b0bc8" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">acorr_ljungbox(model_fit.resid, np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11</span>))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">lb_stat</th>
<th data-quarto-table-cell-role="th">lb_pvalue</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>0.042190</td>
<td>0.837257</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>0.418364</td>
<td>0.811247</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>0.520271</td>
<td>0.914416</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>0.850554</td>
<td>0.931545</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5</td>
<td>0.850841</td>
<td>0.973678</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">6</td>
<td>1.111754</td>
<td>0.981019</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">7</td>
<td>2.124864</td>
<td>0.952607</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">8</td>
<td>3.230558</td>
<td>0.919067</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9</td>
<td>3.248662</td>
<td>0.953615</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">10</td>
<td>3.588289</td>
<td>0.964015</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="007b25df" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> rolling_forecast(df: pd.DataFrame, train_len: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, horizon: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, window: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, method: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>:</span>
<span id="cb21-2">    total_len <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_len <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> horizon</span>
<span id="cb21-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> method <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mean'</span>:</span>
<span id="cb21-4">        pred_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb21-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(train_len, total_len, window):</span>
<span id="cb21-6">            mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(df[:i].values)</span>
<span id="cb21-7">            pred_mean.extend(mean <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(window))</span>
<span id="cb21-8">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> pred_mean</span>
<span id="cb21-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> method <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'last'</span>:</span>
<span id="cb21-10">        pred_last_value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb21-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(train_len, total_len, window):</span>
<span id="cb21-12">            last_value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.iloc[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].values[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb21-13">            pred_last_value.extend(last_value <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(window))</span>
<span id="cb21-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> pred_last_value</span>
<span id="cb21-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> method <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ARMA'</span>:</span>
<span id="cb21-16">        pred_MA <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb21-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(train_len, total_len, window):</span>
<span id="cb21-18">            model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SARIMAX(df[:i], order<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span>
<span id="cb21-19">            res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.fit(disp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb21-20">            predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> res.get_prediction(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> window <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb21-21">            oos_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> predictions.predicted_mean.iloc[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>window:]</span>
<span id="cb21-22">            pred_MA.extend(oos_pred)</span>
<span id="cb21-23">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> pred_MA</span>
<span id="cb21-24"></span>
<span id="cb21-25">pred_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> test.copy()</span>
<span id="cb21-26">TRAIN_LEN <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train)</span>
<span id="cb21-27">HORIZON <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(test)</span>
<span id="cb21-28">WINDOW <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb21-29"></span>
<span id="cb21-30">pred_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rolling_forecast(df_diff, TRAIN_LEN, HORIZON, WINDOW, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mean'</span>)</span>
<span id="cb21-31">pred_last <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rolling_forecast(df_diff, TRAIN_LEN, HORIZON, WINDOW, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'last'</span>)</span>
<span id="cb21-32">pred_ARMA <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rolling_forecast(df_diff, TRAIN_LEN, HORIZON, WINDOW, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ARMA'</span>)</span>
<span id="cb21-33"></span>
<span id="cb21-34">pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_mean'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred_mean</span>
<span id="cb21-35">pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_last'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred_last</span>
<span id="cb21-36">pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_ARMA'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred_ARMA</span>
<span id="cb21-37"></span>
<span id="cb21-38">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pred_df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pred_df.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bandwidth_diff'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'실제값'</span>)</span>
<span id="cb21-39">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pred_df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pred_df.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_mean'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'평균 예측'</span>)</span>
<span id="cb21-40">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pred_df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pred_df.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_last'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'마지막 값 예측'</span>)</span>
<span id="cb21-41">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pred_df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pred_df.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_ARMA'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ARMA(2, 2) 예측'</span>)</span>
<span id="cb21-42">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'시간'</span>)</span>
<span id="cb21-43">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'시간당 대역폭 사용량(MBps)'</span>)</span>
<span id="cb21-44">plt.xticks(</span>
<span id="cb21-45">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9802</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9850</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9898</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9946</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9994</span>],</span>
<span id="cb21-46">    [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-02-13'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-02-15'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-02-17'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-02-19'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-02-21'</span>])</span>
<span id="cb21-47">plt.xlim(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9800</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9999</span>)</span>
<span id="cb21-48">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/05_files/figure-html/cell-17-output-1.png" width="605" height="430" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="5ac9268e" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mean_squared_error, mean_absolute_error</span>
<span id="cb22-2"></span>
<span id="cb22-3">mse_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bandwidth_diff'</span>], pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_mean'</span>])</span>
<span id="cb22-4">mse_last <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bandwidth_diff'</span>], pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_last'</span>])</span>
<span id="cb22-5">mse_ARMA <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bandwidth_diff'</span>], pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_ARMA'</span>])</span>
<span id="cb22-6">mse_mean, mse_last, mse_ARMA</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>(6.306526957989325, 2.2297582947733656, 1.7690462113874967)</code></pre>
</div>
</div>
<section id="역변환" class="level3">
<h3 class="anchored" data-anchor-id="역변환">역변환</h3>
<div id="19218ab7" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_bandwidth'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.Series()</span>
<span id="cb24-2">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_bandwidth'</span>].iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9832</span>:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hourly_bandwidth'</span>].iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9832</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_ARMA'</span>].cumsum()</span>
<span id="cb24-3"></span>
<span id="cb24-4">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hourly_bandwidth'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'실제 값'</span>)</span>
<span id="cb24-5">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_bandwidth'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ARMA(2, 2) 예측'</span>)</span>
<span id="cb24-6">plt.xticks(</span>
<span id="cb24-7">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9802</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9850</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9898</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9946</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9994</span>],</span>
<span id="cb24-8">    [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-02-13'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-02-15'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-02-17'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-02-19'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'2020-02-21'</span>])</span>
<span id="cb24-9">plt.xlim(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9800</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9999</span>)</span>
<span id="cb24-10">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/05_files/figure-html/cell-19-output-1.png" width="619" height="434" class="figure-img"></p>
</figure>
</div>
</div>
</div>


</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>확률 통계</category>
  <category>시계열 분석</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/05.html</guid>
  <pubDate>Thu, 10 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>자기귀모형</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/04.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<ul>
<li>자기회귀과정: 예측값이 이전 값에만 선형적으로 의존한다고 가정</li>
</ul>
<div id="c523bb8d" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-5"></span>
<span id="cb1-6">plt.rcParams[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'font.family'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Noto Sans KR'</span></span>
<span id="cb1-7"></span>
<span id="cb1-8">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/foot.csv'</span>)</span></code></pre></div>
</div>
<div id="fbf9c67a" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.tsa.stattools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> adfuller</span>
<span id="cb2-2"></span>
<span id="cb2-3">ADF_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'foot_traffic'</span>])</span>
<span id="cb2-4">ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(-1.1758885999240625, 0.6838808917896241)</code></pre>
</div>
</div>
<ul>
<li>비 정상성 발견. 차분 진행</li>
</ul>
<div id="042862ba" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">foot_diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.diff(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'foot_traffic'</span>], n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-2"></span>
<span id="cb4-3">ADF_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(foot_diff)</span>
<span id="cb4-4">ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(-5.268231347422049, 6.369317654781143e-06)</code></pre>
</div>
</div>
<div id="a546ebcf" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.graphics.tsaplots <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plot_acf</span>
<span id="cb6-2"></span>
<span id="cb6-3">plot_acf(foot_diff, lags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb6-4">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/04_files/figure-html/cell-5-output-1.png" width="583" height="432" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="0052474d" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.tsa.arima_process <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ArmaProcess</span>
<span id="cb7-2"></span>
<span id="cb7-3">ma2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb7-4">ar2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.33</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.50</span>])</span>
<span id="cb7-5">AR2_process <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ArmaProcess(ar2, ma2).generate_sample(nsample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span></code></pre></div>
</div>
<div id="238b5927" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.graphics.tsaplots <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plot_pacf</span>
<span id="cb8-2"></span>
<span id="cb8-3">plot_pacf(AR2_process, lags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb8-4">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/04_files/figure-html/cell-7-output-1.png" width="583" height="432" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="881e91b0" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">plot_pacf(foot_diff, lags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span>
<span id="cb9-2">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/04_files/figure-html/cell-8-output-1.png" width="583" height="432" class="figure-img"></p>
</figure>
</div>
</div>
</div>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>확률 통계</category>
  <category>시계열 분석</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/04.html</guid>
  <pubDate>Thu, 10 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>이동평균과정 모델링</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/03.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<ul>
<li>이동편균 모델: 현잿 값이 현재와 과거 오차에 선형적으로 비례한다.</li>
</ul>
<div id="d5e02d14" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-5"></span>
<span id="cb1-6">plt.rcParams[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'font.family'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Noto Sans KR'</span></span>
<span id="cb1-7"></span>
<span id="cb1-8">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/widget.csv'</span>)</span>
<span id="cb1-9">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'widget_sales'</span>)</span>
<span id="cb1-10">plt.xticks(</span>
<span id="cb1-11">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">57</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">87</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">116</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">145</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">175</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">204</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">234</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">264</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">293</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">323</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">352</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">382</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">409</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">439</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">468</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">498</span>], </span>
<span id="cb1-12">    [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Jan 2019'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feb'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Mar'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Apr'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'May'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Jun'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Jul'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Aug'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Sep'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Oct'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Nov'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Dec'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Jan 2020'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feb'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Mar'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Apr'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'May'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Jun'</span>])</span>
<span id="cb1-13">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/03_files/figure-html/cell-2-output-1.png" width="583" height="430" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="f610159a" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.tsa.stattools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> adfuller</span>
<span id="cb2-2"></span>
<span id="cb2-3">ADF_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'widget_sales'</span>])</span>
<span id="cb2-4"></span>
<span id="cb2-5">ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>(-1.5121662069359054, 0.5274845352272601)</code></pre>
</div>
</div>
<ul>
<li>정상 시계열이 아님. 차분 진행</li>
</ul>
<div id="54e29262" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">diff_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.diff(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'widget_sales'</span>], n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-2"></span>
<span id="cb4-3">ADF_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(diff_df)</span>
<span id="cb4-4">ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], ADF_result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>(-10.576657780341959, 7.076922818587193e-19)</code></pre>
</div>
</div>
<div id="6ad03d2b" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.graphics.tsaplots <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plot_acf</span>
<span id="cb6-2"></span>
<span id="cb6-3">plot_acf(diff_df, lags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>)</span>
<span id="cb6-4">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/03_files/figure-html/cell-5-output-1.png" width="583" height="432" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>지연 2 이후 유의하지 않음.</li>
<li>MA(2) 진행</li>
</ul>
<div id="2568c04d" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb7-2"></span>
<span id="cb7-3">diff_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'widget_sales_diff'</span>: diff_df})</span>
<span id="cb7-4">train, test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(diff_df, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>)</span></code></pre></div>
</div>
<ul>
<li>MA(q)는 q 크기까지만 예측 가능.</li>
<li>회귀적으로 예측을 진행해야함</li>
</ul>
<div id="9566490a" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.tsa.statespace.sarimax <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SARIMAX</span>
<span id="cb8-2"></span>
<span id="cb8-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> rolling_forecast(df: pd.DataFrame, train_len: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, horizon: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, window: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>, method: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>:</span>
<span id="cb8-4">    total_len <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_len <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> horizon</span>
<span id="cb8-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> method <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mean'</span>:</span>
<span id="cb8-6">        pred_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb8-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(train_len, total_len, window):</span>
<span id="cb8-8">            mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(df[:i].values)</span>
<span id="cb8-9">            pred_mean.extend(mean <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(window))</span>
<span id="cb8-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> pred_mean</span>
<span id="cb8-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> method <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'last'</span>:</span>
<span id="cb8-12">        pred_last_value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb8-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(train_len, total_len, window):</span>
<span id="cb8-14">            last_value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.iloc[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].values[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb8-15">            pred_last_value.extend(last_value <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(window))</span>
<span id="cb8-16">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> pred_last_value</span>
<span id="cb8-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> method <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MA'</span>:</span>
<span id="cb8-18">        pred_MA <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb8-19">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(train_len, total_len, window):</span>
<span id="cb8-20">            model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> SARIMAX(df[:i], order<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))</span>
<span id="cb8-21">            res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.fit(disp<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb8-22">            predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> res.get_prediction(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> window <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb8-23">            oos_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> predictions.predicted_mean.iloc[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>window:]</span>
<span id="cb8-24">            pred_MA.extend(oos_pred)</span>
<span id="cb8-25">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> pred_MA</span></code></pre></div>
</div>
<div id="14201aa4" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">pred_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> test.copy()</span>
<span id="cb9-2">TRAIN_LEN <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train)</span>
<span id="cb9-3">HORIZON <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(test)</span>
<span id="cb9-4">WINDOW <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb9-5"></span>
<span id="cb9-6">pred_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rolling_forecast(diff_df, TRAIN_LEN, HORIZON, WINDOW, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mean'</span>)</span>
<span id="cb9-7">pred_last <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rolling_forecast(diff_df, TRAIN_LEN, HORIZON, WINDOW, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'last'</span>)</span>
<span id="cb9-8">pred_MA <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rolling_forecast(diff_df, TRAIN_LEN, HORIZON, WINDOW, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MA'</span>)</span>
<span id="cb9-9"></span>
<span id="cb9-10">pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_mean'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred_mean</span>
<span id="cb9-11">pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_last'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred_last</span>
<span id="cb9-12">pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_MA'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred_MA</span></code></pre></div>
</div>
<div id="a41a7b9a" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_widget_sales'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.Series()</span>
<span id="cb10-2">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_widget_sales'</span>].iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">450</span>:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'widget_sales'</span>].iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">450</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> pred_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_MA'</span>].cumsum()</span></code></pre></div>
</div>
<div id="33259bb3" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'widget_sales'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'실제 값'</span>)</span>
<span id="cb11-2">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_widget_sales'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'MA(2)'</span>)</span>
<span id="cb11-3">plt.xticks(</span>
<span id="cb11-4">    [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">409</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">439</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">468</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">498</span>], </span>
<span id="cb11-5">    [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Mar'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Apr'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'May'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Jun'</span>])</span>
<span id="cb11-6">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/03_files/figure-html/cell-10-output-1.png" width="583" height="430" class="figure-img"></p>
</figure>
</div>
</div>
</div>



<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a> ]]></description>
  <category>확률 통계</category>
  <category>시계열 분석</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/03.html</guid>
  <pubDate>Thu, 10 Jul 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>확률보행</title>
  <link>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02.html</link>
  <description><![CDATA[ 




<p><img src="https://cryscham123.github.io/img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="what-is-확률보행" class="level2">
<h2 class="anchored" data-anchor-id="what-is-확률보행">what is 확률보행</h2>
<ul>
<li><code>확률보행</code>: 무작위로 상승 또는 하락이 발생할 확률이 동일한 프로세스
<ul>
<li><img src="https://latex.codecogs.com/png.latex?y_t%20=%20C%20+%20y_%7Bt-1%7D%20+%20%CF%B5_t"></li>
<li>C가 0이 아닌 경우 표류가 있는 확률보행</li>
</ul></li>
</ul>
<div id="ad1058b8" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-4"></span>
<span id="cb1-5">plt.rcParams[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'font.family'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Noto Sans KR'</span></span>
<span id="cb1-6"></span>
<span id="cb1-7">steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.standard_normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb1-8">steps[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb1-9">random_walk <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.cumsum(steps)</span>
<span id="cb1-10">sns.lineplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.arange(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(random_walk)), y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>random_walk)</span>
<span id="cb1-11">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'시간'</span>)</span>
<span id="cb1-12">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'값'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>Text(0, 0.5, '값')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-2-output-2.png" width="590" height="430" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="확률보행-식별" class="level2">
<h2 class="anchored" data-anchor-id="확률보행-식별">확률보행 식별</h2>
<ul>
<li>확률보행은 <code>정상적</code>이고 <code>자기상관관계가 없는 시계열</code>로 나타난다.</li>
</ul>
<section id="정상성" class="level3">
<h3 class="anchored" data-anchor-id="정상성">정상성</h3>
<ul>
<li>시간이 지나도 통계적 특성이 변하지 않는 시계열
<ul>
<li>평균과 분산이 상수이고 자기상관관계가 있으며, 이러한 특성들이 시간에 따라 변하지 않는다.</li>
</ul></li>
<li>정상화:
<ul>
<li>평균: 차분</li>
<li>분산: 로그 변환, Box-Cox 변환 등</li>
</ul></li>
<li>정상성 검정:
<ul>
<li>ADF (Augmented Dickey-Fuller) 테스트
<ul>
<li><img src="https://latex.codecogs.com/png.latex?H_0">: 시계열에 단위근<sup>1</sup>이 존재하여 비정상적이다.</li>
<li><img src="https://latex.codecogs.com/png.latex?H_1">: 시계열에 단위근이 존재하지 않아 정상적이다.</li>
</ul></li>
</ul></li>
</ul>
<div id="fa6a622e" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.tsa.stattools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> adfuller</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> simulate_process(alpha: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> np.array:</span>
<span id="cb3-5">    process <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.empty(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">401</span>)</span>
<span id="cb3-6">    process[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb3-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>):</span>
<span id="cb3-8">        process[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> alpha <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> process[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.standard_normal()</span>
<span id="cb3-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> process</span>
<span id="cb3-10"></span>
<span id="cb3-11">stationary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> simulate_process(alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb3-12">non_stationary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> simulate_process(alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-13"></span>
<span id="cb3-14">sns.lineplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.arange(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(stationary)), y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>stationary, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'정상성 프로세스'</span>)</span>
<span id="cb3-15">sns.lineplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.arange(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(non_stationary)), y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>non_stationary, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'비정상성 프로세스'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-3-output-1.png" width="572" height="415" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="e83bbb23" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> mean_var_over_time(process: np.array) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> np.array:</span>
<span id="cb4-2">    means <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb4-3">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">vars</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb4-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(process)):</span>
<span id="cb4-5">        means.append(np.mean(process[:i]))</span>
<span id="cb4-6">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">vars</span>.append(np.var(process[:i]))</span>
<span id="cb4-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> means, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">vars</span></span>
<span id="cb4-8"></span>
<span id="cb4-9">means_stationary, vars_stationary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_var_over_time(stationary)</span>
<span id="cb4-10">means_non_stationary, vars_non_stationary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_var_over_time(non_stationary)</span>
<span id="cb4-11"></span>
<span id="cb4-12">sns.lineplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.arange(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(means_stationary)), y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>means_stationary, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'정상성 평균'</span>)</span>
<span id="cb4-13">sns.lineplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.arange(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(means_non_stationary)), y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>means_non_stationary, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'비정상성 평균'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-4-output-1.png" width="583" height="412" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="11a3d38d" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">sns.lineplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.arange(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(vars_stationary)), y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>vars_stationary, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'정상성 분산'</span>)</span>
<span id="cb5-2">sns.lineplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.arange(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(vars_non_stationary)), y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>vars_non_stationary, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'비정상성 분산'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-5-output-1.png" width="564" height="412" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="757a5cb0" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">result1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(stationary)</span>
<span id="cb6-2">result2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(non_stationary)</span>
<span id="cb6-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'ADF Statistic: 정상성: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result1[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, 비정상성: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result2[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span>
<span id="cb6-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'p-value: 정상성: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result1[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, 비정상성: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result2[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>ADF Statistic: 정상성: -10.182654946345801, 비정상성: -2.2791893442991604
p-value: 정상성: 6.632269182398948e-18, 비정상성: 0.17876768439598817</code></pre>
</div>
</div>
</section>
<section id="자기상관관계" class="level3">
<h3 class="anchored" data-anchor-id="자기상관관계">자기상관관계</h3>
<ul>
<li>자기 상관관계: 시계열의 선행값과 후행값 아이의 선형관계
<ul>
<li>x: 지연 (<img src="https://latex.codecogs.com/png.latex?y_t,%20y_%7Bt-2%7D">의 경우 지연 2)</li>
<li>y: 계수</li>
</ul></li>
<li>추세가 있는 경우: 짧은 지연에서 계수가 높고, 지연이 커질수록 계수가 낮아지는 경향</li>
<li>계절성이 있는 경우: 주기적인 패턴이 나타남.</li>
</ul>
<div id="d3648072" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> statsmodels.graphics.tsaplots <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> plot_acf</span>
<span id="cb8-2"></span>
<span id="cb8-3">plot_acf(non_stationary, lags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-7-output-1.png" width="583" height="432" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-7-output-2.png" width="583" height="432" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>비정상적 시계열에서 추세가 보인다. 차분을 진행해보자.</li>
</ul>
<div id="95126a88" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.diff(non_stationary, n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb9-2"></span>
<span id="cb9-3">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(diff)</span>
<span id="cb9-4">result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>(-19.871934314399926, 0.0)</code></pre>
</div>
</div>
<div id="80dbb7be" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">plot_acf(diff, lags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-9-output-1.png" width="583" height="432" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-9-output-2.png" width="583" height="432" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="예시" class="level2">
<h2 class="anchored" data-anchor-id="예시">예시</h2>
<div id="9b70c5e3" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb12-2"></span>
<span id="cb12-3">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_data/googl.csv'</span>)</span>
<span id="cb12-4">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Date'</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Close'</span>)</span>
<span id="cb12-5"></span>
<span id="cb12-6">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'날짜'</span>)</span>
<span id="cb12-7">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'종가'</span>)</span>
<span id="cb12-8"></span>
<span id="cb12-9">plt.xticks([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">24</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">46</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">68</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">89</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">110</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">132</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">152</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">174</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">193</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">212</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">235</span>],</span>
<span id="cb12-10">           [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'May'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Jun'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Jul'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Aug'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Sep'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Oct'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Nov'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Dec'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Jan'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feb'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Mar'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Apr'</span>],</span>
<span id="cb12-11">           rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">45</span>)</span>
<span id="cb12-12">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-10-output-1.png" width="598" height="444" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="0a6d651d" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Close'</span>])</span>
<span id="cb13-2"></span>
<span id="cb13-3">result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>(0.16025048664771407, 0.9699419435913058)</code></pre>
</div>
</div>
<div id="417fe7e1" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.diff(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Close'</span>], n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb15-2"></span>
<span id="cb15-3">result_diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> adfuller(diff)</span>
<span id="cb15-4">result_diff[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], result_diff[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>(-5.303439704295227, 5.386530961454778e-06)</code></pre>
</div>
</div>
<div id="733884c2" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">plot_acf(diff, lags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-13-output-1.png" width="583" height="432" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-13-output-2.png" width="583" height="432" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="확류보행-예측" class="level2">
<h2 class="anchored" data-anchor-id="확류보행-예측">확류보행 예측</h2>
<div id="ed517e6e" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>: random_walk})</span>
<span id="cb18-2">train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.iloc[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">800</span>]</span>
<span id="cb18-3">test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">800</span>:]</span>
<span id="cb18-4"></span>
<span id="cb18-5">mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.mean(train[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>])</span>
<span id="cb18-6">test[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_mean'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean</span>
<span id="cb18-7"></span>
<span id="cb18-8">last_value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train.iloc[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>]</span>
<span id="cb18-9">test[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_last'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> last_value</span></code></pre></div>
</div>
<section id="표류-기법" class="level3">
<h3 class="anchored" data-anchor-id="표류-기법">표류 기법</h3>
<div id="22d75af6" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">drift <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (train.iloc[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> train.iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(train) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb19-2">drift</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>-0.0073114182124709975</code></pre>
</div>
</div>
<div id="aa1d2d30" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">x_vals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">801</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1001</span>)</span>
<span id="cb21-2">pred_drift <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> drift <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> x_vals</span>
<span id="cb21-3">test[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_drift'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pred_drift</span>
<span id="cb21-4">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>df.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>)</span>
<span id="cb21-5">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_mean'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'평균 예측'</span>)</span>
<span id="cb21-6">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_last'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'마지막 값 예측'</span>)</span>
<span id="cb21-7">sns.lineplot(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>test.index, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_drift'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'표류 예측'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-16-output-1.png" width="590" height="430" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="e7f01675" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mean_squared_error</span>
<span id="cb22-2"></span>
<span id="cb22-3">mse_mean <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(test[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>], test[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_mean'</span>])</span>
<span id="cb22-4">mse_last <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(test[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>], test[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_last'</span>])</span>
<span id="cb22-5">mse_drift <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(test[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>], test[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pred_drift'</span>])</span>
<span id="cb22-6"></span>
<span id="cb22-7">sns.barplot(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'평균'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'마지막 값'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'표류'</span>], y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[mse_mean, mse_last, mse_drift])</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02_files/figure-html/cell-17-output-1.png" width="572" height="412" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="단순-예측법" class="level3">
<h3 class="anchored" data-anchor-id="단순-예측법">단순 예측법</h3>
<div id="069530f1" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">df_shift <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.shift(periods<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb23-2">mse_one_step <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean_squared_error(test[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>], df_shift[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'value'</span>].iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">800</span>:])</span>
<span id="cb23-3">mse_one_step</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>1.0373151143278658</code></pre>
</div>
</div>


</section>
</section>


<a onclick="window.scrollTo(0, 0); return false;" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a><div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">각주</h2>

<ol>
<li id="fn1"><p><img src="https://latex.codecogs.com/png.latex?y_t%20=%20C%20+%20%CE%B1y_%7Bt-1%7D%20+%20%CF%B5_t"> 형태의 시계열로, α가 1보다 작은 경우, 과거의 값이 현재 값에 미치는 영향이 작아져 시계열이 정상적이다.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>확률 통계</category>
  <category>시계열 분석</category>
  <guid>https://cryscham123.github.io/posts/01_projects/adp_실기/notes/time_series/02.html</guid>
  <pubDate>Tue, 08 Jul 2025 15:00:00 GMT</pubDate>
</item>
</channel>
</rss>
