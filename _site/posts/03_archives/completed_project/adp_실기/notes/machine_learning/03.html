<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="ko" xml:lang="ko"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>분류 - 산탄데르 고객 만족 예측 – 김형훈의 학습 블로그</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../../../site_libs/quarto-nav/headroom.min.js"></script>
<link href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/04.html" rel="next">
<link href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/02.html" rel="prev">
<link href="../../../../../../favicon" rel="icon">
<script src="../../../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "language": {
    "search-no-results-text": "일치 없음",
    "search-matching-documents-text": "일치된 문서",
    "search-copy-link-title": "검색 링크 복사",
    "search-hide-matches-text": "추가 검색 결과 숨기기",
    "search-more-match-text": "추가 검색결과",
    "search-more-matches-text": "추가 검색결과",
    "search-clear-button-title": "제거",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "취소",
    "search-submit-button-title": "검색",
    "search-label": "검색"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-GRXCD70RKK"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
 
  gtag('consent', 'default', {
    'ad_storage': 'denied',
    'analytics_storage': 'denied'
  });
gtag('config', 'G-GRXCD70RKK', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdn.jsdelivr.net/npm/@mariusbongarts/previewbox/dist/link/index.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../../../../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../../../index.html">
    <span class="navbar-title">김형훈의 학습 블로그</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="탐색 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../../all.html"> 
<span class="menu-text">전체 게시글</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="사이드바 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Archives</li><li class="breadcrumb-item"><a href="../../../../../../posts/03_archives/completed_project/tofel_준비/index.html">Completed Project</a></li><li class="breadcrumb-item"><a href="../../../../../../posts/03_archives/completed_project/adp_실기/index.html">ADP 실기 준비 - try 1</a></li><li class="breadcrumb-item"><a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/01.html">Notes</a></li><li class="breadcrumb-item"><a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/01.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/03.html">분류 - 산탄데르 고객 만족 예측</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="사이드바 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Projects</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/01_projects/정보처리기사/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">정보처리기사</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/01_projects/toeic/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Toeic 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/01_projects/toeic/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Toeic 문법</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/01_projects/진로준비/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">진로 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">금융</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/01_projects/진로준비/notes/금융/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">관심 분야 JD</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">대학원</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/01_projects/진로준비/notes/대학원/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">관심 분야 JD</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/01_projects/진로준비/notes/대학원/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">연구실</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/01_projects/진로준비/notes/대학원/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">대학원 준비</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/01_projects/진로준비/notes/대학원/03.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">자기소개서</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Categories</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/02_categories/deep_learning/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false">
 <span class="menu-text">Basic</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/deep_learning/notes/basic/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">퍼셉트론</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/deep_learning/notes/basic/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">신경망</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/deep_learning/notes/basic/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">신경망 학습</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/deep_learning/notes/basic/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">오차역전법</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/deep_learning/notes/basic/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">학습 관련 기술들</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/deep_learning/notes/basic/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">합성곱 신경망</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/deep_learning/notes/basic/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">자연어와 단어의 분산 표현</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/deep_learning/notes/basic/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">word2vec</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">Pytorch</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/deep_learning/notes/pytorch/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">pytorch 기초</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">Time Series</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/deep_learning/notes/time_series/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/deep_learning/notes/time_series/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">data windowing &amp; baseline modeling</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/02_categories/42_seoul/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">42 Seoul</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/42_seoul/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ft_transcendence - github action</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/42_seoul/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">inception-of-things part 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/42_seoul/notes/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">cloud-1 개념 설명</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/42_seoul/notes/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">cloud-1 코드 설명</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/02_categories/machine_learning/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-16" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-17" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-17" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">data preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simple Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Polynorminal Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Tree Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">random forest</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Logistic Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">K Nearest Neighbors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support Vector Machine</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Naive Bayes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Decision Tree Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random Forest</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">k-means clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">hierarchical clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Apriori</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/17.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Eclat</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/02_categories/machine_learning/notes/18.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Upper Confidence Bound</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="true">
 <span class="menu-text">Archives</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-18" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-18" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="true">
 <span class="menu-text">Completed Project</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-19" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-19" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/tofel_준비/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">TOFEL 준비</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/completed_project/sqld/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SQLD 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-20" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-20" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-21" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-21" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-21" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/sqld/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">데이터 모델의 이해</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/sqld/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SQL 기본 및 활용</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/completed_project/adp_필기/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ADP 필기 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-22" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-22" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-23" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-23" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-23" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 - 데이터 이해</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 - 데이터의 가치와 미래</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 - 가치 창조를 위한 데이터 사이언스와 전략 인사이트</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 - 데이터 처리 프로세스</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 - 데이터 처리 기술</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 - 데이터 분석 기획의 이해</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 - 분석 마스터 플랜</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - 데이터 마트</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - 통계분석</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - 정형 데이터 마이닝</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - 비정형 데이터 마이닝</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5 - 시각화 인사이트 프로세스</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5 - 시각화 디자인</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">시험을 보고 왔습니다.</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_필기/notes/16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">안녕하세요. 데이터 분석 전문가(진)입니다.</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/completed_project/opic/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OPIc 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-24" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-24" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-25" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-25" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-25" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/opic/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">오픽 구조 파악</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/opic/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">설문 script 정리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/opic/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Tips</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/opic/notes/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">일정 정리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/opic/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">돌발 script 정리</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">학부 3학년 1학기</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-26" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-26" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-27" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-27" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-27" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3학년 1학기 후기</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-28" role="navigation" aria-expanded="false">
 <span class="menu-text">Computer</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-28" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-28" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/computer/01.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">컴퓨팅적 사고 1차 발표 구현 raw script</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/computer/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">컴퓨팅적사고 발표 ppt</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-29" role="navigation" aria-expanded="false">
 <span class="menu-text">Data Mining</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-29" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-29" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">데이터 전처리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분류</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">random forest</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Support vector machine</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">association rule mining</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">clustering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ensemble</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">XGBoost</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/11.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">데이터마이닝 1차 팀과제 script</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dataminig 1차 발표 ppt</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">classification with trees</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">preprocessing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/data_mining/16.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">청소년기의 심리·정서적 요인을 통한 성인 진입기 진로 안정형·탐색형 성향 분류 예측</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-30" role="navigation" aria-expanded="false">
 <span class="menu-text">Dsa</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-30" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-30" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/dsa/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">시험 범위</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/dsa/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">시험 범위</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-31" role="navigation" aria-expanded="false">
 <span class="menu-text">OR</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-31" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-31" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simplex 표 계산</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear Programming Algorithm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simplex Method (part 5)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">쌍대이론과 민감도 분석 (part 6)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/06.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OR 과제 - 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/07.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OR 과제 - 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/08.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OR 과제 - 3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/09.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OR 과제 - 4</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">선형계획을 위한 다른 알고리즘들</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">수송문제와 할당 문제들</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/12.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OR 과제 - 6</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">시험 범위</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">수송문제와 할당 문제들</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/OR/16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">네트워크 최적화 모형</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-32" role="navigation" aria-expanded="false">
 <span class="menu-text">Others</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-32" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-32" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/others/1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">자기 소개서</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/others/2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">성적 장학금</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/others/3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">봉사</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-33" role="navigation" aria-expanded="false">
 <span class="menu-text">Product</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-33" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-33" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Matching Supply with Demand</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">조직을 프로세스 관점에서 바라보기</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">공급 프로세스의 이해: 프로세스 처리능력 평가</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">제품 설계 기법 및 기업 프로세스 유형</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">인건비 추정과 감축</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">배치 생산 및 경제적 주문량 모형</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">프로세스 성과에 미치는 변동성의 영향: 대기시간 문제</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">프로세스 성과에 미치는 변동성의 영향: 산술 손실</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">프로젝트 관리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">예측</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">총괄생산계획</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">기준생산계획 및 자재소요계획</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/product/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">일정 계획</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-34" role="navigation" aria-expanded="false">
 <span class="menu-text">Statistics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-34" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-34" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/statistics/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률과 통계 1 정리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/statistics/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">통계적 추정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/statistics/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">통계적 가설검정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/statistics/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ANOVA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/statistics/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regression Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/statistics/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analysis of categorical data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_1/notes/statistics/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률과 통계 R 실습 과제</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/completed_project/adp_실기/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ADP 실기 준비 - try 1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-35" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-35" class="collapse list-unstyled sidebar-section depth3 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-36" role="navigation" aria-expanded="true">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-36" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-36" class="collapse list-unstyled sidebar-section depth4 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">모델링, 평가 템플릿</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA 템플릿</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">전처리 템플릿</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">회귀분석 템플릿</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분산 분석 템플릿</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">비지도 학습 템플릿</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">시계열 분석</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">기타</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률과 통계</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">try 1 후기</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">결과</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-37" role="navigation" aria-expanded="false">
 <span class="menu-text">Bayse</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-37" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-37" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">베이즈 정리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">비율 추정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">수량 추정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">공산과 가산</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">최솟값, 최댓값 그리고 혼합 분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">포아송 과정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">의사결정분석</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">검정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">비교</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분류</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">로지스틱 회귀</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">회귀</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/17.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">켤레사전분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/bayse/18.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">MCMC</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-38" role="navigation" aria-expanded="false">
 <span class="menu-text">Core</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-38" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-38" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/core/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/core/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">전처리</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-39" role="navigation" aria-expanded="false">
 <span class="menu-text">Etc</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-39" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-39" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/etc/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">다차원 척도법 (Multidimensional Scaling)</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-40" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-40" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-40" class="collapse list-unstyled sidebar-section depth5 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분류 - 결정 트리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분류 - 앙상블</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/03.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">분류 - 산탄데르 고객 만족 예측</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">분류 - 신용 카드 사기 검출</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">회귀</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">차원 축소</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">텍스트 분석</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">텍스트 분석 - 20 뉴스그룹 분류</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">텍스트 분석 - 감성 분석</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-41" role="navigation" aria-expanded="false">
 <span class="menu-text">Nonparametric</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-41" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-41" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/Nonparametric/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">intro</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/Nonparametric/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">순열검정과 전통적인 비모수통계</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/Nonparametric/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">두 변수의 연관성과 독립성</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-42" role="navigation" aria-expanded="false">
 <span class="menu-text">Statistics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-42" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-42" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/statistics/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EDA</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-43" role="navigation" aria-expanded="false">
 <span class="menu-text">Time Series</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-43" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-43" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/time_series/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/time_series/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">단순 미래 예측</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/time_series/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률보행</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/time_series/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">이동평균과정 모델링</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/time_series/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">자기귀모형</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/time_series/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">복잡한 시계열 모델</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/time_series/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">계절성 고려</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/time_series/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">외생 변수 추가하기</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">학부 3학년 2학기</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-44" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-44" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-45" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-45" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-45" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-46" role="navigation" aria-expanded="false">
 <span class="menu-text">Cte</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-46" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-46" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/cte/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Could Quantum Computing be the Next Paradigm Shift Soon?</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-47" role="navigation" aria-expanded="false">
 <span class="menu-text">공급사슬관리</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-47" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-47" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/공급사슬관리/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SCM 의사결정</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/공급사슬관리/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">수요 관리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/공급사슬관리/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">S&amp;OP: Sales and Operations Planning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/공급사슬관리/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">재고 관리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/공급사슬관리/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">재고 관리 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/공급사슬관리/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">채찍 효과</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/공급사슬관리/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">공급사슬 의사결정의 조정과 계약</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/공급사슬관리/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">공급사슬 네트워크 설계</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/공급사슬관리/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">운송 및 창고관리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/공급사슬관리/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">블록체인기술의 SCM</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-48" role="navigation" aria-expanded="false">
 <span class="menu-text">기공수</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-48" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-48" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/기공수/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">무한 급수</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/기공수/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">테일러 급수</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/기공수/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">기말</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-49" role="navigation" aria-expanded="false">
 <span class="menu-text">시뮬레이션</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-49" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-49" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/시뮬레이션/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Intro</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/시뮬레이션/01.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">cheat seet</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/시뮬레이션/02.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">cheat seet</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/시뮬레이션/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">반도체 공정 시뮬레이션</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-50" role="navigation" aria-expanded="false">
 <span class="menu-text">신재생에너지</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-50" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-50" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/신재생에너지/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">개인 발표 - 공짜 탄소배출권 발급 사건</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-51" role="navigation" aria-expanded="false">
 <span class="menu-text">품질경영</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-51" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-51" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/품질경영/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">품질관리의 기본개념</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/품질경영/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">품질변동과 공정능력</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/품질경영/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">관리도</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/품질경영/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">샘플링 검사법</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/품질경영/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">신뢰도 공학</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-52" role="navigation" aria-expanded="false">
 <span class="menu-text">프로세스경영</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-52" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-52" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/프로세스경영/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">프로세스 경영 개요</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/프로세스경영/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BPM 개요</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/프로세스경영/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">프로세스 경영 구축 방법론</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/프로세스경영/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BPM 표준</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/프로세스경영/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">프로세스 모델링 표준: WS-BPEL</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/프로세스경영/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BPMN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/프로세스경영/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DMN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/프로세스경영/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BPM Suite</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/프로세스경영/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Process mining</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/프로세스경영/11.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">주제 제안</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/프로세스경영/12.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5조 기말과제 제안서</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_3_2/notes/프로세스경영/13.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Automation 시연</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/completed_project/aws_saa/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AWS SAA 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-53" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-53" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-54" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-54" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-54" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/00_region.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">aws global infrastructure</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/01_IAM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Define IAM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/02_ec2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">what is EC2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/03_ebs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">what is ebs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/04_elb_asg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ELB</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/05_RDS_aurora_elasticCache.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Amazon RDS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/06_route53.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Route53</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/07_S3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AWS S3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/08_cloudfront.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CloudFront</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/09_aws_storage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AWS Snow Family</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/10_message_queue.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AWS SQS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/11_serverless.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AWS Lambda</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/12_database.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">database choice in aws</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/13_data_analytics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Performance Improvement</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/14_machine_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Amazon Rekognition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/15_monitoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Amazon CloudWatch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/16_IAM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AWS Organization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/17_AWS_secure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KMS(Key Management Service)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/18_VPC.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">VPC</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/aws_saa/notes/19_DR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Disaster Recovery(DR)</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2학년 2학기 학부 정리</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-55" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-55" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-56" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-56" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-56" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-57" role="navigation" aria-expanded="false">
 <span class="menu-text">Bs Database</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-57" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-57" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_database/01-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">An Overview of Database</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_database/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Relational Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_database/04-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Database Normalization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_database/04-2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SQL</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_database/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Modeling and the Entity-Relationship Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_database/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Database Design</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_database/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Database Administration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_database/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ASP.NET</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_database/work1.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">데이터베이스설계및활용 개인과제 #2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_database/work2.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4조 기말과제 제안서</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_database/work4.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">숭실대학교 학생식당 식자제 SCM 설계</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-58" role="navigation" aria-expanded="false">
 <span class="menu-text">Bs Human</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-58" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-58" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_human/0_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Human Factors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_human/1_reaserch_method.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Research Method in Human Factors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_human/2_human_information_processing_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Human Information Processing Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_human/3_sensory_system.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sensor System (Visual)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_human/4_Auditory_Haptic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Auditory Haptic</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_human/5_signal_detction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Signal Detection Theory</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_human/6_attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Attention</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_human/7_display.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Display</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_human/8_control.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Control</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_human/인간공학-보고서-초안.pdf" class="sidebar-item-text sidebar-link">
 <span class="menu-text">맥도날드 키오스크 UI 개선 보고서</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-59" role="navigation" aria-expanded="false">
 <span class="menu-text">Bs Statistics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-59" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-59" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_statistics/1-통계학의-개념.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률과 통계의 정의</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_statistics/2-확률변수와-분포.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률변수와 확률분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_statistics/3-확률변수의-기댓값.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">확률변수의 기댓값</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_statistics/4-이산형 확률분포.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">이산형 확률분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_statistics/5-연속형-확률분포.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">연속형 확률분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_statistics/6-정규분포.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">정규 분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_statistics/7-표본의-분포.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">표본의 분포</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/bs_2_2/notes/bs_statistics/8-central-limit-theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">중심 극한 정리</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/completed_project/toeic_speaking/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">토익 스피킹 준비</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-60" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-60" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-61" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-61" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-61" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/completed_project/toeic_speaking/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">토익 스피킹 후기</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-62" role="navigation" aria-expanded="false">
 <span class="menu-text">Stored Categories</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-62" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-62" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/problem_solve/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Problem Solving</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/blog/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blog</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-63" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-63" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-64" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-64" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-64" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/blog/notes/0.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PARA Blog 제작</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/blog/notes/1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Second Brain - 티아고 포르테</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/hadoop/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hadoop</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-65" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-65" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-66" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-66" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-66" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/hadoop/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hadoop Ecosystem</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/vault/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">vault</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-67" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-67" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-68" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-68" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-68" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/vault/notes/0_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/kaggle/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Kaggle</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-69" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-69" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-70" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-70" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-70" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-71" role="navigation" aria-expanded="false">
 <span class="menu-text">Titanic</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-71" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-71" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/kaggle/notes/titanic/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">titanic</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/선형대수/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">선형대수</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-72" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-72" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-73" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-73" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-73" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">what is linear algebra</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2-기초(1)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2-기초(2)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3-몰라</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">벡터와 공간</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">선형결합과 생성</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">linear independence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Subspaces and the basis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">vector dot product, cross product</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">가감법으로 연립방정식을 풀기 위한 행렬</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Null space and Column space</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">linear transformations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">역함수와 역변환</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/선형대수/notes/13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">전치행렬</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/인생/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">인생</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-74" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-74" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-75" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-75" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-75" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/인생/notes/02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">나의 단점에 관한 고찰</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/helm/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Helm</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-76" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-76" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-77" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-77" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-77" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/helm/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">개요</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/terraform/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Terraform</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-78" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-78" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-79" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-79" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-79" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-80" role="navigation" aria-expanded="false">
 <span class="menu-text">Tfc</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-80" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-80" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/terraform/notes/tfc/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Terraform Cloud</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/k8s/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">k8s</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-81" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-81" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-82" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-82" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-82" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/k8s/notes/0_core_concept.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">k8s cluster architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/k8s/notes/1_scheduler.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">manual scheduling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/k8s/notes/2_logging_monitoring.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">metrics server</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/k8s/notes/3_cluster_maintainance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">fail tolerance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/k8s/notes/4_security.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Authentication</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/k8s/notes/5_storage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Persistant volume</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/k8s/notes/6_network.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">core DNS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/k8s/notes/7_design_cluster.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">HA in master node</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/air_flow/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AirFlow</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-83" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-83" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-84" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-84" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-84" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/air_flow/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/air_flow/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Coding pipeline</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/smart_contract/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Smart Contract</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-85" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-85" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-86" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-86" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-86" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-87" role="navigation" aria-expanded="false">
 <span class="menu-text">Block Chain Basic</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-87" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-87" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/smart_contract/notes/block_chain_basic/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">what is a blockchain?</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/금융/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">금융</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-88" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-88" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-89" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-89" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-89" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/금융/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">돈의 심리학 - 모건 하우절</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/ros/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ROS</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-90" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-90" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-91" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-91" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-91" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/ros/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/quantum_programming/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantum Programming</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-92" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-92" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-93" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-93" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-93" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/quantum_programming/notes/00.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantum Programming</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/quantum_programming/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Qiskit</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../../../posts/03_archives/stored_categories/독서/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">독서</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-94" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-94" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-95" role="navigation" aria-expanded="false">
 <span class="menu-text">Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-95" role="navigation" aria-expanded="false" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-95" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../../../posts/03_archives/stored_categories/독서/notes/01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">인간 관계론 - 데일 카네기</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of Contents</h2>
   
  <ul>
  <li><a href="#preprocessing" id="toc-preprocessing" class="nav-link active" data-scroll-target="#preprocessing">Preprocessing</a></li>
  <li><a href="#xgboost" id="toc-xgboost" class="nav-link" data-scroll-target="#xgboost">XGBoost</a>
  <ul class="collapse">
  <li><a href="#베이지안-최적화" id="toc-베이지안-최적화" class="nav-link" data-scroll-target="#베이지안-최적화">베이지안 최적화</a></li>
  <li><a href="#재-학습" id="toc-재-학습" class="nav-link" data-scroll-target="#재-학습">재 학습</a></li>
  <li><a href="#plot-importance" id="toc-plot-importance" class="nav-link" data-scroll-target="#plot-importance">plot importance</a></li>
  </ul></li>
  <li><a href="#lightgbm" id="toc-lightgbm" class="nav-link" data-scroll-target="#lightgbm">LightGBM</a>
  <ul class="collapse">
  <li><a href="#베이지안-최적화-1" id="toc-베이지안-최적화-1" class="nav-link" data-scroll-target="#베이지안-최적화-1">베이지안 최적화</a></li>
  <li><a href="#재학습" id="toc-재학습" class="nav-link" data-scroll-target="#재학습">재학습</a></li>
  </ul></li>
  <li><a href="#제출" id="toc-제출" class="nav-link" data-scroll-target="#제출">제출</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Archives</li><li class="breadcrumb-item"><a href="../../../../../../posts/03_archives/completed_project/tofel_준비/index.html">Completed Project</a></li><li class="breadcrumb-item"><a href="../../../../../../posts/03_archives/completed_project/adp_실기/index.html">ADP 실기 준비 - try 1</a></li><li class="breadcrumb-item"><a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/01.html">Notes</a></li><li class="breadcrumb-item"><a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/01.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/03.html">분류 - 산탄데르 고객 만족 예측</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">분류 - 산탄데르 고객 만족 예측</h1>
  <div class="quarto-categories">
    <div class="quarto-category">머신 러닝</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">공개</div>
    <div class="quarto-title-meta-contents">
      <p class="date">2025년 7월 27일</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p><img src="../../../../../../img/stat-thumb.jpg" class="post-thumbnail img-fluid"></p>
<section id="preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="preprocessing">Preprocessing</h2>
<div id="30c7f328" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'font.family'</span>] <span class="op">=</span> <span class="st">'Noto Sans KR'</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'_data/santander/train.csv'</span>, encoding<span class="op">=</span><span class="st">'latin-1'</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 76020 entries, 0 to 76019
Columns: 371 entries, ID to TARGET
dtypes: float64(111), int64(260)
memory usage: 215.2 MB</code></pre>
</div>
</div>
<div id="2847c582" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df.describe()</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">ID</th>
<th data-quarto-table-cell-role="th">var3</th>
<th data-quarto-table-cell-role="th">var15</th>
<th data-quarto-table-cell-role="th">imp_ent_var16_ult1</th>
<th data-quarto-table-cell-role="th">imp_op_var39_comer_ult1</th>
<th data-quarto-table-cell-role="th">imp_op_var39_comer_ult3</th>
<th data-quarto-table-cell-role="th">imp_op_var40_comer_ult1</th>
<th data-quarto-table-cell-role="th">imp_op_var40_comer_ult3</th>
<th data-quarto-table-cell-role="th">imp_op_var40_efect_ult1</th>
<th data-quarto-table-cell-role="th">imp_op_var40_efect_ult3</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">saldo_medio_var33_hace2</th>
<th data-quarto-table-cell-role="th">saldo_medio_var33_hace3</th>
<th data-quarto-table-cell-role="th">saldo_medio_var33_ult1</th>
<th data-quarto-table-cell-role="th">saldo_medio_var33_ult3</th>
<th data-quarto-table-cell-role="th">saldo_medio_var44_hace2</th>
<th data-quarto-table-cell-role="th">saldo_medio_var44_hace3</th>
<th data-quarto-table-cell-role="th">saldo_medio_var44_ult1</th>
<th data-quarto-table-cell-role="th">saldo_medio_var44_ult3</th>
<th data-quarto-table-cell-role="th">var38</th>
<th data-quarto-table-cell-role="th">TARGET</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>...</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>76020.000000</td>
<td>7.602000e+04</td>
<td>76020.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>75964.050723</td>
<td>-1523.199277</td>
<td>33.212865</td>
<td>86.208265</td>
<td>72.363067</td>
<td>119.529632</td>
<td>3.559130</td>
<td>6.472698</td>
<td>0.412946</td>
<td>0.567352</td>
<td>...</td>
<td>7.935824</td>
<td>1.365146</td>
<td>12.215580</td>
<td>8.784074</td>
<td>31.505324</td>
<td>1.858575</td>
<td>76.026165</td>
<td>56.614351</td>
<td>1.172358e+05</td>
<td>0.039569</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>43781.947379</td>
<td>39033.462364</td>
<td>12.956486</td>
<td>1614.757313</td>
<td>339.315831</td>
<td>546.266294</td>
<td>93.155749</td>
<td>153.737066</td>
<td>30.604864</td>
<td>36.513513</td>
<td>...</td>
<td>455.887218</td>
<td>113.959637</td>
<td>783.207399</td>
<td>538.439211</td>
<td>2013.125393</td>
<td>147.786584</td>
<td>4040.337842</td>
<td>2852.579397</td>
<td>1.826646e+05</td>
<td>0.194945</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>1.000000</td>
<td>-999999.000000</td>
<td>5.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>5.163750e+03</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>38104.750000</td>
<td>2.000000</td>
<td>23.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>6.787061e+04</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>76043.000000</td>
<td>2.000000</td>
<td>28.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.064092e+05</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>113748.750000</td>
<td>2.000000</td>
<td>40.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.187563e+05</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>151838.000000</td>
<td>238.000000</td>
<td>105.000000</td>
<td>210000.000000</td>
<td>12888.030000</td>
<td>21024.810000</td>
<td>8237.820000</td>
<td>11073.570000</td>
<td>6600.000000</td>
<td>6600.000000</td>
<td>...</td>
<td>50003.880000</td>
<td>20385.720000</td>
<td>138831.630000</td>
<td>91778.730000</td>
<td>438329.220000</td>
<td>24650.010000</td>
<td>681462.900000</td>
<td>397884.300000</td>
<td>2.203474e+07</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

<p>8 rows × 371 columns</p>
</div>
</div>
</div>
<div id="86d1cfd8" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'var3'</span>].replace(<span class="op">-</span><span class="dv">999999</span>, <span class="dv">2</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>df.drop(<span class="st">'ID'</span>, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>X_features <span class="op">=</span> df.iloc[:, :<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> df.iloc[:, <span class="op">-</span><span class="dv">1</span>]</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1b6dbbee" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> pd.read_csv(<span class="st">'_data/santander/test.csv'</span>, encoding<span class="op">=</span><span class="st">'latin-1'</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>test_df[<span class="st">'var3'</span>].replace(<span class="op">-</span><span class="dv">999999</span>, <span class="dv">2</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>test_df.drop(<span class="st">'ID'</span>, axis<span class="op">=</span><span class="dv">1</span>, inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="d4714bf3" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X_features, labels, test_size<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>train, test의 label의 비율이 동일한게 좋은걸까</li>
</ul>
</section>
<section id="xgboost" class="level2">
<h2 class="anchored" data-anchor-id="xgboost">XGBoost</h2>
<div id="b5e6ed7d" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>X_tr, X_val, y_tr, y_val <span class="op">=</span> train_test_split(X_train, y_train, test_size<span class="op">=</span><span class="fl">0.3</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="78fd7b83" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>evals <span class="op">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>xgb_clf <span class="op">=</span> XGBClassifier(n_estimators<span class="op">=</span><span class="dv">400</span>, </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                    learning_rate<span class="op">=</span><span class="fl">0.05</span>, </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>                    early_stopping_rounds<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>                    eval_metric<span class="op">=</span>[<span class="st">'auc'</span>])</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>xgb_clf.fit(X_tr, y_tr, eval_set<span class="op">=</span>evals, verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>xgb_roc_score <span class="op">=</span> roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, <span class="dv">1</span>])</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>xgb_roc_score<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="베이지안-최적화" class="level3">
<h3 class="anchored" data-anchor-id="베이지안-최적화">베이지안 최적화</h3>
<div id="27c21265" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective_func(search_space):</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    xgb_clf <span class="op">=</span> XGBClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>                            early_stopping_rounds<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>                            eval_metric<span class="op">=</span><span class="st">'auc'</span>,</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>                            max_depth<span class="op">=</span><span class="bu">int</span>(search_space[<span class="st">'max_depth'</span>]),</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>                            min_child_weight<span class="op">=</span><span class="bu">int</span>(search_space[<span class="st">'min_child_weight'</span>]),</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>                            colsample_bytree<span class="op">=</span>search_space[<span class="st">'colsample_bytree'</span>],</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>                            learning_rate<span class="op">=</span>search_space[<span class="st">'learning_rate'</span>])</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    roc_auc_list <span class="op">=</span> []</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tr_index, val_index <span class="kw">in</span> kf.split(X_train):</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        X_tr, y_tr <span class="op">=</span> X_train.iloc[tr_index], y_train.iloc[tr_index]</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        X_val, y_val <span class="op">=</span>  X_train.iloc[val_index], y_train.iloc[val_index]</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        xgb_clf.fit(X_tr, y_tr, eval_set<span class="op">=</span>[(X_tr, y_tr), (X_val, y_val)])</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, <span class="dv">1</span>])</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        roc_auc_list.append(score)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span> <span class="op">*</span> np.mean(roc_auc_list)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="73547293" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hyperopt <span class="im">import</span> hp, fmin, tpe, Trials</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>xgb_search_space <span class="op">=</span> {</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">'max_depth'</span>: hp.quniform(<span class="st">'max_depth'</span>, <span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">1</span>),</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">'min_child_weight'</span>: hp.quniform(<span class="st">'min_child_weight'</span>, <span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">1</span>),</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">'colsample_bytree'</span>: hp.uniform(<span class="st">'colsample_bytree'</span>, <span class="fl">0.5</span>, <span class="fl">0.95</span>),</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">'learning_rate'</span>: hp.uniform(<span class="st">'learning_rate'</span>, <span class="fl">0.01</span>, <span class="fl">0.2</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>trials <span class="op">=</span> Trials()</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>best <span class="op">=</span> fmin(fn<span class="op">=</span>objective_func,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>            space<span class="op">=</span>xgb_search_space,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>            algo<span class="op">=</span>tpe.suggest,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>            max_evals<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>            trials<span class="op">=</span>trials)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="재-학습" class="level3">
<h3 class="anchored" data-anchor-id="재-학습">재 학습</h3>
<div id="77a10666" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBClassifier</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>evals <span class="op">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>xgb_clf <span class="op">=</span> XGBClassifier(n_estimators<span class="op">=</span><span class="dv">500</span>, </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>                    learning_rate<span class="op">=</span><span class="bu">round</span>(best[<span class="st">'learning_rate'</span>], <span class="dv">5</span>),</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>                    max_depth<span class="op">=</span><span class="bu">int</span>(best[<span class="st">'max_depth'</span>]),</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>                    min_child_weight<span class="op">=</span><span class="bu">int</span>(best[<span class="st">'min_child_weight'</span>]),</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>                    colsample_bytree<span class="op">=</span><span class="bu">round</span>(best[<span class="st">'colsample_bytree'</span>], <span class="dv">5</span>),</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>                    early_stopping_rounds<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>                    eval_metric<span class="op">=</span>[<span class="st">'auc'</span>])</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>xgb_clf.fit(X_tr, y_tr, eval_set<span class="op">=</span>evals, verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>xgb_roc_score <span class="op">=</span> roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, <span class="dv">1</span>])</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>xgb_roc_score<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="plot-importance" class="level3">
<h3 class="anchored" data-anchor-id="plot-importance">plot importance</h3>
<div id="ac38b14f" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> plot_importance</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>plot_importance(xgb_clf, max_num_features<span class="op">=</span><span class="dv">20</span>, height<span class="op">=</span><span class="fl">0.4</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="lightgbm" class="level2">
<h2 class="anchored" data-anchor-id="lightgbm">LightGBM</h2>
<div id="0ccfd20a" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lightgbm <span class="im">import</span> LGBMClassifier</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>lgbm_clf <span class="op">=</span> LGBMClassifier(n_estimators<span class="op">=</span><span class="dv">500</span>, early_stopping_rounds<span class="op">=</span><span class="dv">100</span>, eval_metric<span class="op">=</span><span class="st">'auc'</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>eval_set <span class="op">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>lgbm_clf.fit(X_tr, y_tr, eval_set<span class="op">=</span>eval_set)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>lgbm_roc_score <span class="op">=</span> roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, <span class="dv">1</span>])</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>lgbm_roc_score<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100
[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Info] Number of positive: 1694, number of negative: 40877
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010137 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 13592
[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 248
[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039792 -&gt; initscore=-3.183475
[LightGBM] [Info] Start training from score -3.183475
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[33]    training's binary_logloss: 0.117693 valid_1's binary_logloss: 0.137269
[LightGBM] [Warning] Unknown parameter: eval_metric
0.836</code></pre>
</div>
</div>
<section id="베이지안-최적화-1" class="level3">
<h3 class="anchored" data-anchor-id="베이지안-최적화-1">베이지안 최적화</h3>
<div id="a629edb1" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> objective_func(search_space):</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    lgbm_clf <span class="op">=</span> LGBMClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>                            early_stopping_rounds<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>                            eval_metric<span class="op">=</span><span class="st">'auc'</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>                            num_leaves<span class="op">=</span><span class="bu">int</span>(search_space[<span class="st">'num_leaves'</span>]),</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>                            max_depth<span class="op">=</span><span class="bu">int</span>(search_space[<span class="st">'max_depth'</span>]),</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>                            min_child_samples<span class="op">=</span><span class="bu">int</span>(search_space[<span class="st">'min_child_samples'</span>]),</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>                            subsample<span class="op">=</span>search_space[<span class="st">'subsample'</span>],</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>                            learning_rate<span class="op">=</span>search_space[<span class="st">'learning_rate'</span>])</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    roc_auc_list <span class="op">=</span> []</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tr_index, val_index <span class="kw">in</span> kf.split(X_train):</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        X_tr, y_tr <span class="op">=</span> X_train.iloc[tr_index], y_train.iloc[tr_index]</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        X_val, y_val <span class="op">=</span>  X_train.iloc[val_index], y_train.iloc[val_index]</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>        lgbm_clf.fit(X_tr, y_tr, eval_set<span class="op">=</span>[(X_tr, y_tr), (X_val, y_val)])</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, <span class="dv">1</span>])</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>        roc_auc_list.append(score)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span> <span class="op">*</span> np.mean(roc_auc_list)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="eed26a4e" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hyperopt <span class="im">import</span> hp, fmin, tpe, Trials</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>lgbm_search_space <span class="op">=</span> {</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">'num_leaves'</span>: hp.quniform(<span class="st">'num_leaves'</span>, <span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">1</span>),</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">'max_depth'</span>: hp.quniform(<span class="st">'max_depth'</span>, <span class="dv">100</span>, <span class="dv">160</span>, <span class="dv">1</span>),</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">'min_child_samples'</span>: hp.quniform(<span class="st">'min_child_samples'</span>, <span class="dv">60</span>, <span class="dv">100</span>, <span class="dv">1</span>),</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">'subsample'</span>: hp.uniform(<span class="st">'subsample'</span>, <span class="fl">0.7</span>, <span class="dv">1</span>),</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">'learning_rate'</span>: hp.uniform(<span class="st">'learning_rate'</span>, <span class="fl">0.01</span>, <span class="fl">0.2</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>trials <span class="op">=</span> Trials()</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>best <span class="op">=</span> fmin(fn<span class="op">=</span>objective_func,</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>            space<span class="op">=</span>lgbm_search_space,</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>            algo<span class="op">=</span>tpe.suggest,</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>            max_evals<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>            trials<span class="op">=</span>trials)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(best)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007286 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Total Bins 12947
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Start training from score -3.161962
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      Training until validation scores don't improve for 30 rounds
  0%|          | 0/50 [00:00&lt;?, ?trial/s, best loss=?]                                                      Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.119239 valid_1's binary_logloss: 0.131547
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009173 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Total Bins 13055
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Start training from score -3.210495
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      Training until validation scores don't improve for 30 rounds
  0%|          | 0/50 [00:01&lt;?, ?trial/s, best loss=?]                                                      Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.11513  valid_1's binary_logloss: 0.139265
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008461 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Total Bins 12996
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Info] Start training from score -3.179828
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      Training until validation scores don't improve for 30 rounds
  0%|          | 0/50 [00:02&lt;?, ?trial/s, best loss=?]                                                      Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.116828 valid_1's binary_logloss: 0.136952
  0%|          | 0/50 [00:03&lt;?, ?trial/s, best loss=?]                                                      [LightGBM] [Warning] Unknown parameter: eval_metric
  0%|          | 0/50 [00:03&lt;?, ?trial/s, best loss=?]  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008509 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Total Bins 12835
  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Start training from score -3.161962
  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 Training until validation scores don't improve for 30 rounds
  2%|▏         | 1/50 [00:03&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.134361 valid_1's binary_logloss: 0.134539
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008662 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Total Bins 12988
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Start training from score -3.210495
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 Training until validation scores don't improve for 30 rounds
  2%|▏         | 1/50 [00:04&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.129831 valid_1's binary_logloss: 0.142347
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008359 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Total Bins 12898
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Start training from score -3.179828
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 Training until validation scores don't improve for 30 rounds
  2%|▏         | 1/50 [00:05&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.131634 valid_1's binary_logloss: 0.139054
  2%|▏         | 1/50 [00:06&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  2%|▏         | 1/50 [00:06&lt;02:57,  3.63s/trial, best loss: -0.8341540202815528]  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008437 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Total Bins 12902
  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Start training from score -3.161962
  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 Training until validation scores don't improve for 30 rounds
  4%|▍         | 2/50 [00:06&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 Did not meet early stopping. Best iteration is:
[88]    training's binary_logloss: 0.113936 valid_1's binary_logloss: 0.131766
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008792 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Total Bins 12988
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Start training from score -3.210495
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 Training until validation scores don't improve for 30 rounds
  4%|▍         | 2/50 [00:07&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 Did not meet early stopping. Best iteration is:
[71]    training's binary_logloss: 0.11326  valid_1's binary_logloss: 0.139317
  4%|▍         | 2/50 [00:08&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:08&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:09&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:09&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:09&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
  4%|▍         | 2/50 [00:09&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009763 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  4%|▍         | 2/50 [00:09&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Total Bins 12898
  4%|▍         | 2/50 [00:09&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  4%|▍         | 2/50 [00:09&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:09&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  4%|▍         | 2/50 [00:09&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
  4%|▍         | 2/50 [00:09&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Start training from score -3.179828
  4%|▍         | 2/50 [00:09&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 Training until validation scores don't improve for 30 rounds
  4%|▍         | 2/50 [00:09&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 Did not meet early stopping. Best iteration is:
[77]    training's binary_logloss: 0.113657 valid_1's binary_logloss: 0.136864
  4%|▍         | 2/50 [00:10&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  4%|▍         | 2/50 [00:10&lt;02:30,  3.13s/trial, best loss: -0.8341540202815528]  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009179 seconds.
You can set `force_col_wise=true` to remove the overhead.
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Total Bins 12835
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Start training from score -3.161962
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 Training until validation scores don't improve for 30 rounds
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 Early stopping, best iteration is:
[39]    training's binary_logloss: 0.12109  valid_1's binary_logloss: 0.131246
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:10&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008369 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Total Bins 12988
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Start training from score -3.210495
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 Training until validation scores don't improve for 30 rounds
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 Early stopping, best iteration is:
[39]    training's binary_logloss: 0.116743 valid_1's binary_logloss: 0.139211
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008111 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Total Bins 12898
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Info] Start training from score -3.179828
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 Training until validation scores don't improve for 30 rounds
  6%|▌         | 3/50 [00:11&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 Early stopping, best iteration is:
[35]    training's binary_logloss: 0.120149 valid_1's binary_logloss: 0.136702
  6%|▌         | 3/50 [00:12&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  6%|▌         | 3/50 [00:12&lt;02:38,  3.38s/trial, best loss: -0.8341540202815528]  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008782 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Total Bins 12947
  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Start training from score -3.161962
  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 Training until validation scores don't improve for 30 rounds
  8%|▊         | 4/50 [00:12&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 Early stopping, best iteration is:
[30]    training's binary_logloss: 0.111064 valid_1's binary_logloss: 0.131895
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010004 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Total Bins 13055
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Start training from score -3.210495
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 Training until validation scores don't improve for 30 rounds
  8%|▊         | 4/50 [00:13&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 Early stopping, best iteration is:
[27]    training's binary_logloss: 0.108994 valid_1's binary_logloss: 0.139854
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009049 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Total Bins 12996
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Start training from score -3.179828
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 Training until validation scores don't improve for 30 rounds
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 Early stopping, best iteration is:
[20]    training's binary_logloss: 0.116146 valid_1's binary_logloss: 0.13756
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
  8%|▊         | 4/50 [00:14&lt;02:16,  2.96s/trial, best loss: -0.8346097688713522] 10%|█         | 5/50 [00:14&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008251 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Total Bins 12947
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Start training from score -3.161962
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 Training until validation scores don't improve for 30 rounds
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 Early stopping, best iteration is:
[25]    training's binary_logloss: 0.120067 valid_1's binary_logloss: 0.131511
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007845 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Total Bins 13055
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Start training from score -3.210495
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 Training until validation scores don't improve for 30 rounds
 10%|█         | 5/50 [00:15&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 Early stopping, best iteration is:
[31]    training's binary_logloss: 0.112434 valid_1's binary_logloss: 0.139423
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009165 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Total Bins 12996
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Start training from score -3.179828
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 Training until validation scores don't improve for 30 rounds
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 Early stopping, best iteration is:
[28]    training's binary_logloss: 0.115651 valid_1's binary_logloss: 0.136891
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 10%|█         | 5/50 [00:16&lt;02:06,  2.80s/trial, best loss: -0.8346097688713522] 12%|█▏        | 6/50 [00:16&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:17&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:17&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:17&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 12%|█▏        | 6/50 [00:17&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010475 seconds.
You can set `force_col_wise=true` to remove the overhead.
 12%|█▏        | 6/50 [00:17&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Total Bins 12902
 12%|█▏        | 6/50 [00:17&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 12%|█▏        | 6/50 [00:17&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:17&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:17&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 12%|█▏        | 6/50 [00:17&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Start training from score -3.161962
 12%|█▏        | 6/50 [00:17&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 Training until validation scores don't improve for 30 rounds
 12%|█▏        | 6/50 [00:17&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.128605 valid_1's binary_logloss: 0.133093
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008203 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Total Bins 12988
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Start training from score -3.210495
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 Training until validation scores don't improve for 30 rounds
 12%|█▏        | 6/50 [00:18&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.124147 valid_1's binary_logloss: 0.141061
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007711 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Total Bins 12898
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Start training from score -3.179828
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 Training until validation scores don't improve for 30 rounds
 12%|█▏        | 6/50 [00:19&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.125878 valid_1's binary_logloss: 0.13813
 12%|█▏        | 6/50 [00:20&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 12%|█▏        | 6/50 [00:20&lt;01:52,  2.55s/trial, best loss: -0.8346097688713522] 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008418 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Total Bins 12947
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Start training from score -3.161962
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 Training until validation scores don't improve for 30 rounds
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 Did not meet early stopping. Best iteration is:
[73]    training's binary_logloss: 0.119266 valid_1's binary_logloss: 0.131216
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:20&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007783 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Total Bins 12998
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Start training from score -3.210495
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 Training until validation scores don't improve for 30 rounds
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 Early stopping, best iteration is:
[63]    training's binary_logloss: 0.116719 valid_1's binary_logloss: 0.139009
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:21&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:22&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 14%|█▍        | 7/50 [00:22&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008308 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 14%|█▍        | 7/50 [00:22&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Total Bins 12968
 14%|█▍        | 7/50 [00:22&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 14%|█▍        | 7/50 [00:22&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:22&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 14%|█▍        | 7/50 [00:22&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 14%|█▍        | 7/50 [00:22&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Info] Start training from score -3.179828
 14%|█▍        | 7/50 [00:22&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 Training until validation scores don't improve for 30 rounds
 14%|█▍        | 7/50 [00:22&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 Early stopping, best iteration is:
[56]    training's binary_logloss: 0.120087 valid_1's binary_logloss: 0.136444
 14%|█▍        | 7/50 [00:22&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 14%|█▍        | 7/50 [00:22&lt;01:58,  2.76s/trial, best loss: -0.8346097688713522] 16%|█▌        | 8/50 [00:22&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:22&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:22&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:22&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 16%|█▌        | 8/50 [00:22&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009077 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 16%|█▌        | 8/50 [00:22&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Total Bins 12835
 16%|█▌        | 8/50 [00:22&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 16%|█▌        | 8/50 [00:22&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:22&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:22&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Start training from score -3.161962
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 Training until validation scores don't improve for 30 rounds
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 Early stopping, best iteration is:
[57]    training's binary_logloss: 0.120993 valid_1's binary_logloss: 0.131385
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007612 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Total Bins 12988
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Start training from score -3.210495
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 Training until validation scores don't improve for 30 rounds
 16%|█▌        | 8/50 [00:23&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 Early stopping, best iteration is:
[62]    training's binary_logloss: 0.115325 valid_1's binary_logloss: 0.13881
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007536 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Total Bins 12898
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Start training from score -3.179828
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 Training until validation scores don't improve for 30 rounds
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 Early stopping, best iteration is:
[50]    training's binary_logloss: 0.120231 valid_1's binary_logloss: 0.136346
 16%|█▌        | 8/50 [00:24&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 16%|█▌        | 8/50 [00:25&lt;01:51,  2.65s/trial, best loss: -0.8354478683012264] 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008124 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Total Bins 12835
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Start training from score -3.161962
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 Training until validation scores don't improve for 30 rounds
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 Early stopping, best iteration is:
[23]    training's binary_logloss: 0.116031 valid_1's binary_logloss: 0.132494
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:25&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007737 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Total Bins 12988
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Start training from score -3.210495
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 Training until validation scores don't improve for 30 rounds
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 Early stopping, best iteration is:
[22]    training's binary_logloss: 0.112419 valid_1's binary_logloss: 0.140329
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007861 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Total Bins 12898
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Info] Start training from score -3.179828
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 Training until validation scores don't improve for 30 rounds
 18%|█▊        | 9/50 [00:26&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 Early stopping, best iteration is:
[20]    training's binary_logloss: 0.115687 valid_1's binary_logloss: 0.137694
 18%|█▊        | 9/50 [00:27&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264]                                                                                 [LightGBM] [Warning] Unknown parameter: eval_metric
 18%|█▊        | 9/50 [00:27&lt;01:46,  2.59s/trial, best loss: -0.8354478683012264] 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007751 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12835
 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 20%|██        | 10/50 [00:27&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[45]    training's binary_logloss: 0.117033 valid_1's binary_logloss: 0.131893
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007925 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12988
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[30]    training's binary_logloss: 0.11876  valid_1's binary_logloss: 0.139543
 20%|██        | 10/50 [00:28&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008278 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12898
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[38]    training's binary_logloss: 0.117423 valid_1's binary_logloss: 0.136738
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 20%|██        | 10/50 [00:29&lt;01:40,  2.52s/trial, best loss: -0.8354478683012264] 22%|██▏       | 11/50 [00:29&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:29&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:29&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008637 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12902
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  Did not meet early stopping. Best iteration is:
[78]    training's binary_logloss: 0.115732 valid_1's binary_logloss: 0.13138
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007739 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12988
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 22%|██▏       | 11/50 [00:30&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  Did not meet early stopping. Best iteration is:
[74]    training's binary_logloss: 0.112624 valid_1's binary_logloss: 0.139339
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008653 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12898
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 22%|██▏       | 11/50 [00:31&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  Did not meet early stopping. Best iteration is:
[74]    training's binary_logloss: 0.114351 valid_1's binary_logloss: 0.136737
 22%|██▏       | 11/50 [00:32&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 22%|██▏       | 11/50 [00:32&lt;01:37,  2.49s/trial, best loss: -0.8354478683012264] 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010321 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12947
 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 24%|██▍       | 12/50 [00:32&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[46]    training's binary_logloss: 0.11276  valid_1's binary_logloss: 0.13165
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009865 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 13055
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 24%|██▍       | 12/50 [00:33&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 24%|██▍       | 12/50 [00:34&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[40]    training's binary_logloss: 0.111011 valid_1's binary_logloss: 0.139831
 24%|██▍       | 12/50 [00:34&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:34&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:34&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:34&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:34&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 24%|██▍       | 12/50 [00:34&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008053 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 24%|██▍       | 12/50 [00:34&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12996
 24%|██▍       | 12/50 [00:34&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 24%|██▍       | 12/50 [00:34&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:35&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 24%|██▍       | 12/50 [00:35&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 24%|██▍       | 12/50 [00:35&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 24%|██▍       | 12/50 [00:35&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 24%|██▍       | 12/50 [00:35&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[43]    training's binary_logloss: 0.111276 valid_1's binary_logloss: 0.137335
 24%|██▍       | 12/50 [00:35&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 24%|██▍       | 12/50 [00:35&lt;01:35,  2.51s/trial, best loss: -0.8354478683012264] 26%|██▌       | 13/50 [00:35&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:35&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:35&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:35&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 26%|██▌       | 13/50 [00:35&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008260 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 26%|██▌       | 13/50 [00:35&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12844
 26%|██▌       | 13/50 [00:35&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195
 26%|██▌       | 13/50 [00:35&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:35&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:35&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 26%|██▌       | 13/50 [00:36&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 26%|██▌       | 13/50 [00:36&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 26%|██▌       | 13/50 [00:36&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.12681  valid_1's binary_logloss: 0.13222
 26%|██▌       | 13/50 [00:36&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:36&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:36&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:36&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008850 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12988
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.122208 valid_1's binary_logloss: 0.139981
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:37&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:38&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 26%|██▌       | 13/50 [00:38&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009314 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 26%|██▌       | 13/50 [00:38&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12898
 26%|██▌       | 13/50 [00:38&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 26%|██▌       | 13/50 [00:38&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:38&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 26%|██▌       | 13/50 [00:38&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 26%|██▌       | 13/50 [00:38&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 26%|██▌       | 13/50 [00:38&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 26%|██▌       | 13/50 [00:38&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.124131 valid_1's binary_logloss: 0.137316
 26%|██▌       | 13/50 [00:39&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 26%|██▌       | 13/50 [00:39&lt;01:41,  2.74s/trial, best loss: -0.8354478683012264] 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010560 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12943
 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 28%|██▊       | 14/50 [00:39&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[19]    training's binary_logloss: 0.119948 valid_1's binary_logloss: 0.132615
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009233 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12988
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[17]    training's binary_logloss: 0.116812 valid_1's binary_logloss: 0.140251
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:40&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009001 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12958
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[19]    training's binary_logloss: 0.117331 valid_1's binary_logloss: 0.137237
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 28%|██▊       | 14/50 [00:41&lt;01:49,  3.04s/trial, best loss: -0.8354478683012264] 30%|███       | 15/50 [00:41&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:41&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:41&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010186 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12943
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[17]    training's binary_logloss: 0.120445 valid_1's binary_logloss: 0.132691
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 30%|███       | 15/50 [00:42&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010950 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12988
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[16]    training's binary_logloss: 0.117054 valid_1's binary_logloss: 0.139941
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008302 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12906
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 30%|███       | 15/50 [00:43&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[20]    training's binary_logloss: 0.115401 valid_1's binary_logloss: 0.137413
 30%|███       | 15/50 [00:44&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 30%|███       | 15/50 [00:44&lt;01:38,  2.83s/trial, best loss: -0.8354478683012264] 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009370 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12835
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[18]    training's binary_logloss: 0.11605  valid_1's binary_logloss: 0.133209
 32%|███▏      | 16/50 [00:44&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008886 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12988
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[15]    training's binary_logloss: 0.114923 valid_1's binary_logloss: 0.140959
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:45&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:46&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 32%|███▏      | 16/50 [00:46&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008924 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 32%|███▏      | 16/50 [00:46&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12898
 32%|███▏      | 16/50 [00:46&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 32%|███▏      | 16/50 [00:46&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:46&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 32%|███▏      | 16/50 [00:46&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 32%|███▏      | 16/50 [00:46&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 32%|███▏      | 16/50 [00:46&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 32%|███▏      | 16/50 [00:46&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[14]    training's binary_logloss: 0.117846 valid_1's binary_logloss: 0.13746
 32%|███▏      | 16/50 [00:46&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 32%|███▏      | 16/50 [00:46&lt;01:32,  2.72s/trial, best loss: -0.8354478683012264] 34%|███▍      | 17/50 [00:46&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:46&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:46&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:46&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 34%|███▍      | 17/50 [00:46&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009462 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 34%|███▍      | 17/50 [00:46&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12835
 34%|███▍      | 17/50 [00:46&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 34%|███▍      | 17/50 [00:46&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:46&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:46&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[49]    training's binary_logloss: 0.11538  valid_1's binary_logloss: 0.131723
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010342 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12988
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 34%|███▍      | 17/50 [00:47&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[31]    training's binary_logloss: 0.117853 valid_1's binary_logloss: 0.139219
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007465 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12898
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.120676 valid_1's binary_logloss: 0.136931
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 34%|███▍      | 17/50 [00:48&lt;01:26,  2.63s/trial, best loss: -0.8354478683012264] 36%|███▌      | 18/50 [00:48&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007036 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12835
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.119523 valid_1's binary_logloss: 0.131926
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008304 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12988
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 36%|███▌      | 18/50 [00:49&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[27]    training's binary_logloss: 0.115902 valid_1's binary_logloss: 0.139583
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010535 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12898
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[24]    training's binary_logloss: 0.11906  valid_1's binary_logloss: 0.137256
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 36%|███▌      | 18/50 [00:50&lt;01:20,  2.53s/trial, best loss: -0.8354478683012264] 38%|███▊      | 19/50 [00:50&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014995 seconds.
You can set `force_col_wise=true` to remove the overhead.
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12835
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[28]    training's binary_logloss: 0.117616 valid_1's binary_logloss: 0.132237
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 38%|███▊      | 19/50 [00:51&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007897 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12988
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[23]    training's binary_logloss: 0.115822 valid_1's binary_logloss: 0.140243
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020219 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 12898
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 38%|███▊      | 19/50 [00:52&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[25]    training's binary_logloss: 0.116668 valid_1's binary_logloss: 0.137218
 38%|███▊      | 19/50 [00:53&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 38%|███▊      | 19/50 [00:53&lt;01:13,  2.38s/trial, best loss: -0.8354478683012264] 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009889 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 13057
 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 211
 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 40%|████      | 20/50 [00:53&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  Did not meet early stopping. Best iteration is:
[71]    training's binary_logloss: 0.118472 valid_1's binary_logloss: 0.130909
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008639 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 13161
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 40%|████      | 20/50 [00:54&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[60]    training's binary_logloss: 0.116535 valid_1's binary_logloss: 0.138826
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009875 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Total Bins 13044
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  Training until validation scores don't improve for 30 rounds
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  Early stopping, best iteration is:
[58]    training's binary_logloss: 0.118597 valid_1's binary_logloss: 0.136638
 40%|████      | 20/50 [00:55&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 40%|████      | 20/50 [00:56&lt;01:12,  2.41s/trial, best loss: -0.8354478683012264] 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008395 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Total Bins 13057
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 211
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  Training until validation scores don't improve for 30 rounds
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  Did not meet early stopping. Best iteration is:
[96]    training's binary_logloss: 0.116806 valid_1's binary_logloss: 0.131693
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:56&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008654 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Total Bins 13161
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  Training until validation scores don't improve for 30 rounds
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  Did not meet early stopping. Best iteration is:
[75]    training's binary_logloss: 0.116396 valid_1's binary_logloss: 0.138474
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:57&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009684 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Total Bins 13044
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  Training until validation scores don't improve for 30 rounds
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  Early stopping, best iteration is:
[65]    training's binary_logloss: 0.119662 valid_1's binary_logloss: 0.136275
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 42%|████▏     | 21/50 [00:58&lt;01:11,  2.46s/trial, best loss: -0.8361261980967356] 44%|████▍     | 22/50 [00:58&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009310 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Total Bins 13057
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 211
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  Training until validation scores don't improve for 30 rounds
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  Early stopping, best iteration is:
[63]    training's binary_logloss: 0.117775 valid_1's binary_logloss: 0.131201
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [00:59&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009518 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Total Bins 13161
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  Training until validation scores don't improve for 30 rounds
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  Early stopping, best iteration is:
[55]    training's binary_logloss: 0.11576  valid_1's binary_logloss: 0.138797
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [01:00&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [01:01&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 44%|████▍     | 22/50 [01:01&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009738 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 44%|████▍     | 22/50 [01:01&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Total Bins 13044
 44%|████▍     | 22/50 [01:01&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 44%|████▍     | 22/50 [01:01&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [01:01&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 44%|████▍     | 22/50 [01:01&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 44%|████▍     | 22/50 [01:01&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 44%|████▍     | 22/50 [01:01&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  Training until validation scores don't improve for 30 rounds
 44%|████▍     | 22/50 [01:01&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  Early stopping, best iteration is:
[48]    training's binary_logloss: 0.119114 valid_1's binary_logloss: 0.136592
 44%|████▍     | 22/50 [01:01&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 44%|████▍     | 22/50 [01:01&lt;01:12,  2.58s/trial, best loss: -0.8361261980967356] 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009989 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Total Bins 12993
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  Training until validation scores don't improve for 30 rounds
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.121674 valid_1's binary_logloss: 0.131107
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [01:01&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009480 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Total Bins 13086
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  Training until validation scores don't improve for 30 rounds
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.11765  valid_1's binary_logloss: 0.138596
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [01:02&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:03&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 46%|████▌     | 23/50 [01:03&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009169 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 46%|████▌     | 23/50 [01:03&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Total Bins 12996
 46%|████▌     | 23/50 [01:03&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 46%|████▌     | 23/50 [01:03&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:03&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 46%|████▌     | 23/50 [01:03&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 46%|████▌     | 23/50 [01:03&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 46%|████▌     | 23/50 [01:03&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  Training until validation scores don't improve for 30 rounds
 46%|████▌     | 23/50 [01:03&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  Did not meet early stopping. Best iteration is:
[95]    training's binary_logloss: 0.119781 valid_1's binary_logloss: 0.136145
 46%|████▌     | 23/50 [01:03&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 46%|████▌     | 23/50 [01:03&lt;01:11,  2.65s/trial, best loss: -0.8361261980967356] 48%|████▊     | 24/50 [01:03&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:03&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:03&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008895 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Total Bins 12993
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  Training until validation scores don't improve for 30 rounds
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.123945 valid_1's binary_logloss: 0.131312
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:04&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009337 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Total Bins 13086
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  Training until validation scores don't improve for 30 rounds
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.119785 valid_1's binary_logloss: 0.138758
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:05&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:06&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 48%|████▊     | 24/50 [01:06&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009450 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 48%|████▊     | 24/50 [01:06&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Total Bins 12996
 48%|████▊     | 24/50 [01:06&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 48%|████▊     | 24/50 [01:06&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:06&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 48%|████▊     | 24/50 [01:06&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 48%|████▊     | 24/50 [01:06&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 48%|████▊     | 24/50 [01:06&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  Training until validation scores don't improve for 30 rounds
 48%|████▊     | 24/50 [01:06&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.121345 valid_1's binary_logloss: 0.136253
 48%|████▊     | 24/50 [01:06&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 48%|████▊     | 24/50 [01:06&lt;01:04,  2.46s/trial, best loss: -0.8362934408440913] 50%|█████     | 25/50 [01:06&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:06&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:06&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:07&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 50%|█████     | 25/50 [01:07&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010296 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 50%|█████     | 25/50 [01:07&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12993
 50%|█████     | 25/50 [01:07&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 50%|█████     | 25/50 [01:07&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:07&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:07&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 50%|█████     | 25/50 [01:07&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 50%|█████     | 25/50 [01:07&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 50%|█████     | 25/50 [01:07&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[99]    training's binary_logloss: 0.115076 valid_1's binary_logloss: 0.131544
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011525 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13086
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 50%|█████     | 25/50 [01:08&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[99]    training's binary_logloss: 0.110704 valid_1's binary_logloss: 0.139171
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009677 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12996
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 50%|█████     | 25/50 [01:09&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[74]    training's binary_logloss: 0.117386 valid_1's binary_logloss: 0.137077
 50%|█████     | 25/50 [01:10&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 50%|█████     | 25/50 [01:10&lt;01:06,  2.65s/trial, best loss: -0.8365225708987197] 52%|█████▏    | 26/50 [01:10&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:10&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:10&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009136 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12993
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[40]    training's binary_logloss: 0.118745 valid_1's binary_logloss: 0.13174
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009702 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13086
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 52%|█████▏    | 26/50 [01:11&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[37]    training's binary_logloss: 0.115548 valid_1's binary_logloss: 0.138995
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010037 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12996
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 52%|█████▏    | 26/50 [01:12&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[32]    training's binary_logloss: 0.119523 valid_1's binary_logloss: 0.136814
 52%|█████▏    | 26/50 [01:13&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 52%|█████▏    | 26/50 [01:13&lt;01:13,  3.05s/trial, best loss: -0.8365225708987197] 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009837 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12993
 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 54%|█████▍    | 27/50 [01:13&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[97]    training's binary_logloss: 0.119337 valid_1's binary_logloss: 0.131417
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010306 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13086
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 54%|█████▍    | 27/50 [01:14&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.114456 valid_1's binary_logloss: 0.139157
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008807 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12996
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 54%|█████▍    | 27/50 [01:15&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[97]    training's binary_logloss: 0.11659  valid_1's binary_logloss: 0.136713
 54%|█████▍    | 27/50 [01:16&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 54%|█████▍    | 27/50 [01:16&lt;01:07,  2.92s/trial, best loss: -0.8365225708987197] 56%|█████▌    | 28/50 [01:16&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:16&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:16&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:16&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 56%|█████▌    | 28/50 [01:16&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008596 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 56%|█████▌    | 28/50 [01:16&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12943
 56%|█████▌    | 28/50 [01:16&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 56%|█████▌    | 28/50 [01:16&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[22]    training's binary_logloss: 0.121698 valid_1's binary_logloss: 0.132138
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008173 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12998
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 56%|█████▌    | 28/50 [01:17&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[25]    training's binary_logloss: 0.11611  valid_1's binary_logloss: 0.139307
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008090 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12958
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[17]    training's binary_logloss: 0.122317 valid_1's binary_logloss: 0.136889
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 56%|█████▌    | 28/50 [01:18&lt;01:06,  3.03s/trial, best loss: -0.8365225708987197] 58%|█████▊    | 29/50 [01:18&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:18&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:18&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:18&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 58%|█████▊    | 29/50 [01:18&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009576 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 58%|█████▊    | 29/50 [01:18&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12943
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.117385 valid_1's binary_logloss: 0.131388
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 58%|█████▊    | 29/50 [01:19&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008772 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 58%|█████▊    | 29/50 [01:20&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12998
 58%|█████▊    | 29/50 [01:20&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
 58%|█████▊    | 29/50 [01:20&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:20&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:20&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 58%|█████▊    | 29/50 [01:20&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 58%|█████▊    | 29/50 [01:20&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 58%|█████▊    | 29/50 [01:20&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[98]    training's binary_logloss: 0.113488 valid_1's binary_logloss: 0.139105
 58%|█████▊    | 29/50 [01:20&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:20&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:20&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:20&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:21&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 58%|█████▊    | 29/50 [01:21&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008569 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 58%|█████▊    | 29/50 [01:21&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12958
 58%|█████▊    | 29/50 [01:21&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 58%|█████▊    | 29/50 [01:21&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:21&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 58%|█████▊    | 29/50 [01:21&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 58%|█████▊    | 29/50 [01:21&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 58%|█████▊    | 29/50 [01:21&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 58%|█████▊    | 29/50 [01:21&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.114829 valid_1's binary_logloss: 0.136714
 58%|█████▊    | 29/50 [01:21&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 58%|█████▊    | 29/50 [01:21&lt;00:57,  2.74s/trial, best loss: -0.8365225708987197] 60%|██████    | 30/50 [01:21&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:21&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:21&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008604 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12993
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.136137 valid_1's binary_logloss: 0.135864
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007794 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13059
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 60%|██████    | 30/50 [01:22&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.131758 valid_1's binary_logloss: 0.143909
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008173 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12996
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 60%|██████    | 30/50 [01:23&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.133319 valid_1's binary_logloss: 0.140365
 60%|██████    | 30/50 [01:24&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 60%|██████    | 30/50 [01:24&lt;00:56,  2.84s/trial, best loss: -0.8365225708987197] 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007810 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12902
 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 62%|██████▏   | 31/50 [01:24&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[52]    training's binary_logloss: 0.120557 valid_1's binary_logloss: 0.131463
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008104 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12988
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[42]    training's binary_logloss: 0.119216 valid_1's binary_logloss: 0.138844
 62%|██████▏   | 31/50 [01:25&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008458 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12898
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[43]    training's binary_logloss: 0.120672 valid_1's binary_logloss: 0.136077
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 62%|██████▏   | 31/50 [01:26&lt;00:52,  2.78s/trial, best loss: -0.8365225708987197] 64%|██████▍   | 32/50 [01:26&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:26&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:26&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008051 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12943
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.116782 valid_1's binary_logloss: 0.132291
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008398 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12998
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 64%|██████▍   | 32/50 [01:27&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.112525 valid_1's binary_logloss: 0.139834
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008790 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12958
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 64%|██████▍   | 32/50 [01:28&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[26]    training's binary_logloss: 0.116376 valid_1's binary_logloss: 0.13759
 64%|██████▍   | 32/50 [01:29&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 64%|██████▍   | 32/50 [01:29&lt;00:47,  2.65s/trial, best loss: -0.8365225708987197] 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007899 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13047
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 210
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.121235 valid_1's binary_logloss: 0.131795
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:29&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:30&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:30&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:30&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 66%|██████▌   | 33/50 [01:30&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010711 seconds.
You can set `force_col_wise=true` to remove the overhead.
 66%|██████▌   | 33/50 [01:30&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13161
 66%|██████▌   | 33/50 [01:30&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 208
 66%|██████▌   | 33/50 [01:30&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:30&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:30&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 66%|██████▌   | 33/50 [01:30&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 66%|██████▌   | 33/50 [01:30&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 66%|██████▌   | 33/50 [01:30&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.117131 valid_1's binary_logloss: 0.139355
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009935 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13044
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 66%|██████▌   | 33/50 [01:31&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.11886  valid_1's binary_logloss: 0.136817
 66%|██████▌   | 33/50 [01:32&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 66%|██████▌   | 33/50 [01:32&lt;00:43,  2.55s/trial, best loss: -0.8365225708987197] 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009479 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13047
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 210
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[87]    training's binary_logloss: 0.119217 valid_1's binary_logloss: 0.131162
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009390 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13130
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 68%|██████▊   | 34/50 [01:32&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[95]    training's binary_logloss: 0.11377  valid_1's binary_logloss: 0.138774
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008385 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13000
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 68%|██████▊   | 34/50 [01:33&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[71]    training's binary_logloss: 0.119355 valid_1's binary_logloss: 0.136516
 68%|██████▊   | 34/50 [01:34&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 68%|██████▊   | 34/50 [01:34&lt;00:44,  2.76s/trial, best loss: -0.8365225708987197] 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008260 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12993
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[20]    training's binary_logloss: 0.117227 valid_1's binary_logloss: 0.132479
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:34&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007966 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13059
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[22]    training's binary_logloss: 0.110745 valid_1's binary_logloss: 0.140016
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007917 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12996
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 70%|███████   | 35/50 [01:35&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[18]    training's binary_logloss: 0.116325 valid_1's binary_logloss: 0.136868
 70%|███████   | 35/50 [01:36&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 70%|███████   | 35/50 [01:36&lt;00:37,  2.51s/trial, best loss: -0.8365225708987197] 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007671 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12902
 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 72%|███████▏  | 36/50 [01:36&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.133676 valid_1's binary_logloss: 0.135443
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007838 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12988
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 72%|███████▏  | 36/50 [01:37&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.129111 valid_1's binary_logloss: 0.143846
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008862 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12898
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 72%|███████▏  | 36/50 [01:38&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.131021 valid_1's binary_logloss: 0.140157
 72%|███████▏  | 36/50 [01:39&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 72%|███████▏  | 36/50 [01:39&lt;00:32,  2.33s/trial, best loss: -0.8365225708987197] 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007790 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12943
 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 74%|███████▍  | 37/50 [01:39&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[65]    training's binary_logloss: 0.118118 valid_1's binary_logloss: 0.131584
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007983 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12988
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 74%|███████▍  | 37/50 [01:40&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[65]    training's binary_logloss: 0.113718 valid_1's binary_logloss: 0.139017
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008166 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12906
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 74%|███████▍  | 37/50 [01:41&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[59]    training's binary_logloss: 0.116916 valid_1's binary_logloss: 0.136382
 74%|███████▍  | 37/50 [01:42&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 74%|███████▍  | 37/50 [01:42&lt;00:34,  2.62s/trial, best loss: -0.8365225708987197] 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008362 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12943
 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 76%|███████▌  | 38/50 [01:42&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[43]    training's binary_logloss: 0.120211 valid_1's binary_logloss: 0.131444
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011524 seconds.
You can set `force_col_wise=true` to remove the overhead.
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12998
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[47]    training's binary_logloss: 0.114602 valid_1's binary_logloss: 0.139106
 76%|███████▌  | 38/50 [01:43&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008487 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12968
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[40]    training's binary_logloss: 0.118651 valid_1's binary_logloss: 0.136544
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 76%|███████▌  | 38/50 [01:44&lt;00:32,  2.68s/trial, best loss: -0.8365225708987197] 78%|███████▊  | 39/50 [01:44&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:44&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:44&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007906 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12947
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[40]    training's binary_logloss: 0.119116 valid_1's binary_logloss: 0.131438
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010484 seconds.
You can set `force_col_wise=true` to remove the overhead.
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13059
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 78%|███████▊  | 39/50 [01:45&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[37]    training's binary_logloss: 0.116085 valid_1's binary_logloss: 0.138771
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008602 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12996
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[34]    training's binary_logloss: 0.11889  valid_1's binary_logloss: 0.136703
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 78%|███████▊  | 39/50 [01:46&lt;00:28,  2.62s/trial, best loss: -0.8365225708987197] 80%|████████  | 40/50 [01:46&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009081 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12947
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.119904 valid_1's binary_logloss: 0.131539
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:47&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011067 seconds.
You can set `force_col_wise=true` to remove the overhead.
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13055
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[28]    training's binary_logloss: 0.115561 valid_1's binary_logloss: 0.139612
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007772 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12996
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 80%|████████  | 40/50 [01:48&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[26]    training's binary_logloss: 0.118624 valid_1's binary_logloss: 0.136879
 80%|████████  | 40/50 [01:49&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 80%|████████  | 40/50 [01:49&lt;00:24,  2.49s/trial, best loss: -0.8365225708987197] 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012833 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12943
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[39]    training's binary_logloss: 0.121601 valid_1's binary_logloss: 0.131732
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:49&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012323 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12998
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[34]    training's binary_logloss: 0.118977 valid_1's binary_logloss: 0.13905
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008469 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12958
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 82%|████████▏ | 41/50 [01:50&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 82%|████████▏ | 41/50 [01:51&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 82%|████████▏ | 41/50 [01:51&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 82%|████████▏ | 41/50 [01:51&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[34]    training's binary_logloss: 0.120814 valid_1's binary_logloss: 0.136438
 82%|████████▏ | 41/50 [01:51&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 82%|████████▏ | 41/50 [01:51&lt;00:21,  2.40s/trial, best loss: -0.8365225708987197] 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008567 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12947
 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 84%|████████▍ | 42/50 [01:51&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.119106 valid_1's binary_logloss: 0.131122
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011181 seconds.
You can set `force_col_wise=true` to remove the overhead.
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12998
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 194
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 84%|████████▍ | 42/50 [01:52&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[90]    training's binary_logloss: 0.116567 valid_1's binary_logloss: 0.138873
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007625 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12968
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 84%|████████▍ | 42/50 [01:53&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[85]    training's binary_logloss: 0.118801 valid_1's binary_logloss: 0.136111
 84%|████████▍ | 42/50 [01:54&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 84%|████████▍ | 42/50 [01:54&lt;00:18,  2.35s/trial, best loss: -0.8365225708987197] 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008375 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13047
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 210
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 86%|████████▌ | 43/50 [01:54&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.12624  valid_1's binary_logloss: 0.132688
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008360 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13130
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 86%|████████▌ | 43/50 [01:55&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.121959 valid_1's binary_logloss: 0.140097
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012750 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13000
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 86%|████████▌ | 43/50 [01:56&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.123583 valid_1's binary_logloss: 0.137169
 86%|████████▌ | 43/50 [01:57&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 86%|████████▌ | 43/50 [01:57&lt;00:17,  2.52s/trial, best loss: -0.8365225708987197] 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009549 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12902
 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 88%|████████▊ | 44/50 [01:57&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[23]    training's binary_logloss: 0.114805 valid_1's binary_logloss: 0.132779
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007723 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12988
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[18]    training's binary_logloss: 0.11472  valid_1's binary_logloss: 0.140404
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:58&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012523 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12898
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[19]    training's binary_logloss: 0.115511 valid_1's binary_logloss: 0.137588
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 88%|████████▊ | 44/50 [01:59&lt;00:16,  2.70s/trial, best loss: -0.8365225708987197] 90%|█████████ | 45/50 [01:59&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:59&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:59&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:59&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 90%|█████████ | 45/50 [01:59&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008368 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 90%|█████████ | 45/50 [01:59&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12835
 90%|█████████ | 45/50 [01:59&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 90%|█████████ | 45/50 [01:59&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [01:59&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [01:59&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 90%|█████████ | 45/50 [01:59&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 90%|█████████ | 45/50 [01:59&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 90%|█████████ | 45/50 [02:00&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[70]    training's binary_logloss: 0.115612 valid_1's binary_logloss: 0.131625
 90%|█████████ | 45/50 [02:00&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [02:00&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [02:00&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [02:00&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [02:00&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 90%|█████████ | 45/50 [02:00&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007622 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 90%|█████████ | 45/50 [02:00&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12988
 90%|█████████ | 45/50 [02:00&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 90%|█████████ | 45/50 [02:00&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[57]    training's binary_logloss: 0.114417 valid_1's binary_logloss: 0.139373
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007511 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12898
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 90%|█████████ | 45/50 [02:01&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [02:02&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 90%|█████████ | 45/50 [02:02&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 90%|█████████ | 45/50 [02:02&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 90%|█████████ | 45/50 [02:02&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 90%|█████████ | 45/50 [02:02&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[62]    training's binary_logloss: 0.114805 valid_1's binary_logloss: 0.136936
 90%|█████████ | 45/50 [02:02&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 90%|█████████ | 45/50 [02:02&lt;00:12,  2.56s/trial, best loss: -0.8365225708987197] 92%|█████████▏| 46/50 [02:02&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008690 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12943
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[14]    training's binary_logloss: 0.123339 valid_1's binary_logloss: 0.132372
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009379 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12988
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 92%|█████████▏| 46/50 [02:03&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[13]    training's binary_logloss: 0.119633 valid_1's binary_logloss: 0.141193
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008788 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12906
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[13]    training's binary_logloss: 0.12138  valid_1's binary_logloss: 0.137428
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 92%|█████████▏| 46/50 [02:04&lt;00:10,  2.75s/trial, best loss: -0.8365225708987197] 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008990 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12835
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[52]    training's binary_logloss: 0.119292 valid_1's binary_logloss: 0.131268
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:04&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007926 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12988
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[51]    training's binary_logloss: 0.11486  valid_1's binary_logloss: 0.139012
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007646 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12898
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 94%|█████████▍| 47/50 [02:05&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 94%|█████████▍| 47/50 [02:06&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 94%|█████████▍| 47/50 [02:06&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 94%|█████████▍| 47/50 [02:06&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[45]    training's binary_logloss: 0.118593 valid_1's binary_logloss: 0.13685
 94%|█████████▍| 47/50 [02:06&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 94%|█████████▍| 47/50 [02:06&lt;00:07,  2.52s/trial, best loss: -0.8365225708987197] 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009040 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12902
 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197
 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 96%|█████████▌| 48/50 [02:06&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.123923 valid_1's binary_logloss: 0.132366
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009230 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12988
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 96%|█████████▌| 48/50 [02:07&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.119581 valid_1's binary_logloss: 0.140569
 96%|█████████▌| 48/50 [02:08&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:08&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:08&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:08&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:09&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 96%|█████████▌| 48/50 [02:09&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010048 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 96%|█████████▌| 48/50 [02:09&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12898
 96%|█████████▌| 48/50 [02:09&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192
 96%|█████████▌| 48/50 [02:09&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:09&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 96%|█████████▌| 48/50 [02:09&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 96%|█████████▌| 48/50 [02:09&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 96%|█████████▌| 48/50 [02:09&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 96%|█████████▌| 48/50 [02:09&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  Did not meet early stopping. Best iteration is:
[100]   training's binary_logloss: 0.121237 valid_1's binary_logloss: 0.137601
 96%|█████████▌| 48/50 [02:10&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 96%|█████████▌| 48/50 [02:10&lt;00:04,  2.25s/trial, best loss: -0.8365225708987197] 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1647, number of negative: 38897
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010404 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12947
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040623 -&gt; initscore=-3.161962
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.161962
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[26]    training's binary_logloss: 0.118459 valid_1's binary_logloss: 0.131829
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:10&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1572, number of negative: 38972
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010339 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 13059
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038773 -&gt; initscore=-3.210495
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.210495
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[29]    training's binary_logloss: 0.11189  valid_1's binary_logloss: 0.139652
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of positive: 1619, number of negative: 38925
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010263 seconds.
You can set `force_col_wise=true` to remove the overhead.
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Total Bins 12996
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039932 -&gt; initscore=-3.179828
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Info] Start training from score -3.179828
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  Training until validation scores don't improve for 30 rounds
 98%|█████████▊| 49/50 [02:11&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  Early stopping, best iteration is:
[26]    training's binary_logloss: 0.115607 valid_1's binary_logloss: 0.137612
 98%|█████████▊| 49/50 [02:12&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]                                                                                  [LightGBM] [Warning] Unknown parameter: eval_metric
 98%|█████████▊| 49/50 [02:12&lt;00:02,  2.66s/trial, best loss: -0.8365225708987197]100%|██████████| 50/50 [02:12&lt;00:00,  2.55s/trial, best loss: -0.8365225708987197]100%|██████████| 50/50 [02:12&lt;00:00,  2.65s/trial, best loss: -0.8365225708987197]
{'learning_rate': 0.028291797782733982, 'max_depth': 154.0, 'min_child_samples': 64.0, 'num_leaves': 32.0, 'subsample': 0.9145203867432408}</code></pre>
</div>
</div>
</section>
<section id="재학습" class="level3">
<h3 class="anchored" data-anchor-id="재학습">재학습</h3>
<div id="305e505b" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>lgbm_clf <span class="op">=</span> LGBMClassifier(n_estimators<span class="op">=</span><span class="dv">500</span>, </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>                          num_leaves<span class="op">=</span><span class="bu">int</span>(best[<span class="st">'num_leaves'</span>]),</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>                          max_depth<span class="op">=</span><span class="bu">int</span>(best[<span class="st">'max_depth'</span>]),</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>                          min_child_samples<span class="op">=</span><span class="bu">int</span>(best[<span class="st">'min_child_samples'</span>]),</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>                          subsample<span class="op">=</span><span class="bu">round</span>(best[<span class="st">'subsample'</span>], <span class="dv">5</span>),</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>                          learning_rate<span class="op">=</span><span class="bu">round</span>(best[<span class="st">'learning_rate'</span>], <span class="dv">5</span>),</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>                          early_stopping_rounds<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>                          eval_metric<span class="op">=</span><span class="st">'auc'</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>eval_set <span class="op">=</span> [(X_tr, y_tr), (X_val, y_val)]</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>lgbm_clf.fit(X_tr, y_tr, eval_set<span class="op">=</span>eval_set)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>lgbm_roc_score <span class="op">=</span> roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, <span class="dv">1</span>])</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>lgbm_roc_score<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100
[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Info] Number of positive: 1694, number of negative: 40877
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012601 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 13334
[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 209
[LightGBM] [Warning] Unknown parameter: eval_metric
[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039792 -&gt; initscore=-3.183475
[LightGBM] [Info] Start training from score -3.183475
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[131]   training's binary_logloss: 0.118645 valid_1's binary_logloss: 0.137022
[LightGBM] [Warning] Unknown parameter: eval_metric
0.839</code></pre>
</div>
</div>
</section>
</section>
<section id="제출" class="level2">
<h2 class="anchored" data-anchor-id="제출">제출</h2>
<div id="4640afe3" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> lgbm_clf.predict(test_df)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>submit <span class="op">=</span> pd.read_csv(<span class="st">'_data/santander/sample_submission.csv'</span>, encoding<span class="op">=</span><span class="st">'latin-1'</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>submit[<span class="st">'TARGET'</span>] <span class="op">=</span> target</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>submit.to_csv(<span class="st">'_data/santander/submission.csv'</span>, encoding<span class="op">=</span><span class="st">'latin-1'</span>, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[LightGBM] [Warning] Unknown parameter: eval_metric</code></pre>
</div>
</div>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> 맨 위로</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "복사완료!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "복사완료!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/cryscham123\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="cryscham123/cryscham123.github.io" data-repo-id="R_kgDONGE9Rw" data-category="Announcements" data-category-id="DIC_kwDONGE9R84CjtIQ" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" data-loading="lazy" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="light">
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/02.html" class="pagination-link" aria-label="분류 - 앙상블">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">분류 - 앙상블</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../../../../posts/03_archives/completed_project/adp_실기/notes/machine_learning/04.html" class="pagination-link" aria-label="분류 - 신용 카드 사기 검출">
        <span class="nav-page-text">분류 - 신용 카드 사기 검출</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2024 김형훈</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




<script src="../../../../../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>